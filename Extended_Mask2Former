digraph {
	graph [size="1438.8,1438.8"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	6077455856 [label="
 ()" fillcolor=darkolivegreen1]
	6077530848 -> 6076882816 [dir=none]
	6076882816 [label="self
 (1, 100, 101)" fillcolor=orange]
	6077530848 [label="MeanBackward0
------------------------------
self          : [saved tensor]
self_sym_sizes:  (1, 100, 101)"]
	6077532000 -> 6077530848
	6077532000 [label="ViewBackward0
--------------------------
self_sym_sizes: (100, 101)"]
	6077531328 -> 6077532000
	6077531328 -> 5126924272 [dir=none]
	5126924272 [label="mat1
 (100, 256)" fillcolor=orange]
	6077531328 -> 6076082000 [dir=none]
	6076082000 [label="mat2
 (256, 101)" fillcolor=orange]
	6077531328 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (100, 256)
mat1_sym_strides:       (256, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (256, 101)
mat2_sym_strides:       (1, 256)"]
	6077531376 -> 6077531328
	6077456256 [label="
 (101)" fillcolor=lightblue]
	6077456256 -> 6077531376
	6077531376 [label=AccumulateGrad]
	6077531136 -> 6077531328
	6077531136 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 100, 256)"]
	6077531808 -> 6077531136
	6077531808 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	6077532336 -> 6077531808
	6077532336 -> 6077456576 [dir=none]
	6077456576 [label="bias
 (256)" fillcolor=orange]
	6077532336 -> 6076883776 [dir=none]
	6076883776 [label="input
 (100, 1, 256)" fillcolor=orange]
	6077532336 -> 6075797872 [dir=none]
	6075797872 [label="result1
 (100, 1, 1)" fillcolor=orange]
	6077532336 -> 6072800800 [dir=none]
	6072800800 [label="result2
 (100, 1, 1)" fillcolor=orange]
	6077532336 -> 6077456736 [dir=none]
	6077456736 [label="weight
 (256)" fillcolor=orange]
	6077532336 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	6077532624 -> 6077532336
	6077532624 [label="AddBackward0
------------
alpha: 1"]
	6077533200 -> 6077532624
	6077533200 -> 5126830048 [dir=none]
	5126830048 [label="bias
 (256)" fillcolor=orange]
	6077533200 -> 6076882656 [dir=none]
	6076882656 [label="input
 (100, 1, 256)" fillcolor=orange]
	6077533200 -> 6072799600 [dir=none]
	6072799600 [label="result1
 (100, 1, 1)" fillcolor=orange]
	6077533200 -> 6060747216 [dir=none]
	6060747216 [label="result2
 (100, 1, 1)" fillcolor=orange]
	6077533200 -> 5124387152 [dir=none]
	5124387152 [label="weight
 (256)" fillcolor=orange]
	6077533200 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	6077533248 -> 6077533200
	6077533248 [label="AddBackward0
------------
alpha: 1"]
	6077533728 -> 6077533248
	6077533728 -> 6077463776 [dir=none]
	6077463776 [label="bias
 (256)" fillcolor=orange]
	6077533728 -> 6076883936 [dir=none]
	6076883936 [label="input
 (100, 1, 256)" fillcolor=orange]
	6077533728 -> 6076358208 [dir=none]
	6076358208 [label="result1
 (100, 1, 1)" fillcolor=orange]
	6077533728 -> 6076355728 [dir=none]
	6076355728 [label="result2
 (100, 1, 1)" fillcolor=orange]
	6077533728 -> 6077462816 [dir=none]
	6077462816 [label="weight
 (256)" fillcolor=orange]
	6077533728 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	6077534160 -> 6077533728
	6077534160 [label="AddBackward0
------------
alpha: 1"]
	6077534352 -> 6077534160
	6077534352 [label="RepeatBackward0
-----------------------------
repeats       :     (1, 1, 1)
self_sym_sizes: (100, 1, 256)"]
	6077535120 -> 6077534352
	6077535120 [label="UnsqueezeBackward0
------------------
dim: 1"]
	6077535072 -> 6077535120
	6076073600 [label="
 (100, 256)" fillcolor=lightblue]
	6076073600 -> 6077535072
	6077535072 [label=AccumulateGrad]
	6077534400 -> 6077534160
	6077534400 [label="ViewBackward0
--------------------------
self_sym_sizes: (100, 256)"]
	6077535264 -> 6077534400
	6077535264 -> 6076884736 [dir=none]
	6076884736 [label="mat1
 (100, 256)" fillcolor=orange]
	6077535264 -> 6076358848 [dir=none]
	6076358848 [label="mat2
 (256, 256)" fillcolor=orange]
	6077535264 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (100, 256)
mat1_sym_strides:       (256, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (256, 256)
mat2_sym_strides:       (1, 256)"]
	6077534880 -> 6077535264
	6077464016 [label="
 (256)" fillcolor=lightblue]
	6077464016 -> 6077534880
	6077534880 [label=AccumulateGrad]
	6077534832 -> 6077535264
	6077534832 [label="ViewBackward0
----------------------------
self_sym_sizes: (100, 8, 32)"]
	6077535216 -> 6077534832
	6077535216 [label=CloneBackward0]
	6077538912 -> 6077535216
	6077538912 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	6077536128 -> 6077538912
	6077536128 -> 6076885616 [dir=none]
	6076885616 [label="mat2
 (8, 90000, 32)" fillcolor=orange]
	6077536128 -> 6076885936 [dir=none]
	6076885936 [label="self
 (8, 100, 90000)" fillcolor=orange]
	6077536128 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	6077536080 -> 6077536128
	6077536080 -> 6172470912 [dir=none]
	6172470912 [label="result
 (8, 100, 90000)" fillcolor=orange]
	6077536080 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	6077536512 -> 6077536080
	6077536512 -> 6076885056 [dir=none]
	6076885056 [label="batch1
 (8, 100, 32)" fillcolor=orange]
	6077536512 -> 6076885696 [dir=none]
	6076885696 [label="batch2
 (8, 32, 90000)" fillcolor=orange]
	6077536512 [label="BaddbmmBackward0
----------------------
alpha :              1
batch1: [saved tensor]
batch2: [saved tensor]
beta  :              1"]
	6077536848 -> 6077536512
	6077536848 -> 6172470592 [dir=none]
	6172470592 [label="other
 ()" fillcolor=orange]
	6077536848 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6077537376 -> 6077536848
	6077537376 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	6077540352 -> 6077537376
	6077540352 [label="ViewBackward0
-----------------------------
self_sym_sizes: (100, 1, 256)"]
	6077537568 -> 6077540352
	6077537568 [label="ViewBackward0
--------------------------
self_sym_sizes: (100, 256)"]
	6077537760 -> 6077537568
	6077537760 -> 6172474032 [dir=none]
	6172474032 [label="mat1
 (100, 256)" fillcolor=orange]
	6077537760 -> 6172474912 [dir=none]
	6172474912 [label="mat2
 (256, 256)" fillcolor=orange]
	6077537760 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (100, 256)
mat1_sym_strides:       (256, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (256, 256)
mat2_sym_strides:       (1, 256)"]
	6077537712 -> 6077537760
	6077537712 [label="SplitBackward0
----------------------
dim           :      0
self_sym_sizes: (768,)
split_size    :    256"]
	6077538528 -> 6077537712
	5117147744 [label="
 (768)" fillcolor=lightblue]
	5117147744 -> 6077538528
	6077538528 [label=AccumulateGrad]
	6077538144 -> 6077537760
	6077538144 [label="ViewBackward0
-----------------------------
self_sym_sizes: (100, 1, 256)"]
	6077538240 -> 6077538144
	6077538240 [label="AddBackward0
------------
alpha: 1"]
	6077534352 -> 6077538240
	6077538624 -> 6077538240
	6077538624 [label="RepeatBackward0
-----------------------------
repeats       :     (1, 1, 1)
self_sym_sizes: (100, 1, 256)"]
	6077542128 -> 6077538624
	6077542128 [label="UnsqueezeBackward0
------------------
dim: 1"]
	6077539152 -> 6077542128
	6076087920 [label="
 (100, 256)" fillcolor=lightblue]
	6076087920 -> 6077539152
	6077539152 [label=AccumulateGrad]
	6077536896 -> 6077537760
	6077536896 [label=TBackward0]
	6077538672 -> 6077536896
	6077538672 [label="SplitBackward0
--------------------------
dim           :          0
self_sym_sizes: (768, 256)
split_size    :        256"]
	6077539104 -> 6077538672
	6076357568 [label="
 (768, 256)" fillcolor=lightblue]
	6076357568 -> 6077539104
	6077539104 [label=AccumulateGrad]
	6077536608 -> 6077536512
	6077536608 [label="TransposeBackward0
--------------------------
dim0: 18446744073709551614
dim1: 18446744073709551615"]
	6077538096 -> 6077536608
	6077538096 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	6077537856 -> 6077538096
	6077537856 [label="ViewBackward0
-------------------------------
self_sym_sizes: (90000, 1, 256)"]
	6077539344 -> 6077537856
	6077539344 [label="AddBackward0
------------
alpha: 1"]
	6077539584 -> 6077539344
	6077539584 [label="UnsafeViewBackward0
----------------------------
self_sym_sizes: (90000, 256)"]
	6077539776 -> 6077539584
	6077539776 -> 6172463952 [dir=none]
	6172463952 [label="mat2
 (256, 256)" fillcolor=orange]
	6077539776 -> 6172463472 [dir=none]
	6172463472 [label="self
 (90000, 256)" fillcolor=orange]
	6077539776 [label="MmBackward0
--------------------------------
mat2            : [saved tensor]
mat2_sym_sizes  :     (256, 256)
mat2_sym_strides:       (1, 256)
self            : [saved tensor]
self_sym_sizes  :   (90000, 256)
self_sym_strides:     (1, 90000)"]
	6077539728 -> 6077539776
	6077539728 [label="ReshapeAliasBackward0
-------------------------------
self_sym_sizes: (90000, 1, 256)"]
	6077540160 -> 6077539728
	6077540160 [label="AddBackward0
------------
alpha: 1"]
	6077540112 -> 6077540160
	6077540112 [label="PermuteBackward0
----------------
dims: (2, 0, 1)"]
	6077540640 -> 6077540112
	6077540640 [label="AddBackward0
------------
alpha: 1"]
	6077541024 -> 6077540640
	6077541024 [label="ReshapeAliasBackward0
----------------------------------
self_sym_sizes: (1, 256, 300, 300)"]
	6077540832 -> 6077541024
	6077540832 [label="AddBackward0
------------
alpha: 1"]
	6077540976 -> 6077540832
	6077540976 [label="UpsampleNearest2DBackward0
----------------------------------
output_size   :         (300, 300)
scales_h      :                2.0
scales_w      :                2.0
self_sym_sizes: (1, 256, 150, 150)"]
	6077541360 -> 6077540976
	6077541360 [label="AddBackward0
------------
alpha: 1"]
	6077541840 -> 6077541360
	6077541840 [label="PixelShuffleBackward0
---------------------
upscale_factor: 2"]
	6077542272 -> 6077541840
	6077542272 -> 6076881376 [dir=none]
	6076881376 [label="input
 (1, 256, 75, 75)" fillcolor=orange]
	6077542272 -> 6077464096 [dir=none]
	6077464096 [label="weight
 (1024, 256, 3, 3)" fillcolor=orange]
	6077542272 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (1024,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6077542224 -> 6077542272
	6077542224 -> 6172461472 [dir=none]
	6172461472 [label="result
 (1, 256, 75, 75)" fillcolor=orange]
	6077542224 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	6077542656 -> 6077542224
	6077542656 -> 6076882736 [dir=none]
	6076882736 [label="input
 (1, 256, 75, 75)" fillcolor=orange]
	6077542656 -> 6172461392 [dir=none]
	6172461392 [label="result1
 (256)" fillcolor=orange]
	6077542656 -> 6172461632 [dir=none]
	6172461632 [label="result2
 (256)" fillcolor=orange]
	6077542656 -> 6077460016 [dir=none]
	6077460016 [label="running_mean
 (256)" fillcolor=orange]
	6077542656 -> 6077453216 [dir=none]
	6077453216 [label="running_var
 (256)" fillcolor=orange]
	6077542656 -> 6077453696 [dir=none]
	6077453696 [label="weight
 (256)" fillcolor=orange]
	6077542656 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6077542992 -> 6077542656
	6077542992 -> 6076887296 [dir=none]
	6076887296 [label="input
 (1, 256, 75, 75)" fillcolor=orange]
	6077542992 -> 6077455216 [dir=none]
	6077455216 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	6077542992 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (256,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6077543136 -> 6077542992
	6077543136 -> 6172460432 [dir=none]
	6172460432 [label="result
 (1, 256, 75, 75)" fillcolor=orange]
	6077543136 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	6077543856 -> 6077543136
	6077543856 -> 6076875936 [dir=none]
	6076875936 [label="input
 (1, 256, 75, 75)" fillcolor=orange]
	6077543856 -> 6172460272 [dir=none]
	6172460272 [label="result1
 (256)" fillcolor=orange]
	6077543856 -> 6172460912 [dir=none]
	6172460912 [label="result2
 (256)" fillcolor=orange]
	6077543856 -> 6077452256 [dir=none]
	6077452256 [label="running_mean
 (256)" fillcolor=orange]
	6077543856 -> 6077461936 [dir=none]
	6077461936 [label="running_var
 (256)" fillcolor=orange]
	6077543856 -> 6077449136 [dir=none]
	6077449136 [label="weight
 (256)" fillcolor=orange]
	6077543856 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6077544144 -> 6077543856
	6077544144 -> 6076876736 [dir=none]
	6076876736 [label="input
 (1, 256, 75, 75)" fillcolor=orange]
	6077544144 -> 6077451216 [dir=none]
	6077451216 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	6077544144 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (256,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6077544624 -> 6077544144
	6077544624 -> 6172460752 [dir=none]
	6172460752 [label="result
 (1, 256, 75, 75)" fillcolor=orange]
	6077544624 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	6077544864 -> 6077544624
	6077544864 -> 6076877376 [dir=none]
	6076877376 [label="input
 (1, 256, 75, 75)" fillcolor=orange]
	6077544864 -> 6172459472 [dir=none]
	6172459472 [label="result1
 (256)" fillcolor=orange]
	6077544864 -> 6172459872 [dir=none]
	6172459872 [label="result2
 (256)" fillcolor=orange]
	6077544864 -> 6077452416 [dir=none]
	6077452416 [label="running_mean
 (256)" fillcolor=orange]
	6077544864 -> 6077459296 [dir=none]
	6077459296 [label="running_var
 (256)" fillcolor=orange]
	6077544864 -> 6077459696 [dir=none]
	6077459696 [label="weight
 (256)" fillcolor=orange]
	6077544864 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6077545392 -> 6077544864
	6077545392 -> 6076880176 [dir=none]
	6076880176 [label="input
 (1, 256, 75, 75)" fillcolor=orange]
	6077545392 -> 6077449616 [dir=none]
	6077449616 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	6077545392 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (256,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6077545536 -> 6077545392
	6077545536 [label="AddBackward0
------------
alpha: 1"]
	6077546112 -> 6077545536
	6077546112 -> 6077044176 [dir=none]
	6077044176 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6077546112 -> 6077459936 [dir=none]
	6077459936 [label="weight
 (256, 80, 1, 1)" fillcolor=orange]
	6077546112 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (256,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6077546352 -> 6077546112
	6077546352 [label="AddBackward0
------------
alpha: 1"]
	6078660816 -> 6077546352
	6078660816 -> 6077041776 [dir=none]
	6077041776 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6078660816 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078660912 -> 6078660816
	6078660912 -> 6172266464 [dir=none]
	6172266464 [label="other
 ()" fillcolor=orange]
	6078660912 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078661104 -> 6078660912
	6078661104 -> 6077045216 [dir=none]
	6077045216 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6078661104 -> 6172275984 [dir=none]
	6172275984 [label="result1
 (80)" fillcolor=orange]
	6078661104 -> 6172263264 [dir=none]
	6172263264 [label="result2
 (80)" fillcolor=orange]
	6078661104 -> 6073088608 [dir=none]
	6073088608 [label="running_mean
 (80)" fillcolor=orange]
	6078661104 -> 6073088928 [dir=none]
	6073088928 [label="running_var
 (80)" fillcolor=orange]
	6078661104 -> 6073088768 [dir=none]
	6073088768 [label="weight
 (80)" fillcolor=orange]
	6078661104 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078661056 -> 6078661104
	6078661056 -> 6077045376 [dir=none]
	6077045376 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6078661056 -> 6073088688 [dir=none]
	6073088688 [label="weight
 (80, 480, 1, 1)" fillcolor=orange]
	6078661056 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078661872 -> 6078661056
	6078661872 -> 6077048576 [dir=none]
	6077048576 [label="other
 (1, 480, 75, 75)" fillcolor=orange]
	6078661872 -> 6077047776 [dir=none]
	6077047776 [label="self
 (1, 480, 1, 1)" fillcolor=orange]
	6078661872 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6078662064 -> 6078661872
	6078662064 -> 6172265024 [dir=none]
	6172265024 [label="result
 (1, 480, 1, 1)" fillcolor=orange]
	6078662064 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6078665472 -> 6078662064
	6078665472 -> 6077046816 [dir=none]
	6077046816 [label="input
 (1, 20, 1, 1)" fillcolor=orange]
	6078665472 -> 6073088448 [dir=none]
	6073088448 [label="weight
 (480, 20, 1, 1)" fillcolor=orange]
	6078665472 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (480,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079035456 -> 6078665472
	6079035456 [label=SwishImplementationBackward]
	6078662832 -> 6079035456
	6078662832 -> 6077049376 [dir=none]
	6077049376 [label="input
 (1, 480, 1, 1)" fillcolor=orange]
	6078662832 -> 6073088128 [dir=none]
	6073088128 [label="weight
 (20, 480, 1, 1)" fillcolor=orange]
	6078662832 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (20,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078662976 -> 6078662832
	6078662976 -> 6077048576 [dir=none]
	6077048576 [label="self
 (1, 480, 75, 75)" fillcolor=orange]
	6078662976 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 480, 75, 75)"]
	6079035232 -> 6078662976
	6079035232 [label=SwishImplementationBackward]
	6078664080 -> 6079035232
	6078664080 -> 6077052736 [dir=none]
	6077052736 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6078664080 -> 6172271664 [dir=none]
	6172271664 [label="result1
 (480)" fillcolor=orange]
	6078664080 -> 6172264864 [dir=none]
	6172264864 [label="result2
 (480)" fillcolor=orange]
	6078664080 -> 6073085808 [dir=none]
	6073085808 [label="running_mean
 (480)" fillcolor=orange]
	6078664080 -> 6073087648 [dir=none]
	6073087648 [label="running_var
 (480)" fillcolor=orange]
	6078664080 -> 6073087408 [dir=none]
	6073087408 [label="weight
 (480)" fillcolor=orange]
	6078664080 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078664224 -> 6078664080
	6078664224 -> 6077053536 [dir=none]
	6077053536 [label="input
 (1, 480, 79, 79)" fillcolor=orange]
	6078664224 -> 6073087488 [dir=none]
	6073087488 [label="weight
 (480, 1, 5, 5)" fillcolor=orange]
	6078664224 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            480
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078664320 -> 6078664224
	6078664320 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6079035008 -> 6078664320
	6079035008 [label=SwishImplementationBackward]
	6078665280 -> 6079035008
	6078665280 -> 6077052336 [dir=none]
	6077052336 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6078665280 -> 6172273424 [dir=none]
	6172273424 [label="result1
 (480)" fillcolor=orange]
	6078665280 -> 6172263824 [dir=none]
	6172263824 [label="result2
 (480)" fillcolor=orange]
	6078665280 -> 6073086688 [dir=none]
	6073086688 [label="running_mean
 (480)" fillcolor=orange]
	6078665280 -> 6073087008 [dir=none]
	6073087008 [label="running_var
 (480)" fillcolor=orange]
	6078665280 -> 6073086848 [dir=none]
	6073086848 [label="weight
 (480)" fillcolor=orange]
	6078665280 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078668592 -> 6078665280
	6078668592 -> 6077039056 [dir=none]
	6077039056 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6078668592 -> 6073086768 [dir=none]
	6073086768 [label="weight
 (480, 80, 1, 1)" fillcolor=orange]
	6078668592 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078662352 -> 6078668592
	6078662352 [label="AddBackward0
------------
alpha: 1"]
	6078665856 -> 6078662352
	6078665856 -> 6077054896 [dir=none]
	6077054896 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6078665856 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078666192 -> 6078665856
	6078666192 -> 6172266224 [dir=none]
	6172266224 [label="other
 ()" fillcolor=orange]
	6078666192 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078666384 -> 6078666192
	6078666384 -> 6077042256 [dir=none]
	6077042256 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6078666384 -> 6172264544 [dir=none]
	6172264544 [label="result1
 (80)" fillcolor=orange]
	6078666384 -> 6172266064 [dir=none]
	6172266064 [label="result2
 (80)" fillcolor=orange]
	6078666384 -> 6073086048 [dir=none]
	6073086048 [label="running_mean
 (80)" fillcolor=orange]
	6078666384 -> 6073086368 [dir=none]
	6073086368 [label="running_var
 (80)" fillcolor=orange]
	6078666384 -> 6073086208 [dir=none]
	6073086208 [label="weight
 (80)" fillcolor=orange]
	6078666384 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078666864 -> 6078666384
	6078666864 -> 6077044656 [dir=none]
	6077044656 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6078666864 -> 6073086128 [dir=none]
	6073086128 [label="weight
 (80, 480, 1, 1)" fillcolor=orange]
	6078666864 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078667056 -> 6078666864
	6078667056 -> 6077053296 [dir=none]
	6077053296 [label="other
 (1, 480, 75, 75)" fillcolor=orange]
	6078667056 -> 6077050656 [dir=none]
	6077050656 [label="self
 (1, 480, 1, 1)" fillcolor=orange]
	6078667056 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6078667632 -> 6078667056
	6078667632 -> 6172277424 [dir=none]
	6172277424 [label="result
 (1, 480, 1, 1)" fillcolor=orange]
	6078667632 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6078667584 -> 6078667632
	6078667584 -> 6077048416 [dir=none]
	6077048416 [label="input
 (1, 20, 1, 1)" fillcolor=orange]
	6078667584 -> 6073085888 [dir=none]
	6073085888 [label="weight
 (480, 20, 1, 1)" fillcolor=orange]
	6078667584 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (480,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079034784 -> 6078667584
	6079034784 [label=SwishImplementationBackward]
	6078668304 -> 6079034784
	6078668304 -> 6077042016 [dir=none]
	6077042016 [label="input
 (1, 480, 1, 1)" fillcolor=orange]
	6078668304 -> 6073085648 [dir=none]
	6073085648 [label="weight
 (20, 480, 1, 1)" fillcolor=orange]
	6078668304 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (20,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078671616 -> 6078668304
	6078671616 -> 6077053296 [dir=none]
	6077053296 [label="self
 (1, 480, 75, 75)" fillcolor=orange]
	6078671616 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 480, 75, 75)"]
	6079034560 -> 6078671616
	6079034560 [label=SwishImplementationBackward]
	6078668880 -> 6079034560
	6078668880 -> 6077045936 [dir=none]
	6077045936 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6078668880 -> 6172275584 [dir=none]
	6172275584 [label="result1
 (480)" fillcolor=orange]
	6078668880 -> 6172277264 [dir=none]
	6172277264 [label="result2
 (480)" fillcolor=orange]
	6078668880 -> 6073083328 [dir=none]
	6073083328 [label="running_mean
 (480)" fillcolor=orange]
	6078668880 -> 6073085168 [dir=none]
	6073085168 [label="running_var
 (480)" fillcolor=orange]
	6078668880 -> 6073084928 [dir=none]
	6073084928 [label="weight
 (480)" fillcolor=orange]
	6078668880 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078669120 -> 6078668880
	6078669120 -> 6077049056 [dir=none]
	6077049056 [label="input
 (1, 480, 79, 79)" fillcolor=orange]
	6078669120 -> 6073085008 [dir=none]
	6073085008 [label="weight
 (480, 1, 5, 5)" fillcolor=orange]
	6078669120 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            480
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078669840 -> 6078669120
	6078669840 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6079034336 -> 6078669840
	6079034336 [label=SwishImplementationBackward]
	6078670080 -> 6079034336
	6078670080 -> 6077047456 [dir=none]
	6077047456 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6078670080 -> 6172272224 [dir=none]
	6172272224 [label="result1
 (480)" fillcolor=orange]
	6078670080 -> 6172273184 [dir=none]
	6172273184 [label="result2
 (480)" fillcolor=orange]
	6078670080 -> 6073084208 [dir=none]
	6073084208 [label="running_mean
 (480)" fillcolor=orange]
	6078670080 -> 6073084528 [dir=none]
	6073084528 [label="running_var
 (480)" fillcolor=orange]
	6078670080 -> 6073084368 [dir=none]
	6073084368 [label="weight
 (480)" fillcolor=orange]
	6078670080 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078670368 -> 6078670080
	6078670368 -> 6077040736 [dir=none]
	6077040736 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6078670368 -> 6073084288 [dir=none]
	6073084288 [label="weight
 (480, 80, 1, 1)" fillcolor=orange]
	6078670368 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078665952 -> 6078670368
	6078665952 [label="AddBackward0
------------
alpha: 1"]
	6078671136 -> 6078665952
	6078671136 -> 6077040256 [dir=none]
	6077040256 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6078671136 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078671328 -> 6078671136
	6078671328 -> 6172270704 [dir=none]
	6172270704 [label="other
 ()" fillcolor=orange]
	6078671328 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078673056 -> 6078671328
	6078673056 -> 6077041216 [dir=none]
	6077041216 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6078673056 -> 6172269744 [dir=none]
	6172269744 [label="result1
 (80)" fillcolor=orange]
	6078673056 -> 6172270064 [dir=none]
	6172270064 [label="result2
 (80)" fillcolor=orange]
	6078673056 -> 6073083568 [dir=none]
	6073083568 [label="running_mean
 (80)" fillcolor=orange]
	6078673056 -> 6073083888 [dir=none]
	6073083888 [label="running_var
 (80)" fillcolor=orange]
	6078673056 -> 6073083728 [dir=none]
	6073083728 [label="weight
 (80)" fillcolor=orange]
	6078673056 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078671856 -> 6078673056
	6078671856 -> 6077044416 [dir=none]
	6077044416 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6078671856 -> 6073083648 [dir=none]
	6073083648 [label="weight
 (80, 480, 1, 1)" fillcolor=orange]
	6078671856 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078672000 -> 6078671856
	6078672000 -> 6077052096 [dir=none]
	6077052096 [label="other
 (1, 480, 75, 75)" fillcolor=orange]
	6078672000 -> 6077047136 [dir=none]
	6077047136 [label="self
 (1, 480, 1, 1)" fillcolor=orange]
	6078672000 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6078672336 -> 6078672000
	6078672336 -> 6172268144 [dir=none]
	6172268144 [label="result
 (1, 480, 1, 1)" fillcolor=orange]
	6078672336 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6078672624 -> 6078672336
	6078672624 -> 6077046256 [dir=none]
	6077046256 [label="input
 (1, 20, 1, 1)" fillcolor=orange]
	6078672624 -> 6073083408 [dir=none]
	6073083408 [label="weight
 (480, 20, 1, 1)" fillcolor=orange]
	6078672624 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (480,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079034112 -> 6078672624
	6079034112 [label=SwishImplementationBackward]
	6078673584 -> 6079034112
	6078673584 -> 6077046576 [dir=none]
	6077046576 [label="input
 (1, 480, 1, 1)" fillcolor=orange]
	6078673584 -> 6073083168 [dir=none]
	6073083168 [label="weight
 (20, 480, 1, 1)" fillcolor=orange]
	6078673584 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (20,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078673824 -> 6078673584
	6078673824 -> 6077052096 [dir=none]
	6077052096 [label="self
 (1, 480, 75, 75)" fillcolor=orange]
	6078673824 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 480, 75, 75)"]
	6079033888 -> 6078673824
	6079033888 [label=SwishImplementationBackward]
	6078674352 -> 6079033888
	6078674352 -> 6077334048 [dir=none]
	6077334048 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6078674352 -> 6172264384 [dir=none]
	6172264384 [label="result1
 (480)" fillcolor=orange]
	6078674352 -> 6172267984 [dir=none]
	6172267984 [label="result2
 (480)" fillcolor=orange]
	6078674352 -> 6073080848 [dir=none]
	6073080848 [label="running_mean
 (480)" fillcolor=orange]
	6078674352 -> 6073082688 [dir=none]
	6073082688 [label="running_var
 (480)" fillcolor=orange]
	6078674352 -> 6073082448 [dir=none]
	6073082448 [label="weight
 (480)" fillcolor=orange]
	6078674352 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078676080 -> 6078674352
	6078676080 -> 6077334368 [dir=none]
	6077334368 [label="input
 (1, 480, 79, 79)" fillcolor=orange]
	6078676080 -> 6073082528 [dir=none]
	6073082528 [label="weight
 (480, 1, 5, 5)" fillcolor=orange]
	6078676080 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            480
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078674976 -> 6078676080
	6078674976 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6079033664 -> 6078674976
	6079033664 [label=SwishImplementationBackward]
	6078675264 -> 6079033664
	6078675264 -> 6077335488 [dir=none]
	6077335488 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6078675264 -> 6172278384 [dir=none]
	6172278384 [label="result1
 (480)" fillcolor=orange]
	6078675264 -> 6172278704 [dir=none]
	6172278704 [label="result2
 (480)" fillcolor=orange]
	6078675264 -> 6073081728 [dir=none]
	6073081728 [label="running_mean
 (480)" fillcolor=orange]
	6078675264 -> 6073082048 [dir=none]
	6073082048 [label="running_var
 (480)" fillcolor=orange]
	6078675264 -> 6073081888 [dir=none]
	6073081888 [label="weight
 (480)" fillcolor=orange]
	6078675264 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078675600 -> 6078675264
	6078675600 -> 6077334688 [dir=none]
	6077334688 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6078675600 -> 6073081808 [dir=none]
	6073081808 [label="weight
 (480, 80, 1, 1)" fillcolor=orange]
	6078675600 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078670896 -> 6078675600
	6078670896 [label="AddBackward0
------------
alpha: 1"]
	6078676320 -> 6078670896
	6078676320 -> 6077334528 [dir=none]
	6077334528 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6078676320 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078676896 -> 6078676320
	6078676896 -> 6172277664 [dir=none]
	6172277664 [label="other
 ()" fillcolor=orange]
	6078676896 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078676848 -> 6078676896
	6078676848 -> 6077334768 [dir=none]
	6077334768 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6078676848 -> 6172277184 [dir=none]
	6172277184 [label="result1
 (80)" fillcolor=orange]
	6078676848 -> 6172277504 [dir=none]
	6172277504 [label="result2
 (80)" fillcolor=orange]
	6078676848 -> 6073081088 [dir=none]
	6073081088 [label="running_mean
 (80)" fillcolor=orange]
	6078676848 -> 6073081408 [dir=none]
	6073081408 [label="running_var
 (80)" fillcolor=orange]
	6078676848 -> 6073081248 [dir=none]
	6073081248 [label="weight
 (80)" fillcolor=orange]
	6078676848 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078676608 -> 6078676848
	6078676608 -> 6077334928 [dir=none]
	6077334928 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6078676608 -> 6073081168 [dir=none]
	6073081168 [label="weight
 (80, 480, 1, 1)" fillcolor=orange]
	6078676608 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078775744 -> 6078676608
	6078775744 -> 6077335648 [dir=none]
	6077335648 [label="other
 (1, 480, 75, 75)" fillcolor=orange]
	6078775744 -> 6077335168 [dir=none]
	6077335168 [label="self
 (1, 480, 1, 1)" fillcolor=orange]
	6078775744 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6078775936 -> 6078775744
	6078775936 -> 6172276544 [dir=none]
	6172276544 [label="result
 (1, 480, 1, 1)" fillcolor=orange]
	6078775936 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6078779248 -> 6078775936
	6078779248 -> 6077335088 [dir=none]
	6077335088 [label="input
 (1, 20, 1, 1)" fillcolor=orange]
	6078779248 -> 6073080928 [dir=none]
	6073080928 [label="weight
 (480, 20, 1, 1)" fillcolor=orange]
	6078779248 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (480,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079033440 -> 6078779248
	6079033440 [label=SwishImplementationBackward]
	6078776512 -> 6079033440
	6078776512 -> 6077335888 [dir=none]
	6077335888 [label="input
 (1, 480, 1, 1)" fillcolor=orange]
	6078776512 -> 6073080688 [dir=none]
	6073080688 [label="weight
 (20, 480, 1, 1)" fillcolor=orange]
	6078776512 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (20,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078776752 -> 6078776512
	6078776752 -> 6077335648 [dir=none]
	6077335648 [label="self
 (1, 480, 75, 75)" fillcolor=orange]
	6078776752 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 480, 75, 75)"]
	6079033216 -> 6078776752
	6079033216 [label=SwishImplementationBackward]
	6078777328 -> 6079033216
	6078777328 -> 6077336288 [dir=none]
	6077336288 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6078777328 -> 6172275664 [dir=none]
	6172275664 [label="result1
 (480)" fillcolor=orange]
	6078777328 -> 6172276384 [dir=none]
	6172276384 [label="result2
 (480)" fillcolor=orange]
	6078777328 -> 6073078368 [dir=none]
	6073078368 [label="running_mean
 (480)" fillcolor=orange]
	6078777328 -> 6073080208 [dir=none]
	6073080208 [label="running_var
 (480)" fillcolor=orange]
	6078777328 -> 6073079968 [dir=none]
	6073079968 [label="weight
 (480)" fillcolor=orange]
	6078777328 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078777760 -> 6078777328
	6078777760 -> 6077336608 [dir=none]
	6077336608 [label="input
 (1, 480, 79, 79)" fillcolor=orange]
	6078777760 -> 6073080048 [dir=none]
	6073080048 [label="weight
 (480, 1, 5, 5)" fillcolor=orange]
	6078777760 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            480
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078778288 -> 6078777760
	6078778288 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6079032992 -> 6078778288
	6079032992 [label=SwishImplementationBackward]
	6078778768 -> 6079032992
	6078778768 -> 6075490096 [dir=none]
	6075490096 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6078778768 -> 6172274944 [dir=none]
	6172274944 [label="result1
 (480)" fillcolor=orange]
	6078778768 -> 6172275104 [dir=none]
	6172275104 [label="result2
 (480)" fillcolor=orange]
	6078778768 -> 6073079248 [dir=none]
	6073079248 [label="running_mean
 (480)" fillcolor=orange]
	6078778768 -> 6073079568 [dir=none]
	6073079568 [label="running_var
 (480)" fillcolor=orange]
	6078778768 -> 6073079408 [dir=none]
	6073079408 [label="weight
 (480)" fillcolor=orange]
	6078778768 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078778720 -> 6078778768
	6078778720 -> 6077336928 [dir=none]
	6077336928 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6078778720 -> 6073079328 [dir=none]
	6073079328 [label="weight
 (480, 80, 1, 1)" fillcolor=orange]
	6078778720 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078676368 -> 6078778720
	6078676368 [label="AddBackward0
------------
alpha: 1"]
	6078779488 -> 6078676368
	6078779488 -> 6077336768 [dir=none]
	6077336768 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6078779488 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078779536 -> 6078779488
	6078779536 -> 6172274304 [dir=none]
	6172274304 [label="other
 ()" fillcolor=orange]
	6078779536 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078779776 -> 6078779536
	6078779776 -> 6077337088 [dir=none]
	6077337088 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6078779776 -> 6172273904 [dir=none]
	6172273904 [label="result1
 (80)" fillcolor=orange]
	6078779776 -> 6172274144 [dir=none]
	6172274144 [label="result2
 (80)" fillcolor=orange]
	6078779776 -> 6073078608 [dir=none]
	6073078608 [label="running_mean
 (80)" fillcolor=orange]
	6078779776 -> 6073078928 [dir=none]
	6073078928 [label="running_var
 (80)" fillcolor=orange]
	6078779776 -> 6073078768 [dir=none]
	6073078768 [label="weight
 (80)" fillcolor=orange]
	6078779776 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078780208 -> 6078779776
	6078780208 -> 6077337168 [dir=none]
	6077337168 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6078780208 -> 6073078688 [dir=none]
	6073078688 [label="weight
 (80, 480, 1, 1)" fillcolor=orange]
	6078780208 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078780448 -> 6078780208
	6078780448 -> 6077337488 [dir=none]
	6077337488 [label="other
 (1, 480, 75, 75)" fillcolor=orange]
	6078780448 -> 6077337408 [dir=none]
	6077337408 [label="self
 (1, 480, 1, 1)" fillcolor=orange]
	6078780448 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6078780736 -> 6078780448
	6078780736 -> 6172273264 [dir=none]
	6172273264 [label="result
 (1, 480, 1, 1)" fillcolor=orange]
	6078780736 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6078781024 -> 6078780736
	6078781024 -> 6077337328 [dir=none]
	6077337328 [label="input
 (1, 20, 1, 1)" fillcolor=orange]
	6078781024 -> 6073078448 [dir=none]
	6073078448 [label="weight
 (480, 20, 1, 1)" fillcolor=orange]
	6078781024 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (480,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079032768 -> 6078781024
	6079032768 [label=SwishImplementationBackward]
	6078781936 -> 6079032768
	6078781936 -> 6077455536 [dir=none]
	6077455536 [label="input
 (1, 480, 1, 1)" fillcolor=orange]
	6078781936 -> 6073078208 [dir=none]
	6073078208 [label="weight
 (20, 480, 1, 1)" fillcolor=orange]
	6078781936 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (20,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078781888 -> 6078781936
	6078781888 -> 6077337488 [dir=none]
	6077337488 [label="self
 (1, 480, 75, 75)" fillcolor=orange]
	6078781888 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 480, 75, 75)"]
	6079032544 -> 6078781888
	6079032544 [label=SwishImplementationBackward]
	6078782656 -> 6079032544
	6078782656 -> 6077338368 [dir=none]
	6077338368 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6078782656 -> 6172272384 [dir=none]
	6172272384 [label="result1
 (480)" fillcolor=orange]
	6078782656 -> 6172273104 [dir=none]
	6172273104 [label="result2
 (480)" fillcolor=orange]
	6078782656 -> 6073075888 [dir=none]
	6073075888 [label="running_mean
 (480)" fillcolor=orange]
	6078782656 -> 6073077728 [dir=none]
	6073077728 [label="running_var
 (480)" fillcolor=orange]
	6078782656 -> 6073077488 [dir=none]
	6073077488 [label="weight
 (480)" fillcolor=orange]
	6078782656 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078782800 -> 6078782656
	6078782800 -> 6077338528 [dir=none]
	6077338528 [label="input
 (1, 480, 79, 79)" fillcolor=orange]
	6078782800 -> 6073077568 [dir=none]
	6073077568 [label="weight
 (480, 1, 5, 5)" fillcolor=orange]
	6078782800 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            480
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078783040 -> 6078782800
	6078783040 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6079032320 -> 6078783040
	6079032320 [label=SwishImplementationBackward]
	6078783520 -> 6079032320
	6078783520 -> 6075483376 [dir=none]
	6075483376 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6078783520 -> 6172271424 [dir=none]
	6172271424 [label="result1
 (480)" fillcolor=orange]
	6078783520 -> 6172271904 [dir=none]
	6172271904 [label="result2
 (480)" fillcolor=orange]
	6078783520 -> 6073076768 [dir=none]
	6073076768 [label="running_mean
 (480)" fillcolor=orange]
	6078783520 -> 6073077088 [dir=none]
	6073077088 [label="running_var
 (480)" fillcolor=orange]
	6078783520 -> 6073076928 [dir=none]
	6073076928 [label="weight
 (480)" fillcolor=orange]
	6078783520 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078783952 -> 6078783520
	6078783952 -> 6077339008 [dir=none]
	6077339008 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6078783952 -> 6073076848 [dir=none]
	6073076848 [label="weight
 (480, 80, 1, 1)" fillcolor=orange]
	6078783952 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078779392 -> 6078783952
	6078779392 [label="AddBackward0
------------
alpha: 1"]
	6078784528 -> 6078779392
	6078784528 -> 6077338848 [dir=none]
	6077338848 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6078784528 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078785056 -> 6078784528
	6078785056 -> 6172270784 [dir=none]
	6172270784 [label="other
 ()" fillcolor=orange]
	6078785056 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078785008 -> 6078785056
	6078785008 -> 6077339168 [dir=none]
	6077339168 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6078785008 -> 6172270384 [dir=none]
	6172270384 [label="result1
 (80)" fillcolor=orange]
	6078785008 -> 6172270624 [dir=none]
	6172270624 [label="result2
 (80)" fillcolor=orange]
	6078785008 -> 6073076128 [dir=none]
	6073076128 [label="running_mean
 (80)" fillcolor=orange]
	6078785008 -> 6073076448 [dir=none]
	6073076448 [label="running_var
 (80)" fillcolor=orange]
	6078785008 -> 6073076288 [dir=none]
	6073076288 [label="weight
 (80)" fillcolor=orange]
	6078785008 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078785200 -> 6078785008
	6078785200 -> 6077339328 [dir=none]
	6077339328 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6078785200 -> 6073076208 [dir=none]
	6073076208 [label="weight
 (80, 480, 1, 1)" fillcolor=orange]
	6078785200 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078785776 -> 6078785200
	6078785776 -> 6077339888 [dir=none]
	6077339888 [label="other
 (1, 480, 75, 75)" fillcolor=orange]
	6078785776 -> 6077339568 [dir=none]
	6077339568 [label="self
 (1, 480, 1, 1)" fillcolor=orange]
	6078785776 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6078785824 -> 6078785776
	6078785824 -> 6172269664 [dir=none]
	6172269664 [label="result
 (1, 480, 1, 1)" fillcolor=orange]
	6078785824 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6078786064 -> 6078785824
	6078786064 -> 6077339488 [dir=none]
	6077339488 [label="input
 (1, 20, 1, 1)" fillcolor=orange]
	6078786064 -> 6073075968 [dir=none]
	6073075968 [label="weight
 (480, 20, 1, 1)" fillcolor=orange]
	6078786064 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (480,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079032096 -> 6078786064
	6079032096 [label=SwishImplementationBackward]
	6078786544 -> 6079032096
	6078786544 -> 6077340208 [dir=none]
	6077340208 [label="input
 (1, 480, 1, 1)" fillcolor=orange]
	6078786544 -> 6073075728 [dir=none]
	6073075728 [label="weight
 (20, 480, 1, 1)" fillcolor=orange]
	6078786544 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (20,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078787216 -> 6078786544
	6078787216 -> 6077339888 [dir=none]
	6077339888 [label="self
 (1, 480, 75, 75)" fillcolor=orange]
	6078787216 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 480, 75, 75)"]
	6079031872 -> 6078787216
	6079031872 [label=SwishImplementationBackward]
	6078787600 -> 6079031872
	6078787600 -> 6077340528 [dir=none]
	6077340528 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6078787600 -> 6172268864 [dir=none]
	6172268864 [label="result1
 (480)" fillcolor=orange]
	6078787600 -> 6172269584 [dir=none]
	6172269584 [label="result2
 (480)" fillcolor=orange]
	6078787600 -> 6072811280 [dir=none]
	6072811280 [label="running_mean
 (480)" fillcolor=orange]
	6078787600 -> 6073075248 [dir=none]
	6073075248 [label="running_var
 (480)" fillcolor=orange]
	6078787600 -> 6073075008 [dir=none]
	6073075008 [label="weight
 (480)" fillcolor=orange]
	6078787600 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078788032 -> 6078787600
	6078788032 -> 6077340848 [dir=none]
	6077340848 [label="input
 (1, 480, 79, 79)" fillcolor=orange]
	6078788032 -> 6073075088 [dir=none]
	6073075088 [label="weight
 (480, 1, 5, 5)" fillcolor=orange]
	6078788032 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            480
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078788272 -> 6078788032
	6078788272 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6079031648 -> 6078788272
	6079031648 [label=SwishImplementationBackward]
	6078788560 -> 6079031648
	6078788560 -> 6077342048 [dir=none]
	6077342048 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6078788560 -> 6172267904 [dir=none]
	6172267904 [label="result1
 (480)" fillcolor=orange]
	6078788560 -> 6172268384 [dir=none]
	6172268384 [label="result2
 (480)" fillcolor=orange]
	6078788560 -> 6073074288 [dir=none]
	6073074288 [label="running_mean
 (480)" fillcolor=orange]
	6078788560 -> 6073074608 [dir=none]
	6073074608 [label="running_var
 (480)" fillcolor=orange]
	6078788560 -> 6073074448 [dir=none]
	6073074448 [label="weight
 (480)" fillcolor=orange]
	6078788560 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078788848 -> 6078788560
	6078788848 -> 6077341168 [dir=none]
	6077341168 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6078788848 -> 6073074368 [dir=none]
	6073074368 [label="weight
 (480, 80, 1, 1)" fillcolor=orange]
	6078788848 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078784048 -> 6078788848
	6078784048 -> 6077341328 [dir=none]
	6077341328 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6078784048 -> 6172267664 [dir=none]
	6172267664 [label="result1
 (80)" fillcolor=orange]
	6078784048 -> 6172267264 [dir=none]
	6172267264 [label="result2
 (80)" fillcolor=orange]
	6078784048 -> 6073073728 [dir=none]
	6073073728 [label="running_mean
 (80)" fillcolor=orange]
	6078784048 -> 6073074048 [dir=none]
	6073074048 [label="running_var
 (80)" fillcolor=orange]
	6078784048 -> 6073073888 [dir=none]
	6073073888 [label="weight
 (80)" fillcolor=orange]
	6078784048 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078789712 -> 6078784048
	6078789712 -> 6077341488 [dir=none]
	6077341488 [label="input
 (1, 288, 75, 75)" fillcolor=orange]
	6078789712 -> 6073073808 [dir=none]
	6073073808 [label="weight
 (80, 288, 1, 1)" fillcolor=orange]
	6078789712 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078790048 -> 6078789712
	6078790048 -> 6077342368 [dir=none]
	6077342368 [label="other
 (1, 288, 75, 75)" fillcolor=orange]
	6078790048 -> 6077341888 [dir=none]
	6077341888 [label="self
 (1, 288, 1, 1)" fillcolor=orange]
	6078790048 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6078790816 -> 6078790048
	6078790816 -> 6172266544 [dir=none]
	6172266544 [label="result
 (1, 288, 1, 1)" fillcolor=orange]
	6078790816 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6078790768 -> 6078790816
	6078790768 -> 6077341568 [dir=none]
	6077341568 [label="input
 (1, 12, 1, 1)" fillcolor=orange]
	6078790768 -> 6072811360 [dir=none]
	6072811360 [label="weight
 (288, 12, 1, 1)" fillcolor=orange]
	6078790768 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (288,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079031424 -> 6078790768
	6079031424 [label=SwishImplementationBackward]
	6078791296 -> 6079031424
	6078791296 -> 6077342848 [dir=none]
	6077342848 [label="input
 (1, 288, 1, 1)" fillcolor=orange]
	6078791296 -> 6072811120 [dir=none]
	6072811120 [label="weight
 (12, 288, 1, 1)" fillcolor=orange]
	6078791296 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (12,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078791440 -> 6078791296
	6078791440 -> 6077342368 [dir=none]
	6077342368 [label="self
 (1, 288, 75, 75)" fillcolor=orange]
	6078791440 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 288, 75, 75)"]
	6079031200 -> 6078791440
	6079031200 [label=SwishImplementationBackward]
	6078824512 -> 6079031200
	6078824512 -> 6077343328 [dir=none]
	6077343328 [label="input
 (1, 288, 75, 75)" fillcolor=orange]
	6078824512 -> 6172265184 [dir=none]
	6172265184 [label="result1
 (288)" fillcolor=orange]
	6078824512 -> 6172267504 [dir=none]
	6172267504 [label="result2
 (288)" fillcolor=orange]
	6078824512 -> 6072808800 [dir=none]
	6072808800 [label="running_mean
 (288)" fillcolor=orange]
	6078824512 -> 6072810640 [dir=none]
	6072810640 [label="running_var
 (288)" fillcolor=orange]
	6078824512 -> 6072810400 [dir=none]
	6072810400 [label="weight
 (288)" fillcolor=orange]
	6078824512 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078824704 -> 6078824512
	6078824704 -> 6077343408 [dir=none]
	6077343408 [label="input
 (1, 288, 153, 153)" fillcolor=orange]
	6078824704 -> 6072810480 [dir=none]
	6072810480 [label="weight
 (288, 1, 5, 5)" fillcolor=orange]
	6078824704 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            288
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	6078825376 -> 6078824704
	6078825376 [label="ConstantPadNdBackward0
----------------------
pad: (1, 2, 1, 2)"]
	6079030976 -> 6078825376
	6079030976 [label=SwishImplementationBackward]
	6078828784 -> 6079030976
	6078828784 -> 6077344528 [dir=none]
	6077344528 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6078828784 -> 6172265824 [dir=none]
	6172265824 [label="result1
 (288)" fillcolor=orange]
	6078828784 -> 6172265344 [dir=none]
	6172265344 [label="result2
 (288)" fillcolor=orange]
	6078828784 -> 6072809680 [dir=none]
	6072809680 [label="running_mean
 (288)" fillcolor=orange]
	6078828784 -> 6072810000 [dir=none]
	6072810000 [label="running_var
 (288)" fillcolor=orange]
	6078828784 -> 6072809840 [dir=none]
	6072809840 [label="weight
 (288)" fillcolor=orange]
	6078828784 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078825904 -> 6078828784
	6078825904 -> 6077343648 [dir=none]
	6077343648 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	6078825904 -> 6072809760 [dir=none]
	6072809760 [label="weight
 (288, 48, 1, 1)" fillcolor=orange]
	6078825904 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078826144 -> 6078825904
	6078826144 [label="AddBackward0
------------
alpha: 1"]
	6078826912 -> 6078826144
	6078826912 -> 6077343568 [dir=none]
	6077343568 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6078826912 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078827008 -> 6078826912
	6078827008 -> 6172264784 [dir=none]
	6172264784 [label="other
 ()" fillcolor=orange]
	6078827008 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078827200 -> 6078827008
	6078827200 -> 6077343888 [dir=none]
	6077343888 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	6078827200 -> 6172264224 [dir=none]
	6172264224 [label="result1
 (48)" fillcolor=orange]
	6078827200 -> 6172264304 [dir=none]
	6172264304 [label="result2
 (48)" fillcolor=orange]
	6078827200 -> 6072809040 [dir=none]
	6072809040 [label="running_mean
 (48)" fillcolor=orange]
	6078827200 -> 6072809360 [dir=none]
	6072809360 [label="running_var
 (48)" fillcolor=orange]
	6078827200 -> 6072809200 [dir=none]
	6072809200 [label="weight
 (48)" fillcolor=orange]
	6078827200 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078827392 -> 6078827200
	6078827392 -> 6077344048 [dir=none]
	6077344048 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6078827392 -> 6072809120 [dir=none]
	6072809120 [label="weight
 (48, 288, 1, 1)" fillcolor=orange]
	6078827392 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078828112 -> 6078827392
	6078828112 -> 6077344688 [dir=none]
	6077344688 [label="other
 (1, 288, 150, 150)" fillcolor=orange]
	6078828112 -> 6077344368 [dir=none]
	6077344368 [label="self
 (1, 288, 1, 1)" fillcolor=orange]
	6078828112 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6078828160 -> 6078828112
	6078828160 -> 6172263904 [dir=none]
	6172263904 [label="result
 (1, 288, 1, 1)" fillcolor=orange]
	6078828160 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6078828448 -> 6078828160
	6078828448 -> 6077344208 [dir=none]
	6077344208 [label="input
 (1, 12, 1, 1)" fillcolor=orange]
	6078828448 -> 6072808880 [dir=none]
	6072808880 [label="weight
 (288, 12, 1, 1)" fillcolor=orange]
	6078828448 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (288,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079030752 -> 6078828448
	6079030752 [label=SwishImplementationBackward]
	6078829024 -> 6079030752
	6078829024 -> 6077345088 [dir=none]
	6077345088 [label="input
 (1, 288, 1, 1)" fillcolor=orange]
	6078829024 -> 6072808640 [dir=none]
	6072808640 [label="weight
 (12, 288, 1, 1)" fillcolor=orange]
	6078829024 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (12,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078829216 -> 6078829024
	6078829216 -> 6077344688 [dir=none]
	6077344688 [label="self
 (1, 288, 150, 150)" fillcolor=orange]
	6078829216 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                           (1, 288, 150, 150)"]
	6079030528 -> 6078829216
	6079030528 [label=SwishImplementationBackward]
	6078830176 -> 6079030528
	6078830176 -> 6077345568 [dir=none]
	6077345568 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6078830176 -> 6172265104 [dir=none]
	6172265104 [label="result1
 (288)" fillcolor=orange]
	6078830176 -> 6172262624 [dir=none]
	6172262624 [label="result2
 (288)" fillcolor=orange]
	6078830176 -> 6072806320 [dir=none]
	6072806320 [label="running_mean
 (288)" fillcolor=orange]
	6078830176 -> 6072808160 [dir=none]
	6072808160 [label="running_var
 (288)" fillcolor=orange]
	6078830176 -> 6072807920 [dir=none]
	6072807920 [label="weight
 (288)" fillcolor=orange]
	6078830176 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078830128 -> 6078830176
	6078830128 -> 6077345728 [dir=none]
	6077345728 [label="input
 (1, 288, 152, 152)" fillcolor=orange]
	6078830128 -> 6072808000 [dir=none]
	6072808000 [label="weight
 (288, 1, 3, 3)" fillcolor=orange]
	6078830128 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            288
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078830656 -> 6078830128
	6078830656 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6079030304 -> 6078830656
	6079030304 [label=SwishImplementationBackward]
	6078831376 -> 6079030304
	6078831376 -> 6076080880 [dir=none]
	6076080880 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6078831376 -> 6076890736 [dir=none]
	6076890736 [label="result1
 (288)" fillcolor=orange]
	6078831376 -> 6076888896 [dir=none]
	6076888896 [label="result2
 (288)" fillcolor=orange]
	6078831376 -> 6072807200 [dir=none]
	6072807200 [label="running_mean
 (288)" fillcolor=orange]
	6078831376 -> 6072807520 [dir=none]
	6072807520 [label="running_var
 (288)" fillcolor=orange]
	6078831376 -> 6072807360 [dir=none]
	6072807360 [label="weight
 (288)" fillcolor=orange]
	6078831376 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078831568 -> 6078831376
	6078831568 -> 6077346128 [dir=none]
	6077346128 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	6078831568 -> 6072807280 [dir=none]
	6072807280 [label="weight
 (288, 48, 1, 1)" fillcolor=orange]
	6078831568 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078826384 -> 6078831568
	6078826384 [label="AddBackward0
------------
alpha: 1"]
	6078834928 -> 6078826384
	6078834928 -> 6077345808 [dir=none]
	6077345808 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6078834928 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078832672 -> 6078834928
	6078832672 -> 6076876416 [dir=none]
	6076876416 [label="other
 ()" fillcolor=orange]
	6078832672 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078832816 -> 6078832672
	6078832816 -> 6077346288 [dir=none]
	6077346288 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	6078832816 -> 6076878656 [dir=none]
	6076878656 [label="result1
 (48)" fillcolor=orange]
	6078832816 -> 6076878496 [dir=none]
	6076878496 [label="result2
 (48)" fillcolor=orange]
	6078832816 -> 6072806560 [dir=none]
	6072806560 [label="running_mean
 (48)" fillcolor=orange]
	6078832816 -> 6072806880 [dir=none]
	6072806880 [label="running_var
 (48)" fillcolor=orange]
	6078832816 -> 6072806720 [dir=none]
	6072806720 [label="weight
 (48)" fillcolor=orange]
	6078832816 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078832768 -> 6078832816
	6078832768 -> 6077346608 [dir=none]
	6077346608 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6078832768 -> 6072806640 [dir=none]
	6072806640 [label="weight
 (48, 288, 1, 1)" fillcolor=orange]
	6078832768 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078832912 -> 6078832768
	6078832912 -> 6077347248 [dir=none]
	6077347248 [label="other
 (1, 288, 150, 150)" fillcolor=orange]
	6078832912 -> 6077347088 [dir=none]
	6077347088 [label="self
 (1, 288, 1, 1)" fillcolor=orange]
	6078832912 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6078833344 -> 6078832912
	6078833344 -> 6076879616 [dir=none]
	6076879616 [label="result
 (1, 288, 1, 1)" fillcolor=orange]
	6078833344 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6078833536 -> 6078833344
	6078833536 -> 6077346768 [dir=none]
	6077346768 [label="input
 (1, 12, 1, 1)" fillcolor=orange]
	6078833536 -> 6072806400 [dir=none]
	6072806400 [label="weight
 (288, 12, 1, 1)" fillcolor=orange]
	6078833536 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (288,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079030080 -> 6078833536
	6079030080 [label=SwishImplementationBackward]
	6078834448 -> 6079030080
	6078834448 -> 6077347568 [dir=none]
	6077347568 [label="input
 (1, 288, 1, 1)" fillcolor=orange]
	6078834448 -> 6072806160 [dir=none]
	6072806160 [label="weight
 (12, 288, 1, 1)" fillcolor=orange]
	6078834448 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (12,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078834400 -> 6078834448
	6078834400 -> 6077347248 [dir=none]
	6077347248 [label="self
 (1, 288, 150, 150)" fillcolor=orange]
	6078834400 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                           (1, 288, 150, 150)"]
	6079029856 -> 6078834400
	6079029856 [label=SwishImplementationBackward]
	6078838048 -> 6079029856
	6078838048 -> 6077348048 [dir=none]
	6077348048 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6078838048 -> 6076887136 [dir=none]
	6076887136 [label="result1
 (288)" fillcolor=orange]
	6078838048 -> 6076890336 [dir=none]
	6076890336 [label="result2
 (288)" fillcolor=orange]
	6078838048 -> 6072803840 [dir=none]
	6072803840 [label="running_mean
 (288)" fillcolor=orange]
	6078838048 -> 6072805680 [dir=none]
	6072805680 [label="running_var
 (288)" fillcolor=orange]
	6078838048 -> 6072805440 [dir=none]
	6072805440 [label="weight
 (288)" fillcolor=orange]
	6078838048 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078835168 -> 6078838048
	6078835168 -> 6077348208 [dir=none]
	6077348208 [label="input
 (1, 288, 152, 152)" fillcolor=orange]
	6078835168 -> 6072805520 [dir=none]
	6072805520 [label="weight
 (288, 1, 3, 3)" fillcolor=orange]
	6078835168 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            288
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078835408 -> 6078835168
	6078835408 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6079029632 -> 6078835408
	6079029632 [label=SwishImplementationBackward]
	6078836032 -> 6079029632
	6078836032 -> 6075490736 [dir=none]
	6075490736 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6078836032 -> 6172244256 [dir=none]
	6172244256 [label="result1
 (288)" fillcolor=orange]
	6078836032 -> 6172245936 [dir=none]
	6172245936 [label="result2
 (288)" fillcolor=orange]
	6078836032 -> 6072804720 [dir=none]
	6072804720 [label="running_mean
 (288)" fillcolor=orange]
	6078836032 -> 6072805040 [dir=none]
	6072805040 [label="running_var
 (288)" fillcolor=orange]
	6078836032 -> 6072804880 [dir=none]
	6072804880 [label="weight
 (288)" fillcolor=orange]
	6078836032 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078836416 -> 6078836032
	6078836416 -> 6077348528 [dir=none]
	6077348528 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	6078836416 -> 6072804800 [dir=none]
	6072804800 [label="weight
 (288, 48, 1, 1)" fillcolor=orange]
	6078836416 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078831952 -> 6078836416
	6078831952 [label="AddBackward0
------------
alpha: 1"]
	6078836896 -> 6078831952
	6078836896 -> 6077348368 [dir=none]
	6077348368 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6078836896 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078837472 -> 6078836896
	6078837472 -> 6172236096 [dir=none]
	6172236096 [label="other
 ()" fillcolor=orange]
	6078837472 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078837424 -> 6078837472
	6078837424 -> 6077348688 [dir=none]
	6077348688 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	6078837424 -> 6172239536 [dir=none]
	6172239536 [label="result1
 (48)" fillcolor=orange]
	6078837424 -> 6172235296 [dir=none]
	6172235296 [label="result2
 (48)" fillcolor=orange]
	6078837424 -> 6072804080 [dir=none]
	6072804080 [label="running_mean
 (48)" fillcolor=orange]
	6078837424 -> 6072804400 [dir=none]
	6072804400 [label="running_var
 (48)" fillcolor=orange]
	6078837424 -> 6072804240 [dir=none]
	6072804240 [label="weight
 (48)" fillcolor=orange]
	6078837424 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078837712 -> 6078837424
	6078837712 -> 6077348848 [dir=none]
	6077348848 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6078837712 -> 6072804160 [dir=none]
	6072804160 [label="weight
 (48, 288, 1, 1)" fillcolor=orange]
	6078837712 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078838240 -> 6078837712
	6078838240 -> 6077349408 [dir=none]
	6077349408 [label="other
 (1, 288, 150, 150)" fillcolor=orange]
	6078838240 -> 6077349248 [dir=none]
	6077349248 [label="self
 (1, 288, 1, 1)" fillcolor=orange]
	6078838240 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6078838480 -> 6078838240
	6078838480 -> 6172230736 [dir=none]
	6172230736 [label="result
 (1, 288, 1, 1)" fillcolor=orange]
	6078838480 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6078838432 -> 6078838480
	6078838432 -> 6077349088 [dir=none]
	6077349088 [label="input
 (1, 12, 1, 1)" fillcolor=orange]
	6078838432 -> 6072803920 [dir=none]
	6072803920 [label="weight
 (288, 12, 1, 1)" fillcolor=orange]
	6078838432 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (288,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079029408 -> 6078838432
	6079029408 [label=SwishImplementationBackward]
	6078839296 -> 6079029408
	6078839296 -> 6076083760 [dir=none]
	6076083760 [label="input
 (1, 288, 1, 1)" fillcolor=orange]
	6078839296 -> 6072803680 [dir=none]
	6072803680 [label="weight
 (12, 288, 1, 1)" fillcolor=orange]
	6078839296 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (12,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078839488 -> 6078839296
	6078839488 -> 6077349408 [dir=none]
	6077349408 [label="self
 (1, 288, 150, 150)" fillcolor=orange]
	6078839488 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                           (1, 288, 150, 150)"]
	6079029184 -> 6078839488
	6079029184 [label=SwishImplementationBackward]
	6078840208 -> 6079029184
	6078840208 -> 6077334608 [dir=none]
	6077334608 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6078840208 -> 6172233536 [dir=none]
	6172233536 [label="result1
 (288)" fillcolor=orange]
	6078840208 -> 6172245216 [dir=none]
	6172245216 [label="result2
 (288)" fillcolor=orange]
	6078840208 -> 6072801360 [dir=none]
	6072801360 [label="running_mean
 (288)" fillcolor=orange]
	6078840208 -> 6072803200 [dir=none]
	6072803200 [label="running_var
 (288)" fillcolor=orange]
	6078840208 -> 6072802960 [dir=none]
	6072802960 [label="weight
 (288)" fillcolor=orange]
	6078840208 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078840448 -> 6078840208
	6078840448 -> 6077335968 [dir=none]
	6077335968 [label="input
 (1, 288, 152, 152)" fillcolor=orange]
	6078840448 -> 6072803040 [dir=none]
	6072803040 [label="weight
 (288, 1, 3, 3)" fillcolor=orange]
	6078840448 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            288
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078840784 -> 6078840448
	6078840784 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6079028960 -> 6078840784
	6079028960 [label=SwishImplementationBackward]
	6078946400 -> 6079028960
	6078946400 -> 6077338208 [dir=none]
	6077338208 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6078946400 -> 6172241856 [dir=none]
	6172241856 [label="result1
 (288)" fillcolor=orange]
	6078946400 -> 6172238976 [dir=none]
	6172238976 [label="result2
 (288)" fillcolor=orange]
	6078946400 -> 6072802240 [dir=none]
	6072802240 [label="running_mean
 (288)" fillcolor=orange]
	6078946400 -> 6072802560 [dir=none]
	6072802560 [label="running_var
 (288)" fillcolor=orange]
	6078946400 -> 6072802400 [dir=none]
	6072802400 [label="weight
 (288)" fillcolor=orange]
	6078946400 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078939584 -> 6078946400
	6078939584 -> 6077336448 [dir=none]
	6077336448 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	6078939584 -> 6072802320 [dir=none]
	6072802320 [label="weight
 (288, 48, 1, 1)" fillcolor=orange]
	6078939584 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078837136 -> 6078939584
	6078837136 [label="AddBackward0
------------
alpha: 1"]
	6078940112 -> 6078837136
	6078940112 -> 6077336208 [dir=none]
	6077336208 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6078940112 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078940352 -> 6078940112
	6078940352 -> 6172235856 [dir=none]
	6172235856 [label="other
 ()" fillcolor=orange]
	6078940352 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078940640 -> 6078940352
	6078940640 -> 6077336688 [dir=none]
	6077336688 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	6078940640 -> 6172233216 [dir=none]
	6172233216 [label="result1
 (48)" fillcolor=orange]
	6078940640 -> 6172233376 [dir=none]
	6172233376 [label="result2
 (48)" fillcolor=orange]
	6078940640 -> 6072801600 [dir=none]
	6072801600 [label="running_mean
 (48)" fillcolor=orange]
	6078940640 -> 6072801920 [dir=none]
	6072801920 [label="running_var
 (48)" fillcolor=orange]
	6078940640 -> 6072801760 [dir=none]
	6072801760 [label="weight
 (48)" fillcolor=orange]
	6078940640 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078940592 -> 6078940640
	6078940592 -> 6077336848 [dir=none]
	6077336848 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6078940592 -> 6072801680 [dir=none]
	6072801680 [label="weight
 (48, 288, 1, 1)" fillcolor=orange]
	6078940592 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078942416 -> 6078940592
	6078942416 -> 6077338448 [dir=none]
	6077338448 [label="other
 (1, 288, 150, 150)" fillcolor=orange]
	6078942416 -> 6077337888 [dir=none]
	6077337888 [label="self
 (1, 288, 1, 1)" fillcolor=orange]
	6078942416 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6078941120 -> 6078942416
	6078941120 -> 6172232896 [dir=none]
	6172232896 [label="result
 (1, 288, 1, 1)" fillcolor=orange]
	6078941120 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6078941600 -> 6078941120
	6078941600 -> 6077337008 [dir=none]
	6077337008 [label="input
 (1, 12, 1, 1)" fillcolor=orange]
	6078941600 -> 6072801440 [dir=none]
	6072801440 [label="weight
 (288, 12, 1, 1)" fillcolor=orange]
	6078941600 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (288,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079028736 -> 6078941600
	6079028736 [label=SwishImplementationBackward]
	6078942080 -> 6079028736
	6078942080 -> 6077339248 [dir=none]
	6077339248 [label="input
 (1, 288, 1, 1)" fillcolor=orange]
	6078942080 -> 6072801200 [dir=none]
	6072801200 [label="weight
 (12, 288, 1, 1)" fillcolor=orange]
	6078942080 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (12,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078942272 -> 6078942080
	6078942272 -> 6077338448 [dir=none]
	6077338448 [label="self
 (1, 288, 150, 150)" fillcolor=orange]
	6078942272 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                           (1, 288, 150, 150)"]
	6079028512 -> 6078942272
	6079028512 [label=SwishImplementationBackward]
	6078943088 -> 6079028512
	6078943088 -> 6077341088 [dir=none]
	6077341088 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6078943088 -> 6172238656 [dir=none]
	6172238656 [label="result1
 (288)" fillcolor=orange]
	6078943088 -> 6172244656 [dir=none]
	6172244656 [label="result2
 (288)" fillcolor=orange]
	6078943088 -> 6072798960 [dir=none]
	6072798960 [label="running_mean
 (288)" fillcolor=orange]
	6078943088 -> 6072800720 [dir=none]
	6072800720 [label="running_var
 (288)" fillcolor=orange]
	6078943088 -> 6072800480 [dir=none]
	6072800480 [label="weight
 (288)" fillcolor=orange]
	6078943088 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078943376 -> 6078943088
	6078943376 -> 6077341248 [dir=none]
	6077341248 [label="input
 (1, 288, 152, 152)" fillcolor=orange]
	6078943376 -> 6072800560 [dir=none]
	6072800560 [label="weight
 (288, 1, 3, 3)" fillcolor=orange]
	6078943376 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            288
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078943520 -> 6078943376
	6078943520 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6079028288 -> 6078943520
	6079028288 [label=SwishImplementationBackward]
	6078943856 -> 6079028288
	6078943856 -> 6076083120 [dir=none]
	6076083120 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6078943856 -> 6172244496 [dir=none]
	6172244496 [label="result1
 (288)" fillcolor=orange]
	6078943856 -> 6172241456 [dir=none]
	6172241456 [label="result2
 (288)" fillcolor=orange]
	6078943856 -> 6072799840 [dir=none]
	6072799840 [label="running_mean
 (288)" fillcolor=orange]
	6078943856 -> 6072800160 [dir=none]
	6072800160 [label="running_var
 (288)" fillcolor=orange]
	6078943856 -> 6072800000 [dir=none]
	6072800000 [label="weight
 (288)" fillcolor=orange]
	6078943856 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078944144 -> 6078943856
	6078944144 -> 6077341728 [dir=none]
	6077341728 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	6078944144 -> 6072799920 [dir=none]
	6072799920 [label="weight
 (288, 48, 1, 1)" fillcolor=orange]
	6078944144 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078939824 -> 6078944144
	6078939824 [label="AddBackward0
------------
alpha: 1"]
	6078946160 -> 6078939824
	6078946160 -> 6077341408 [dir=none]
	6077341408 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6078946160 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078945536 -> 6078946160
	6078945536 -> 6172239696 [dir=none]
	6172239696 [label="other
 ()" fillcolor=orange]
	6078945536 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078945680 -> 6078945536
	6078945680 -> 6077341968 [dir=none]
	6077341968 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	6078945680 -> 6172237936 [dir=none]
	6172237936 [label="result1
 (48)" fillcolor=orange]
	6078945680 -> 6172238096 [dir=none]
	6172238096 [label="result2
 (48)" fillcolor=orange]
	6078945680 -> 6072799200 [dir=none]
	6072799200 [label="running_mean
 (48)" fillcolor=orange]
	6078945680 -> 6072799520 [dir=none]
	6072799520 [label="running_var
 (48)" fillcolor=orange]
	6078945680 -> 6072799360 [dir=none]
	6072799360 [label="weight
 (48)" fillcolor=orange]
	6078945680 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078945632 -> 6078945680
	6078945632 -> 6077343488 [dir=none]
	6077343488 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6078945632 -> 6072799280 [dir=none]
	6072799280 [label="weight
 (48, 288, 1, 1)" fillcolor=orange]
	6078945632 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078945872 -> 6078945632
	6078945872 -> 6077344848 [dir=none]
	6077344848 [label="other
 (1, 288, 150, 150)" fillcolor=orange]
	6078945872 -> 6077344608 [dir=none]
	6077344608 [label="self
 (1, 288, 1, 1)" fillcolor=orange]
	6078945872 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6078946928 -> 6078945872
	6078946928 -> 6172237136 [dir=none]
	6172237136 [label="result
 (1, 288, 1, 1)" fillcolor=orange]
	6078946928 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6078946592 -> 6078946928
	6078946592 -> 6077343808 [dir=none]
	6077343808 [label="input
 (1, 12, 1, 1)" fillcolor=orange]
	6078946592 -> 6072799040 [dir=none]
	6072799040 [label="weight
 (288, 12, 1, 1)" fillcolor=orange]
	6078946592 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (288,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079028064 -> 6078946592
	6079028064 [label=SwishImplementationBackward]
	11670924512 -> 6079028064
	11670924512 -> 6077347968 [dir=none]
	6077347968 [label="input
 (1, 288, 1, 1)" fillcolor=orange]
	11670924512 -> 6072798800 [dir=none]
	6072798800 [label="weight
 (12, 288, 1, 1)" fillcolor=orange]
	11670924512 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (12,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11670924032 -> 11670924512
	11670924032 -> 6077344848 [dir=none]
	6077344848 [label="self
 (1, 288, 150, 150)" fillcolor=orange]
	11670924032 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                           (1, 288, 150, 150)"]
	6079027840 -> 11670924032
	6079027840 [label=SwishImplementationBackward]
	11670924896 -> 6079027840
	11670924896 -> 6077349488 [dir=none]
	6077349488 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	11670924896 -> 6172240416 [dir=none]
	6172240416 [label="result1
 (288)" fillcolor=orange]
	11670924896 -> 6172232096 [dir=none]
	6172232096 [label="result2
 (288)" fillcolor=orange]
	11670924896 -> 6072796480 [dir=none]
	6072796480 [label="running_mean
 (288)" fillcolor=orange]
	11670924896 -> 6072798320 [dir=none]
	6072798320 [label="running_var
 (288)" fillcolor=orange]
	11670924896 -> 6072798080 [dir=none]
	6072798080 [label="weight
 (288)" fillcolor=orange]
	11670924896 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11670925952 -> 11670924896
	11670925952 -> 6077349648 [dir=none]
	6077349648 [label="input
 (1, 288, 152, 152)" fillcolor=orange]
	11670925952 -> 6072798160 [dir=none]
	6072798160 [label="weight
 (288, 1, 3, 3)" fillcolor=orange]
	11670925952 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            288
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11670924752 -> 11670925952
	11670924752 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6079027616 -> 11670924752
	6079027616 [label=SwishImplementationBackward]
	11670925184 -> 6079027616
	11670925184 -> 6077343248 [dir=none]
	6077343248 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	11670925184 -> 6172231616 [dir=none]
	6172231616 [label="result1
 (288)" fillcolor=orange]
	11670925184 -> 6172245696 [dir=none]
	6172245696 [label="result2
 (288)" fillcolor=orange]
	11670925184 -> 6072797360 [dir=none]
	6072797360 [label="running_mean
 (288)" fillcolor=orange]
	11670925184 -> 6072797680 [dir=none]
	6072797680 [label="running_var
 (288)" fillcolor=orange]
	11670925184 -> 6072797520 [dir=none]
	6072797520 [label="weight
 (288)" fillcolor=orange]
	11670925184 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11670925808 -> 11670925184
	11670925808 -> 6077337248 [dir=none]
	6077337248 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	11670925808 -> 6072797440 [dir=none]
	6072797440 [label="weight
 (288, 48, 1, 1)" fillcolor=orange]
	11670925808 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078944768 -> 11670925808
	6078944768 [label="AddBackward0
------------
alpha: 1"]
	11670926480 -> 6078944768
	11670926480 -> 6077334448 [dir=none]
	6077334448 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11670926480 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11670926528 -> 11670926480
	11670926528 -> 6172245136 [dir=none]
	6172245136 [label="other
 ()" fillcolor=orange]
	11670926528 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11670926624 -> 11670926528
	11670926624 -> 6077339088 [dir=none]
	6077339088 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	11670926624 -> 6172244576 [dir=none]
	6172244576 [label="result1
 (48)" fillcolor=orange]
	11670926624 -> 6172244736 [dir=none]
	6172244736 [label="result2
 (48)" fillcolor=orange]
	11670926624 -> 6072796720 [dir=none]
	6072796720 [label="running_mean
 (48)" fillcolor=orange]
	11670926624 -> 6072797040 [dir=none]
	6072797040 [label="running_var
 (48)" fillcolor=orange]
	11670926624 -> 6072796880 [dir=none]
	6072796880 [label="weight
 (48)" fillcolor=orange]
	11670926624 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11670926768 -> 11670926624
	11670926768 -> 6077339408 [dir=none]
	6077339408 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	11670926768 -> 6072796800 [dir=none]
	6072796800 [label="weight
 (48, 288, 1, 1)" fillcolor=orange]
	11670926768 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11670927056 -> 11670926768
	11670927056 -> 6077344448 [dir=none]
	6077344448 [label="other
 (1, 288, 150, 150)" fillcolor=orange]
	11670927056 -> 6077343088 [dir=none]
	6077343088 [label="self
 (1, 288, 1, 1)" fillcolor=orange]
	11670927056 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11670927392 -> 11670927056
	11670927392 -> 6172244336 [dir=none]
	6172244336 [label="result
 (1, 288, 1, 1)" fillcolor=orange]
	11670927392 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11670927536 -> 11670927392
	11670927536 -> 6077342448 [dir=none]
	6077342448 [label="input
 (1, 12, 1, 1)" fillcolor=orange]
	11670927536 -> 6072796560 [dir=none]
	6072796560 [label="weight
 (288, 12, 1, 1)" fillcolor=orange]
	11670927536 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (288,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079027392 -> 11670927536
	6079027392 [label=SwishImplementationBackward]
	11670928208 -> 6079027392
	11670928208 -> 6077345328 [dir=none]
	6077345328 [label="input
 (1, 288, 1, 1)" fillcolor=orange]
	11670928208 -> 6072796320 [dir=none]
	6072796320 [label="weight
 (12, 288, 1, 1)" fillcolor=orange]
	11670928208 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (12,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11670927824 -> 11670928208
	11670927824 -> 6077344448 [dir=none]
	6077344448 [label="self
 (1, 288, 150, 150)" fillcolor=orange]
	11670927824 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                           (1, 288, 150, 150)"]
	6079027168 -> 11670927824
	6079027168 [label=SwishImplementationBackward]
	11670928256 -> 6079027168
	11670928256 -> 6077345648 [dir=none]
	6077345648 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	11670928256 -> 6172245376 [dir=none]
	6172245376 [label="result1
 (288)" fillcolor=orange]
	11670928256 -> 6172242976 [dir=none]
	6172242976 [label="result2
 (288)" fillcolor=orange]
	11670928256 -> 6046246976 [dir=none]
	6046246976 [label="running_mean
 (288)" fillcolor=orange]
	11670928256 -> 6072795840 [dir=none]
	6072795840 [label="running_var
 (288)" fillcolor=orange]
	11670928256 -> 6072795600 [dir=none]
	6072795600 [label="weight
 (288)" fillcolor=orange]
	11670928256 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11670929072 -> 11670928256
	11670929072 -> 6077345968 [dir=none]
	6077345968 [label="input
 (1, 288, 152, 152)" fillcolor=orange]
	11670929072 -> 6072795680 [dir=none]
	6072795680 [label="weight
 (288, 1, 3, 3)" fillcolor=orange]
	11670929072 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            288
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11670928400 -> 11670929072
	11670928400 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6079026944 -> 11670928400
	6079026944 [label=SwishImplementationBackward]
	11670928928 -> 6079026944
	11670928928 -> 6077333888 [dir=none]
	6077333888 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	11670928928 -> 6172242816 [dir=none]
	6172242816 [label="result1
 (288)" fillcolor=orange]
	11670928928 -> 6172242416 [dir=none]
	6172242416 [label="result2
 (288)" fillcolor=orange]
	11670928928 -> 6060752576 [dir=none]
	6060752576 [label="running_mean
 (288)" fillcolor=orange]
	11670928928 -> 6072795200 [dir=none]
	6072795200 [label="running_var
 (288)" fillcolor=orange]
	11670928928 -> 6060752736 [dir=none]
	6060752736 [label="weight
 (288)" fillcolor=orange]
	11670928928 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11670926048 -> 11670928928
	11670926048 -> 6077346688 [dir=none]
	6077346688 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	11670926048 -> 6060752656 [dir=none]
	6060752656 [label="weight
 (288, 48, 1, 1)" fillcolor=orange]
	11670926048 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11670925904 -> 11670926048
	11670925904 -> 6077346928 [dir=none]
	6077346928 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	11670925904 -> 6172242336 [dir=none]
	6172242336 [label="result1
 (48)" fillcolor=orange]
	11670925904 -> 6172242176 [dir=none]
	6172242176 [label="result2
 (48)" fillcolor=orange]
	11670925904 -> 6060752016 [dir=none]
	6060752016 [label="running_mean
 (48)" fillcolor=orange]
	11670925904 -> 6060752336 [dir=none]
	6060752336 [label="running_var
 (48)" fillcolor=orange]
	11670925904 -> 6060752176 [dir=none]
	6060752176 [label="weight
 (48)" fillcolor=orange]
	11670925904 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11670923312 -> 11670925904
	11670923312 -> 6077347168 [dir=none]
	6077347168 [label="input
 (1, 192, 150, 150)" fillcolor=orange]
	11670923312 -> 6060752096 [dir=none]
	6060752096 [label="weight
 (48, 192, 1, 1)" fillcolor=orange]
	11670923312 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11670923024 -> 11670923312
	11670923024 -> 6077334208 [dir=none]
	6077334208 [label="other
 (1, 192, 150, 150)" fillcolor=orange]
	11670923024 -> 6077347488 [dir=none]
	6077347488 [label="self
 (1, 192, 1, 1)" fillcolor=orange]
	11670923024 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11670922928 -> 11670923024
	11670922928 -> 6172241696 [dir=none]
	6172241696 [label="result
 (1, 192, 1, 1)" fillcolor=orange]
	11670922928 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11670922784 -> 11670922928
	11670922784 -> 6077347328 [dir=none]
	6077347328 [label="input
 (1, 8, 1, 1)" fillcolor=orange]
	11670922784 -> 6060751856 [dir=none]
	6060751856 [label="weight
 (192, 8, 1, 1)" fillcolor=orange]
	11670922784 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (192,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079026720 -> 11670922784
	6079026720 [label=SwishImplementationBackward]
	11670922352 -> 6079026720
	11670922352 -> 6077335008 [dir=none]
	6077335008 [label="input
 (1, 192, 1, 1)" fillcolor=orange]
	11670922352 -> 6060751616 [dir=none]
	6060751616 [label="weight
 (8, 192, 1, 1)" fillcolor=orange]
	11670922352 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (8,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11670922208 -> 11670922352
	11670922208 -> 6077334208 [dir=none]
	6077334208 [label="self
 (1, 192, 150, 150)" fillcolor=orange]
	11670922208 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                           (1, 192, 150, 150)"]
	6079026496 -> 11670922208
	6079026496 [label=SwishImplementationBackward]
	11670921776 -> 6079026496
	11670921776 -> 6077342208 [dir=none]
	6077342208 [label="input
 (1, 192, 150, 150)" fillcolor=orange]
	11670921776 -> 6172241776 [dir=none]
	6172241776 [label="result1
 (192)" fillcolor=orange]
	11670921776 -> 6172240496 [dir=none]
	6172240496 [label="result2
 (192)" fillcolor=orange]
	11670921776 -> 6060749296 [dir=none]
	6060749296 [label="running_mean
 (192)" fillcolor=orange]
	11670921776 -> 6060751136 [dir=none]
	6060751136 [label="running_var
 (192)" fillcolor=orange]
	11670921776 -> 6060750896 [dir=none]
	6060750896 [label="weight
 (192)" fillcolor=orange]
	11670921776 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11670921632 -> 11670921776
	11670921632 -> 6077335328 [dir=none]
	6077335328 [label="input
 (1, 192, 301, 301)" fillcolor=orange]
	11670921632 -> 6060750976 [dir=none]
	6060750976 [label="weight
 (192, 1, 3, 3)" fillcolor=orange]
	11670921632 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            192
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	11670921344 -> 11670921632
	11670921344 [label="ConstantPadNdBackward0
----------------------
pad: (0, 1, 0, 1)"]
	6079026272 -> 11670921344
	6079026272 [label=SwishImplementationBackward]
	11670920864 -> 6079026272
	11670920864 -> 6077449296 [dir=none]
	6077449296 [label="input
 (1, 192, 300, 300)" fillcolor=orange]
	11670920864 -> 6172240336 [dir=none]
	6172240336 [label="result1
 (192)" fillcolor=orange]
	11670920864 -> 6172239456 [dir=none]
	6172239456 [label="result2
 (192)" fillcolor=orange]
	11670920864 -> 6060750176 [dir=none]
	6060750176 [label="running_mean
 (192)" fillcolor=orange]
	11670920864 -> 6060750496 [dir=none]
	6060750496 [label="running_var
 (192)" fillcolor=orange]
	11670920864 -> 6060750336 [dir=none]
	6060750336 [label="weight
 (192)" fillcolor=orange]
	11670920864 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11670920720 -> 11670920864
	11670920720 -> 6077349808 [dir=none]
	6077349808 [label="input
 (1, 32, 300, 300)" fillcolor=orange]
	11670920720 -> 6060750256 [dir=none]
	6060750256 [label="weight
 (192, 32, 1, 1)" fillcolor=orange]
	11670920720 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11670920432 -> 11670920720
	11670920432 [label="AddBackward0
------------
alpha: 1"]
	11670920336 -> 11670920432
	11670920336 -> 6077344128 [dir=none]
	6077344128 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11670920336 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11670920000 -> 11670920336
	11670920000 -> 6172238896 [dir=none]
	6172238896 [label="other
 ()" fillcolor=orange]
	11670920000 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11670919856 -> 11670920000
	11670919856 -> 6077348288 [dir=none]
	6077348288 [label="input
 (1, 32, 300, 300)" fillcolor=orange]
	11670919856 -> 6172238256 [dir=none]
	6172238256 [label="result1
 (32)" fillcolor=orange]
	11670919856 -> 6172238416 [dir=none]
	6172238416 [label="result2
 (32)" fillcolor=orange]
	11670919856 -> 6060749536 [dir=none]
	6060749536 [label="running_mean
 (32)" fillcolor=orange]
	11670919856 -> 6060749856 [dir=none]
	6060749856 [label="running_var
 (32)" fillcolor=orange]
	11670919856 -> 6060749696 [dir=none]
	6060749696 [label="weight
 (32)" fillcolor=orange]
	11670919856 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11670919712 -> 11670919856
	11670919712 -> 6077348768 [dir=none]
	6077348768 [label="input
 (1, 32, 300, 300)" fillcolor=orange]
	11670919712 -> 6060749616 [dir=none]
	6060749616 [label="weight
 (32, 32, 1, 1)" fillcolor=orange]
	11670919712 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11670919424 -> 11670919712
	11670919424 -> 6077448736 [dir=none]
	6077448736 [label="other
 (1, 32, 300, 300)" fillcolor=orange]
	11670919424 -> 6072808240 [dir=none]
	6072808240 [label="self
 (1, 32, 1, 1)" fillcolor=orange]
	11670919424 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11670919328 -> 11670919424
	11670919328 -> 6172238016 [dir=none]
	6172238016 [label="result
 (1, 32, 1, 1)" fillcolor=orange]
	11670919328 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11670919184 -> 11670919328
	11670919184 -> 6077448256 [dir=none]
	6077448256 [label="input
 (1, 8, 1, 1)" fillcolor=orange]
	11670919184 -> 6060749376 [dir=none]
	6060749376 [label="weight
 (32, 8, 1, 1)" fillcolor=orange]
	11670919184 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (32,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079026048 -> 11670919184
	6079026048 [label=SwishImplementationBackward]
	11670918752 -> 6079026048
	11670918752 -> 6072807600 [dir=none]
	6072807600 [label="input
 (1, 32, 1, 1)" fillcolor=orange]
	11670918752 -> 6060749136 [dir=none]
	6060749136 [label="weight
 (8, 32, 1, 1)" fillcolor=orange]
	11670918752 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (8,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11670918608 -> 11670918752
	11670918608 -> 6077448736 [dir=none]
	6077448736 [label="self
 (1, 32, 300, 300)" fillcolor=orange]
	11670918608 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 32, 300, 300)"]
	6079025824 -> 11670918608
	6079025824 [label=SwishImplementationBackward]
	11670918176 -> 6079025824
	11670918176 -> 6077450176 [dir=none]
	6077450176 [label="input
 (1, 32, 300, 300)" fillcolor=orange]
	11670918176 -> 6172236896 [dir=none]
	6172236896 [label="result1
 (32)" fillcolor=orange]
	11670918176 -> 6172237616 [dir=none]
	6172237616 [label="result2
 (32)" fillcolor=orange]
	11670918176 -> 6060748256 [dir=none]
	6060748256 [label="running_mean
 (32)" fillcolor=orange]
	11670918176 -> 6060748656 [dir=none]
	6060748656 [label="running_var
 (32)" fillcolor=orange]
	11670918176 -> 6060748416 [dir=none]
	6060748416 [label="weight
 (32)" fillcolor=orange]
	11670918176 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11670918032 -> 11670918176
	11670918032 -> 6077450816 [dir=none]
	6077450816 [label="input
 (1, 32, 302, 302)" fillcolor=orange]
	11670918032 -> 6060748496 [dir=none]
	6060748496 [label="weight
 (32, 1, 3, 3)" fillcolor=orange]
	11670918032 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :             32
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11670917744 -> 11670918032
	11670917744 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	11670920288 -> 11670917744
	11670920288 [label="AddBackward0
------------
alpha: 1"]
	11670917456 -> 11670920288
	11670917456 -> 6077448976 [dir=none]
	6077448976 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11670917456 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11670917120 -> 11670917456
	11670917120 -> 6172235936 [dir=none]
	6172235936 [label="other
 ()" fillcolor=orange]
	11670917120 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11670916976 -> 11670917120
	11670916976 -> 6077449456 [dir=none]
	6077449456 [label="input
 (1, 32, 300, 300)" fillcolor=orange]
	11670916976 -> 6172235376 [dir=none]
	6172235376 [label="result1
 (32)" fillcolor=orange]
	11670916976 -> 6172235536 [dir=none]
	6172235536 [label="result2
 (32)" fillcolor=orange]
	11670916976 -> 6060747696 [dir=none]
	6060747696 [label="running_mean
 (32)" fillcolor=orange]
	11670916976 -> 6060748016 [dir=none]
	6060748016 [label="running_var
 (32)" fillcolor=orange]
	11670916976 -> 6060747856 [dir=none]
	6060747856 [label="weight
 (32)" fillcolor=orange]
	11670916976 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11670916832 -> 11670916976
	11670916832 -> 6077449776 [dir=none]
	6077449776 [label="input
 (1, 32, 300, 300)" fillcolor=orange]
	11670916832 -> 6060747776 [dir=none]
	6060747776 [label="weight
 (32, 32, 1, 1)" fillcolor=orange]
	11670916832 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11670916544 -> 11670916832
	11670916544 -> 6077450256 [dir=none]
	6077450256 [label="other
 (1, 32, 300, 300)" fillcolor=orange]
	11670916544 -> 6077450016 [dir=none]
	6077450016 [label="self
 (1, 32, 1, 1)" fillcolor=orange]
	11670916544 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11670916448 -> 11670916544
	11670916448 -> 6172235056 [dir=none]
	6172235056 [label="result
 (1, 32, 1, 1)" fillcolor=orange]
	11670916448 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11670916304 -> 11670916448
	11670916304 -> 6077449936 [dir=none]
	6077449936 [label="input
 (1, 8, 1, 1)" fillcolor=orange]
	11670916304 -> 6060624688 [dir=none]
	6060624688 [label="weight
 (32, 8, 1, 1)" fillcolor=orange]
	11670916304 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (32,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079025600 -> 11670916304
	6079025600 [label=SwishImplementationBackward]
	11670915872 -> 6079025600
	11670915872 -> 6077450656 [dir=none]
	6077450656 [label="input
 (1, 32, 1, 1)" fillcolor=orange]
	11670915872 -> 6060747616 [dir=none]
	6060747616 [label="weight
 (8, 32, 1, 1)" fillcolor=orange]
	11670915872 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (8,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11670915728 -> 11670915872
	11670915728 -> 6077450256 [dir=none]
	6077450256 [label="self
 (1, 32, 300, 300)" fillcolor=orange]
	11670915728 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 32, 300, 300)"]
	6079025376 -> 11670915728
	6079025376 [label=SwishImplementationBackward]
	11670915296 -> 6079025376
	11670915296 -> 6077451616 [dir=none]
	6077451616 [label="input
 (1, 32, 300, 300)" fillcolor=orange]
	11670915296 -> 6172233856 [dir=none]
	6172233856 [label="result1
 (32)" fillcolor=orange]
	11670915296 -> 6172234576 [dir=none]
	6172234576 [label="result2
 (32)" fillcolor=orange]
	11670915296 -> 6060746736 [dir=none]
	6060746736 [label="running_mean
 (32)" fillcolor=orange]
	11670915296 -> 6060747136 [dir=none]
	6060747136 [label="running_var
 (32)" fillcolor=orange]
	11670915296 -> 6060746896 [dir=none]
	6060746896 [label="weight
 (32)" fillcolor=orange]
	11670915296 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11670915152 -> 11670915296
	11670915152 -> 6077452496 [dir=none]
	6077452496 [label="input
 (1, 32, 302, 302)" fillcolor=orange]
	11670915152 -> 6060746976 [dir=none]
	6060746976 [label="weight
 (32, 1, 3, 3)" fillcolor=orange]
	11670915152 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :             32
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11670914864 -> 11670915152
	11670914864 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	11670917552 -> 11670914864
	11670917552 [label="AddBackward0
------------
alpha: 1"]
	11670914576 -> 11670917552
	11670914576 -> 6077454656 [dir=none]
	6077454656 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11670914576 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11670914240 -> 11670914576
	11670914240 -> 6172232816 [dir=none]
	6172232816 [label="other
 ()" fillcolor=orange]
	11670914240 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11670914096 -> 11670914240
	11670914096 -> 6077450976 [dir=none]
	6077450976 [label="input
 (1, 32, 300, 300)" fillcolor=orange]
	11670914096 -> 6172232496 [dir=none]
	6172232496 [label="result1
 (32)" fillcolor=orange]
	11670914096 -> 6172232416 [dir=none]
	6172232416 [label="result2
 (32)" fillcolor=orange]
	11670914096 -> 6060746176 [dir=none]
	6060746176 [label="running_mean
 (32)" fillcolor=orange]
	11670914096 -> 6060746496 [dir=none]
	6060746496 [label="running_var
 (32)" fillcolor=orange]
	11670914096 -> 6060746336 [dir=none]
	6060746336 [label="weight
 (32)" fillcolor=orange]
	11670914096 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11670913952 -> 11670914096
	11670913952 -> 6077451136 [dir=none]
	6077451136 [label="input
 (1, 32, 300, 300)" fillcolor=orange]
	11670913952 -> 6060746256 [dir=none]
	6060746256 [label="weight
 (32, 32, 1, 1)" fillcolor=orange]
	11670913952 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11670913664 -> 11670913952
	11670913664 -> 6077451696 [dir=none]
	6077451696 [label="other
 (1, 32, 300, 300)" fillcolor=orange]
	11670913664 -> 6077451456 [dir=none]
	6077451456 [label="self
 (1, 32, 1, 1)" fillcolor=orange]
	11670913664 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11670913568 -> 11670913664
	11670913568 -> 6172232176 [dir=none]
	6172232176 [label="result
 (1, 32, 1, 1)" fillcolor=orange]
	11670913568 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11670913424 -> 11670913568
	11670913424 -> 6077451296 [dir=none]
	6077451296 [label="input
 (1, 8, 1, 1)" fillcolor=orange]
	11670913424 -> 6060746016 [dir=none]
	6060746016 [label="weight
 (32, 8, 1, 1)" fillcolor=orange]
	11670913424 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (32,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079025152 -> 11670913424
	6079025152 [label=SwishImplementationBackward]
	11670913136 -> 6079025152
	11670913136 -> 6077452176 [dir=none]
	6077452176 [label="input
 (1, 32, 1, 1)" fillcolor=orange]
	11670913136 -> 6060745776 [dir=none]
	6060745776 [label="weight
 (8, 32, 1, 1)" fillcolor=orange]
	11670913136 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (8,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172720912 -> 11670913136
	6172720912 -> 6077451696 [dir=none]
	6077451696 [label="self
 (1, 32, 300, 300)" fillcolor=orange]
	6172720912 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 32, 300, 300)"]
	6079024928 -> 6172720912
	6079024928 [label=SwishImplementationBackward]
	6172720480 -> 6079024928
	6172720480 -> 6077453296 [dir=none]
	6077453296 [label="input
 (1, 32, 300, 300)" fillcolor=orange]
	6172720480 -> 6172231056 [dir=none]
	6172231056 [label="result1
 (32)" fillcolor=orange]
	6172720480 -> 6172231776 [dir=none]
	6172231776 [label="result2
 (32)" fillcolor=orange]
	6172720480 -> 6060744976 [dir=none]
	6060744976 [label="running_mean
 (32)" fillcolor=orange]
	6172720480 -> 6060745376 [dir=none]
	6060745376 [label="running_var
 (32)" fillcolor=orange]
	6172720480 -> 6060745136 [dir=none]
	6060745136 [label="weight
 (32)" fillcolor=orange]
	6172720480 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172720336 -> 6172720480
	6172720336 -> 6077464176 [dir=none]
	6077464176 [label="input
 (1, 32, 302, 302)" fillcolor=orange]
	6172720336 -> 6060745216 [dir=none]
	6060745216 [label="weight
 (32, 1, 3, 3)" fillcolor=orange]
	6172720336 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :             32
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172720048 -> 6172720336
	6172720048 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	11670914672 -> 6172720048
	11670914672 -> 6077452656 [dir=none]
	6077452656 [label="input
 (1, 32, 300, 300)" fillcolor=orange]
	11670914672 -> 6172230576 [dir=none]
	6172230576 [label="result1
 (32)" fillcolor=orange]
	11670914672 -> 6172230256 [dir=none]
	6172230256 [label="result2
 (32)" fillcolor=orange]
	11670914672 -> 6060744416 [dir=none]
	6060744416 [label="running_mean
 (32)" fillcolor=orange]
	11670914672 -> 6060744736 [dir=none]
	6060744736 [label="running_var
 (32)" fillcolor=orange]
	11670914672 -> 6060744576 [dir=none]
	6060744576 [label="weight
 (32)" fillcolor=orange]
	11670914672 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172719760 -> 11670914672
	6172719760 -> 6077452736 [dir=none]
	6077452736 [label="input
 (1, 64, 300, 300)" fillcolor=orange]
	6172719760 -> 6060744496 [dir=none]
	6060744496 [label="weight
 (32, 64, 1, 1)" fillcolor=orange]
	6172719760 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172719472 -> 6172719760
	6172719472 -> 6077454096 [dir=none]
	6077454096 [label="other
 (1, 64, 300, 300)" fillcolor=orange]
	6172719472 -> 6077453136 [dir=none]
	6077453136 [label="self
 (1, 64, 1, 1)" fillcolor=orange]
	6172719472 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6172719136 -> 6172719472
	6172719136 -> 6076952512 [dir=none]
	6076952512 [label="result
 (1, 64, 1, 1)" fillcolor=orange]
	6172719136 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6172718992 -> 6172719136
	6172718992 -> 6077452976 [dir=none]
	6077452976 [label="input
 (1, 16, 1, 1)" fillcolor=orange]
	6172718992 -> 6060744256 [dir=none]
	6060744256 [label="weight
 (64, 16, 1, 1)" fillcolor=orange]
	6172718992 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (64,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079024704 -> 6172718992
	6079024704 [label=SwishImplementationBackward]
	6172718560 -> 6079024704
	6172718560 -> 6077458016 [dir=none]
	6077458016 [label="input
 (1, 64, 1, 1)" fillcolor=orange]
	6172718560 -> 6060744016 [dir=none]
	6060744016 [label="weight
 (16, 64, 1, 1)" fillcolor=orange]
	6172718560 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (16,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172718416 -> 6172718560
	6172718416 -> 6077454096 [dir=none]
	6077454096 [label="self
 (1, 64, 300, 300)" fillcolor=orange]
	6172718416 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 64, 300, 300)"]
	6079024480 -> 6172718416
	6079024480 [label=SwishImplementationBackward]
	6172717984 -> 6079024480
	6172717984 -> 6077454256 [dir=none]
	6077454256 [label="input
 (1, 64, 300, 300)" fillcolor=orange]
	6172717984 -> 6078650528 [dir=none]
	6078650528 [label="result1
 (64)" fillcolor=orange]
	6172717984 -> 6078656448 [dir=none]
	6078656448 [label="result2
 (64)" fillcolor=orange]
	6172717984 -> 6060743216 [dir=none]
	6060743216 [label="running_mean
 (64)" fillcolor=orange]
	6172717984 -> 6060743616 [dir=none]
	6060743616 [label="running_var
 (64)" fillcolor=orange]
	6172717984 -> 6060743376 [dir=none]
	6060743376 [label="weight
 (64)" fillcolor=orange]
	6172717984 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172717840 -> 6172717984
	6172717840 -> 6077454576 [dir=none]
	6077454576 [label="input
 (1, 64, 302, 302)" fillcolor=orange]
	6172717840 -> 6060743456 [dir=none]
	6060743456 [label="weight
 (64, 1, 3, 3)" fillcolor=orange]
	6172717840 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :             64
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172717552 -> 6172717840
	6172717552 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6079024256 -> 6172717552
	6079024256 [label=SwishImplementationBackward]
	6172717312 -> 6079024256
	6172717312 -> 6060637808 [dir=none]
	6060637808 [label="input
 (1, 64, 300, 300)" fillcolor=orange]
	6172717312 -> 6078647328 [dir=none]
	6078647328 [label="result1
 (64)" fillcolor=orange]
	6172717312 -> 6078645728 [dir=none]
	6078645728 [label="result2
 (64)" fillcolor=orange]
	6172717312 -> 6060742656 [dir=none]
	6060742656 [label="running_mean
 (64)" fillcolor=orange]
	6172717312 -> 6060742896 [dir=none]
	6060742896 [label="running_var
 (64)" fillcolor=orange]
	6172717312 -> 6060742736 [dir=none]
	6060742736 [label="weight
 (64)" fillcolor=orange]
	6172717312 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172717168 -> 6172717312
	6172717168 -> 6075802832 [dir=none]
	6075802832 [label="input
 (1, 3, 601, 601)" fillcolor=orange]
	6172717168 -> 6060742496 [dir=none]
	6060742496 [label="weight
 (64, 3, 3, 3)" fillcolor=orange]
	6172717168 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	6172716880 -> 6172717168
	6060742496 [label="
 (64, 3, 3, 3)" fillcolor=lightblue]
	6060742496 -> 6172716880
	6172716880 [label=AccumulateGrad]
	6172717120 -> 6172717312
	6060742736 [label="
 (64)" fillcolor=lightblue]
	6060742736 -> 6172717120
	6172717120 [label=AccumulateGrad]
	6172717600 -> 6172717312
	6060742816 [label="
 (64)" fillcolor=lightblue]
	6060742816 -> 6172717600
	6172717600 [label=AccumulateGrad]
	6075498016 -> 6079024256
	6075498016 [label="
 (1, 64, 300, 300)" fillcolor=orange]
	6172717744 -> 6172717840
	6060743456 [label="
 (64, 1, 3, 3)" fillcolor=lightblue]
	6060743456 -> 6172717744
	6172717744 [label=AccumulateGrad]
	6172718032 -> 6172717984
	6060743376 [label="
 (64)" fillcolor=lightblue]
	6060743376 -> 6172718032
	6172718032 [label=AccumulateGrad]
	6172718272 -> 6172717984
	6060743536 [label="
 (64)" fillcolor=lightblue]
	6060743536 -> 6172718272
	6172718272 [label=AccumulateGrad]
	6077454416 -> 6079024480
	6077454416 [label="
 (1, 64, 300, 300)" fillcolor=orange]
	6172718608 -> 6172718560
	6060744016 [label="
 (16, 64, 1, 1)" fillcolor=lightblue]
	6060744016 -> 6172718608
	6172718608 [label=AccumulateGrad]
	6172718704 -> 6172718560
	6060744096 [label="
 (16)" fillcolor=lightblue]
	6060744096 -> 6172718704
	6172718704 [label=AccumulateGrad]
	6077453776 -> 6079024704
	6077453776 [label="
 (1, 16, 1, 1)" fillcolor=orange]
	6172718848 -> 6172718992
	6060744256 [label="
 (64, 16, 1, 1)" fillcolor=lightblue]
	6060744256 -> 6172718848
	6172718848 [label=AccumulateGrad]
	6172719040 -> 6172718992
	6060744336 [label="
 (64)" fillcolor=lightblue]
	6060744336 -> 6172719040
	6172719040 [label=AccumulateGrad]
	6079024480 -> 6172719472
	6172719424 -> 6172719760
	6060744496 [label="
 (32, 64, 1, 1)" fillcolor=lightblue]
	6060744496 -> 6172719424
	6172719424 [label=AccumulateGrad]
	6172719856 -> 11670914672
	6060744576 [label="
 (32)" fillcolor=lightblue]
	6060744576 -> 6172719856
	6172719856 [label=AccumulateGrad]
	6172719904 -> 11670914672
	6060744656 [label="
 (32)" fillcolor=lightblue]
	6060744656 -> 6172719904
	6172719904 [label=AccumulateGrad]
	6172720000 -> 6172720336
	6060745216 [label="
 (32, 1, 3, 3)" fillcolor=lightblue]
	6060745216 -> 6172720000
	6172720000 [label=AccumulateGrad]
	6172720288 -> 6172720480
	6060745136 [label="
 (32)" fillcolor=lightblue]
	6060745136 -> 6172720288
	6172720288 [label=AccumulateGrad]
	6172720768 -> 6172720480
	6060745296 [label="
 (32)" fillcolor=lightblue]
	6060745296 -> 6172720768
	6172720768 [label=AccumulateGrad]
	6077452336 -> 6079024928
	6077452336 [label="
 (1, 32, 300, 300)" fillcolor=orange]
	6172720864 -> 11670913136
	6060745776 [label="
 (8, 32, 1, 1)" fillcolor=lightblue]
	6060745776 -> 6172720864
	6172720864 [label=AccumulateGrad]
	6172721008 -> 11670913136
	6060745856 [label="
 (8)" fillcolor=lightblue]
	6060745856 -> 6172721008
	6172721008 [label=AccumulateGrad]
	6077452016 -> 6079025152
	6077452016 [label="
 (1, 8, 1, 1)" fillcolor=orange]
	11670913280 -> 11670913424
	6060746016 [label="
 (32, 8, 1, 1)" fillcolor=lightblue]
	6060746016 -> 11670913280
	11670913280 [label=AccumulateGrad]
	11670913232 -> 11670913424
	6060746096 [label="
 (32)" fillcolor=lightblue]
	6060746096 -> 11670913232
	11670913232 [label=AccumulateGrad]
	6079024928 -> 11670913664
	11670913856 -> 11670913952
	6060746256 [label="
 (32, 32, 1, 1)" fillcolor=lightblue]
	6060746256 -> 11670913856
	11670913856 [label=AccumulateGrad]
	11670914144 -> 11670914096
	6060746336 [label="
 (32)" fillcolor=lightblue]
	6060746336 -> 11670914144
	11670914144 [label=AccumulateGrad]
	11670914384 -> 11670914096
	6060746416 [label="
 (32)" fillcolor=lightblue]
	6060746416 -> 11670914384
	11670914384 [label=AccumulateGrad]
	11670914672 -> 11670917552
	11670914816 -> 11670915152
	6060746976 [label="
 (32, 1, 3, 3)" fillcolor=lightblue]
	6060746976 -> 11670914816
	11670914816 [label=AccumulateGrad]
	11670915104 -> 11670915296
	6060746896 [label="
 (32)" fillcolor=lightblue]
	6060746896 -> 11670915104
	11670915104 [label=AccumulateGrad]
	11670915584 -> 11670915296
	6060747056 [label="
 (32)" fillcolor=lightblue]
	6060747056 -> 11670915584
	11670915584 [label=AccumulateGrad]
	6077450416 -> 6079025376
	6077450416 [label="
 (1, 32, 300, 300)" fillcolor=orange]
	11670915680 -> 11670915872
	6060747616 [label="
 (8, 32, 1, 1)" fillcolor=lightblue]
	6060747616 -> 11670915680
	11670915680 [label=AccumulateGrad]
	11670916016 -> 11670915872
	6060635248 [label="
 (8)" fillcolor=lightblue]
	6060635248 -> 11670916016
	11670916016 [label=AccumulateGrad]
	6077450576 -> 6079025600
	6077450576 [label="
 (1, 8, 1, 1)" fillcolor=orange]
	11670916160 -> 11670916304
	6060624688 [label="
 (32, 8, 1, 1)" fillcolor=lightblue]
	6060624688 -> 11670916160
	11670916160 [label=AccumulateGrad]
	11670916112 -> 11670916304
	6060747456 [label="
 (32)" fillcolor=lightblue]
	6060747456 -> 11670916112
	11670916112 [label=AccumulateGrad]
	6079025376 -> 11670916544
	11670916736 -> 11670916832
	6060747776 [label="
 (32, 32, 1, 1)" fillcolor=lightblue]
	6060747776 -> 11670916736
	11670916736 [label=AccumulateGrad]
	11670917024 -> 11670916976
	6060747856 [label="
 (32)" fillcolor=lightblue]
	6060747856 -> 11670917024
	11670917024 [label=AccumulateGrad]
	11670917264 -> 11670916976
	6060747936 [label="
 (32)" fillcolor=lightblue]
	6060747936 -> 11670917264
	11670917264 [label=AccumulateGrad]
	11670917552 -> 11670920288
	11670917696 -> 11670918032
	6060748496 [label="
 (32, 1, 3, 3)" fillcolor=lightblue]
	6060748496 -> 11670917696
	11670917696 [label=AccumulateGrad]
	11670917984 -> 11670918176
	6060748416 [label="
 (32)" fillcolor=lightblue]
	6060748416 -> 11670917984
	11670917984 [label=AccumulateGrad]
	11670918464 -> 11670918176
	6060748576 [label="
 (32)" fillcolor=lightblue]
	6060748576 -> 11670918464
	11670918464 [label=AccumulateGrad]
	6077448576 -> 6079025824
	6077448576 [label="
 (1, 32, 300, 300)" fillcolor=orange]
	11670918560 -> 11670918752
	6060749136 [label="
 (8, 32, 1, 1)" fillcolor=lightblue]
	6060749136 -> 11670918560
	11670918560 [label=AccumulateGrad]
	11670918896 -> 11670918752
	6060749216 [label="
 (8)" fillcolor=lightblue]
	6060749216 -> 11670918896
	11670918896 [label=AccumulateGrad]
	6077448896 -> 6079026048
	6077448896 [label="
 (1, 8, 1, 1)" fillcolor=orange]
	11670919040 -> 11670919184
	6060749376 [label="
 (32, 8, 1, 1)" fillcolor=lightblue]
	6060749376 -> 11670919040
	11670919040 [label=AccumulateGrad]
	11670918992 -> 11670919184
	6060749456 [label="
 (32)" fillcolor=lightblue]
	6060749456 -> 11670918992
	11670918992 [label=AccumulateGrad]
	6079025824 -> 11670919424
	11670919616 -> 11670919712
	6060749616 [label="
 (32, 32, 1, 1)" fillcolor=lightblue]
	6060749616 -> 11670919616
	11670919616 [label=AccumulateGrad]
	11670919904 -> 11670919856
	6060749696 [label="
 (32)" fillcolor=lightblue]
	6060749696 -> 11670919904
	11670919904 [label=AccumulateGrad]
	11670920144 -> 11670919856
	6060749776 [label="
 (32)" fillcolor=lightblue]
	6060749776 -> 11670920144
	11670920144 [label=AccumulateGrad]
	11670920288 -> 11670920432
	11670920624 -> 11670920720
	6060750256 [label="
 (192, 32, 1, 1)" fillcolor=lightblue]
	6060750256 -> 11670920624
	11670920624 [label=AccumulateGrad]
	11670920912 -> 11670920864
	6060750336 [label="
 (192)" fillcolor=lightblue]
	6060750336 -> 11670920912
	11670920912 [label=AccumulateGrad]
	11670921152 -> 11670920864
	6060750416 [label="
 (192)" fillcolor=lightblue]
	6060750416 -> 11670921152
	11670921152 [label=AccumulateGrad]
	6077448336 -> 6079026272
	6077448336 [label="
 (1, 192, 300, 300)" fillcolor=orange]
	11670921296 -> 11670921632
	6060750976 [label="
 (192, 1, 3, 3)" fillcolor=lightblue]
	6060750976 -> 11670921296
	11670921296 [label=AccumulateGrad]
	11670921584 -> 11670921776
	6060750896 [label="
 (192)" fillcolor=lightblue]
	6060750896 -> 11670921584
	11670921584 [label=AccumulateGrad]
	11670922064 -> 11670921776
	6060751056 [label="
 (192)" fillcolor=lightblue]
	6060751056 -> 11670922064
	11670922064 [label=AccumulateGrad]
	6077337648 -> 6079026496
	6077337648 [label="
 (1, 192, 150, 150)" fillcolor=orange]
	11670922160 -> 11670922352
	6060751616 [label="
 (8, 192, 1, 1)" fillcolor=lightblue]
	6060751616 -> 11670922160
	11670922160 [label=AccumulateGrad]
	11670922496 -> 11670922352
	6060751696 [label="
 (8)" fillcolor=lightblue]
	6060751696 -> 11670922496
	11670922496 [label=AccumulateGrad]
	6077334848 -> 6079026720
	6077334848 [label="
 (1, 8, 1, 1)" fillcolor=orange]
	11670922640 -> 11670922784
	6060751856 [label="
 (192, 8, 1, 1)" fillcolor=lightblue]
	6060751856 -> 11670922640
	11670922640 [label=AccumulateGrad]
	11670922592 -> 11670922784
	6060751936 [label="
 (192)" fillcolor=lightblue]
	6060751936 -> 11670922592
	11670922592 [label=AccumulateGrad]
	6079026496 -> 11670923024
	11670923216 -> 11670923312
	6060752096 [label="
 (48, 192, 1, 1)" fillcolor=lightblue]
	6060752096 -> 11670923216
	11670923216 [label=AccumulateGrad]
	11670923504 -> 11670925904
	6060752176 [label="
 (48)" fillcolor=lightblue]
	6060752176 -> 11670923504
	11670923504 [label=AccumulateGrad]
	11670926240 -> 11670925904
	6060752256 [label="
 (48)" fillcolor=lightblue]
	6060752256 -> 11670926240
	11670926240 [label=AccumulateGrad]
	11670923744 -> 11670926048
	6060752656 [label="
 (288, 48, 1, 1)" fillcolor=lightblue]
	6060752656 -> 11670923744
	11670923744 [label=AccumulateGrad]
	11670929216 -> 11670928928
	6060752736 [label="
 (288)" fillcolor=lightblue]
	6060752736 -> 11670929216
	11670929216 [label=AccumulateGrad]
	11670928496 -> 11670928928
	6060752816 [label="
 (288)" fillcolor=lightblue]
	6060752816 -> 11670928496
	11670928496 [label=AccumulateGrad]
	6077346208 -> 6079026944
	6077346208 [label="
 (1, 288, 150, 150)" fillcolor=orange]
	11670928640 -> 11670929072
	6072795680 [label="
 (288, 1, 3, 3)" fillcolor=lightblue]
	6072795680 -> 11670928640
	11670928640 [label=AccumulateGrad]
	11670928352 -> 11670928256
	6072795600 [label="
 (288)" fillcolor=lightblue]
	6072795600 -> 11670928352
	11670928352 [label=AccumulateGrad]
	11670927968 -> 11670928256
	6072795760 [label="
 (288)" fillcolor=lightblue]
	6072795760 -> 11670927968
	11670927968 [label=AccumulateGrad]
	6077345488 -> 6079027168
	6077345488 [label="
 (1, 288, 150, 150)" fillcolor=orange]
	11670927632 -> 11670928208
	6072796320 [label="
 (12, 288, 1, 1)" fillcolor=lightblue]
	6072796320 -> 11670927632
	11670927632 [label=AccumulateGrad]
	11670927488 -> 11670928208
	6072796400 [label="
 (12)" fillcolor=lightblue]
	6072796400 -> 11670927488
	11670927488 [label=AccumulateGrad]
	6077345168 -> 6079027392
	6077345168 [label="
 (1, 12, 1, 1)" fillcolor=orange]
	11670929120 -> 11670927536
	6072796560 [label="
 (288, 12, 1, 1)" fillcolor=lightblue]
	6072796560 -> 11670929120
	11670929120 [label=AccumulateGrad]
	11670927680 -> 11670927536
	6072796640 [label="
 (288)" fillcolor=lightblue]
	6072796640 -> 11670927680
	11670927680 [label=AccumulateGrad]
	6079027168 -> 11670927056
	11670927104 -> 11670926768
	6072796800 [label="
 (48, 288, 1, 1)" fillcolor=lightblue]
	6072796800 -> 11670927104
	11670927104 [label=AccumulateGrad]
	11670926816 -> 11670926624
	6072796880 [label="
 (48)" fillcolor=lightblue]
	6072796880 -> 11670926816
	11670926816 [label=AccumulateGrad]
	11670926384 -> 11670926624
	6072796960 [label="
 (48)" fillcolor=lightblue]
	6072796960 -> 11670926384
	11670926384 [label=AccumulateGrad]
	11670925904 -> 6078944768
	11670925520 -> 11670925808
	6072797440 [label="
 (288, 48, 1, 1)" fillcolor=lightblue]
	6072797440 -> 11670925520
	11670925520 [label=AccumulateGrad]
	11670925040 -> 11670925184
	6072797520 [label="
 (288)" fillcolor=lightblue]
	6072797520 -> 11670925040
	11670925040 [label=AccumulateGrad]
	11670924944 -> 11670925184
	6072797600 [label="
 (288)" fillcolor=lightblue]
	6072797600 -> 11670924944
	11670924944 [label=AccumulateGrad]
	6077349328 -> 6079027616
	6077349328 [label="
 (1, 288, 150, 150)" fillcolor=orange]
	11670924800 -> 11670925952
	6072798160 [label="
 (288, 1, 3, 3)" fillcolor=lightblue]
	6072798160 -> 11670924800
	11670924800 [label=AccumulateGrad]
	11670925760 -> 11670924896
	6072798080 [label="
 (288)" fillcolor=lightblue]
	6072798080 -> 11670925760
	11670925760 [label=AccumulateGrad]
	11670924176 -> 11670924896
	6072798240 [label="
 (288)" fillcolor=lightblue]
	6072798240 -> 11670924176
	11670924176 [label=AccumulateGrad]
	6077348448 -> 6079027840
	6077348448 [label="
 (1, 288, 150, 150)" fillcolor=orange]
	11670924080 -> 11670924512
	6072798800 [label="
 (12, 288, 1, 1)" fillcolor=lightblue]
	6072798800 -> 11670924080
	11670924080 [label=AccumulateGrad]
	11670923600 -> 11670924512
	6072798880 [label="
 (12)" fillcolor=lightblue]
	6072798880 -> 11670923600
	11670923600 [label=AccumulateGrad]
	6077347648 -> 6079028064
	6077347648 [label="
 (1, 12, 1, 1)" fillcolor=orange]
	11670923456 -> 6078946592
	6072799040 [label="
 (288, 12, 1, 1)" fillcolor=lightblue]
	6072799040 -> 11670923456
	11670923456 [label=AccumulateGrad]
	11670923792 -> 6078946592
	6072799120 [label="
 (288)" fillcolor=lightblue]
	6072799120 -> 11670923792
	11670923792 [label=AccumulateGrad]
	6079027840 -> 6078945872
	6078946112 -> 6078945632
	6072799280 [label="
 (48, 288, 1, 1)" fillcolor=lightblue]
	6072799280 -> 6078946112
	6078946112 [label=AccumulateGrad]
	6078945248 -> 6078945680
	6072799360 [label="
 (48)" fillcolor=lightblue]
	6072799360 -> 6078945248
	6078945248 [label=AccumulateGrad]
	6078945152 -> 6078945680
	6072799440 [label="
 (48)" fillcolor=lightblue]
	6072799440 -> 6078945152
	6078945152 [label=AccumulateGrad]
	6078944768 -> 6078939824
	6078944720 -> 6078944144
	6072799920 [label="
 (288, 48, 1, 1)" fillcolor=lightblue]
	6072799920 -> 6078944720
	6078944720 [label=AccumulateGrad]
	6078944336 -> 6078943856
	6072800000 [label="
 (288)" fillcolor=lightblue]
	6072800000 -> 6078944336
	6078944336 [label=AccumulateGrad]
	6078944912 -> 6078943856
	6072800080 [label="
 (288)" fillcolor=lightblue]
	6072800080 -> 6078944912
	6078944912 [label=AccumulateGrad]
	6077340928 -> 6079028288
	6077340928 [label="
 (1, 288, 150, 150)" fillcolor=orange]
	6078943472 -> 6078943376
	6072800560 [label="
 (288, 1, 3, 3)" fillcolor=lightblue]
	6072800560 -> 6078943472
	6078943472 [label=AccumulateGrad]
	6078942896 -> 6078943088
	6072800480 [label="
 (288)" fillcolor=lightblue]
	6072800480 -> 6078942896
	6078942896 [label=AccumulateGrad]
	6078942368 -> 6078943088
	6072800640 [label="
 (288)" fillcolor=lightblue]
	6072800640 -> 6078942368
	6078942368 [label=AccumulateGrad]
	6077340128 -> 6079028512
	6077340128 [label="
 (1, 288, 150, 150)" fillcolor=orange]
	6078942224 -> 6078942080
	6072801200 [label="
 (12, 288, 1, 1)" fillcolor=lightblue]
	6072801200 -> 6078942224
	6078942224 [label=AccumulateGrad]
	6078942128 -> 6078942080
	6072801280 [label="
 (12)" fillcolor=lightblue]
	6072801280 -> 6078942128
	6078942128 [label=AccumulateGrad]
	6077338688 -> 6079028736
	6077338688 [label="
 (1, 12, 1, 1)" fillcolor=orange]
	6078941840 -> 6078941600
	6072801440 [label="
 (288, 12, 1, 1)" fillcolor=lightblue]
	6072801440 -> 6078941840
	6078941840 [label=AccumulateGrad]
	6078941360 -> 6078941600
	6072801520 [label="
 (288)" fillcolor=lightblue]
	6072801520 -> 6078941360
	6078941360 [label=AccumulateGrad]
	6079028512 -> 6078942416
	6078941024 -> 6078940592
	6072801680 [label="
 (48, 288, 1, 1)" fillcolor=lightblue]
	6072801680 -> 6078941024
	6078941024 [label=AccumulateGrad]
	6078940400 -> 6078940640
	6072801760 [label="
 (48)" fillcolor=lightblue]
	6072801760 -> 6078940400
	6078940400 [label=AccumulateGrad]
	6078940208 -> 6078940640
	6072801840 [label="
 (48)" fillcolor=lightblue]
	6072801840 -> 6078940208
	6078940208 [label=AccumulateGrad]
	6078939824 -> 6078837136
	6078941168 -> 6078939584
	6072802320 [label="
 (288, 48, 1, 1)" fillcolor=lightblue]
	6072802320 -> 6078941168
	6078941168 [label=AccumulateGrad]
	6078939872 -> 6078946400
	6072802400 [label="
 (288)" fillcolor=lightblue]
	6072802400 -> 6078939872
	6078939872 [label=AccumulateGrad]
	6078946736 -> 6078946400
	6072802480 [label="
 (288)" fillcolor=lightblue]
	6072802480 -> 6078946736
	6078946736 [label=AccumulateGrad]
	6077333648 -> 6079028960
	6077333648 [label="
 (1, 288, 150, 150)" fillcolor=orange]
	6078840736 -> 6078840448
	6072803040 [label="
 (288, 1, 3, 3)" fillcolor=lightblue]
	6072803040 -> 6078840736
	6078840736 [label=AccumulateGrad]
	6078840592 -> 6078840208
	6072802960 [label="
 (288)" fillcolor=lightblue]
	6072802960 -> 6078840592
	6078840592 [label=AccumulateGrad]
	6078839968 -> 6078840208
	6072803120 [label="
 (288)" fillcolor=lightblue]
	6072803120 -> 6078839968
	6078839968 [label=AccumulateGrad]
	6077349728 -> 6079029184
	6077349728 [label="
 (1, 288, 150, 150)" fillcolor=orange]
	6078839440 -> 6078839296
	6072803680 [label="
 (12, 288, 1, 1)" fillcolor=lightblue]
	6072803680 -> 6078839440
	6078839440 [label=AccumulateGrad]
	6078839344 -> 6078839296
	6072803760 [label="
 (12)" fillcolor=lightblue]
	6072803760 -> 6078839344
	6078839344 [label=AccumulateGrad]
	6077349568 -> 6079029408
	6077349568 [label="
 (1, 12, 1, 1)" fillcolor=orange]
	6078838672 -> 6078838432
	6072803920 [label="
 (288, 12, 1, 1)" fillcolor=lightblue]
	6072803920 -> 6078838672
	6078838672 [label=AccumulateGrad]
	6078838912 -> 6078838432
	6072804000 [label="
 (288)" fillcolor=lightblue]
	6072804000 -> 6078838912
	6078838912 [label=AccumulateGrad]
	6079029184 -> 6078838240
	6078837808 -> 6078837712
	6072804160 [label="
 (48, 288, 1, 1)" fillcolor=lightblue]
	6072804160 -> 6078837808
	6078837808 [label=AccumulateGrad]
	6078837664 -> 6078837424
	6072804240 [label="
 (48)" fillcolor=lightblue]
	6072804240 -> 6078837664
	6078837664 [label=AccumulateGrad]
	6078837280 -> 6078837424
	6072804320 [label="
 (48)" fillcolor=lightblue]
	6072804320 -> 6078837280
	6078837280 [label=AccumulateGrad]
	6078837136 -> 6078831952
	6078836944 -> 6078836416
	6072804800 [label="
 (288, 48, 1, 1)" fillcolor=lightblue]
	6072804800 -> 6078836944
	6078836944 [label=AccumulateGrad]
	6078836176 -> 6078836032
	6072804880 [label="
 (288)" fillcolor=lightblue]
	6072804880 -> 6078836176
	6078836176 [label=AccumulateGrad]
	6078835888 -> 6078836032
	6072804960 [label="
 (288)" fillcolor=lightblue]
	6072804960 -> 6078835888
	6078835888 [label=AccumulateGrad]
	6077347808 -> 6079029632
	6077347808 [label="
 (1, 288, 150, 150)" fillcolor=orange]
	6078835936 -> 6078835168
	6072805520 [label="
 (288, 1, 3, 3)" fillcolor=lightblue]
	6072805520 -> 6078835936
	6078835936 [label=AccumulateGrad]
	6078835216 -> 6078838048
	6072805440 [label="
 (288)" fillcolor=lightblue]
	6072805440 -> 6078835216
	6078835216 [label=AccumulateGrad]
	6078834688 -> 6078838048
	6072805600 [label="
 (288)" fillcolor=lightblue]
	6072805600 -> 6078834688
	6078834688 [label=AccumulateGrad]
	6077347728 -> 6079029856
	6077347728 [label="
 (1, 288, 150, 150)" fillcolor=orange]
	6078834208 -> 6078834448
	6072806160 [label="
 (12, 288, 1, 1)" fillcolor=lightblue]
	6072806160 -> 6078834208
	6078834208 [label=AccumulateGrad]
	6078834160 -> 6078834448
	6072806240 [label="
 (12)" fillcolor=lightblue]
	6072806240 -> 6078834160
	6078834160 [label=AccumulateGrad]
	6077347408 -> 6079030080
	6077347408 [label="
 (1, 12, 1, 1)" fillcolor=orange]
	6078833920 -> 6078833536
	6072806400 [label="
 (288, 12, 1, 1)" fillcolor=lightblue]
	6072806400 -> 6078833920
	6078833920 [label=AccumulateGrad]
	6078833728 -> 6078833536
	6072806480 [label="
 (288)" fillcolor=lightblue]
	6072806480 -> 6078833728
	6078833728 [label=AccumulateGrad]
	6079029856 -> 6078832912
	6078833200 -> 6078832768
	6072806640 [label="
 (48, 288, 1, 1)" fillcolor=lightblue]
	6072806640 -> 6078833200
	6078833200 [label=AccumulateGrad]
	6078832384 -> 6078832816
	6072806720 [label="
 (48)" fillcolor=lightblue]
	6072806720 -> 6078832384
	6078832384 [label=AccumulateGrad]
	6078832192 -> 6078832816
	6072806800 [label="
 (48)" fillcolor=lightblue]
	6072806800 -> 6078832192
	6078832192 [label=AccumulateGrad]
	6078831952 -> 6078826384
	6078833584 -> 6078831568
	6072807280 [label="
 (288, 48, 1, 1)" fillcolor=lightblue]
	6072807280 -> 6078833584
	6078833584 [label=AccumulateGrad]
	6078831136 -> 6078831376
	6072807360 [label="
 (288)" fillcolor=lightblue]
	6072807360 -> 6078831136
	6078831136 [label=AccumulateGrad]
	6078831184 -> 6078831376
	6072807440 [label="
 (288)" fillcolor=lightblue]
	6072807440 -> 6078831184
	6078831184 [label=AccumulateGrad]
	6077345408 -> 6079030304
	6077345408 [label="
 (1, 288, 150, 150)" fillcolor=orange]
	6078830704 -> 6078830128
	6072808000 [label="
 (288, 1, 3, 3)" fillcolor=lightblue]
	6072808000 -> 6078830704
	6078830704 [label=AccumulateGrad]
	6078829888 -> 6078830176
	6072807920 [label="
 (288)" fillcolor=lightblue]
	6072807920 -> 6078829888
	6078829888 [label=AccumulateGrad]
	6078829168 -> 6078830176
	6072808080 [label="
 (288)" fillcolor=lightblue]
	6072808080 -> 6078829168
	6078829168 [label=AccumulateGrad]
	6077345248 -> 6079030528
	6077345248 [label="
 (1, 288, 150, 150)" fillcolor=orange]
	6078829456 -> 6078829024
	6072808640 [label="
 (12, 288, 1, 1)" fillcolor=lightblue]
	6072808640 -> 6078829456
	6078829456 [label=AccumulateGrad]
	6078830464 -> 6078829024
	6072808720 [label="
 (12)" fillcolor=lightblue]
	6072808720 -> 6078830464
	6078830464 [label=AccumulateGrad]
	6077344928 -> 6079030752
	6077344928 [label="
 (1, 12, 1, 1)" fillcolor=orange]
	6078828832 -> 6078828448
	6072808880 [label="
 (288, 12, 1, 1)" fillcolor=lightblue]
	6072808880 -> 6078828832
	6078828832 [label=AccumulateGrad]
	6078828688 -> 6078828448
	6072808960 [label="
 (288)" fillcolor=lightblue]
	6072808960 -> 6078828688
	6078828688 [label=AccumulateGrad]
	6079030528 -> 6078828112
	6078827632 -> 6078827392
	6072809120 [label="
 (48, 288, 1, 1)" fillcolor=lightblue]
	6072809120 -> 6078827632
	6078827632 [label=AccumulateGrad]
	6078830416 -> 6078827200
	6072809200 [label="
 (48)" fillcolor=lightblue]
	6072809200 -> 6078830416
	6078830416 [label=AccumulateGrad]
	6078827056 -> 6078827200
	6072809280 [label="
 (48)" fillcolor=lightblue]
	6072809280 -> 6078827056
	6078827056 [label=AccumulateGrad]
	6078826384 -> 6078826144
	6078826672 -> 6078825904
	6072809760 [label="
 (288, 48, 1, 1)" fillcolor=lightblue]
	6072809760 -> 6078826672
	6078826672 [label=AccumulateGrad]
	6078825952 -> 6078828784
	6072809840 [label="
 (288)" fillcolor=lightblue]
	6072809840 -> 6078825952
	6078825952 [label=AccumulateGrad]
	6078825424 -> 6078828784
	6072809920 [label="
 (288)" fillcolor=lightblue]
	6072809920 -> 6078825424
	6078825424 [label=AccumulateGrad]
	6077343168 -> 6079030976
	6077343168 [label="
 (1, 288, 150, 150)" fillcolor=orange]
	6078825136 -> 6078824704
	6072810480 [label="
 (288, 1, 5, 5)" fillcolor=lightblue]
	6072810480 -> 6078825136
	6078825136 [label=AccumulateGrad]
	6078824896 -> 6078824512
	6072810400 [label="
 (288)" fillcolor=lightblue]
	6072810400 -> 6078824896
	6078824896 [label=AccumulateGrad]
	6078825760 -> 6078824512
	6072810560 [label="
 (288)" fillcolor=lightblue]
	6072810560 -> 6078825760
	6078825760 [label=AccumulateGrad]
	6077343008 -> 6079031200
	6077343008 [label="
 (1, 288, 75, 75)" fillcolor=orange]
	6078791344 -> 6078791296
	6072811120 [label="
 (12, 288, 1, 1)" fillcolor=lightblue]
	6072811120 -> 6078791344
	6078791344 [label=AccumulateGrad]
	6078790912 -> 6078791296
	6072811200 [label="
 (12)" fillcolor=lightblue]
	6072811200 -> 6078790912
	6078790912 [label=AccumulateGrad]
	6077342528 -> 6079031424
	6077342528 [label="
 (1, 12, 1, 1)" fillcolor=orange]
	6078790960 -> 6078790768
	6072811360 [label="
 (288, 12, 1, 1)" fillcolor=lightblue]
	6072811360 -> 6078790960
	6078790960 [label=AccumulateGrad]
	6078790528 -> 6078790768
	6072811440 [label="
 (288)" fillcolor=lightblue]
	6072811440 -> 6078790528
	6078790528 [label=AccumulateGrad]
	6079031200 -> 6078790048
	6078790096 -> 6078789712
	6073073808 [label="
 (80, 288, 1, 1)" fillcolor=lightblue]
	6073073808 -> 6078790096
	6078790096 [label=AccumulateGrad]
	6078789568 -> 6078784048
	6073073888 [label="
 (80)" fillcolor=lightblue]
	6073073888 -> 6078789568
	6078789568 [label=AccumulateGrad]
	6078789088 -> 6078784048
	6073073968 [label="
 (80)" fillcolor=lightblue]
	6073073968 -> 6078789088
	6078789088 [label=AccumulateGrad]
	6078789520 -> 6078788848
	6073074368 [label="
 (480, 80, 1, 1)" fillcolor=lightblue]
	6073074368 -> 6078789520
	6078789520 [label=AccumulateGrad]
	6078789040 -> 6078788560
	6073074448 [label="
 (480)" fillcolor=lightblue]
	6073074448 -> 6078789040
	6078789040 [label=AccumulateGrad]
	6078791488 -> 6078788560
	6073074528 [label="
 (480)" fillcolor=lightblue]
	6073074528 -> 6078791488
	6078791488 [label=AccumulateGrad]
	6077341008 -> 6079031648
	6077341008 [label="
 (1, 480, 75, 75)" fillcolor=orange]
	6078789808 -> 6078788032
	6073075088 [label="
 (480, 1, 5, 5)" fillcolor=lightblue]
	6073075088 -> 6078789808
	6078789808 [label=AccumulateGrad]
	6078787792 -> 6078787600
	6073075008 [label="
 (480)" fillcolor=lightblue]
	6073075008 -> 6078787792
	6078787792 [label=AccumulateGrad]
	6078787168 -> 6078787600
	6073075168 [label="
 (480)" fillcolor=lightblue]
	6073075168 -> 6078787168
	6078787168 [label=AccumulateGrad]
	6077340368 -> 6079031872
	6077340368 [label="
 (1, 480, 75, 75)" fillcolor=orange]
	6078786928 -> 6078786544
	6073075728 [label="
 (20, 480, 1, 1)" fillcolor=lightblue]
	6073075728 -> 6078786928
	6078786928 [label=AccumulateGrad]
	6078786592 -> 6078786544
	6073075808 [label="
 (20)" fillcolor=lightblue]
	6073075808 -> 6078786592
	6078786592 [label=AccumulateGrad]
	6077340048 -> 6079032096
	6077340048 [label="
 (1, 20, 1, 1)" fillcolor=orange]
	6078786400 -> 6078786064
	6073075968 [label="
 (480, 20, 1, 1)" fillcolor=lightblue]
	6073075968 -> 6078786400
	6078786400 [label=AccumulateGrad]
	6078786256 -> 6078786064
	6073076048 [label="
 (480)" fillcolor=lightblue]
	6073076048 -> 6078786256
	6078786256 [label=AccumulateGrad]
	6079031872 -> 6078785776
	6078785584 -> 6078785200
	6073076208 [label="
 (80, 480, 1, 1)" fillcolor=lightblue]
	6073076208 -> 6078785584
	6078785584 [label=AccumulateGrad]
	6078785152 -> 6078785008
	6073076288 [label="
 (80)" fillcolor=lightblue]
	6073076288 -> 6078785152
	6078785152 [label=AccumulateGrad]
	6078784288 -> 6078785008
	6073076368 [label="
 (80)" fillcolor=lightblue]
	6073076368 -> 6078784288
	6078784288 [label=AccumulateGrad]
	6078784048 -> 6078779392
	6078784576 -> 6078783952
	6073076848 [label="
 (480, 80, 1, 1)" fillcolor=lightblue]
	6073076848 -> 6078784576
	6078784576 [label=AccumulateGrad]
	6078786976 -> 6078783520
	6073076928 [label="
 (480)" fillcolor=lightblue]
	6073076928 -> 6078786976
	6078786976 [label=AccumulateGrad]
	6078783280 -> 6078783520
	6073077008 [label="
 (480)" fillcolor=lightblue]
	6073077008 -> 6078783280
	6078783280 [label=AccumulateGrad]
	6077338048 -> 6079032320
	6077338048 [label="
 (1, 480, 75, 75)" fillcolor=orange]
	6078782848 -> 6078782800
	6073077568 [label="
 (480, 1, 5, 5)" fillcolor=lightblue]
	6073077568 -> 6078782848
	6078782848 [label=AccumulateGrad]
	6078782416 -> 6078782656
	6073077488 [label="
 (480)" fillcolor=lightblue]
	6073077488 -> 6078782416
	6078782416 [label=AccumulateGrad]
	6078782080 -> 6078782656
	6073077648 [label="
 (480)" fillcolor=lightblue]
	6073077648 -> 6078782080
	6078782080 [label=AccumulateGrad]
	6077337968 -> 6079032544
	6077337968 [label="
 (1, 480, 75, 75)" fillcolor=orange]
	6078781744 -> 6078781936
	6073078208 [label="
 (20, 480, 1, 1)" fillcolor=lightblue]
	6073078208 -> 6078781744
	6078781744 [label=AccumulateGrad]
	6078781264 -> 6078781936
	6073078288 [label="
 (20)" fillcolor=lightblue]
	6073078288 -> 6078781264
	6078781264 [label=AccumulateGrad]
	6077337808 -> 6079032768
	6077337808 [label="
 (1, 20, 1, 1)" fillcolor=orange]
	6078780976 -> 6078781024
	6073078448 [label="
 (480, 20, 1, 1)" fillcolor=lightblue]
	6073078448 -> 6078780976
	6078780976 [label=AccumulateGrad]
	6078781552 -> 6078781024
	6073078528 [label="
 (480)" fillcolor=lightblue]
	6073078528 -> 6078781552
	6078781552 [label=AccumulateGrad]
	6079032544 -> 6078780448
	6078780640 -> 6078780208
	6073078688 [label="
 (80, 480, 1, 1)" fillcolor=lightblue]
	6073078688 -> 6078780640
	6078780640 [label=AccumulateGrad]
	6078779968 -> 6078779776
	6073078768 [label="
 (80)" fillcolor=lightblue]
	6073078768 -> 6078779968
	6078779968 [label=AccumulateGrad]
	6078779344 -> 6078779776
	6073078848 [label="
 (80)" fillcolor=lightblue]
	6073078848 -> 6078779344
	6078779344 [label=AccumulateGrad]
	6078779392 -> 6078676368
	6078779200 -> 6078778720
	6073079328 [label="
 (480, 80, 1, 1)" fillcolor=lightblue]
	6073079328 -> 6078779200
	6078779200 [label=AccumulateGrad]
	6078778480 -> 6078778768
	6073079408 [label="
 (480)" fillcolor=lightblue]
	6073079408 -> 6078778480
	6078778480 [label=AccumulateGrad]
	6078777856 -> 6078778768
	6073079488 [label="
 (480)" fillcolor=lightblue]
	6073079488 -> 6078777856
	6078777856 [label=AccumulateGrad]
	6077336128 -> 6079032992
	6077336128 [label="
 (1, 480, 75, 75)" fillcolor=orange]
	6078777904 -> 6078777760
	6073080048 [label="
 (480, 1, 5, 5)" fillcolor=lightblue]
	6073080048 -> 6078777904
	6078777904 [label=AccumulateGrad]
	6078780592 -> 6078777328
	6073079968 [label="
 (480)" fillcolor=lightblue]
	6073079968 -> 6078780592
	6078780592 [label=AccumulateGrad]
	6078777184 -> 6078777328
	6073080128 [label="
 (480)" fillcolor=lightblue]
	6073080128 -> 6078777184
	6078777184 [label=AccumulateGrad]
	6077336048 -> 6079033216
	6077336048 [label="
 (1, 480, 75, 75)" fillcolor=orange]
	6078776992 -> 6078776512
	6073080688 [label="
 (20, 480, 1, 1)" fillcolor=lightblue]
	6073080688 -> 6078776992
	6078776992 [label=AccumulateGrad]
	6078776224 -> 6078776512
	6073080768 [label="
 (20)" fillcolor=lightblue]
	6073080768 -> 6078776224
	6078776224 [label=AccumulateGrad]
	6077335728 -> 6079033440
	6077335728 [label="
 (1, 20, 1, 1)" fillcolor=orange]
	6078776272 -> 6078779248
	6073080928 [label="
 (480, 20, 1, 1)" fillcolor=lightblue]
	6073080928 -> 6078776272
	6078776272 [label=AccumulateGrad]
	6078776080 -> 6078779248
	6073081008 [label="
 (480)" fillcolor=lightblue]
	6073081008 -> 6078776080
	6078776080 [label=AccumulateGrad]
	6079033216 -> 6078775744
	6078775504 -> 6078676608
	6073081168 [label="
 (80, 480, 1, 1)" fillcolor=lightblue]
	6073081168 -> 6078775504
	6078775504 [label=AccumulateGrad]
	6078676656 -> 6078676848
	6073081248 [label="
 (80)" fillcolor=lightblue]
	6073081248 -> 6078676656
	6078676656 [label=AccumulateGrad]
	6078788464 -> 6078676848
	6073081328 [label="
 (80)" fillcolor=lightblue]
	6073081328 -> 6078788464
	6078788464 [label=AccumulateGrad]
	6078676368 -> 6078670896
	6078675840 -> 6078675600
	6073081808 [label="
 (480, 80, 1, 1)" fillcolor=lightblue]
	6073081808 -> 6078675840
	6078675840 [label=AccumulateGrad]
	6078675360 -> 6078675264
	6073081888 [label="
 (480)" fillcolor=lightblue]
	6073081888 -> 6078675360
	6078675360 [label=AccumulateGrad]
	6078674832 -> 6078675264
	6073081968 [label="
 (480)" fillcolor=lightblue]
	6073081968 -> 6078674832
	6078674832 [label=AccumulateGrad]
	6077333968 -> 6079033664
	6077333968 [label="
 (1, 480, 75, 75)" fillcolor=orange]
	6078674880 -> 6078676080
	6073082528 [label="
 (480, 1, 5, 5)" fillcolor=lightblue]
	6073082528 -> 6078674880
	6078674880 [label=AccumulateGrad]
	6078674496 -> 6078674352
	6073082448 [label="
 (480)" fillcolor=lightblue]
	6073082448 -> 6078674496
	6078674496 [label=AccumulateGrad]
	6078674112 -> 6078674352
	6073082608 [label="
 (480)" fillcolor=lightblue]
	6073082608 -> 6078674112
	6078674112 [label=AccumulateGrad]
	6077333808 -> 6079033888
	6077333808 [label="
 (1, 480, 75, 75)" fillcolor=orange]
	6078673344 -> 6078673584
	6073083168 [label="
 (20, 480, 1, 1)" fillcolor=lightblue]
	6073083168 -> 6078673344
	6078673344 [label=AccumulateGrad]
	6078673200 -> 6078673584
	6073083248 [label="
 (20)" fillcolor=lightblue]
	6073083248 -> 6078673200
	6078673200 [label=AccumulateGrad]
	6077052976 -> 6079034112
	6077052976 [label="
 (1, 20, 1, 1)" fillcolor=orange]
	6078673104 -> 6078672624
	6073083408 [label="
 (480, 20, 1, 1)" fillcolor=lightblue]
	6073083408 -> 6078673104
	6078673104 [label=AccumulateGrad]
	6078672864 -> 6078672624
	6073083488 [label="
 (480)" fillcolor=lightblue]
	6073083488 -> 6078672864
	6078672864 [label=AccumulateGrad]
	6079033888 -> 6078672000
	6078672096 -> 6078671856
	6073083648 [label="
 (80, 480, 1, 1)" fillcolor=lightblue]
	6073083648 -> 6078672096
	6078672096 [label=AccumulateGrad]
	6078671568 -> 6078673056
	6073083728 [label="
 (80)" fillcolor=lightblue]
	6073083728 -> 6078671568
	6078671568 [label=AccumulateGrad]
	6078670848 -> 6078673056
	6073083808 [label="
 (80)" fillcolor=lightblue]
	6073083808 -> 6078670848
	6078670848 [label=AccumulateGrad]
	6078670896 -> 6078665952
	6078670464 -> 6078670368
	6073084288 [label="
 (480, 80, 1, 1)" fillcolor=lightblue]
	6073084288 -> 6078670464
	6078670464 [label=AccumulateGrad]
	6078670512 -> 6078670080
	6073084368 [label="
 (480)" fillcolor=lightblue]
	6073084368 -> 6078670512
	6078670512 [label=AccumulateGrad]
	6078669984 -> 6078670080
	6073084448 [label="
 (480)" fillcolor=lightblue]
	6073084448 -> 6078669984
	6078669984 [label=AccumulateGrad]
	6077044976 -> 6079034336
	6077044976 [label="
 (1, 480, 75, 75)" fillcolor=orange]
	6078669600 -> 6078669120
	6073085008 [label="
 (480, 1, 5, 5)" fillcolor=lightblue]
	6073085008 -> 6078669600
	6078669600 [label=AccumulateGrad]
	6078669360 -> 6078668880
	6073084928 [label="
 (480)" fillcolor=lightblue]
	6073084928 -> 6078669360
	6078669360 [label=AccumulateGrad]
	6078668736 -> 6078668880
	6073085088 [label="
 (480)" fillcolor=lightblue]
	6073085088 -> 6078668736
	6078668736 [label=AccumulateGrad]
	6077042496 -> 6079034560
	6077042496 [label="
 (1, 480, 75, 75)" fillcolor=orange]
	6078668352 -> 6078668304
	6073085648 [label="
 (20, 480, 1, 1)" fillcolor=lightblue]
	6073085648 -> 6078668352
	6078668352 [label=AccumulateGrad]
	6078667824 -> 6078668304
	6073085728 [label="
 (20)" fillcolor=lightblue]
	6073085728 -> 6078667824
	6078667824 [label=AccumulateGrad]
	6077053776 -> 6079034784
	6077053776 [label="
 (1, 20, 1, 1)" fillcolor=orange]
	6078667872 -> 6078667584
	6073085888 [label="
 (480, 20, 1, 1)" fillcolor=lightblue]
	6073085888 -> 6078667872
	6078667872 [label=AccumulateGrad]
	6078667440 -> 6078667584
	6073085968 [label="
 (480)" fillcolor=lightblue]
	6073085968 -> 6078667440
	6078667440 [label=AccumulateGrad]
	6079034560 -> 6078667056
	6078667104 -> 6078666864
	6073086128 [label="
 (80, 480, 1, 1)" fillcolor=lightblue]
	6073086128 -> 6078667104
	6078667104 [label=AccumulateGrad]
	6078666624 -> 6078666384
	6073086208 [label="
 (80)" fillcolor=lightblue]
	6073086208 -> 6078666624
	6078666624 [label=AccumulateGrad]
	6078666240 -> 6078666384
	6073086288 [label="
 (80)" fillcolor=lightblue]
	6073086288 -> 6078666240
	6078666240 [label=AccumulateGrad]
	6078665952 -> 6078662352
	6078665568 -> 6078668592
	6073086768 [label="
 (480, 80, 1, 1)" fillcolor=lightblue]
	6073086768 -> 6078665568
	6078665568 [label=AccumulateGrad]
	6078665328 -> 6078665280
	6073086848 [label="
 (480)" fillcolor=lightblue]
	6073086848 -> 6078665328
	6078665328 [label=AccumulateGrad]
	6078664848 -> 6078665280
	6073086928 [label="
 (480)" fillcolor=lightblue]
	6073086928 -> 6078664848
	6078664848 [label=AccumulateGrad]
	6077050416 -> 6079035008
	6077050416 [label="
 (1, 480, 75, 75)" fillcolor=orange]
	6078664560 -> 6078664224
	6073087488 [label="
 (480, 1, 5, 5)" fillcolor=lightblue]
	6073087488 -> 6078664560
	6078664560 [label=AccumulateGrad]
	6078664032 -> 6078664080
	6073087408 [label="
 (480)" fillcolor=lightblue]
	6073087408 -> 6078664032
	6078664032 [label=AccumulateGrad]
	6078663312 -> 6078664080
	6073087568 [label="
 (480)" fillcolor=lightblue]
	6073087568 -> 6078663312
	6078663312 [label=AccumulateGrad]
	6077049536 -> 6079035232
	6077049536 [label="
 (1, 480, 75, 75)" fillcolor=orange]
	6078663120 -> 6078662832
	6073088128 [label="
 (20, 480, 1, 1)" fillcolor=lightblue]
	6073088128 -> 6078663120
	6078663120 [label=AccumulateGrad]
	6078662544 -> 6078662832
	6073088288 [label="
 (20)" fillcolor=lightblue]
	6073088288 -> 6078662544
	6078662544 [label=AccumulateGrad]
	6077048816 -> 6079035456
	6077048816 [label="
 (1, 20, 1, 1)" fillcolor=orange]
	6078662592 -> 6078665472
	6073088448 [label="
 (480, 20, 1, 1)" fillcolor=lightblue]
	6073088448 -> 6078662592
	6078662592 [label=AccumulateGrad]
	6078662304 -> 6078665472
	6073088528 [label="
 (480)" fillcolor=lightblue]
	6073088528 -> 6078662304
	6078662304 [label=AccumulateGrad]
	6079035232 -> 6078661872
	6078661728 -> 6078661056
	6073088688 [label="
 (80, 480, 1, 1)" fillcolor=lightblue]
	6073088688 -> 6078661728
	6078661728 [label=AccumulateGrad]
	6078661488 -> 6078661104
	6073088768 [label="
 (80)" fillcolor=lightblue]
	6073088768 -> 6078661488
	6078661488 [label=AccumulateGrad]
	6078663792 -> 6078661104
	6073088848 [label="
 (80)" fillcolor=lightblue]
	6073088848 -> 6078663792
	6078663792 [label=AccumulateGrad]
	6078662352 -> 6077546352
	6077546400 -> 6077546112
	6077459936 [label="
 (256, 80, 1, 1)" fillcolor=lightblue]
	6077459936 -> 6077546400
	6077546400 [label=AccumulateGrad]
	6077546160 -> 6077546112
	6077459776 [label="
 (256)" fillcolor=lightblue]
	6077459776 -> 6077546160
	6077546160 [label=AccumulateGrad]
	6077545872 -> 6077545536
	6077545872 [label="UpsampleNearest2DBackward0
--------------------------------
output_size   :         (75, 75)
scales_h      :             None
scales_w      :             None
self_sym_sizes: (1, 256, 38, 38)"]
	6078660960 -> 6077545872
	6078660960 [label="AddBackward0
------------
alpha: 1"]
	6078661440 -> 6078660960
	6078661440 -> 6076992944 [dir=none]
	6076992944 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6078661440 -> 6077460576 [dir=none]
	6077460576 [label="weight
 (256, 224, 1, 1)" fillcolor=orange]
	6078661440 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (256,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078662112 -> 6078661440
	6078662112 [label="AddBackward0
------------
alpha: 1"]
	6078663552 -> 6078662112
	6078663552 -> 6076992784 [dir=none]
	6076992784 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6078663552 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078664176 -> 6078663552
	6078664176 -> 11670942192 [dir=none]
	11670942192 [label="other
 ()" fillcolor=orange]
	6078664176 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078665040 -> 6078664176
	6078665040 -> 6076993104 [dir=none]
	6076993104 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6078665040 -> 11670941392 [dir=none]
	11670941392 [label="result1
 (224)" fillcolor=orange]
	6078665040 -> 11670941552 [dir=none]
	11670941552 [label="result2
 (224)" fillcolor=orange]
	6078665040 -> 6075808512 [dir=none]
	6075808512 [label="running_mean
 (224)" fillcolor=orange]
	6078665040 -> 6075808832 [dir=none]
	6075808832 [label="running_var
 (224)" fillcolor=orange]
	6078665040 -> 6075808672 [dir=none]
	6075808672 [label="weight
 (224)" fillcolor=orange]
	6078665040 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078665808 -> 6078665040
	6078665808 -> 6076993184 [dir=none]
	6076993184 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6078665808 -> 6075808592 [dir=none]
	6075808592 [label="weight
 (224, 1344, 1, 1)" fillcolor=orange]
	6078665808 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078666576 -> 6078665808
	6078666576 -> 6076993824 [dir=none]
	6076993824 [label="other
 (1, 1344, 38, 38)" fillcolor=orange]
	6078666576 -> 6076993584 [dir=none]
	6076993584 [label="self
 (1, 1344, 1, 1)" fillcolor=orange]
	6078666576 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6078667296 -> 6078666576
	6078667296 -> 11670941072 [dir=none]
	11670941072 [label="result
 (1, 1344, 1, 1)" fillcolor=orange]
	6078667296 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6078668064 -> 6078667296
	6078668064 -> 6076993424 [dir=none]
	6076993424 [label="input
 (1, 56, 1, 1)" fillcolor=orange]
	6078668064 -> 6075808352 [dir=none]
	6075808352 [label="weight
 (1344, 56, 1, 1)" fillcolor=orange]
	6078668064 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (1344,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078606784 -> 6078668064
	6078606784 [label=SwishImplementationBackward]
	6078670752 -> 6078606784
	6078670752 -> 6076994224 [dir=none]
	6076994224 [label="input
 (1, 1344, 1, 1)" fillcolor=orange]
	6078670752 -> 6075808112 [dir=none]
	6075808112 [label="weight
 (56, 1344, 1, 1)" fillcolor=orange]
	6078670752 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (56,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078673248 -> 6078670752
	6078673248 -> 6076993824 [dir=none]
	6076993824 [label="self
 (1, 1344, 38, 38)" fillcolor=orange]
	6078673248 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 1344, 38, 38)"]
	6078606560 -> 6078673248
	6078606560 [label=SwishImplementationBackward]
	6078671808 -> 6078606560
	6078671808 -> 6076994624 [dir=none]
	6076994624 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6078671808 -> 11670939552 [dir=none]
	11670939552 [label="result1
 (1344)" fillcolor=orange]
	6078671808 -> 11670939392 [dir=none]
	11670939392 [label="result2
 (1344)" fillcolor=orange]
	6078671808 -> 6075805872 [dir=none]
	6075805872 [label="running_mean
 (1344)" fillcolor=orange]
	6078671808 -> 6075807632 [dir=none]
	6075807632 [label="running_var
 (1344)" fillcolor=orange]
	6078671808 -> 6075807392 [dir=none]
	6075807392 [label="weight
 (1344)" fillcolor=orange]
	6078671808 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078672576 -> 6078671808
	6078672576 -> 6076994704 [dir=none]
	6076994704 [label="input
 (1, 1344, 42, 42)" fillcolor=orange]
	6078672576 -> 6075807472 [dir=none]
	6075807472 [label="weight
 (1344, 1, 5, 5)" fillcolor=orange]
	6078672576 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1344
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078674064 -> 6078672576
	6078674064 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6078606336 -> 6078674064
	6078606336 [label=SwishImplementationBackward]
	6078675408 -> 6078606336
	6078675408 -> 6076995744 [dir=none]
	6076995744 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6078675408 -> 11670938512 [dir=none]
	11670938512 [label="result1
 (1344)" fillcolor=orange]
	6078675408 -> 11670938352 [dir=none]
	11670938352 [label="result2
 (1344)" fillcolor=orange]
	6078675408 -> 6075806512 [dir=none]
	6075806512 [label="running_mean
 (1344)" fillcolor=orange]
	6078675408 -> 6075806992 [dir=none]
	6075806992 [label="running_var
 (1344)" fillcolor=orange]
	6078675408 -> 6075806752 [dir=none]
	6075806752 [label="weight
 (1344)" fillcolor=orange]
	6078675408 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078676128 -> 6078675408
	6078676128 -> 6076994944 [dir=none]
	6076994944 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6078676128 -> 6075806832 [dir=none]
	6075806832 [label="weight
 (1344, 224, 1, 1)" fillcolor=orange]
	6078676128 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078663072 -> 6078676128
	6078663072 [label="AddBackward0
------------
alpha: 1"]
	6078775456 -> 6078663072
	6078775456 -> 6076994864 [dir=none]
	6076994864 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6078775456 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078776704 -> 6078775456
	6078776704 -> 11670937792 [dir=none]
	11670937792 [label="other
 ()" fillcolor=orange]
	6078776704 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078777376 -> 6078776704
	6078777376 -> 6076995104 [dir=none]
	6076995104 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6078777376 -> 11670937232 [dir=none]
	11670937232 [label="result1
 (224)" fillcolor=orange]
	6078777376 -> 11670937392 [dir=none]
	11670937392 [label="result2
 (224)" fillcolor=orange]
	6078777376 -> 6075806112 [dir=none]
	6075806112 [label="running_mean
 (224)" fillcolor=orange]
	6078777376 -> 6075806432 [dir=none]
	6075806432 [label="running_var
 (224)" fillcolor=orange]
	6078777376 -> 6075806272 [dir=none]
	6075806272 [label="weight
 (224)" fillcolor=orange]
	6078777376 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078777712 -> 6078777376
	6078777712 -> 6076995264 [dir=none]
	6076995264 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6078777712 -> 6075806192 [dir=none]
	6075806192 [label="weight
 (224, 1344, 1, 1)" fillcolor=orange]
	6078777712 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078778096 -> 6078777712
	6078778096 -> 6076995904 [dir=none]
	6076995904 [label="other
 (1, 1344, 38, 38)" fillcolor=orange]
	6078778096 -> 6076995584 [dir=none]
	6076995584 [label="self
 (1, 1344, 1, 1)" fillcolor=orange]
	6078778096 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6078779728 -> 6078778096
	6078779728 -> 11670937072 [dir=none]
	11670937072 [label="result
 (1, 1344, 1, 1)" fillcolor=orange]
	6078779728 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6078780256 -> 6078779728
	6078780256 -> 6076995344 [dir=none]
	6076995344 [label="input
 (1, 56, 1, 1)" fillcolor=orange]
	6078780256 -> 6075805952 [dir=none]
	6075805952 [label="weight
 (1344, 56, 1, 1)" fillcolor=orange]
	6078780256 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (1344,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078606112 -> 6078780256
	6078606112 [label=SwishImplementationBackward]
	6078782032 -> 6078606112
	6078782032 -> 6076996144 [dir=none]
	6076996144 [label="input
 (1, 1344, 1, 1)" fillcolor=orange]
	6078782032 -> 6075805712 [dir=none]
	6075805712 [label="weight
 (56, 1344, 1, 1)" fillcolor=orange]
	6078782032 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (56,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078782464 -> 6078782032
	6078782464 -> 6076995904 [dir=none]
	6076995904 [label="self
 (1, 1344, 38, 38)" fillcolor=orange]
	6078782464 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 1344, 38, 38)"]
	6078605888 -> 6078782464
	6078605888 [label=SwishImplementationBackward]
	6078784096 -> 6078605888
	6078784096 -> 6076996464 [dir=none]
	6076996464 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6078784096 -> 11670935712 [dir=none]
	11670935712 [label="result1
 (1344)" fillcolor=orange]
	6078784096 -> 11670935552 [dir=none]
	11670935552 [label="result2
 (1344)" fillcolor=orange]
	6078784096 -> 6075803392 [dir=none]
	6075803392 [label="running_mean
 (1344)" fillcolor=orange]
	6078784096 -> 6075805232 [dir=none]
	6075805232 [label="running_var
 (1344)" fillcolor=orange]
	6078784096 -> 6075804992 [dir=none]
	6075804992 [label="weight
 (1344)" fillcolor=orange]
	6078784096 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078784816 -> 6078784096
	6078784816 -> 6076996624 [dir=none]
	6076996624 [label="input
 (1, 1344, 42, 42)" fillcolor=orange]
	6078784816 -> 6075805072 [dir=none]
	6075805072 [label="weight
 (1344, 1, 5, 5)" fillcolor=orange]
	6078784816 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1344
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078785536 -> 6078784816
	6078785536 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6078605664 -> 6078785536
	6078605664 [label=SwishImplementationBackward]
	6078787360 -> 6078605664
	6078787360 -> 6076997664 [dir=none]
	6076997664 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6078787360 -> 11670934592 [dir=none]
	11670934592 [label="result1
 (1344)" fillcolor=orange]
	6078787360 -> 11670934432 [dir=none]
	11670934432 [label="result2
 (1344)" fillcolor=orange]
	6078787360 -> 6075804272 [dir=none]
	6075804272 [label="running_mean
 (1344)" fillcolor=orange]
	6078787360 -> 6075804592 [dir=none]
	6075804592 [label="running_var
 (1344)" fillcolor=orange]
	6078787360 -> 6075804432 [dir=none]
	6075804432 [label="weight
 (1344)" fillcolor=orange]
	6078787360 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078788080 -> 6078787360
	6078788080 -> 6076997024 [dir=none]
	6076997024 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6078788080 -> 6075804352 [dir=none]
	6075804352 [label="weight
 (1344, 224, 1, 1)" fillcolor=orange]
	6078788080 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078777472 -> 6078788080
	6078777472 [label="AddBackward0
------------
alpha: 1"]
	6078790576 -> 6078777472
	6078790576 -> 6076996784 [dir=none]
	6076996784 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6078790576 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078790288 -> 6078790576
	6078790288 -> 11670933872 [dir=none]
	11670933872 [label="other
 ()" fillcolor=orange]
	6078790288 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078791056 -> 6078790288
	6078791056 -> 6076997184 [dir=none]
	6076997184 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6078791056 -> 11670933232 [dir=none]
	11670933232 [label="result1
 (224)" fillcolor=orange]
	6078791056 -> 11670933392 [dir=none]
	11670933392 [label="result2
 (224)" fillcolor=orange]
	6078791056 -> 6075803632 [dir=none]
	6075803632 [label="running_mean
 (224)" fillcolor=orange]
	6078791056 -> 6075803952 [dir=none]
	6075803952 [label="running_var
 (224)" fillcolor=orange]
	6078791056 -> 6075803792 [dir=none]
	6075803792 [label="weight
 (224)" fillcolor=orange]
	6078791056 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078789664 -> 6078791056
	6078789664 -> 6076997344 [dir=none]
	6076997344 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6078789664 -> 6075803712 [dir=none]
	6075803712 [label="weight
 (224, 1344, 1, 1)" fillcolor=orange]
	6078789664 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078826432 -> 6078789664
	6078826432 -> 6076997824 [dir=none]
	6076997824 [label="other
 (1, 1344, 38, 38)" fillcolor=orange]
	6078826432 -> 6076997584 [dir=none]
	6076997584 [label="self
 (1, 1344, 1, 1)" fillcolor=orange]
	6078826432 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6078826192 -> 6078826432
	6078826192 -> 11670933072 [dir=none]
	11670933072 [label="result
 (1, 1344, 1, 1)" fillcolor=orange]
	6078826192 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6078826864 -> 6078826192
	6078826864 -> 6076997424 [dir=none]
	6076997424 [label="input
 (1, 56, 1, 1)" fillcolor=orange]
	6078826864 -> 6075803472 [dir=none]
	6075803472 [label="weight
 (1344, 56, 1, 1)" fillcolor=orange]
	6078826864 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (1344,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078605440 -> 6078826864
	6078605440 [label=SwishImplementationBackward]
	6078828304 -> 6078605440
	6078828304 -> 6076998064 [dir=none]
	6076998064 [label="input
 (1, 1344, 1, 1)" fillcolor=orange]
	6078828304 -> 6075803232 [dir=none]
	6075803232 [label="weight
 (56, 1344, 1, 1)" fillcolor=orange]
	6078828304 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (56,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078829696 -> 6078828304
	6078829696 -> 6076997824 [dir=none]
	6076997824 [label="self
 (1, 1344, 38, 38)" fillcolor=orange]
	6078829696 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 1344, 38, 38)"]
	6078605216 -> 6078829696
	6078605216 [label=SwishImplementationBackward]
	6078830896 -> 6078605216
	6078830896 -> 6076998544 [dir=none]
	6076998544 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6078830896 -> 11670931712 [dir=none]
	11670931712 [label="result1
 (1344)" fillcolor=orange]
	6078830896 -> 11670931552 [dir=none]
	11670931552 [label="result2
 (1344)" fillcolor=orange]
	6078830896 -> 6075800912 [dir=none]
	6075800912 [label="running_mean
 (1344)" fillcolor=orange]
	6078830896 -> 6075802752 [dir=none]
	6075802752 [label="running_var
 (1344)" fillcolor=orange]
	6078830896 -> 6075802512 [dir=none]
	6075802512 [label="weight
 (1344)" fillcolor=orange]
	6078830896 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078831664 -> 6078830896
	6078831664 -> 6076998704 [dir=none]
	6076998704 [label="input
 (1, 1344, 42, 42)" fillcolor=orange]
	6078831664 -> 6075802592 [dir=none]
	6075802592 [label="weight
 (1344, 1, 5, 5)" fillcolor=orange]
	6078831664 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1344
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078832624 -> 6078831664
	6078832624 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6078604992 -> 6078832624
	6078604992 [label=SwishImplementationBackward]
	6078833968 -> 6078604992
	6078833968 -> 6076999984 [dir=none]
	6076999984 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6078833968 -> 11670930672 [dir=none]
	11670930672 [label="result1
 (1344)" fillcolor=orange]
	6078833968 -> 11670930512 [dir=none]
	11670930512 [label="result2
 (1344)" fillcolor=orange]
	6078833968 -> 6075801792 [dir=none]
	6075801792 [label="running_mean
 (1344)" fillcolor=orange]
	6078833968 -> 6075802112 [dir=none]
	6075802112 [label="running_var
 (1344)" fillcolor=orange]
	6078833968 -> 6075801952 [dir=none]
	6075801952 [label="weight
 (1344)" fillcolor=orange]
	6078833968 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078834976 -> 6078833968
	6078834976 -> 6076999104 [dir=none]
	6076999104 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6078834976 -> 6075801872 [dir=none]
	6075801872 [label="weight
 (1344, 224, 1, 1)" fillcolor=orange]
	6078834976 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078789280 -> 6078834976
	6078789280 [label="AddBackward0
------------
alpha: 1"]
	6078836080 -> 6078789280
	6078836080 -> 6076998864 [dir=none]
	6076998864 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6078836080 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078837184 -> 6078836080
	6078837184 -> 11670929872 [dir=none]
	11670929872 [label="other
 ()" fillcolor=orange]
	6078837184 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078837856 -> 6078837184
	6078837856 -> 6076999264 [dir=none]
	6076999264 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6078837856 -> 11670934352 [dir=none]
	11670934352 [label="result1
 (224)" fillcolor=orange]
	6078837856 -> 11670937872 [dir=none]
	11670937872 [label="result2
 (224)" fillcolor=orange]
	6078837856 -> 6075801152 [dir=none]
	6075801152 [label="running_mean
 (224)" fillcolor=orange]
	6078837856 -> 6075801472 [dir=none]
	6075801472 [label="running_var
 (224)" fillcolor=orange]
	6078837856 -> 6075801312 [dir=none]
	6075801312 [label="weight
 (224)" fillcolor=orange]
	6078837856 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078838192 -> 6078837856
	6078838192 -> 6076999424 [dir=none]
	6076999424 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6078838192 -> 6075801232 [dir=none]
	6075801232 [label="weight
 (224, 1344, 1, 1)" fillcolor=orange]
	6078838192 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078839680 -> 6078838192
	6078839680 -> 6077000144 [dir=none]
	6077000144 [label="other
 (1, 1344, 38, 38)" fillcolor=orange]
	6078839680 -> 6076999824 [dir=none]
	6076999824 [label="self
 (1, 1344, 1, 1)" fillcolor=orange]
	6078839680 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6078840544 -> 6078839680
	6078840544 -> 6172402096 [dir=none]
	6172402096 [label="result
 (1, 1344, 1, 1)" fillcolor=orange]
	6078840544 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6078839920 -> 6078840544
	6078839920 -> 6076999504 [dir=none]
	6076999504 [label="input
 (1, 56, 1, 1)" fillcolor=orange]
	6078839920 -> 6075800992 [dir=none]
	6075800992 [label="weight
 (1344, 56, 1, 1)" fillcolor=orange]
	6078839920 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (1344,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078604768 -> 6078839920
	6078604768 [label=SwishImplementationBackward]
	6078939632 -> 6078604768
	6078939632 -> 6077000384 [dir=none]
	6077000384 [label="input
 (1, 1344, 1, 1)" fillcolor=orange]
	6078939632 -> 6075800752 [dir=none]
	6075800752 [label="weight
 (56, 1344, 1, 1)" fillcolor=orange]
	6078939632 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (56,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078940784 -> 6078939632
	6078940784 -> 6077000144 [dir=none]
	6077000144 [label="self
 (1, 1344, 38, 38)" fillcolor=orange]
	6078940784 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 1344, 38, 38)"]
	6078604544 -> 6078940784
	6078604544 [label=SwishImplementationBackward]
	6078942848 -> 6078604544
	6078942848 -> 6077000784 [dir=none]
	6077000784 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6078942848 -> 6172402336 [dir=none]
	6172402336 [label="result1
 (1344)" fillcolor=orange]
	6078942848 -> 6172401936 [dir=none]
	6172401936 [label="result2
 (1344)" fillcolor=orange]
	6078942848 -> 6075798432 [dir=none]
	6075798432 [label="running_mean
 (1344)" fillcolor=orange]
	6078942848 -> 6075800272 [dir=none]
	6075800272 [label="running_var
 (1344)" fillcolor=orange]
	6078942848 -> 6075800032 [dir=none]
	6075800032 [label="weight
 (1344)" fillcolor=orange]
	6078942848 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078943136 -> 6078942848
	6078943136 -> 6077001104 [dir=none]
	6077001104 [label="input
 (1, 1344, 42, 42)" fillcolor=orange]
	6078943136 -> 6075800112 [dir=none]
	6075800112 [label="weight
 (1344, 1, 5, 5)" fillcolor=orange]
	6078943136 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1344
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078943904 -> 6078943136
	6078943904 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6078604320 -> 6078943904
	6078604320 [label=SwishImplementationBackward]
	6078945488 -> 6078604320
	6078945488 -> 6077002064 [dir=none]
	6077002064 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6078945488 -> 6172400976 [dir=none]
	6172400976 [label="result1
 (1344)" fillcolor=orange]
	6078945488 -> 6172400816 [dir=none]
	6172400816 [label="result2
 (1344)" fillcolor=orange]
	6078945488 -> 6075799312 [dir=none]
	6075799312 [label="running_mean
 (1344)" fillcolor=orange]
	6078945488 -> 6075799632 [dir=none]
	6075799632 [label="running_var
 (1344)" fillcolor=orange]
	6078945488 -> 6075799472 [dir=none]
	6075799472 [label="weight
 (1344)" fillcolor=orange]
	6078945488 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078946784 -> 6078945488
	6078946784 -> 6077001344 [dir=none]
	6077001344 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6078946784 -> 6075799392 [dir=none]
	6075799392 [label="weight
 (1344, 224, 1, 1)" fillcolor=orange]
	6078946784 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078836224 -> 6078946784
	6078836224 [label="AddBackward0
------------
alpha: 1"]
	11670924656 -> 6078836224
	11670924656 -> 6077001264 [dir=none]
	6077001264 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11670924656 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11670925328 -> 11670924656
	11670925328 -> 6172398256 [dir=none]
	6172398256 [label="other
 ()" fillcolor=orange]
	11670925328 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11670925088 -> 11670925328
	11670925088 -> 6077001504 [dir=none]
	6077001504 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	11670925088 -> 6172397616 [dir=none]
	6172397616 [label="result1
 (224)" fillcolor=orange]
	11670925088 -> 6172397776 [dir=none]
	6172397776 [label="result2
 (224)" fillcolor=orange]
	11670925088 -> 6075798672 [dir=none]
	6075798672 [label="running_mean
 (224)" fillcolor=orange]
	11670925088 -> 6075798992 [dir=none]
	6075798992 [label="running_var
 (224)" fillcolor=orange]
	11670925088 -> 6075798832 [dir=none]
	6075798832 [label="weight
 (224)" fillcolor=orange]
	11670925088 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11670926672 -> 11670925088
	11670926672 -> 6077001664 [dir=none]
	6077001664 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	11670926672 -> 6075798752 [dir=none]
	6075798752 [label="weight
 (224, 1344, 1, 1)" fillcolor=orange]
	11670926672 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11670926912 -> 11670926672
	11670926912 -> 6077002304 [dir=none]
	6077002304 [label="other
 (1, 1344, 38, 38)" fillcolor=orange]
	11670926912 -> 6077001904 [dir=none]
	6077001904 [label="self
 (1, 1344, 1, 1)" fillcolor=orange]
	11670926912 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11670927200 -> 11670926912
	11670927200 -> 6172397216 [dir=none]
	6172397216 [label="result
 (1, 1344, 1, 1)" fillcolor=orange]
	11670927200 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11670927776 -> 11670927200
	11670927776 -> 6077001744 [dir=none]
	6077001744 [label="input
 (1, 56, 1, 1)" fillcolor=orange]
	11670927776 -> 6075798512 [dir=none]
	6075798512 [label="weight
 (1344, 56, 1, 1)" fillcolor=orange]
	11670927776 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (1344,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078604096 -> 11670927776
	6078604096 [label=SwishImplementationBackward]
	11670928976 -> 6078604096
	11670928976 -> 6077002624 [dir=none]
	6077002624 [label="input
 (1, 1344, 1, 1)" fillcolor=orange]
	11670928976 -> 6075798272 [dir=none]
	6075798272 [label="weight
 (56, 1344, 1, 1)" fillcolor=orange]
	11670928976 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (56,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11670923936 -> 11670928976
	11670923936 -> 6077002304 [dir=none]
	6077002304 [label="self
 (1, 1344, 38, 38)" fillcolor=orange]
	11670923936 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 1344, 38, 38)"]
	6078603872 -> 11670923936
	6078603872 [label=SwishImplementationBackward]
	11670922304 -> 6078603872
	11670922304 -> 6077002944 [dir=none]
	6077002944 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	11670922304 -> 6172404736 [dir=none]
	6172404736 [label="result1
 (1344)" fillcolor=orange]
	11670922304 -> 6172404576 [dir=none]
	6172404576 [label="result2
 (1344)" fillcolor=orange]
	11670922304 -> 6075795952 [dir=none]
	6075795952 [label="running_mean
 (1344)" fillcolor=orange]
	11670922304 -> 6075797792 [dir=none]
	6075797792 [label="running_var
 (1344)" fillcolor=orange]
	11670922304 -> 6075797552 [dir=none]
	6075797552 [label="weight
 (1344)" fillcolor=orange]
	11670922304 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11670921920 -> 11670922304
	11670921920 -> 6077003104 [dir=none]
	6077003104 [label="input
 (1, 1344, 42, 42)" fillcolor=orange]
	11670921920 -> 6075797632 [dir=none]
	6075797632 [label="weight
 (1344, 1, 5, 5)" fillcolor=orange]
	11670921920 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1344
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11670920768 -> 11670921920
	11670920768 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6078603648 -> 11670920768
	6078603648 [label=SwishImplementationBackward]
	11670920192 -> 6078603648
	11670920192 -> 6077004144 [dir=none]
	6077004144 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	11670920192 -> 6172393856 [dir=none]
	6172393856 [label="result1
 (1344)" fillcolor=orange]
	11670920192 -> 6172393696 [dir=none]
	6172393696 [label="result2
 (1344)" fillcolor=orange]
	11670920192 -> 6075796832 [dir=none]
	6075796832 [label="running_mean
 (1344)" fillcolor=orange]
	11670920192 -> 6075797152 [dir=none]
	6075797152 [label="running_var
 (1344)" fillcolor=orange]
	11670920192 -> 6075796992 [dir=none]
	6075796992 [label="weight
 (1344)" fillcolor=orange]
	11670920192 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11670919760 -> 11670920192
	11670919760 -> 6077003424 [dir=none]
	6077003424 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	11670919760 -> 6075796912 [dir=none]
	6075796912 [label="weight
 (1344, 224, 1, 1)" fillcolor=orange]
	11670919760 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11670924464 -> 11670919760
	11670924464 [label="AddBackward0
------------
alpha: 1"]
	11670918416 -> 11670924464
	11670918416 -> 6077003264 [dir=none]
	6077003264 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11670918416 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11670917840 -> 11670918416
	11670917840 -> 6172409216 [dir=none]
	6172409216 [label="other
 ()" fillcolor=orange]
	11670917840 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11670917312 -> 11670917840
	11670917312 -> 6077003504 [dir=none]
	6077003504 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	11670917312 -> 6172408336 [dir=none]
	6172408336 [label="result1
 (224)" fillcolor=orange]
	11670917312 -> 6172408496 [dir=none]
	6172408496 [label="result2
 (224)" fillcolor=orange]
	11670917312 -> 6075796192 [dir=none]
	6075796192 [label="running_mean
 (224)" fillcolor=orange]
	11670917312 -> 6075796512 [dir=none]
	6075796512 [label="running_var
 (224)" fillcolor=orange]
	11670917312 -> 6075796352 [dir=none]
	6075796352 [label="weight
 (224)" fillcolor=orange]
	11670917312 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11670917408 -> 11670917312
	11670917408 -> 6077003744 [dir=none]
	6077003744 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	11670917408 -> 6075796272 [dir=none]
	6075796272 [label="weight
 (224, 1344, 1, 1)" fillcolor=orange]
	11670917408 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11670916592 -> 11670917408
	11670916592 -> 6077004384 [dir=none]
	6077004384 [label="other
 (1, 1344, 38, 38)" fillcolor=orange]
	11670916592 -> 6077004064 [dir=none]
	6077004064 [label="self
 (1, 1344, 1, 1)" fillcolor=orange]
	11670916592 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11670915824 -> 11670916592
	11670915824 -> 6172408176 [dir=none]
	6172408176 [label="result
 (1, 1344, 1, 1)" fillcolor=orange]
	11670915824 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11670915440 -> 11670915824
	11670915440 -> 6077003904 [dir=none]
	6077003904 [label="input
 (1, 56, 1, 1)" fillcolor=orange]
	11670915440 -> 6075796032 [dir=none]
	6075796032 [label="weight
 (1344, 56, 1, 1)" fillcolor=orange]
	11670915440 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (1344,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078603424 -> 11670915440
	6078603424 [label=SwishImplementationBackward]
	11670914528 -> 6078603424
	11670914528 -> 6077004704 [dir=none]
	6077004704 [label="input
 (1, 1344, 1, 1)" fillcolor=orange]
	11670914528 -> 6075795792 [dir=none]
	6075795792 [label="weight
 (56, 1344, 1, 1)" fillcolor=orange]
	11670914528 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (56,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11670914000 -> 11670914528
	11670914000 -> 6077004384 [dir=none]
	6077004384 [label="self
 (1, 1344, 38, 38)" fillcolor=orange]
	11670914000 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 1344, 38, 38)"]
	6078603200 -> 11670914000
	6078603200 [label=SwishImplementationBackward]
	11670913712 -> 6078603200
	11670913712 -> 6077005264 [dir=none]
	6077005264 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	11670913712 -> 6172406496 [dir=none]
	6172406496 [label="result1
 (1344)" fillcolor=orange]
	11670913712 -> 6172405216 [dir=none]
	6172405216 [label="result2
 (1344)" fillcolor=orange]
	11670913712 -> 6075793472 [dir=none]
	6075793472 [label="running_mean
 (1344)" fillcolor=orange]
	11670913712 -> 6075795312 [dir=none]
	6075795312 [label="running_var
 (1344)" fillcolor=orange]
	11670913712 -> 6075795072 [dir=none]
	6075795072 [label="weight
 (1344)" fillcolor=orange]
	11670913712 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172720432 -> 11670913712
	6172720432 -> 6077005424 [dir=none]
	6077005424 [label="input
 (1, 1344, 42, 42)" fillcolor=orange]
	6172720432 -> 6075795152 [dir=none]
	6075795152 [label="weight
 (1344, 1, 5, 5)" fillcolor=orange]
	6172720432 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1344
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172719568 -> 6172720432
	6172719568 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6078602976 -> 6172719568
	6078602976 [label=SwishImplementationBackward]
	6172718752 -> 6078602976
	6172718752 -> 6077000064 [dir=none]
	6077000064 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6172718752 -> 6172402816 [dir=none]
	6172402816 [label="result1
 (1344)" fillcolor=orange]
	6172718752 -> 6172402656 [dir=none]
	6172402656 [label="result2
 (1344)" fillcolor=orange]
	6172718752 -> 6075794352 [dir=none]
	6075794352 [label="running_mean
 (1344)" fillcolor=orange]
	6172718752 -> 6075794672 [dir=none]
	6075794672 [label="running_var
 (1344)" fillcolor=orange]
	6172718752 -> 6075794512 [dir=none]
	6075794512 [label="weight
 (1344)" fillcolor=orange]
	6172718752 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172718128 -> 6172718752
	6172718128 -> 6077005664 [dir=none]
	6077005664 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6172718128 -> 6075794432 [dir=none]
	6075794432 [label="weight
 (1344, 224, 1, 1)" fillcolor=orange]
	6172718128 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11670918704 -> 6172718128
	11670918704 [label="AddBackward0
------------
alpha: 1"]
	6172717456 -> 11670918704
	6172717456 -> 6077005584 [dir=none]
	6077005584 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6172717456 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172717024 -> 6172717456
	6172717024 -> 6172399696 [dir=none]
	6172399696 [label="other
 ()" fillcolor=orange]
	6172717024 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172716592 -> 6172717024
	6172716592 -> 6076990384 [dir=none]
	6076990384 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6172716592 -> 6172398816 [dir=none]
	6172398816 [label="result1
 (224)" fillcolor=orange]
	6172716592 -> 6172399216 [dir=none]
	6172399216 [label="result2
 (224)" fillcolor=orange]
	6172716592 -> 6075793712 [dir=none]
	6075793712 [label="running_mean
 (224)" fillcolor=orange]
	6172716592 -> 6075794032 [dir=none]
	6075794032 [label="running_var
 (224)" fillcolor=orange]
	6172716592 -> 6075793872 [dir=none]
	6075793872 [label="weight
 (224)" fillcolor=orange]
	6172716592 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172716448 -> 6172716592
	6172716448 -> 6076992224 [dir=none]
	6076992224 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6172716448 -> 6075793792 [dir=none]
	6075793792 [label="weight
 (224, 1344, 1, 1)" fillcolor=orange]
	6172716448 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172716160 -> 6172716448
	6172716160 -> 6077000544 [dir=none]
	6077000544 [label="other
 (1, 1344, 38, 38)" fillcolor=orange]
	6172716160 -> 6076999904 [dir=none]
	6076999904 [label="self
 (1, 1344, 1, 1)" fillcolor=orange]
	6172716160 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6172715824 -> 6172716160
	6172715824 -> 6172397456 [dir=none]
	6172397456 [label="result
 (1, 1344, 1, 1)" fillcolor=orange]
	6172715824 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6172715680 -> 6172715824
	6172715680 -> 6076999024 [dir=none]
	6076999024 [label="input
 (1, 56, 1, 1)" fillcolor=orange]
	6172715680 -> 6075793552 [dir=none]
	6075793552 [label="weight
 (1344, 56, 1, 1)" fillcolor=orange]
	6172715680 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (1344,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078602752 -> 6172715680
	6078602752 [label=SwishImplementationBackward]
	6172715248 -> 6078602752
	6172715248 -> 6077001984 [dir=none]
	6077001984 [label="input
 (1, 1344, 1, 1)" fillcolor=orange]
	6172715248 -> 6075498336 [dir=none]
	6075498336 [label="weight
 (56, 1344, 1, 1)" fillcolor=orange]
	6172715248 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (56,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172715104 -> 6172715248
	6172715104 -> 6077000544 [dir=none]
	6077000544 [label="self
 (1, 1344, 38, 38)" fillcolor=orange]
	6172715104 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 1344, 38, 38)"]
	6078602528 -> 6172715104
	6078602528 [label=SwishImplementationBackward]
	6172714672 -> 6078602528
	6172714672 -> 6077002784 [dir=none]
	6077002784 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6172714672 -> 6172394656 [dir=none]
	6172394656 [label="result1
 (1344)" fillcolor=orange]
	6172714672 -> 6172409776 [dir=none]
	6172409776 [label="result2
 (1344)" fillcolor=orange]
	6172714672 -> 6075496176 [dir=none]
	6075496176 [label="running_mean
 (1344)" fillcolor=orange]
	6172714672 -> 6075497936 [dir=none]
	6075497936 [label="running_var
 (1344)" fillcolor=orange]
	6172714672 -> 6075497696 [dir=none]
	6075497696 [label="weight
 (1344)" fillcolor=orange]
	6172714672 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172714528 -> 6172714672
	6172714528 -> 6077003024 [dir=none]
	6077003024 [label="input
 (1, 1344, 42, 42)" fillcolor=orange]
	6172714528 -> 6075497776 [dir=none]
	6075497776 [label="weight
 (1344, 1, 5, 5)" fillcolor=orange]
	6172714528 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1344
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172714240 -> 6172714528
	6172714240 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6078602304 -> 6172714240
	6078602304 [label=SwishImplementationBackward]
	6172714000 -> 6078602304
	6172714000 -> 6076992704 [dir=none]
	6076992704 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6172714000 -> 6172408816 [dir=none]
	6172408816 [label="result1
 (1344)" fillcolor=orange]
	6172714000 -> 6172408736 [dir=none]
	6172408736 [label="result2
 (1344)" fillcolor=orange]
	6172714000 -> 6075496976 [dir=none]
	6075496976 [label="running_mean
 (1344)" fillcolor=orange]
	6172714000 -> 6075497296 [dir=none]
	6075497296 [label="running_var
 (1344)" fillcolor=orange]
	6172714000 -> 6075497136 [dir=none]
	6075497136 [label="weight
 (1344)" fillcolor=orange]
	6172714000 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172713856 -> 6172714000
	6172713856 -> 6077004624 [dir=none]
	6077004624 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6172713856 -> 6075497056 [dir=none]
	6075497056 [label="weight
 (1344, 224, 1, 1)" fillcolor=orange]
	6172713856 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172717264 -> 6172713856
	6172717264 [label="AddBackward0
------------
alpha: 1"]
	6172713424 -> 6172717264
	6172713424 -> 6077003984 [dir=none]
	6077003984 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6172713424 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172713088 -> 6172713424
	6172713088 -> 6172408096 [dir=none]
	6172408096 [label="other
 ()" fillcolor=orange]
	6172713088 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172712944 -> 6172713088
	6172712944 -> 6077004944 [dir=none]
	6077004944 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6172712944 -> 6172407456 [dir=none]
	6172407456 [label="result1
 (224)" fillcolor=orange]
	6172712944 -> 6172407616 [dir=none]
	6172407616 [label="result2
 (224)" fillcolor=orange]
	6172712944 -> 6075496416 [dir=none]
	6075496416 [label="running_mean
 (224)" fillcolor=orange]
	6172712944 -> 6075496736 [dir=none]
	6075496736 [label="running_var
 (224)" fillcolor=orange]
	6172712944 -> 6075496576 [dir=none]
	6075496576 [label="weight
 (224)" fillcolor=orange]
	6172712944 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172712800 -> 6172712944
	6172712800 -> 6077005184 [dir=none]
	6077005184 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6172712800 -> 6075496496 [dir=none]
	6075496496 [label="weight
 (224, 1344, 1, 1)" fillcolor=orange]
	6172712800 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172712512 -> 6172712800
	6172712512 -> 6076994304 [dir=none]
	6076994304 [label="other
 (1, 1344, 38, 38)" fillcolor=orange]
	6172712512 -> 6076991264 [dir=none]
	6076991264 [label="self
 (1, 1344, 1, 1)" fillcolor=orange]
	6172712512 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6172712416 -> 6172712512
	6172712416 -> 6172407296 [dir=none]
	6172407296 [label="result
 (1, 1344, 1, 1)" fillcolor=orange]
	6172712416 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6172712272 -> 6172712416
	6172712272 -> 6076991024 [dir=none]
	6076991024 [label="input
 (1, 56, 1, 1)" fillcolor=orange]
	6172712272 -> 6075496256 [dir=none]
	6075496256 [label="weight
 (1344, 56, 1, 1)" fillcolor=orange]
	6172712272 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (1344,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078602080 -> 6172712272
	6078602080 [label=SwishImplementationBackward]
	6172711840 -> 6078602080
	6172711840 -> 6076995504 [dir=none]
	6076995504 [label="input
 (1, 1344, 1, 1)" fillcolor=orange]
	6172711840 -> 6075496016 [dir=none]
	6075496016 [label="weight
 (56, 1344, 1, 1)" fillcolor=orange]
	6172711840 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (56,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172711696 -> 6172711840
	6172711696 -> 6076994304 [dir=none]
	6076994304 [label="self
 (1, 1344, 38, 38)" fillcolor=orange]
	6172711696 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 1344, 38, 38)"]
	6078601856 -> 6172711696
	6078601856 [label=SwishImplementationBackward]
	6172711264 -> 6078601856
	6172711264 -> 6076997984 [dir=none]
	6076997984 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6172711264 -> 6172406256 [dir=none]
	6172406256 [label="result1
 (1344)" fillcolor=orange]
	6172711264 -> 6172406176 [dir=none]
	6172406176 [label="result2
 (1344)" fillcolor=orange]
	6172711264 -> 6075493776 [dir=none]
	6075493776 [label="running_mean
 (1344)" fillcolor=orange]
	6172711264 -> 6075495616 [dir=none]
	6075495616 [label="running_var
 (1344)" fillcolor=orange]
	6172711264 -> 6075495376 [dir=none]
	6075495376 [label="weight
 (1344)" fillcolor=orange]
	6172711264 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172711120 -> 6172711264
	6172711120 -> 6076998784 [dir=none]
	6076998784 [label="input
 (1, 1344, 42, 42)" fillcolor=orange]
	6172711120 -> 6075495456 [dir=none]
	6075495456 [label="weight
 (1344, 1, 5, 5)" fillcolor=orange]
	6172711120 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1344
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172710832 -> 6172711120
	6172710832 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6078601632 -> 6172710832
	6078601632 [label=SwishImplementationBackward]
	6172710352 -> 6078601632
	6172710352 -> 6076993344 [dir=none]
	6076993344 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6172710352 -> 6172405536 [dir=none]
	6172405536 [label="result1
 (1344)" fillcolor=orange]
	6172710352 -> 6172405376 [dir=none]
	6172405376 [label="result2
 (1344)" fillcolor=orange]
	6172710352 -> 6075494656 [dir=none]
	6075494656 [label="running_mean
 (1344)" fillcolor=orange]
	6172710352 -> 6075494976 [dir=none]
	6075494976 [label="running_var
 (1344)" fillcolor=orange]
	6172710352 -> 6075494816 [dir=none]
	6075494816 [label="weight
 (1344)" fillcolor=orange]
	6172710352 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172710208 -> 6172710352
	6172710208 -> 6077000304 [dir=none]
	6077000304 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6172710208 -> 6075494736 [dir=none]
	6075494736 [label="weight
 (1344, 224, 1, 1)" fillcolor=orange]
	6172710208 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172713376 -> 6172710208
	6172713376 [label="AddBackward0
------------
alpha: 1"]
	6172709776 -> 6172713376
	6172709776 -> 6076999664 [dir=none]
	6076999664 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6172709776 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172709680 -> 6172709776
	6172709680 -> 6172404816 [dir=none]
	6172404816 [label="other
 ()" fillcolor=orange]
	6172709680 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172709536 -> 6172709680
	6172709536 -> 6077003664 [dir=none]
	6077003664 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6172709536 -> 6172404176 [dir=none]
	6172404176 [label="result1
 (224)" fillcolor=orange]
	6172709536 -> 6172404336 [dir=none]
	6172404336 [label="result2
 (224)" fillcolor=orange]
	6172709536 -> 6075494016 [dir=none]
	6075494016 [label="running_mean
 (224)" fillcolor=orange]
	6172709536 -> 6075494336 [dir=none]
	6075494336 [label="running_var
 (224)" fillcolor=orange]
	6172709536 -> 6075494176 [dir=none]
	6075494176 [label="weight
 (224)" fillcolor=orange]
	6172709536 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172709392 -> 6172709536
	6172709392 -> 6076990624 [dir=none]
	6076990624 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6172709392 -> 6075494096 [dir=none]
	6075494096 [label="weight
 (224, 1344, 1, 1)" fillcolor=orange]
	6172709392 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172709104 -> 6172709392
	6172709104 -> 6076993664 [dir=none]
	6076993664 [label="other
 (1, 1344, 38, 38)" fillcolor=orange]
	6172709104 -> 6076991584 [dir=none]
	6076991584 [label="self
 (1, 1344, 1, 1)" fillcolor=orange]
	6172709104 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6172708768 -> 6172709104
	6172708768 -> 6172404016 [dir=none]
	6172404016 [label="result
 (1, 1344, 1, 1)" fillcolor=orange]
	6172708768 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6172708624 -> 6172708768
	6172708624 -> 6076990864 [dir=none]
	6076990864 [label="input
 (1, 56, 1, 1)" fillcolor=orange]
	6172708624 -> 6075493856 [dir=none]
	6075493856 [label="weight
 (1344, 56, 1, 1)" fillcolor=orange]
	6172708624 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (1344,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078601408 -> 6172708624
	6078601408 [label=SwishImplementationBackward]
	6172708192 -> 6078601408
	6172708192 -> 6076997744 [dir=none]
	6076997744 [label="input
 (1, 1344, 1, 1)" fillcolor=orange]
	6172708192 -> 6075493616 [dir=none]
	6075493616 [label="weight
 (56, 1344, 1, 1)" fillcolor=orange]
	6172708192 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (56,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172708048 -> 6172708192
	6172708048 -> 6076993664 [dir=none]
	6076993664 [label="self
 (1, 1344, 38, 38)" fillcolor=orange]
	6172708048 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 1344, 38, 38)"]
	6078601184 -> 6172708048
	6078601184 [label=SwishImplementationBackward]
	6172707616 -> 6078601184
	6172707616 -> 6077003184 [dir=none]
	6077003184 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6172707616 -> 6172402736 [dir=none]
	6172402736 [label="result1
 (1344)" fillcolor=orange]
	6172707616 -> 6172402576 [dir=none]
	6172402576 [label="result2
 (1344)" fillcolor=orange]
	6172707616 -> 6075491296 [dir=none]
	6075491296 [label="running_mean
 (1344)" fillcolor=orange]
	6172707616 -> 6075493136 [dir=none]
	6075493136 [label="running_var
 (1344)" fillcolor=orange]
	6172707616 -> 6075492896 [dir=none]
	6075492896 [label="weight
 (1344)" fillcolor=orange]
	6172707616 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172707472 -> 6172707616
	6172707472 -> 6077004304 [dir=none]
	6077004304 [label="input
 (1, 1344, 42, 42)" fillcolor=orange]
	6172707472 -> 6075492976 [dir=none]
	6075492976 [label="weight
 (1344, 1, 5, 5)" fillcolor=orange]
	6172707472 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1344
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172707184 -> 6172707472
	6172707184 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6078600960 -> 6172707184
	6078600960 [label=SwishImplementationBackward]
	6172706944 -> 6078600960
	6172706944 -> 6077005344 [dir=none]
	6077005344 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6172706944 -> 6172401696 [dir=none]
	6172401696 [label="result1
 (1344)" fillcolor=orange]
	6172706944 -> 6172401536 [dir=none]
	6172401536 [label="result2
 (1344)" fillcolor=orange]
	6172706944 -> 6075492176 [dir=none]
	6075492176 [label="running_mean
 (1344)" fillcolor=orange]
	6172706944 -> 6075492496 [dir=none]
	6075492496 [label="running_var
 (1344)" fillcolor=orange]
	6172706944 -> 6075492336 [dir=none]
	6075492336 [label="weight
 (1344)" fillcolor=orange]
	6172706944 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172706800 -> 6172706944
	6172706800 -> 6076990224 [dir=none]
	6076990224 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6172706800 -> 6075492256 [dir=none]
	6075492256 [label="weight
 (1344, 224, 1, 1)" fillcolor=orange]
	6172706800 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172709968 -> 6172706800
	6172709968 -> 6076992384 [dir=none]
	6076992384 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6172709968 -> 6172402176 [dir=none]
	6172402176 [label="result1
 (224)" fillcolor=orange]
	6172709968 -> 6172402256 [dir=none]
	6172402256 [label="result2
 (224)" fillcolor=orange]
	6172709968 -> 6075491536 [dir=none]
	6075491536 [label="running_mean
 (224)" fillcolor=orange]
	6172709968 -> 6075491856 [dir=none]
	6075491856 [label="running_var
 (224)" fillcolor=orange]
	6172709968 -> 6075491696 [dir=none]
	6075491696 [label="weight
 (224)" fillcolor=orange]
	6172709968 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172706368 -> 6172709968
	6172706368 -> 6076995024 [dir=none]
	6076995024 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172706368 -> 6075491616 [dir=none]
	6075491616 [label="weight
 (224, 960, 1, 1)" fillcolor=orange]
	6172706368 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172706080 -> 6172706368
	6172706080 -> 6076989584 [dir=none]
	6076989584 [label="other
 (1, 960, 38, 38)" fillcolor=orange]
	6172706080 -> 6077001424 [dir=none]
	6077001424 [label="self
 (1, 960, 1, 1)" fillcolor=orange]
	6172706080 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6172705744 -> 6172706080
	6172705744 -> 6172400256 [dir=none]
	6172400256 [label="result
 (1, 960, 1, 1)" fillcolor=orange]
	6172705744 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6172705600 -> 6172705744
	6172705600 -> 6076998144 [dir=none]
	6076998144 [label="input
 (1, 40, 1, 1)" fillcolor=orange]
	6172705600 -> 6075491376 [dir=none]
	6075491376 [label="weight
 (960, 40, 1, 1)" fillcolor=orange]
	6172705600 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (960,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078600736 -> 6172705600
	6078600736 [label=SwishImplementationBackward]
	6172705168 -> 6078600736
	6172705168 -> 6076993024 [dir=none]
	6076993024 [label="input
 (1, 960, 1, 1)" fillcolor=orange]
	6172705168 -> 6075491136 [dir=none]
	6075491136 [label="weight
 (40, 960, 1, 1)" fillcolor=orange]
	6172705168 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (40,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172705024 -> 6172705168
	6172705024 -> 6076989584 [dir=none]
	6076989584 [label="self
 (1, 960, 38, 38)" fillcolor=orange]
	6172705024 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 960, 38, 38)"]
	6078600512 -> 6172705024
	6078600512 [label=SwishImplementationBackward]
	6172622608 -> 6078600512
	6172622608 -> 6076999344 [dir=none]
	6076999344 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172622608 -> 6172399456 [dir=none]
	6172399456 [label="result1
 (960)" fillcolor=orange]
	6172622608 -> 6172401216 [dir=none]
	6172401216 [label="result2
 (960)" fillcolor=orange]
	6172622608 -> 6075488816 [dir=none]
	6075488816 [label="running_mean
 (960)" fillcolor=orange]
	6172622608 -> 6075490656 [dir=none]
	6075490656 [label="running_var
 (960)" fillcolor=orange]
	6172622608 -> 6075490416 [dir=none]
	6075490416 [label="weight
 (960)" fillcolor=orange]
	6172622608 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172622464 -> 6172622608
	6172622464 -> 6077001584 [dir=none]
	6077001584 [label="input
 (1, 960, 42, 42)" fillcolor=orange]
	6172622464 -> 6075490496 [dir=none]
	6075490496 [label="weight
 (960, 1, 5, 5)" fillcolor=orange]
	6172622464 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            960
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172622176 -> 6172622464
	6172622176 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6078600288 -> 6172622176
	6078600288 [label=SwishImplementationBackward]
	6172621936 -> 6078600288
	6172621936 -> 6077005744 [dir=none]
	6077005744 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172621936 -> 6172398496 [dir=none]
	6172398496 [label="result1
 (960)" fillcolor=orange]
	6172621936 -> 6172398896 [dir=none]
	6172398896 [label="result2
 (960)" fillcolor=orange]
	6172621936 -> 6075489696 [dir=none]
	6075489696 [label="running_mean
 (960)" fillcolor=orange]
	6172621936 -> 6075490016 [dir=none]
	6075490016 [label="running_var
 (960)" fillcolor=orange]
	6172621936 -> 6075489856 [dir=none]
	6075489856 [label="weight
 (960)" fillcolor=orange]
	6172621936 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172621792 -> 6172621936
	6172621792 -> 6077005504 [dir=none]
	6077005504 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	6172621792 -> 6075489776 [dir=none]
	6075489776 [label="weight
 (960, 160, 1, 1)" fillcolor=orange]
	6172621792 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172621504 -> 6172621792
	6172621504 [label="AddBackward0
------------
alpha: 1"]
	6172621168 -> 6172621504
	6172621168 -> 6077003344 [dir=none]
	6077003344 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6172621168 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172621072 -> 6172621168
	6172621072 -> 6172397696 [dir=none]
	6172397696 [label="other
 ()" fillcolor=orange]
	6172621072 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172620928 -> 6172621072
	6172620928 -> 6076995824 [dir=none]
	6076995824 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	6172620928 -> 11670934112 [dir=none]
	11670934112 [label="result1
 (160)" fillcolor=orange]
	6172620928 -> 6172397296 [dir=none]
	6172397296 [label="result2
 (160)" fillcolor=orange]
	6172620928 -> 6075489056 [dir=none]
	6075489056 [label="running_mean
 (160)" fillcolor=orange]
	6172620928 -> 6075489376 [dir=none]
	6075489376 [label="running_var
 (160)" fillcolor=orange]
	6172620928 -> 6075489216 [dir=none]
	6075489216 [label="weight
 (160)" fillcolor=orange]
	6172620928 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172620784 -> 6172620928
	6172620784 -> 6076996064 [dir=none]
	6076996064 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172620784 -> 6075489136 [dir=none]
	6075489136 [label="weight
 (160, 960, 1, 1)" fillcolor=orange]
	6172620784 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172620496 -> 6172620784
	6172620496 -> 6060737296 [dir=none]
	6060737296 [label="other
 (1, 960, 38, 38)" fillcolor=orange]
	6172620496 -> 6076996544 [dir=none]
	6076996544 [label="self
 (1, 960, 1, 1)" fillcolor=orange]
	6172620496 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6172620160 -> 6172620496
	6172620160 -> 6172396656 [dir=none]
	6172396656 [label="result
 (1, 960, 1, 1)" fillcolor=orange]
	6172620160 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6172620016 -> 6172620160
	6172620016 -> 6076996304 [dir=none]
	6076996304 [label="input
 (1, 40, 1, 1)" fillcolor=orange]
	6172620016 -> 6075488896 [dir=none]
	6075488896 [label="weight
 (960, 40, 1, 1)" fillcolor=orange]
	6172620016 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (960,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078600064 -> 6172620016
	6078600064 [label=SwishImplementationBackward]
	6172619584 -> 6078600064
	6172619584 -> 6060750576 [dir=none]
	6060750576 [label="input
 (1, 960, 1, 1)" fillcolor=orange]
	6172619584 -> 6075488656 [dir=none]
	6075488656 [label="weight
 (40, 960, 1, 1)" fillcolor=orange]
	6172619584 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (40,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172619440 -> 6172619584
	6172619440 -> 6060737296 [dir=none]
	6060737296 [label="self
 (1, 960, 38, 38)" fillcolor=orange]
	6172619440 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 960, 38, 38)"]
	6078599840 -> 6172619440
	6078599840 [label=SwishImplementationBackward]
	6172619008 -> 6078599840
	6172619008 -> 6077038896 [dir=none]
	6077038896 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172619008 -> 6172395776 [dir=none]
	6172395776 [label="result1
 (960)" fillcolor=orange]
	6172619008 -> 6172396496 [dir=none]
	6172396496 [label="result2
 (960)" fillcolor=orange]
	6172619008 -> 6075487056 [dir=none]
	6075487056 [label="running_mean
 (960)" fillcolor=orange]
	6172619008 -> 6075488176 [dir=none]
	6075488176 [label="running_var
 (960)" fillcolor=orange]
	6172619008 -> 6075487936 [dir=none]
	6075487936 [label="weight
 (960)" fillcolor=orange]
	6172619008 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172618864 -> 6172619008
	6172618864 -> 6077039216 [dir=none]
	6077039216 [label="input
 (1, 960, 40, 40)" fillcolor=orange]
	6172618864 -> 6075488016 [dir=none]
	6075488016 [label="weight
 (960, 1, 3, 3)" fillcolor=orange]
	6172618864 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            960
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172618576 -> 6172618864
	6172618576 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6078599616 -> 6172618576
	6078599616 [label=SwishImplementationBackward]
	6172618336 -> 6078599616
	6172618336 -> 6077040336 [dir=none]
	6077040336 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172618336 -> 6172394736 [dir=none]
	6172394736 [label="result1
 (960)" fillcolor=orange]
	6172618336 -> 11670932832 [dir=none]
	11670932832 [label="result2
 (960)" fillcolor=orange]
	6172618336 -> 6075487216 [dir=none]
	6075487216 [label="running_mean
 (960)" fillcolor=orange]
	6172618336 -> 6075487536 [dir=none]
	6075487536 [label="running_var
 (960)" fillcolor=orange]
	6172618336 -> 6075487376 [dir=none]
	6075487376 [label="weight
 (960)" fillcolor=orange]
	6172618336 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172618192 -> 6172618336
	6172618192 -> 6077039456 [dir=none]
	6077039456 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	6172618192 -> 6075487296 [dir=none]
	6075487296 [label="weight
 (960, 160, 1, 1)" fillcolor=orange]
	6172618192 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172621360 -> 6172618192
	6172621360 [label="AddBackward0
------------
alpha: 1"]
	6172617760 -> 6172621360
	6172617760 -> 6077039376 [dir=none]
	6077039376 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6172617760 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172617424 -> 6172617760
	6172617424 -> 6172395376 [dir=none]
	6172395376 [label="other
 ()" fillcolor=orange]
	6172617424 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172617280 -> 6172617424
	6172617280 -> 6077039616 [dir=none]
	6077039616 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	6172617280 -> 6172393616 [dir=none]
	6172393616 [label="result1
 (160)" fillcolor=orange]
	6172617280 -> 6172393776 [dir=none]
	6172393776 [label="result2
 (160)" fillcolor=orange]
	6172617280 -> 6075486656 [dir=none]
	6075486656 [label="running_mean
 (160)" fillcolor=orange]
	6172617280 -> 6075486976 [dir=none]
	6075486976 [label="running_var
 (160)" fillcolor=orange]
	6172617280 -> 6075486816 [dir=none]
	6075486816 [label="weight
 (160)" fillcolor=orange]
	6172617280 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172617136 -> 6172617280
	6172617136 -> 6077039696 [dir=none]
	6077039696 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172617136 -> 6075486736 [dir=none]
	6075486736 [label="weight
 (160, 960, 1, 1)" fillcolor=orange]
	6172617136 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172616848 -> 6172617136
	6172616848 -> 6077040496 [dir=none]
	6077040496 [label="other
 (1, 960, 38, 38)" fillcolor=orange]
	6172616848 -> 6077040016 [dir=none]
	6077040016 [label="self
 (1, 960, 1, 1)" fillcolor=orange]
	6172616848 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6172616752 -> 6172616848
	6172616752 -> 6172394416 [dir=none]
	6172394416 [label="result
 (1, 960, 1, 1)" fillcolor=orange]
	6172616752 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6172616608 -> 6172616752
	6172616608 -> 6077039856 [dir=none]
	6077039856 [label="input
 (1, 40, 1, 1)" fillcolor=orange]
	6172616608 -> 6075486496 [dir=none]
	6075486496 [label="weight
 (960, 40, 1, 1)" fillcolor=orange]
	6172616608 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (960,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078599392 -> 6172616608
	6078599392 [label=SwishImplementationBackward]
	6172616176 -> 6078599392
	6172616176 -> 6077040816 [dir=none]
	6077040816 [label="input
 (1, 960, 1, 1)" fillcolor=orange]
	6172616176 -> 6075486256 [dir=none]
	6075486256 [label="weight
 (40, 960, 1, 1)" fillcolor=orange]
	6172616176 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (40,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172616032 -> 6172616176
	6172616032 -> 6077040496 [dir=none]
	6077040496 [label="self
 (1, 960, 38, 38)" fillcolor=orange]
	6172616032 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 960, 38, 38)"]
	6078599168 -> 6172616032
	6078599168 [label=SwishImplementationBackward]
	6172615600 -> 6078599168
	6172615600 -> 6077041296 [dir=none]
	6077041296 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172615600 -> 11671095072 [dir=none]
	11671095072 [label="result1
 (960)" fillcolor=orange]
	6172615600 -> 11671095392 [dir=none]
	11671095392 [label="result2
 (960)" fillcolor=orange]
	6172615600 -> 6075483936 [dir=none]
	6075483936 [label="running_mean
 (960)" fillcolor=orange]
	6172615600 -> 6075485776 [dir=none]
	6075485776 [label="running_var
 (960)" fillcolor=orange]
	6172615600 -> 6075485536 [dir=none]
	6075485536 [label="weight
 (960)" fillcolor=orange]
	6172615600 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172615456 -> 6172615600
	6172615456 -> 6077041536 [dir=none]
	6077041536 [label="input
 (1, 960, 40, 40)" fillcolor=orange]
	6172615456 -> 6075485616 [dir=none]
	6075485616 [label="weight
 (960, 1, 3, 3)" fillcolor=orange]
	6172615456 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            960
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172615168 -> 6172615456
	6172615168 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6078598944 -> 6172615168
	6078598944 [label=SwishImplementationBackward]
	6172614688 -> 6078598944
	6172614688 -> 6077042976 [dir=none]
	6077042976 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172614688 -> 11671093712 [dir=none]
	11671093712 [label="result1
 (960)" fillcolor=orange]
	6172614688 -> 11671094192 [dir=none]
	11671094192 [label="result2
 (960)" fillcolor=orange]
	6172614688 -> 6075484816 [dir=none]
	6075484816 [label="running_mean
 (960)" fillcolor=orange]
	6172614688 -> 6075485136 [dir=none]
	6075485136 [label="running_var
 (960)" fillcolor=orange]
	6172614688 -> 6075484976 [dir=none]
	6075484976 [label="weight
 (960)" fillcolor=orange]
	6172614688 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172614544 -> 6172614688
	6172614544 -> 6077041856 [dir=none]
	6077041856 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	6172614544 -> 6075484896 [dir=none]
	6075484896 [label="weight
 (960, 160, 1, 1)" fillcolor=orange]
	6172614544 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172617712 -> 6172614544
	6172617712 [label="AddBackward0
------------
alpha: 1"]
	6172614112 -> 6172617712
	6172614112 -> 6077041696 [dir=none]
	6077041696 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6172614112 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172614016 -> 6172614112
	6172614016 -> 11671094352 [dir=none]
	11671094352 [label="other
 ()" fillcolor=orange]
	6172614016 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172613872 -> 6172614016
	6172613872 -> 6077042176 [dir=none]
	6077042176 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	6172613872 -> 11671109152 [dir=none]
	11671109152 [label="result1
 (160)" fillcolor=orange]
	6172613872 -> 11671109312 [dir=none]
	11671109312 [label="result2
 (160)" fillcolor=orange]
	6172613872 -> 6075484176 [dir=none]
	6075484176 [label="running_mean
 (160)" fillcolor=orange]
	6172613872 -> 6075484496 [dir=none]
	6075484496 [label="running_var
 (160)" fillcolor=orange]
	6172613872 -> 6075484336 [dir=none]
	6075484336 [label="weight
 (160)" fillcolor=orange]
	6172613872 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172613728 -> 6172613872
	6172613728 -> 6077042336 [dir=none]
	6077042336 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172613728 -> 6075484256 [dir=none]
	6075484256 [label="weight
 (160, 960, 1, 1)" fillcolor=orange]
	6172613728 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172613440 -> 6172613728
	6172613440 -> 6077043056 [dir=none]
	6077043056 [label="other
 (1, 960, 38, 38)" fillcolor=orange]
	6172613440 -> 6077042816 [dir=none]
	6077042816 [label="self
 (1, 960, 1, 1)" fillcolor=orange]
	6172613440 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6172613104 -> 6172613440
	6172613104 -> 11671108832 [dir=none]
	11671108832 [label="result
 (1, 960, 1, 1)" fillcolor=orange]
	6172613104 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6172612960 -> 6172613104
	6172612960 -> 6077042656 [dir=none]
	6077042656 [label="input
 (1, 40, 1, 1)" fillcolor=orange]
	6172612960 -> 6075484016 [dir=none]
	6075484016 [label="weight
 (960, 40, 1, 1)" fillcolor=orange]
	6172612960 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (960,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078598720 -> 6172612960
	6078598720 [label=SwishImplementationBackward]
	6172612528 -> 6078598720
	6172612528 -> 6077043376 [dir=none]
	6077043376 [label="input
 (1, 960, 1, 1)" fillcolor=orange]
	6172612528 -> 6075483776 [dir=none]
	6075483776 [label="weight
 (40, 960, 1, 1)" fillcolor=orange]
	6172612528 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (40,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172612384 -> 6172612528
	6172612384 -> 6077043056 [dir=none]
	6077043056 [label="self
 (1, 960, 38, 38)" fillcolor=orange]
	6172612384 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 960, 38, 38)"]
	6078598496 -> 6172612384
	6078598496 [label=SwishImplementationBackward]
	6172611952 -> 6078598496
	6172611952 -> 6077043936 [dir=none]
	6077043936 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172611952 -> 11671108352 [dir=none]
	11671108352 [label="result1
 (960)" fillcolor=orange]
	6172611952 -> 11671108752 [dir=none]
	11671108752 [label="result2
 (960)" fillcolor=orange]
	6172611952 -> 6073400624 [dir=none]
	6073400624 [label="running_mean
 (960)" fillcolor=orange]
	6172611952 -> 6075483296 [dir=none]
	6075483296 [label="running_var
 (960)" fillcolor=orange]
	6172611952 -> 6075483056 [dir=none]
	6075483056 [label="weight
 (960)" fillcolor=orange]
	6172611952 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172611808 -> 6172611952
	6172611808 -> 6077044096 [dir=none]
	6077044096 [label="input
 (1, 960, 40, 40)" fillcolor=orange]
	6172611808 -> 6075483136 [dir=none]
	6075483136 [label="weight
 (960, 1, 3, 3)" fillcolor=orange]
	6172611808 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            960
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172611520 -> 6172611808
	6172611520 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6078598272 -> 6172611520
	6078598272 [label=SwishImplementationBackward]
	6172611280 -> 6078598272
	6172611280 -> 6077045296 [dir=none]
	6077045296 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172611280 -> 11671107792 [dir=none]
	11671107792 [label="result1
 (960)" fillcolor=orange]
	6172611280 -> 11671108032 [dir=none]
	11671108032 [label="result2
 (960)" fillcolor=orange]
	6172611280 -> 6075482336 [dir=none]
	6075482336 [label="running_mean
 (960)" fillcolor=orange]
	6172611280 -> 6075482656 [dir=none]
	6075482656 [label="running_var
 (960)" fillcolor=orange]
	6172611280 -> 6075482496 [dir=none]
	6075482496 [label="weight
 (960)" fillcolor=orange]
	6172611280 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172611136 -> 6172611280
	6172611136 -> 6077044336 [dir=none]
	6077044336 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	6172611136 -> 6075482416 [dir=none]
	6075482416 [label="weight
 (960, 160, 1, 1)" fillcolor=orange]
	6172611136 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172614304 -> 6172611136
	6172614304 [label="AddBackward0
------------
alpha: 1"]
	6172610704 -> 6172614304
	6172610704 -> 6077044256 [dir=none]
	6077044256 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6172610704 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172610368 -> 6172610704
	6172610368 -> 11671107392 [dir=none]
	11671107392 [label="other
 ()" fillcolor=orange]
	6172610368 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172610224 -> 6172610368
	6172610224 -> 6077044496 [dir=none]
	6077044496 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	6172610224 -> 11671107072 [dir=none]
	11671107072 [label="result1
 (160)" fillcolor=orange]
	6172610224 -> 11671107152 [dir=none]
	11671107152 [label="result2
 (160)" fillcolor=orange]
	6172610224 -> 6073400864 [dir=none]
	6073400864 [label="running_mean
 (160)" fillcolor=orange]
	6172610224 -> 6073401184 [dir=none]
	6073401184 [label="running_var
 (160)" fillcolor=orange]
	6172610224 -> 6073401024 [dir=none]
	6073401024 [label="weight
 (160)" fillcolor=orange]
	6172610224 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172610080 -> 6172610224
	6172610080 -> 6077044576 [dir=none]
	6077044576 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172610080 -> 6073400944 [dir=none]
	6073400944 [label="weight
 (160, 960, 1, 1)" fillcolor=orange]
	6172610080 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172609792 -> 6172610080
	6172609792 -> 6077045456 [dir=none]
	6077045456 [label="other
 (1, 960, 38, 38)" fillcolor=orange]
	6172609792 -> 6077045136 [dir=none]
	6077045136 [label="self
 (1, 960, 1, 1)" fillcolor=orange]
	6172609792 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6172609696 -> 6172609792
	6172609696 -> 11671106752 [dir=none]
	11671106752 [label="result
 (1, 960, 1, 1)" fillcolor=orange]
	6172609696 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6172609552 -> 6172609696
	6172609552 -> 6077044736 [dir=none]
	6077044736 [label="input
 (1, 40, 1, 1)" fillcolor=orange]
	6172609552 -> 6073400704 [dir=none]
	6073400704 [label="weight
 (960, 40, 1, 1)" fillcolor=orange]
	6172609552 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (960,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078598048 -> 6172609552
	6078598048 [label=SwishImplementationBackward]
	6172609120 -> 6078598048
	6172609120 -> 6077045696 [dir=none]
	6077045696 [label="input
 (1, 960, 1, 1)" fillcolor=orange]
	6172609120 -> 6073400464 [dir=none]
	6073400464 [label="weight
 (40, 960, 1, 1)" fillcolor=orange]
	6172609120 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (40,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172608976 -> 6172609120
	6172608976 -> 6077045456 [dir=none]
	6077045456 [label="self
 (1, 960, 38, 38)" fillcolor=orange]
	6172608976 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 960, 38, 38)"]
	6078597824 -> 6172608976
	6078597824 [label=SwishImplementationBackward]
	6172608544 -> 6078597824
	6172608544 -> 6077046096 [dir=none]
	6077046096 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172608544 -> 11671106272 [dir=none]
	11671106272 [label="result1
 (960)" fillcolor=orange]
	6172608544 -> 11671106672 [dir=none]
	11671106672 [label="result2
 (960)" fillcolor=orange]
	6172608544 -> 6073398144 [dir=none]
	6073398144 [label="running_mean
 (960)" fillcolor=orange]
	6172608544 -> 6073399984 [dir=none]
	6073399984 [label="running_var
 (960)" fillcolor=orange]
	6172608544 -> 6073399744 [dir=none]
	6073399744 [label="weight
 (960)" fillcolor=orange]
	6172608544 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172608400 -> 6172608544
	6172608400 -> 6077046336 [dir=none]
	6077046336 [label="input
 (1, 960, 40, 40)" fillcolor=orange]
	6172608400 -> 6073399824 [dir=none]
	6073399824 [label="weight
 (960, 1, 3, 3)" fillcolor=orange]
	6172608400 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            960
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172608112 -> 6172608400
	6172608112 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6078597600 -> 6172608112
	6078597600 [label=SwishImplementationBackward]
	6172607632 -> 6078597600
	6172607632 -> 6077047536 [dir=none]
	6077047536 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172607632 -> 11671105712 [dir=none]
	11671105712 [label="result1
 (960)" fillcolor=orange]
	6172607632 -> 11671105952 [dir=none]
	11671105952 [label="result2
 (960)" fillcolor=orange]
	6172607632 -> 6073399024 [dir=none]
	6073399024 [label="running_mean
 (960)" fillcolor=orange]
	6172607632 -> 6073399344 [dir=none]
	6073399344 [label="running_var
 (960)" fillcolor=orange]
	6172607632 -> 6073399184 [dir=none]
	6073399184 [label="weight
 (960)" fillcolor=orange]
	6172607632 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172607488 -> 6172607632
	6172607488 -> 6077046656 [dir=none]
	6077046656 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	6172607488 -> 6073399104 [dir=none]
	6073399104 [label="weight
 (960, 160, 1, 1)" fillcolor=orange]
	6172607488 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172610656 -> 6172607488
	6172610656 [label="AddBackward0
------------
alpha: 1"]
	6172607056 -> 6172610656
	6172607056 -> 6077046496 [dir=none]
	6077046496 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6172607056 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172606960 -> 6172607056
	6172606960 -> 11671105312 [dir=none]
	11671105312 [label="other
 ()" fillcolor=orange]
	6172606960 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172606816 -> 6172606960
	6172606816 -> 6077046896 [dir=none]
	6077046896 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	6172606816 -> 11671104992 [dir=none]
	11671104992 [label="result1
 (160)" fillcolor=orange]
	6172606816 -> 11671105072 [dir=none]
	11671105072 [label="result2
 (160)" fillcolor=orange]
	6172606816 -> 6073398384 [dir=none]
	6073398384 [label="running_mean
 (160)" fillcolor=orange]
	6172606816 -> 6073398704 [dir=none]
	6073398704 [label="running_var
 (160)" fillcolor=orange]
	6172606816 -> 6073398544 [dir=none]
	6073398544 [label="weight
 (160)" fillcolor=orange]
	6172606816 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172606672 -> 6172606816
	6172606672 -> 6077047056 [dir=none]
	6077047056 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172606672 -> 6073398464 [dir=none]
	6073398464 [label="weight
 (160, 960, 1, 1)" fillcolor=orange]
	6172606672 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172540784 -> 6172606672
	6172540784 -> 6077047696 [dir=none]
	6077047696 [label="other
 (1, 960, 38, 38)" fillcolor=orange]
	6172540784 -> 6077047296 [dir=none]
	6077047296 [label="self
 (1, 960, 1, 1)" fillcolor=orange]
	6172540784 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6172540448 -> 6172540784
	6172540448 -> 11671104672 [dir=none]
	11671104672 [label="result
 (1, 960, 1, 1)" fillcolor=orange]
	6172540448 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6172540304 -> 6172540448
	6172540304 -> 6077047216 [dir=none]
	6077047216 [label="input
 (1, 40, 1, 1)" fillcolor=orange]
	6172540304 -> 6073398224 [dir=none]
	6073398224 [label="weight
 (960, 40, 1, 1)" fillcolor=orange]
	6172540304 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (960,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078597376 -> 6172540304
	6078597376 [label=SwishImplementationBackward]
	6172539872 -> 6078597376
	6172539872 -> 6077047936 [dir=none]
	6077047936 [label="input
 (1, 960, 1, 1)" fillcolor=orange]
	6172539872 -> 6073397984 [dir=none]
	6073397984 [label="weight
 (40, 960, 1, 1)" fillcolor=orange]
	6172539872 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (40,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172539728 -> 6172539872
	6172539728 -> 6077047696 [dir=none]
	6077047696 [label="self
 (1, 960, 38, 38)" fillcolor=orange]
	6172539728 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 960, 38, 38)"]
	6078597152 -> 6172539728
	6078597152 [label=SwishImplementationBackward]
	6172539296 -> 6078597152
	6172539296 -> 6077048336 [dir=none]
	6077048336 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172539296 -> 11671104192 [dir=none]
	11671104192 [label="result1
 (960)" fillcolor=orange]
	6172539296 -> 11671104592 [dir=none]
	11671104592 [label="result2
 (960)" fillcolor=orange]
	6172539296 -> 6073395664 [dir=none]
	6073395664 [label="running_mean
 (960)" fillcolor=orange]
	6172539296 -> 6073397504 [dir=none]
	6073397504 [label="running_var
 (960)" fillcolor=orange]
	6172539296 -> 6073397264 [dir=none]
	6073397264 [label="weight
 (960)" fillcolor=orange]
	6172539296 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172539152 -> 6172539296
	6172539152 -> 6077048496 [dir=none]
	6077048496 [label="input
 (1, 960, 40, 40)" fillcolor=orange]
	6172539152 -> 6073397344 [dir=none]
	6073397344 [label="weight
 (960, 1, 3, 3)" fillcolor=orange]
	6172539152 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            960
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172538864 -> 6172539152
	6172538864 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6078596928 -> 6172538864
	6078596928 [label=SwishImplementationBackward]
	6172538624 -> 6078596928
	6172538624 -> 6077049936 [dir=none]
	6077049936 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172538624 -> 11671103632 [dir=none]
	11671103632 [label="result1
 (960)" fillcolor=orange]
	6172538624 -> 11671103872 [dir=none]
	11671103872 [label="result2
 (960)" fillcolor=orange]
	6172538624 -> 6073396544 [dir=none]
	6073396544 [label="running_mean
 (960)" fillcolor=orange]
	6172538624 -> 6073396864 [dir=none]
	6073396864 [label="running_var
 (960)" fillcolor=orange]
	6172538624 -> 6073396704 [dir=none]
	6073396704 [label="weight
 (960)" fillcolor=orange]
	6172538624 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172538480 -> 6172538624
	6172538480 -> 6077048976 [dir=none]
	6077048976 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	6172538480 -> 6073396624 [dir=none]
	6073396624 [label="weight
 (960, 160, 1, 1)" fillcolor=orange]
	6172538480 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172607248 -> 6172538480
	6172607248 [label="AddBackward0
------------
alpha: 1"]
	6172538048 -> 6172607248
	6172538048 -> 6077048656 [dir=none]
	6077048656 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6172538048 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172537712 -> 6172538048
	6172537712 -> 11671103232 [dir=none]
	11671103232 [label="other
 ()" fillcolor=orange]
	6172537712 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172537568 -> 6172537712
	6172537568 -> 6077049136 [dir=none]
	6077049136 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	6172537568 -> 11671102912 [dir=none]
	11671102912 [label="result1
 (160)" fillcolor=orange]
	6172537568 -> 11671102992 [dir=none]
	11671102992 [label="result2
 (160)" fillcolor=orange]
	6172537568 -> 6073395904 [dir=none]
	6073395904 [label="running_mean
 (160)" fillcolor=orange]
	6172537568 -> 6073396224 [dir=none]
	6073396224 [label="running_var
 (160)" fillcolor=orange]
	6172537568 -> 6073396064 [dir=none]
	6073396064 [label="weight
 (160)" fillcolor=orange]
	6172537568 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172537424 -> 6172537568
	6172537424 -> 6077049296 [dir=none]
	6077049296 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172537424 -> 6073395984 [dir=none]
	6073395984 [label="weight
 (160, 960, 1, 1)" fillcolor=orange]
	6172537424 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172537136 -> 6172537424
	6172537136 -> 6077050096 [dir=none]
	6077050096 [label="other
 (1, 960, 38, 38)" fillcolor=orange]
	6172537136 -> 6077049616 [dir=none]
	6077049616 [label="self
 (1, 960, 1, 1)" fillcolor=orange]
	6172537136 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6172537040 -> 6172537136
	6172537040 -> 11671102592 [dir=none]
	11671102592 [label="result
 (1, 960, 1, 1)" fillcolor=orange]
	6172537040 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6172536896 -> 6172537040
	6172536896 -> 6077049456 [dir=none]
	6077049456 [label="input
 (1, 40, 1, 1)" fillcolor=orange]
	6172536896 -> 6073395744 [dir=none]
	6073395744 [label="weight
 (960, 40, 1, 1)" fillcolor=orange]
	6172536896 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (960,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078596704 -> 6172536896
	6078596704 [label=SwishImplementationBackward]
	6172536464 -> 6078596704
	6172536464 -> 6077050336 [dir=none]
	6077050336 [label="input
 (1, 960, 1, 1)" fillcolor=orange]
	6172536464 -> 6073395504 [dir=none]
	6073395504 [label="weight
 (40, 960, 1, 1)" fillcolor=orange]
	6172536464 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (40,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172536320 -> 6172536464
	6172536320 -> 6077050096 [dir=none]
	6077050096 [label="self
 (1, 960, 38, 38)" fillcolor=orange]
	6172536320 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 960, 38, 38)"]
	6078596480 -> 6172536320
	6078596480 [label=SwishImplementationBackward]
	6172535888 -> 6078596480
	6172535888 -> 6077050736 [dir=none]
	6077050736 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172535888 -> 11671102112 [dir=none]
	11671102112 [label="result1
 (960)" fillcolor=orange]
	6172535888 -> 11671102512 [dir=none]
	11671102512 [label="result2
 (960)" fillcolor=orange]
	6172535888 -> 6073393184 [dir=none]
	6073393184 [label="running_mean
 (960)" fillcolor=orange]
	6172535888 -> 6073395024 [dir=none]
	6073395024 [label="running_var
 (960)" fillcolor=orange]
	6172535888 -> 6073394784 [dir=none]
	6073394784 [label="weight
 (960)" fillcolor=orange]
	6172535888 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172535744 -> 6172535888
	6172535744 -> 6077050816 [dir=none]
	6077050816 [label="input
 (1, 960, 40, 40)" fillcolor=orange]
	6172535744 -> 6073394864 [dir=none]
	6073394864 [label="weight
 (960, 1, 3, 3)" fillcolor=orange]
	6172535744 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            960
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172535456 -> 6172535744
	6172535456 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6078596256 -> 6172535456
	6078596256 [label=SwishImplementationBackward]
	6172534976 -> 6078596256
	6172534976 -> 6077052016 [dir=none]
	6077052016 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172534976 -> 11671101552 [dir=none]
	11671101552 [label="result1
 (960)" fillcolor=orange]
	6172534976 -> 11671101792 [dir=none]
	11671101792 [label="result2
 (960)" fillcolor=orange]
	6172534976 -> 6073394064 [dir=none]
	6073394064 [label="running_mean
 (960)" fillcolor=orange]
	6172534976 -> 6073394384 [dir=none]
	6073394384 [label="running_var
 (960)" fillcolor=orange]
	6172534976 -> 6073394224 [dir=none]
	6073394224 [label="weight
 (960)" fillcolor=orange]
	6172534976 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172534832 -> 6172534976
	6172534832 -> 6077051136 [dir=none]
	6077051136 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	6172534832 -> 6073394144 [dir=none]
	6073394144 [label="weight
 (960, 160, 1, 1)" fillcolor=orange]
	6172534832 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172538000 -> 6172534832
	6172538000 [label="AddBackward0
------------
alpha: 1"]
	6172534400 -> 6172538000
	6172534400 -> 6077051056 [dir=none]
	6077051056 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6172534400 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172534304 -> 6172534400
	6172534304 -> 11671101152 [dir=none]
	11671101152 [label="other
 ()" fillcolor=orange]
	6172534304 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172534160 -> 6172534304
	6172534160 -> 6077051296 [dir=none]
	6077051296 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	6172534160 -> 11671100832 [dir=none]
	11671100832 [label="result1
 (160)" fillcolor=orange]
	6172534160 -> 11671100912 [dir=none]
	11671100912 [label="result2
 (160)" fillcolor=orange]
	6172534160 -> 6073393424 [dir=none]
	6073393424 [label="running_mean
 (160)" fillcolor=orange]
	6172534160 -> 6073393744 [dir=none]
	6073393744 [label="running_var
 (160)" fillcolor=orange]
	6172534160 -> 6073393584 [dir=none]
	6073393584 [label="weight
 (160)" fillcolor=orange]
	6172534160 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172534016 -> 6172534160
	6172534016 -> 6077051456 [dir=none]
	6077051456 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172534016 -> 6073393504 [dir=none]
	6073393504 [label="weight
 (160, 960, 1, 1)" fillcolor=orange]
	6172534016 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172533728 -> 6172534016
	6172533728 -> 6077052176 [dir=none]
	6077052176 [label="other
 (1, 960, 38, 38)" fillcolor=orange]
	6172533728 -> 6077051696 [dir=none]
	6077051696 [label="self
 (1, 960, 1, 1)" fillcolor=orange]
	6172533728 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6172533392 -> 6172533728
	6172533392 -> 11671100512 [dir=none]
	11671100512 [label="result
 (1, 960, 1, 1)" fillcolor=orange]
	6172533392 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6172533248 -> 6172533392
	6172533248 -> 6077051616 [dir=none]
	6077051616 [label="input
 (1, 40, 1, 1)" fillcolor=orange]
	6172533248 -> 6073393264 [dir=none]
	6073393264 [label="weight
 (960, 40, 1, 1)" fillcolor=orange]
	6172533248 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (960,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078596032 -> 6172533248
	6078596032 [label=SwishImplementationBackward]
	6172532816 -> 6078596032
	6172532816 -> 6077052656 [dir=none]
	6077052656 [label="input
 (1, 960, 1, 1)" fillcolor=orange]
	6172532816 -> 6073393024 [dir=none]
	6073393024 [label="weight
 (40, 960, 1, 1)" fillcolor=orange]
	6172532816 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (40,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172532672 -> 6172532816
	6172532672 -> 6077052176 [dir=none]
	6077052176 [label="self
 (1, 960, 38, 38)" fillcolor=orange]
	6172532672 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 960, 38, 38)"]
	6078595808 -> 6172532672
	6078595808 [label=SwishImplementationBackward]
	6172532240 -> 6078595808
	6172532240 -> 6077053056 [dir=none]
	6077053056 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172532240 -> 11671100032 [dir=none]
	11671100032 [label="result1
 (960)" fillcolor=orange]
	6172532240 -> 11671100432 [dir=none]
	11671100432 [label="result2
 (960)" fillcolor=orange]
	6172532240 -> 6073390704 [dir=none]
	6073390704 [label="running_mean
 (960)" fillcolor=orange]
	6172532240 -> 6073392544 [dir=none]
	6073392544 [label="running_var
 (960)" fillcolor=orange]
	6172532240 -> 6073392304 [dir=none]
	6073392304 [label="weight
 (960)" fillcolor=orange]
	6172532240 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172532096 -> 6172532240
	6172532096 -> 6077053216 [dir=none]
	6077053216 [label="input
 (1, 960, 40, 40)" fillcolor=orange]
	6172532096 -> 6073392384 [dir=none]
	6073392384 [label="weight
 (960, 1, 3, 3)" fillcolor=orange]
	6172532096 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            960
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172531808 -> 6172532096
	6172531808 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6078595584 -> 6172531808
	6078595584 [label=SwishImplementationBackward]
	6172531568 -> 6078595584
	6172531568 -> 6077054336 [dir=none]
	6077054336 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172531568 -> 11671099472 [dir=none]
	11671099472 [label="result1
 (960)" fillcolor=orange]
	6172531568 -> 11671099712 [dir=none]
	11671099712 [label="result2
 (960)" fillcolor=orange]
	6172531568 -> 6073391584 [dir=none]
	6073391584 [label="running_mean
 (960)" fillcolor=orange]
	6172531568 -> 6073391904 [dir=none]
	6073391904 [label="running_var
 (960)" fillcolor=orange]
	6172531568 -> 6073391744 [dir=none]
	6073391744 [label="weight
 (960)" fillcolor=orange]
	6172531568 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172531424 -> 6172531568
	6172531424 -> 6077053696 [dir=none]
	6077053696 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	6172531424 -> 6073391664 [dir=none]
	6073391664 [label="weight
 (960, 160, 1, 1)" fillcolor=orange]
	6172531424 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172534592 -> 6172531424
	6172534592 [label="AddBackward0
------------
alpha: 1"]
	6172530992 -> 6172534592
	6172530992 -> 6077053376 [dir=none]
	6077053376 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6172530992 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172530656 -> 6172530992
	6172530656 -> 11671099072 [dir=none]
	11671099072 [label="other
 ()" fillcolor=orange]
	6172530656 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172530512 -> 6172530656
	6172530512 -> 6077053856 [dir=none]
	6077053856 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	6172530512 -> 11671098752 [dir=none]
	11671098752 [label="result1
 (160)" fillcolor=orange]
	6172530512 -> 11671098832 [dir=none]
	11671098832 [label="result2
 (160)" fillcolor=orange]
	6172530512 -> 6073390944 [dir=none]
	6073390944 [label="running_mean
 (160)" fillcolor=orange]
	6172530512 -> 6073391264 [dir=none]
	6073391264 [label="running_var
 (160)" fillcolor=orange]
	6172530512 -> 6073391104 [dir=none]
	6073391104 [label="weight
 (160)" fillcolor=orange]
	6172530512 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172530368 -> 6172530512
	6172530368 -> 6077053936 [dir=none]
	6077053936 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172530368 -> 6073391024 [dir=none]
	6073391024 [label="weight
 (160, 960, 1, 1)" fillcolor=orange]
	6172530368 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172530080 -> 6172530368
	6172530080 -> 6077054816 [dir=none]
	6077054816 [label="other
 (1, 960, 38, 38)" fillcolor=orange]
	6172530080 -> 6077054176 [dir=none]
	6077054176 [label="self
 (1, 960, 1, 1)" fillcolor=orange]
	6172530080 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6172529984 -> 6172530080
	6172529984 -> 11671098432 [dir=none]
	11671098432 [label="result
 (1, 960, 1, 1)" fillcolor=orange]
	6172529984 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6172529840 -> 6172529984
	6172529840 -> 6077054096 [dir=none]
	6077054096 [label="input
 (1, 40, 1, 1)" fillcolor=orange]
	6172529840 -> 6073390784 [dir=none]
	6073390784 [label="weight
 (960, 40, 1, 1)" fillcolor=orange]
	6172529840 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (960,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078595360 -> 6172529840
	6078595360 [label=SwishImplementationBackward]
	6172529408 -> 6078595360
	6172529408 -> 6077039536 [dir=none]
	6077039536 [label="input
 (1, 960, 1, 1)" fillcolor=orange]
	6172529408 -> 6073390544 [dir=none]
	6073390544 [label="weight
 (40, 960, 1, 1)" fillcolor=orange]
	6172529408 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (40,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172529264 -> 6172529408
	6172529264 -> 6077054816 [dir=none]
	6077054816 [label="self
 (1, 960, 38, 38)" fillcolor=orange]
	6172529264 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 960, 38, 38)"]
	6078595136 -> 6172529264
	6078595136 [label=SwishImplementationBackward]
	6172528832 -> 6078595136
	6172528832 -> 6077041136 [dir=none]
	6077041136 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172528832 -> 11671097952 [dir=none]
	11671097952 [label="result1
 (960)" fillcolor=orange]
	6172528832 -> 11671098352 [dir=none]
	11671098352 [label="result2
 (960)" fillcolor=orange]
	6172528832 -> 6073388304 [dir=none]
	6073388304 [label="running_mean
 (960)" fillcolor=orange]
	6172528832 -> 6073390064 [dir=none]
	6073390064 [label="running_var
 (960)" fillcolor=orange]
	6172528832 -> 6073389824 [dir=none]
	6073389824 [label="weight
 (960)" fillcolor=orange]
	6172528832 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172528688 -> 6172528832
	6172528688 -> 6077041456 [dir=none]
	6077041456 [label="input
 (1, 960, 40, 40)" fillcolor=orange]
	6172528688 -> 6073389904 [dir=none]
	6073389904 [label="weight
 (960, 1, 3, 3)" fillcolor=orange]
	6172528688 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            960
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172528400 -> 6172528688
	6172528400 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6079037024 -> 6172528400
	6079037024 [label=SwishImplementationBackward]
	6172527920 -> 6079037024
	6172527920 -> 6077044016 [dir=none]
	6077044016 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172527920 -> 11671097392 [dir=none]
	11671097392 [label="result1
 (960)" fillcolor=orange]
	6172527920 -> 11671097632 [dir=none]
	11671097632 [label="result2
 (960)" fillcolor=orange]
	6172527920 -> 6073389184 [dir=none]
	6073389184 [label="running_mean
 (960)" fillcolor=orange]
	6172527920 -> 6073389504 [dir=none]
	6073389504 [label="running_var
 (960)" fillcolor=orange]
	6172527920 -> 6073389344 [dir=none]
	6073389344 [label="weight
 (960)" fillcolor=orange]
	6172527920 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172527776 -> 6172527920
	6172527776 -> 6077042896 [dir=none]
	6077042896 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	6172527776 -> 6073389264 [dir=none]
	6073389264 [label="weight
 (960, 160, 1, 1)" fillcolor=orange]
	6172527776 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172530944 -> 6172527776
	6172530944 [label="AddBackward0
------------
alpha: 1"]
	6172527344 -> 6172530944
	6172527344 -> 6077042736 [dir=none]
	6077042736 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6172527344 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172527248 -> 6172527344
	6172527248 -> 11671096992 [dir=none]
	11671096992 [label="other
 ()" fillcolor=orange]
	6172527248 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172527104 -> 6172527248
	6172527104 -> 6077043136 [dir=none]
	6077043136 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	6172527104 -> 11671096672 [dir=none]
	11671096672 [label="result1
 (160)" fillcolor=orange]
	6172527104 -> 11671096752 [dir=none]
	11671096752 [label="result2
 (160)" fillcolor=orange]
	6172527104 -> 6073388544 [dir=none]
	6073388544 [label="running_mean
 (160)" fillcolor=orange]
	6172527104 -> 6073388864 [dir=none]
	6073388864 [label="running_var
 (160)" fillcolor=orange]
	6172527104 -> 6073388704 [dir=none]
	6073388704 [label="weight
 (160)" fillcolor=orange]
	6172527104 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172526960 -> 6172527104
	6172526960 -> 6077043296 [dir=none]
	6077043296 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172526960 -> 6073388624 [dir=none]
	6073388624 [label="weight
 (160, 960, 1, 1)" fillcolor=orange]
	6172526960 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172526672 -> 6172526960
	6172526672 -> 6077044816 [dir=none]
	6077044816 [label="other
 (1, 960, 38, 38)" fillcolor=orange]
	6172526672 -> 6077043776 [dir=none]
	6077043776 [label="self
 (1, 960, 1, 1)" fillcolor=orange]
	6172526672 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6172526336 -> 6172526672
	6172526336 -> 11671096352 [dir=none]
	11671096352 [label="result
 (1, 960, 1, 1)" fillcolor=orange]
	6172526336 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6172526192 -> 6172526336
	6172526192 -> 6077043456 [dir=none]
	6077043456 [label="input
 (1, 40, 1, 1)" fillcolor=orange]
	6172526192 -> 6073388384 [dir=none]
	6073388384 [label="weight
 (960, 40, 1, 1)" fillcolor=orange]
	6172526192 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (960,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079036800 -> 6172526192
	6079036800 [label=SwishImplementationBackward]
	6172525760 -> 6079036800
	6172525760 -> 6077045856 [dir=none]
	6077045856 [label="input
 (1, 960, 1, 1)" fillcolor=orange]
	6172525760 -> 6073388144 [dir=none]
	6073388144 [label="weight
 (40, 960, 1, 1)" fillcolor=orange]
	6172525760 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (40,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172525616 -> 6172525760
	6172525616 -> 6077044816 [dir=none]
	6077044816 [label="self
 (1, 960, 38, 38)" fillcolor=orange]
	6172525616 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 960, 38, 38)"]
	6079036576 -> 6172525616
	6079036576 [label=SwishImplementationBackward]
	6172525184 -> 6079036576
	6172525184 -> 6077049216 [dir=none]
	6077049216 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172525184 -> 11671095872 [dir=none]
	11671095872 [label="result1
 (960)" fillcolor=orange]
	6172525184 -> 11671096272 [dir=none]
	11671096272 [label="result2
 (960)" fillcolor=orange]
	6172525184 -> 6073385824 [dir=none]
	6073385824 [label="running_mean
 (960)" fillcolor=orange]
	6172525184 -> 6073387664 [dir=none]
	6073387664 [label="running_var
 (960)" fillcolor=orange]
	6172525184 -> 6073387424 [dir=none]
	6073387424 [label="weight
 (960)" fillcolor=orange]
	6172525184 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172525040 -> 6172525184
	6172525040 -> 6077049696 [dir=none]
	6077049696 [label="input
 (1, 960, 40, 40)" fillcolor=orange]
	6172525040 -> 6073387504 [dir=none]
	6073387504 [label="weight
 (960, 1, 3, 3)" fillcolor=orange]
	6172525040 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            960
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172524752 -> 6172525040
	6172524752 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6079036352 -> 6172524752
	6079036352 [label=SwishImplementationBackward]
	6172524800 -> 6079036352
	6172524800 -> 6077053136 [dir=none]
	6077053136 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	6172524800 -> 11671094592 [dir=none]
	11671094592 [label="result1
 (960)" fillcolor=orange]
	6172524800 -> 11671054880 [dir=none]
	11671054880 [label="result2
 (960)" fillcolor=orange]
	6172524800 -> 6073386704 [dir=none]
	6073386704 [label="running_mean
 (960)" fillcolor=orange]
	6172524800 -> 6073387024 [dir=none]
	6073387024 [label="running_var
 (960)" fillcolor=orange]
	6172524800 -> 6073386864 [dir=none]
	6073386864 [label="weight
 (960)" fillcolor=orange]
	6172524800 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172442384 -> 6172524800
	6172442384 -> 6077050176 [dir=none]
	6077050176 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	6172442384 -> 6073386784 [dir=none]
	6073386784 [label="weight
 (960, 160, 1, 1)" fillcolor=orange]
	6172442384 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172527536 -> 6172442384
	6172527536 -> 6077050896 [dir=none]
	6077050896 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	6172527536 -> 11671057120 [dir=none]
	11671057120 [label="result1
 (160)" fillcolor=orange]
	6172527536 -> 11671044320 [dir=none]
	11671044320 [label="result2
 (160)" fillcolor=orange]
	6172527536 -> 6073386064 [dir=none]
	6073386064 [label="running_mean
 (160)" fillcolor=orange]
	6172527536 -> 6073386384 [dir=none]
	6073386384 [label="running_var
 (160)" fillcolor=orange]
	6172527536 -> 6073386224 [dir=none]
	6073386224 [label="weight
 (160)" fillcolor=orange]
	6172527536 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172441952 -> 6172527536
	6172441952 -> 6077051216 [dir=none]
	6077051216 [label="input
 (1, 480, 38, 38)" fillcolor=orange]
	6172441952 -> 6073386144 [dir=none]
	6073386144 [label="weight
 (160, 480, 1, 1)" fillcolor=orange]
	6172441952 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172441664 -> 6172441952
	6172441664 -> 6077054016 [dir=none]
	6077054016 [label="other
 (1, 480, 38, 38)" fillcolor=orange]
	6172441664 -> 6077052576 [dir=none]
	6077052576 [label="self
 (1, 480, 1, 1)" fillcolor=orange]
	6172441664 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6172441328 -> 6172441664
	6172441328 -> 11671055200 [dir=none]
	11671055200 [label="result
 (1, 480, 1, 1)" fillcolor=orange]
	6172441328 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6172441184 -> 6172441328
	6172441184 -> 6077051536 [dir=none]
	6077051536 [label="input
 (1, 20, 1, 1)" fillcolor=orange]
	6172441184 -> 6073385904 [dir=none]
	6073385904 [label="weight
 (480, 20, 1, 1)" fillcolor=orange]
	6172441184 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (480,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079036128 -> 6172441184
	6079036128 [label=SwishImplementationBackward]
	6172440752 -> 6079036128
	6172440752 -> 6077054416 [dir=none]
	6077054416 [label="input
 (1, 480, 1, 1)" fillcolor=orange]
	6172440752 -> 6073385664 [dir=none]
	6073385664 [label="weight
 (20, 480, 1, 1)" fillcolor=orange]
	6172440752 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (20,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172440608 -> 6172440752
	6172440608 -> 6077054016 [dir=none]
	6077054016 [label="self
 (1, 480, 38, 38)" fillcolor=orange]
	6172440608 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 480, 38, 38)"]
	6079035904 -> 6172440608
	6079035904 [label=SwishImplementationBackward]
	6172440176 -> 6079035904
	6172440176 -> 6077040096 [dir=none]
	6077040096 [label="input
 (1, 480, 38, 38)" fillcolor=orange]
	6172440176 -> 11671046480 [dir=none]
	11671046480 [label="result1
 (480)" fillcolor=orange]
	6172440176 -> 11671057440 [dir=none]
	11671057440 [label="result2
 (480)" fillcolor=orange]
	6172440176 -> 6073088368 [dir=none]
	6073088368 [label="running_mean
 (480)" fillcolor=orange]
	6172440176 -> 6073385184 [dir=none]
	6073385184 [label="running_var
 (480)" fillcolor=orange]
	6172440176 -> 6073089968 [dir=none]
	6073089968 [label="weight
 (480)" fillcolor=orange]
	6172440176 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172440032 -> 6172440176
	6172440032 -> 6077040896 [dir=none]
	6077040896 [label="input
 (1, 480, 77, 77)" fillcolor=orange]
	6172440032 -> 6073385024 [dir=none]
	6073385024 [label="weight
 (480, 1, 3, 3)" fillcolor=orange]
	6172440032 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            480
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	6172439744 -> 6172440032
	6172439744 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6079035680 -> 6172439744
	6079035680 [label=SwishImplementationBackward]
	6172439504 -> 6079035680
	6172439504 -> 6077048016 [dir=none]
	6077048016 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6172439504 -> 11671045920 [dir=none]
	11671045920 [label="result1
 (480)" fillcolor=orange]
	6172439504 -> 11671058480 [dir=none]
	11671058480 [label="result2
 (480)" fillcolor=orange]
	6172439504 -> 6073089248 [dir=none]
	6073089248 [label="running_mean
 (480)" fillcolor=orange]
	6172439504 -> 6073089568 [dir=none]
	6073089568 [label="running_var
 (480)" fillcolor=orange]
	6172439504 -> 6073089408 [dir=none]
	6073089408 [label="weight
 (480)" fillcolor=orange]
	6172439504 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172439360 -> 6172439504
	6172439360 -> 6077044176 [dir=none]
	6077044176 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6172439360 -> 6073089328 [dir=none]
	6073089328 [label="weight
 (480, 80, 1, 1)" fillcolor=orange]
	6172439360 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6077546352 -> 6172439360
	6172439072 -> 6172439360
	6073089328 [label="
 (480, 80, 1, 1)" fillcolor=lightblue]
	6073089328 -> 6172439072
	6172439072 [label=AccumulateGrad]
	6172439312 -> 6172439504
	6073089408 [label="
 (480)" fillcolor=lightblue]
	6073089408 -> 6172439312
	6172439312 [label=AccumulateGrad]
	6172439792 -> 6172439504
	6073089488 [label="
 (480)" fillcolor=lightblue]
	6073089488 -> 6172439792
	6172439792 [label=AccumulateGrad]
	6077039936 -> 6079035680
	6077039936 [label="
 (1, 480, 75, 75)" fillcolor=orange]
	6172439936 -> 6172440032
	6073385024 [label="
 (480, 1, 3, 3)" fillcolor=lightblue]
	6073385024 -> 6172439936
	6172439936 [label=AccumulateGrad]
	6172440224 -> 6172440176
	6073089968 [label="
 (480)" fillcolor=lightblue]
	6073089968 -> 6172440224
	6172440224 [label=AccumulateGrad]
	6172440464 -> 6172440176
	6073385104 [label="
 (480)" fillcolor=lightblue]
	6073385104 -> 6172440464
	6172440464 [label=AccumulateGrad]
	6077039296 -> 6079035904
	6077039296 [label="
 (1, 480, 38, 38)" fillcolor=orange]
	6172440800 -> 6172440752
	6073385664 [label="
 (20, 480, 1, 1)" fillcolor=lightblue]
	6073385664 -> 6172440800
	6172440800 [label=AccumulateGrad]
	6172440896 -> 6172440752
	6073385744 [label="
 (20)" fillcolor=lightblue]
	6073385744 -> 6172440896
	6172440896 [label=AccumulateGrad]
	6077054256 -> 6079036128
	6077054256 [label="
 (1, 20, 1, 1)" fillcolor=orange]
	6172441040 -> 6172441184
	6073385904 [label="
 (480, 20, 1, 1)" fillcolor=lightblue]
	6073385904 -> 6172441040
	6172441040 [label=AccumulateGrad]
	6172441232 -> 6172441184
	6073385984 [label="
 (480)" fillcolor=lightblue]
	6073385984 -> 6172441232
	6172441232 [label=AccumulateGrad]
	6079035904 -> 6172441664
	6172441616 -> 6172441952
	6073386144 [label="
 (160, 480, 1, 1)" fillcolor=lightblue]
	6073386144 -> 6172441616
	6172441616 [label=AccumulateGrad]
	6172441904 -> 6172527536
	6073386224 [label="
 (160)" fillcolor=lightblue]
	6073386224 -> 6172441904
	6172441904 [label=AccumulateGrad]
	6172442240 -> 6172527536
	6073386304 [label="
 (160)" fillcolor=lightblue]
	6073386304 -> 6172442240
	6172442240 [label=AccumulateGrad]
	6172442096 -> 6172442384
	6073386784 [label="
 (960, 160, 1, 1)" fillcolor=lightblue]
	6073386784 -> 6172442096
	6172442096 [label=AccumulateGrad]
	6172442336 -> 6172524800
	6073386864 [label="
 (960)" fillcolor=lightblue]
	6073386864 -> 6172442336
	6172442336 [label=AccumulateGrad]
	6172442480 -> 6172524800
	6073386944 [label="
 (960)" fillcolor=lightblue]
	6073386944 -> 6172442480
	6172442480 [label=AccumulateGrad]
	6077049856 -> 6079036352
	6077049856 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	6172524944 -> 6172525040
	6073387504 [label="
 (960, 1, 3, 3)" fillcolor=lightblue]
	6073387504 -> 6172524944
	6172524944 [label=AccumulateGrad]
	6172525232 -> 6172525184
	6073387424 [label="
 (960)" fillcolor=lightblue]
	6073387424 -> 6172525232
	6172525232 [label=AccumulateGrad]
	6172525472 -> 6172525184
	6073387584 [label="
 (960)" fillcolor=lightblue]
	6073387584 -> 6172525472
	6172525472 [label=AccumulateGrad]
	6077048256 -> 6079036576
	6077048256 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	6172525808 -> 6172525760
	6073388144 [label="
 (40, 960, 1, 1)" fillcolor=lightblue]
	6073388144 -> 6172525808
	6172525808 [label=AccumulateGrad]
	6172525904 -> 6172525760
	6073388224 [label="
 (40)" fillcolor=lightblue]
	6073388224 -> 6172525904
	6172525904 [label=AccumulateGrad]
	6077045616 -> 6079036800
	6077045616 [label="
 (1, 40, 1, 1)" fillcolor=orange]
	6172526048 -> 6172526192
	6073388384 [label="
 (960, 40, 1, 1)" fillcolor=lightblue]
	6073388384 -> 6172526048
	6172526048 [label=AccumulateGrad]
	6172526240 -> 6172526192
	6073388464 [label="
 (960)" fillcolor=lightblue]
	6073388464 -> 6172526240
	6172526240 [label=AccumulateGrad]
	6079036576 -> 6172526672
	6172526624 -> 6172526960
	6073388624 [label="
 (160, 960, 1, 1)" fillcolor=lightblue]
	6073388624 -> 6172526624
	6172526624 [label=AccumulateGrad]
	6172526912 -> 6172527104
	6073388704 [label="
 (160)" fillcolor=lightblue]
	6073388704 -> 6172526912
	6172526912 [label=AccumulateGrad]
	6172527392 -> 6172527104
	6073388784 [label="
 (160)" fillcolor=lightblue]
	6073388784 -> 6172527392
	6172527392 [label=AccumulateGrad]
	6172527536 -> 6172530944
	6172527488 -> 6172527776
	6073389264 [label="
 (960, 160, 1, 1)" fillcolor=lightblue]
	6073389264 -> 6172527488
	6172527488 [label=AccumulateGrad]
	6172527968 -> 6172527920
	6073389344 [label="
 (960)" fillcolor=lightblue]
	6073389344 -> 6172527968
	6172527968 [label=AccumulateGrad]
	6172528208 -> 6172527920
	6073389424 [label="
 (960)" fillcolor=lightblue]
	6073389424 -> 6172528208
	6172528208 [label=AccumulateGrad]
	6077040576 -> 6079037024
	6077040576 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	6172528352 -> 6172528688
	6073389904 [label="
 (960, 1, 3, 3)" fillcolor=lightblue]
	6073389904 -> 6172528352
	6172528352 [label=AccumulateGrad]
	6172528640 -> 6172528832
	6073389824 [label="
 (960)" fillcolor=lightblue]
	6073389824 -> 6172528640
	6172528640 [label=AccumulateGrad]
	6172529120 -> 6172528832
	6073389984 [label="
 (960)" fillcolor=lightblue]
	6073389984 -> 6172529120
	6172529120 [label=AccumulateGrad]
	6077039776 -> 6078595136
	6077039776 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	6172529216 -> 6172529408
	6073390544 [label="
 (40, 960, 1, 1)" fillcolor=lightblue]
	6073390544 -> 6172529216
	6172529216 [label=AccumulateGrad]
	6172529552 -> 6172529408
	6073390624 [label="
 (40)" fillcolor=lightblue]
	6073390624 -> 6172529552
	6172529552 [label=AccumulateGrad]
	6077038736 -> 6078595360
	6077038736 [label="
 (1, 40, 1, 1)" fillcolor=orange]
	6172529696 -> 6172529840
	6073390784 [label="
 (960, 40, 1, 1)" fillcolor=lightblue]
	6073390784 -> 6172529696
	6172529696 [label=AccumulateGrad]
	6172529648 -> 6172529840
	6073390864 [label="
 (960)" fillcolor=lightblue]
	6073390864 -> 6172529648
	6172529648 [label=AccumulateGrad]
	6078595136 -> 6172530080
	6172530272 -> 6172530368
	6073391024 [label="
 (160, 960, 1, 1)" fillcolor=lightblue]
	6073391024 -> 6172530272
	6172530272 [label=AccumulateGrad]
	6172530560 -> 6172530512
	6073391104 [label="
 (160)" fillcolor=lightblue]
	6073391104 -> 6172530560
	6172530560 [label=AccumulateGrad]
	6172530800 -> 6172530512
	6073391184 [label="
 (160)" fillcolor=lightblue]
	6073391184 -> 6172530800
	6172530800 [label=AccumulateGrad]
	6172530944 -> 6172534592
	6172531136 -> 6172531424
	6073391664 [label="
 (960, 160, 1, 1)" fillcolor=lightblue]
	6073391664 -> 6172531136
	6172531136 [label=AccumulateGrad]
	6172531376 -> 6172531568
	6073391744 [label="
 (960)" fillcolor=lightblue]
	6073391744 -> 6172531376
	6172531376 [label=AccumulateGrad]
	6172531856 -> 6172531568
	6073391824 [label="
 (960)" fillcolor=lightblue]
	6073391824 -> 6172531856
	6172531856 [label=AccumulateGrad]
	6077052896 -> 6078595584
	6077052896 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	6172532000 -> 6172532096
	6073392384 [label="
 (960, 1, 3, 3)" fillcolor=lightblue]
	6073392384 -> 6172532000
	6172532000 [label=AccumulateGrad]
	6172532288 -> 6172532240
	6073392304 [label="
 (960)" fillcolor=lightblue]
	6073392304 -> 6172532288
	6172532288 [label=AccumulateGrad]
	6172532528 -> 6172532240
	6073392464 [label="
 (960)" fillcolor=lightblue]
	6073392464 -> 6172532528
	6172532528 [label=AccumulateGrad]
	6077052816 -> 6078595808
	6077052816 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	6172532864 -> 6172532816
	6073393024 [label="
 (40, 960, 1, 1)" fillcolor=lightblue]
	6073393024 -> 6172532864
	6172532864 [label=AccumulateGrad]
	6172532960 -> 6172532816
	6073393104 [label="
 (40)" fillcolor=lightblue]
	6073393104 -> 6172532960
	6172532960 [label=AccumulateGrad]
	6077052496 -> 6078596032
	6077052496 [label="
 (1, 40, 1, 1)" fillcolor=orange]
	6172533104 -> 6172533248
	6073393264 [label="
 (960, 40, 1, 1)" fillcolor=lightblue]
	6073393264 -> 6172533104
	6172533104 [label=AccumulateGrad]
	6172533296 -> 6172533248
	6073393344 [label="
 (960)" fillcolor=lightblue]
	6073393344 -> 6172533296
	6172533296 [label=AccumulateGrad]
	6078595808 -> 6172533728
	6172533680 -> 6172534016
	6073393504 [label="
 (160, 960, 1, 1)" fillcolor=lightblue]
	6073393504 -> 6172533680
	6172533680 [label=AccumulateGrad]
	6172533968 -> 6172534160
	6073393584 [label="
 (160)" fillcolor=lightblue]
	6073393584 -> 6172533968
	6172533968 [label=AccumulateGrad]
	6172534448 -> 6172534160
	6073393664 [label="
 (160)" fillcolor=lightblue]
	6073393664 -> 6172534448
	6172534448 [label=AccumulateGrad]
	6172534592 -> 6172538000
	6172534544 -> 6172534832
	6073394144 [label="
 (960, 160, 1, 1)" fillcolor=lightblue]
	6073394144 -> 6172534544
	6172534544 [label=AccumulateGrad]
	6172535024 -> 6172534976
	6073394224 [label="
 (960)" fillcolor=lightblue]
	6073394224 -> 6172535024
	6172535024 [label=AccumulateGrad]
	6172535264 -> 6172534976
	6073394304 [label="
 (960)" fillcolor=lightblue]
	6073394304 -> 6172535264
	6172535264 [label=AccumulateGrad]
	6077050576 -> 6078596256
	6077050576 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	6172535408 -> 6172535744
	6073394864 [label="
 (960, 1, 3, 3)" fillcolor=lightblue]
	6073394864 -> 6172535408
	6172535408 [label=AccumulateGrad]
	6172535696 -> 6172535888
	6073394784 [label="
 (960)" fillcolor=lightblue]
	6073394784 -> 6172535696
	6172535696 [label=AccumulateGrad]
	6172536176 -> 6172535888
	6073394944 [label="
 (960)" fillcolor=lightblue]
	6073394944 -> 6172536176
	6172536176 [label=AccumulateGrad]
	6077050496 -> 6078596480
	6077050496 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	6172536272 -> 6172536464
	6073395504 [label="
 (40, 960, 1, 1)" fillcolor=lightblue]
	6073395504 -> 6172536272
	6172536272 [label=AccumulateGrad]
	6172536608 -> 6172536464
	6073395584 [label="
 (40)" fillcolor=lightblue]
	6073395584 -> 6172536608
	6172536608 [label=AccumulateGrad]
	6077050256 -> 6078596704
	6077050256 [label="
 (1, 40, 1, 1)" fillcolor=orange]
	6172536752 -> 6172536896
	6073395744 [label="
 (960, 40, 1, 1)" fillcolor=lightblue]
	6073395744 -> 6172536752
	6172536752 [label=AccumulateGrad]
	6172536704 -> 6172536896
	6073395824 [label="
 (960)" fillcolor=lightblue]
	6073395824 -> 6172536704
	6172536704 [label=AccumulateGrad]
	6078596480 -> 6172537136
	6172537328 -> 6172537424
	6073395984 [label="
 (160, 960, 1, 1)" fillcolor=lightblue]
	6073395984 -> 6172537328
	6172537328 [label=AccumulateGrad]
	6172537616 -> 6172537568
	6073396064 [label="
 (160)" fillcolor=lightblue]
	6073396064 -> 6172537616
	6172537616 [label=AccumulateGrad]
	6172537856 -> 6172537568
	6073396144 [label="
 (160)" fillcolor=lightblue]
	6073396144 -> 6172537856
	6172537856 [label=AccumulateGrad]
	6172538000 -> 6172607248
	6172538192 -> 6172538480
	6073396624 [label="
 (960, 160, 1, 1)" fillcolor=lightblue]
	6073396624 -> 6172538192
	6172538192 [label=AccumulateGrad]
	6172538432 -> 6172538624
	6073396704 [label="
 (960)" fillcolor=lightblue]
	6073396704 -> 6172538432
	6172538432 [label=AccumulateGrad]
	6172538912 -> 6172538624
	6073396784 [label="
 (960)" fillcolor=lightblue]
	6073396784 -> 6172538912
	6172538912 [label=AccumulateGrad]
	6077048176 -> 6078596928
	6077048176 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	6172539056 -> 6172539152
	6073397344 [label="
 (960, 1, 3, 3)" fillcolor=lightblue]
	6073397344 -> 6172539056
	6172539056 [label=AccumulateGrad]
	6172539344 -> 6172539296
	6073397264 [label="
 (960)" fillcolor=lightblue]
	6073397264 -> 6172539344
	6172539344 [label=AccumulateGrad]
	6172539584 -> 6172539296
	6073397424 [label="
 (960)" fillcolor=lightblue]
	6073397424 -> 6172539584
	6172539584 [label=AccumulateGrad]
	6077048096 -> 6078597152
	6077048096 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	6172539920 -> 6172539872
	6073397984 [label="
 (40, 960, 1, 1)" fillcolor=lightblue]
	6073397984 -> 6172539920
	6172539920 [label=AccumulateGrad]
	6172540016 -> 6172539872
	6073398064 [label="
 (40)" fillcolor=lightblue]
	6073398064 -> 6172540016
	6172540016 [label=AccumulateGrad]
	6077047856 -> 6078597376
	6077047856 [label="
 (1, 40, 1, 1)" fillcolor=orange]
	6172540160 -> 6172540304
	6073398224 [label="
 (960, 40, 1, 1)" fillcolor=lightblue]
	6073398224 -> 6172540160
	6172540160 [label=AccumulateGrad]
	6172540352 -> 6172540304
	6073398304 [label="
 (960)" fillcolor=lightblue]
	6073398304 -> 6172540352
	6172540352 [label=AccumulateGrad]
	6078597152 -> 6172540784
	6172540736 -> 6172606672
	6073398464 [label="
 (160, 960, 1, 1)" fillcolor=lightblue]
	6073398464 -> 6172540736
	6172540736 [label=AccumulateGrad]
	6172606624 -> 6172606816
	6073398544 [label="
 (160)" fillcolor=lightblue]
	6073398544 -> 6172606624
	6172606624 [label=AccumulateGrad]
	6172607104 -> 6172606816
	6073398624 [label="
 (160)" fillcolor=lightblue]
	6073398624 -> 6172607104
	6172607104 [label=AccumulateGrad]
	6172607248 -> 6172610656
	6172607200 -> 6172607488
	6073399104 [label="
 (960, 160, 1, 1)" fillcolor=lightblue]
	6073399104 -> 6172607200
	6172607200 [label=AccumulateGrad]
	6172607680 -> 6172607632
	6073399184 [label="
 (960)" fillcolor=lightblue]
	6073399184 -> 6172607680
	6172607680 [label=AccumulateGrad]
	6172607920 -> 6172607632
	6073399264 [label="
 (960)" fillcolor=lightblue]
	6073399264 -> 6172607920
	6172607920 [label=AccumulateGrad]
	6077046016 -> 6078597600
	6077046016 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	6172608064 -> 6172608400
	6073399824 [label="
 (960, 1, 3, 3)" fillcolor=lightblue]
	6073399824 -> 6172608064
	6172608064 [label=AccumulateGrad]
	6172608352 -> 6172608544
	6073399744 [label="
 (960)" fillcolor=lightblue]
	6073399744 -> 6172608352
	6172608352 [label=AccumulateGrad]
	6172608832 -> 6172608544
	6073399904 [label="
 (960)" fillcolor=lightblue]
	6073399904 -> 6172608832
	6172608832 [label=AccumulateGrad]
	6077045776 -> 6078597824
	6077045776 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	6172608928 -> 6172609120
	6073400464 [label="
 (40, 960, 1, 1)" fillcolor=lightblue]
	6073400464 -> 6172608928
	6172608928 [label=AccumulateGrad]
	6172609264 -> 6172609120
	6073400544 [label="
 (40)" fillcolor=lightblue]
	6073400544 -> 6172609264
	6172609264 [label=AccumulateGrad]
	6077045536 -> 6078598048
	6077045536 [label="
 (1, 40, 1, 1)" fillcolor=orange]
	6172609408 -> 6172609552
	6073400704 [label="
 (960, 40, 1, 1)" fillcolor=lightblue]
	6073400704 -> 6172609408
	6172609408 [label=AccumulateGrad]
	6172609360 -> 6172609552
	6073400784 [label="
 (960)" fillcolor=lightblue]
	6073400784 -> 6172609360
	6172609360 [label=AccumulateGrad]
	6078597824 -> 6172609792
	6172609984 -> 6172610080
	6073400944 [label="
 (160, 960, 1, 1)" fillcolor=lightblue]
	6073400944 -> 6172609984
	6172609984 [label=AccumulateGrad]
	6172610272 -> 6172610224
	6073401024 [label="
 (160)" fillcolor=lightblue]
	6073401024 -> 6172610272
	6172610272 [label=AccumulateGrad]
	6172610512 -> 6172610224
	6073401104 [label="
 (160)" fillcolor=lightblue]
	6073401104 -> 6172610512
	6172610512 [label=AccumulateGrad]
	6172610656 -> 6172614304
	6172610848 -> 6172611136
	6075482416 [label="
 (960, 160, 1, 1)" fillcolor=lightblue]
	6075482416 -> 6172610848
	6172610848 [label=AccumulateGrad]
	6172611088 -> 6172611280
	6075482496 [label="
 (960)" fillcolor=lightblue]
	6075482496 -> 6172611088
	6172611088 [label=AccumulateGrad]
	6172611568 -> 6172611280
	6075482576 [label="
 (960)" fillcolor=lightblue]
	6075482576 -> 6172611568
	6172611568 [label=AccumulateGrad]
	6077043616 -> 6078598272
	6077043616 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	6172611712 -> 6172611808
	6075483136 [label="
 (960, 1, 3, 3)" fillcolor=lightblue]
	6075483136 -> 6172611712
	6172611712 [label=AccumulateGrad]
	6172612000 -> 6172611952
	6075483056 [label="
 (960)" fillcolor=lightblue]
	6075483056 -> 6172612000
	6172612000 [label=AccumulateGrad]
	6172612240 -> 6172611952
	6075483216 [label="
 (960)" fillcolor=lightblue]
	6075483216 -> 6172612240
	6172612240 [label=AccumulateGrad]
	6077043536 -> 6078598496
	6077043536 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	6172612576 -> 6172612528
	6075483776 [label="
 (40, 960, 1, 1)" fillcolor=lightblue]
	6075483776 -> 6172612576
	6172612576 [label=AccumulateGrad]
	6172612672 -> 6172612528
	6075483856 [label="
 (40)" fillcolor=lightblue]
	6075483856 -> 6172612672
	6172612672 [label=AccumulateGrad]
	6077043216 -> 6078598720
	6077043216 [label="
 (1, 40, 1, 1)" fillcolor=orange]
	6172612816 -> 6172612960
	6075484016 [label="
 (960, 40, 1, 1)" fillcolor=lightblue]
	6075484016 -> 6172612816
	6172612816 [label=AccumulateGrad]
	6172613008 -> 6172612960
	6075484096 [label="
 (960)" fillcolor=lightblue]
	6075484096 -> 6172613008
	6172613008 [label=AccumulateGrad]
	6078598496 -> 6172613440
	6172613392 -> 6172613728
	6075484256 [label="
 (160, 960, 1, 1)" fillcolor=lightblue]
	6075484256 -> 6172613392
	6172613392 [label=AccumulateGrad]
	6172613680 -> 6172613872
	6075484336 [label="
 (160)" fillcolor=lightblue]
	6075484336 -> 6172613680
	6172613680 [label=AccumulateGrad]
	6172614160 -> 6172613872
	6075484416 [label="
 (160)" fillcolor=lightblue]
	6075484416 -> 6172614160
	6172614160 [label=AccumulateGrad]
	6172614304 -> 6172617712
	6172614256 -> 6172614544
	6075484896 [label="
 (960, 160, 1, 1)" fillcolor=lightblue]
	6075484896 -> 6172614256
	6172614256 [label=AccumulateGrad]
	6172614736 -> 6172614688
	6075484976 [label="
 (960)" fillcolor=lightblue]
	6075484976 -> 6172614736
	6172614736 [label=AccumulateGrad]
	6172614976 -> 6172614688
	6075485056 [label="
 (960)" fillcolor=lightblue]
	6075485056 -> 6172614976
	6172614976 [label=AccumulateGrad]
	6077041056 -> 6078598944
	6077041056 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	6172615120 -> 6172615456
	6075485616 [label="
 (960, 1, 3, 3)" fillcolor=lightblue]
	6075485616 -> 6172615120
	6172615120 [label=AccumulateGrad]
	6172615408 -> 6172615600
	6075485536 [label="
 (960)" fillcolor=lightblue]
	6075485536 -> 6172615408
	6172615408 [label=AccumulateGrad]
	6172615888 -> 6172615600
	6075485696 [label="
 (960)" fillcolor=lightblue]
	6075485696 -> 6172615888
	6172615888 [label=AccumulateGrad]
	6077040976 -> 6078599168
	6077040976 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	6172615984 -> 6172616176
	6075486256 [label="
 (40, 960, 1, 1)" fillcolor=lightblue]
	6075486256 -> 6172615984
	6172615984 [label=AccumulateGrad]
	6172616320 -> 6172616176
	6075486336 [label="
 (40)" fillcolor=lightblue]
	6075486336 -> 6172616320
	6172616320 [label=AccumulateGrad]
	6077040656 -> 6078599392
	6077040656 [label="
 (1, 40, 1, 1)" fillcolor=orange]
	6172616464 -> 6172616608
	6075486496 [label="
 (960, 40, 1, 1)" fillcolor=lightblue]
	6075486496 -> 6172616464
	6172616464 [label=AccumulateGrad]
	6172616416 -> 6172616608
	6075486576 [label="
 (960)" fillcolor=lightblue]
	6075486576 -> 6172616416
	6172616416 [label=AccumulateGrad]
	6078599168 -> 6172616848
	6172617040 -> 6172617136
	6075486736 [label="
 (160, 960, 1, 1)" fillcolor=lightblue]
	6075486736 -> 6172617040
	6172617040 [label=AccumulateGrad]
	6172617328 -> 6172617280
	6075486816 [label="
 (160)" fillcolor=lightblue]
	6075486816 -> 6172617328
	6172617328 [label=AccumulateGrad]
	6172617568 -> 6172617280
	6075486896 [label="
 (160)" fillcolor=lightblue]
	6075486896 -> 6172617568
	6172617568 [label=AccumulateGrad]
	6172617712 -> 6172621360
	6172617904 -> 6172618192
	6075487296 [label="
 (960, 160, 1, 1)" fillcolor=lightblue]
	6075487296 -> 6172617904
	6172617904 [label=AccumulateGrad]
	6172618144 -> 6172618336
	6075487376 [label="
 (960)" fillcolor=lightblue]
	6075487376 -> 6172618144
	6172618144 [label=AccumulateGrad]
	6172618624 -> 6172618336
	6075487456 [label="
 (960)" fillcolor=lightblue]
	6075487456 -> 6172618624
	6172618624 [label=AccumulateGrad]
	6077038816 -> 6078599616
	6077038816 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	6172618768 -> 6172618864
	6075488016 [label="
 (960, 1, 3, 3)" fillcolor=lightblue]
	6075488016 -> 6172618768
	6172618768 [label=AccumulateGrad]
	6172619056 -> 6172619008
	6075487936 [label="
 (960)" fillcolor=lightblue]
	6075487936 -> 6172619056
	6172619056 [label=AccumulateGrad]
	6172619296 -> 6172619008
	6075488096 [label="
 (960)" fillcolor=lightblue]
	6075488096 -> 6172619296
	6172619296 [label=AccumulateGrad]
	6077038656 -> 6078599840
	6077038656 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	6172619632 -> 6172619584
	6075488656 [label="
 (40, 960, 1, 1)" fillcolor=lightblue]
	6075488656 -> 6172619632
	6172619632 [label=AccumulateGrad]
	6172619728 -> 6172619584
	6075488736 [label="
 (40)" fillcolor=lightblue]
	6075488736 -> 6172619728
	6172619728 [label=AccumulateGrad]
	6060737376 -> 6078600064
	6060737376 [label="
 (1, 40, 1, 1)" fillcolor=orange]
	6172619872 -> 6172620016
	6075488896 [label="
 (960, 40, 1, 1)" fillcolor=lightblue]
	6075488896 -> 6172619872
	6172619872 [label=AccumulateGrad]
	6172620064 -> 6172620016
	6075488976 [label="
 (960)" fillcolor=lightblue]
	6075488976 -> 6172620064
	6172620064 [label=AccumulateGrad]
	6078599840 -> 6172620496
	6172620448 -> 6172620784
	6075489136 [label="
 (160, 960, 1, 1)" fillcolor=lightblue]
	6075489136 -> 6172620448
	6172620448 [label=AccumulateGrad]
	6172620736 -> 6172620928
	6075489216 [label="
 (160)" fillcolor=lightblue]
	6075489216 -> 6172620736
	6172620736 [label=AccumulateGrad]
	6172621216 -> 6172620928
	6075489296 [label="
 (160)" fillcolor=lightblue]
	6075489296 -> 6172621216
	6172621216 [label=AccumulateGrad]
	6172621360 -> 6172621504
	6172621456 -> 6172621792
	6075489776 [label="
 (960, 160, 1, 1)" fillcolor=lightblue]
	6075489776 -> 6172621456
	6172621456 [label=AccumulateGrad]
	6172621744 -> 6172621936
	6075489856 [label="
 (960)" fillcolor=lightblue]
	6075489856 -> 6172621744
	6172621744 [label=AccumulateGrad]
	6172622224 -> 6172621936
	6075489936 [label="
 (960)" fillcolor=lightblue]
	6075489936 -> 6172622224
	6172622224 [label=AccumulateGrad]
	6076997264 -> 6078600288
	6076997264 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	6172622368 -> 6172622464
	6075490496 [label="
 (960, 1, 5, 5)" fillcolor=lightblue]
	6075490496 -> 6172622368
	6172622368 [label=AccumulateGrad]
	6172622656 -> 6172622608
	6075490416 [label="
 (960)" fillcolor=lightblue]
	6075490416 -> 6172622656
	6172622656 [label=AccumulateGrad]
	6172622752 -> 6172622608
	6075490576 [label="
 (960)" fillcolor=lightblue]
	6075490576 -> 6172622752
	6172622752 [label=AccumulateGrad]
	6076993984 -> 6078600512
	6076993984 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	6172705216 -> 6172705168
	6075491136 [label="
 (40, 960, 1, 1)" fillcolor=lightblue]
	6075491136 -> 6172705216
	6172705216 [label=AccumulateGrad]
	6172705312 -> 6172705168
	6075491216 [label="
 (40)" fillcolor=lightblue]
	6075491216 -> 6172705312
	6172705312 [label=AccumulateGrad]
	6076991824 -> 6078600736
	6076991824 [label="
 (1, 40, 1, 1)" fillcolor=orange]
	6172705456 -> 6172705600
	6075491376 [label="
 (960, 40, 1, 1)" fillcolor=lightblue]
	6075491376 -> 6172705456
	6172705456 [label=AccumulateGrad]
	6172705648 -> 6172705600
	6075491456 [label="
 (960)" fillcolor=lightblue]
	6075491456 -> 6172705648
	6172705648 [label=AccumulateGrad]
	6078600512 -> 6172706080
	6172706032 -> 6172706368
	6075491616 [label="
 (224, 960, 1, 1)" fillcolor=lightblue]
	6075491616 -> 6172706032
	6172706032 [label=AccumulateGrad]
	6172706320 -> 6172709968
	6075491696 [label="
 (224)" fillcolor=lightblue]
	6075491696 -> 6172706320
	6172706320 [label=AccumulateGrad]
	6172706656 -> 6172709968
	6075491776 [label="
 (224)" fillcolor=lightblue]
	6075491776 -> 6172706656
	6172706656 [label=AccumulateGrad]
	6172706512 -> 6172706800
	6075492256 [label="
 (1344, 224, 1, 1)" fillcolor=lightblue]
	6075492256 -> 6172706512
	6172706512 [label=AccumulateGrad]
	6172706752 -> 6172706944
	6075492336 [label="
 (1344)" fillcolor=lightblue]
	6075492336 -> 6172706752
	6172706752 [label=AccumulateGrad]
	6172707232 -> 6172706944
	6075492416 [label="
 (1344)" fillcolor=lightblue]
	6075492416 -> 6172707232
	6172707232 [label=AccumulateGrad]
	6076989904 -> 6078600960
	6076989904 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	6172707376 -> 6172707472
	6075492976 [label="
 (1344, 1, 5, 5)" fillcolor=lightblue]
	6075492976 -> 6172707376
	6172707376 [label=AccumulateGrad]
	6172707664 -> 6172707616
	6075492896 [label="
 (1344)" fillcolor=lightblue]
	6075492896 -> 6172707664
	6172707664 [label=AccumulateGrad]
	6172707904 -> 6172707616
	6075493056 [label="
 (1344)" fillcolor=lightblue]
	6075493056 -> 6172707904
	6172707904 [label=AccumulateGrad]
	6077000944 -> 6078601184
	6077000944 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	6172708240 -> 6172708192
	6075493616 [label="
 (56, 1344, 1, 1)" fillcolor=lightblue]
	6075493616 -> 6172708240
	6172708240 [label=AccumulateGrad]
	6172708336 -> 6172708192
	6075493696 [label="
 (56)" fillcolor=lightblue]
	6075493696 -> 6172708336
	6172708336 [label=AccumulateGrad]
	6076995184 -> 6078601408
	6076995184 [label="
 (1, 56, 1, 1)" fillcolor=orange]
	6172708480 -> 6172708624
	6075493856 [label="
 (1344, 56, 1, 1)" fillcolor=lightblue]
	6075493856 -> 6172708480
	6172708480 [label=AccumulateGrad]
	6172708672 -> 6172708624
	6075493936 [label="
 (1344)" fillcolor=lightblue]
	6075493936 -> 6172708672
	6172708672 [label=AccumulateGrad]
	6078601184 -> 6172709104
	6172709056 -> 6172709392
	6075494096 [label="
 (224, 1344, 1, 1)" fillcolor=lightblue]
	6075494096 -> 6172709056
	6172709056 [label=AccumulateGrad]
	6172709344 -> 6172709536
	6075494176 [label="
 (224)" fillcolor=lightblue]
	6075494176 -> 6172709344
	6172709344 [label=AccumulateGrad]
	6172709824 -> 6172709536
	6075494256 [label="
 (224)" fillcolor=lightblue]
	6075494256 -> 6172709824
	6172709824 [label=AccumulateGrad]
	6172709968 -> 6172713376
	6172709920 -> 6172710208
	6075494736 [label="
 (1344, 224, 1, 1)" fillcolor=lightblue]
	6075494736 -> 6172709920
	6172709920 [label=AccumulateGrad]
	6172710400 -> 6172710352
	6075494816 [label="
 (1344)" fillcolor=lightblue]
	6075494816 -> 6172710400
	6172710400 [label=AccumulateGrad]
	6172710640 -> 6172710352
	6075494896 [label="
 (1344)" fillcolor=lightblue]
	6075494896 -> 6172710640
	6172710640 [label=AccumulateGrad]
	6076996944 -> 6078601632
	6076996944 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	6172710784 -> 6172711120
	6075495456 [label="
 (1344, 1, 5, 5)" fillcolor=lightblue]
	6075495456 -> 6172710784
	6172710784 [label=AccumulateGrad]
	6172711072 -> 6172711264
	6075495376 [label="
 (1344)" fillcolor=lightblue]
	6075495376 -> 6172711072
	6172711072 [label=AccumulateGrad]
	6172711552 -> 6172711264
	6075495536 [label="
 (1344)" fillcolor=lightblue]
	6075495536 -> 6172711552
	6172711552 [label=AccumulateGrad]
	6076996704 -> 6078601856
	6076996704 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	6172711648 -> 6172711840
	6075496016 [label="
 (56, 1344, 1, 1)" fillcolor=lightblue]
	6075496016 -> 6172711648
	6172711648 [label=AccumulateGrad]
	6172711984 -> 6172711840
	6075496096 [label="
 (56)" fillcolor=lightblue]
	6075496096 -> 6172711984
	6172711984 [label=AccumulateGrad]
	6076994544 -> 6078602080
	6076994544 [label="
 (1, 56, 1, 1)" fillcolor=orange]
	6172712128 -> 6172712272
	6075496256 [label="
 (1344, 56, 1, 1)" fillcolor=lightblue]
	6075496256 -> 6172712128
	6172712128 [label=AccumulateGrad]
	6172712080 -> 6172712272
	6075496336 [label="
 (1344)" fillcolor=lightblue]
	6075496336 -> 6172712080
	6172712080 [label=AccumulateGrad]
	6078601856 -> 6172712512
	6172712704 -> 6172712800
	6075496496 [label="
 (224, 1344, 1, 1)" fillcolor=lightblue]
	6075496496 -> 6172712704
	6172712704 [label=AccumulateGrad]
	6172712992 -> 6172712944
	6075496576 [label="
 (224)" fillcolor=lightblue]
	6075496576 -> 6172712992
	6172712992 [label=AccumulateGrad]
	6172713232 -> 6172712944
	6075496656 [label="
 (224)" fillcolor=lightblue]
	6075496656 -> 6172713232
	6172713232 [label=AccumulateGrad]
	6172713376 -> 6172717264
	6172713568 -> 6172713856
	6075497056 [label="
 (1344, 224, 1, 1)" fillcolor=lightblue]
	6075497056 -> 6172713568
	6172713568 [label=AccumulateGrad]
	6172713808 -> 6172714000
	6075497136 [label="
 (1344)" fillcolor=lightblue]
	6075497136 -> 6172713808
	6172713808 [label=AccumulateGrad]
	6172714288 -> 6172714000
	6075497216 [label="
 (1344)" fillcolor=lightblue]
	6075497216 -> 6172714288
	6172714288 [label=AccumulateGrad]
	6077002544 -> 6078602304
	6077002544 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	6172714432 -> 6172714528
	6075497776 [label="
 (1344, 1, 5, 5)" fillcolor=lightblue]
	6075497776 -> 6172714432
	6172714432 [label=AccumulateGrad]
	6172714720 -> 6172714672
	6075497696 [label="
 (1344)" fillcolor=lightblue]
	6075497696 -> 6172714720
	6172714720 [label=AccumulateGrad]
	6172714960 -> 6172714672
	6075497856 [label="
 (1344)" fillcolor=lightblue]
	6075497856 -> 6172714960
	6172714960 [label=AccumulateGrad]
	6077002224 -> 6078602528
	6077002224 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	6172715296 -> 6172715248
	6075498336 [label="
 (56, 1344, 1, 1)" fillcolor=lightblue]
	6075498336 -> 6172715296
	6172715296 [label=AccumulateGrad]
	6172715392 -> 6172715248
	6075498416 [label="
 (56)" fillcolor=lightblue]
	6075498416 -> 6172715392
	6172715392 [label=AccumulateGrad]
	6077001824 -> 6078602752
	6077001824 [label="
 (1, 56, 1, 1)" fillcolor=orange]
	6172715536 -> 6172715680
	6075793552 [label="
 (1344, 56, 1, 1)" fillcolor=lightblue]
	6075793552 -> 6172715536
	6172715536 [label=AccumulateGrad]
	6172715728 -> 6172715680
	6075793632 [label="
 (1344)" fillcolor=lightblue]
	6075793632 -> 6172715728
	6172715728 [label=AccumulateGrad]
	6078602528 -> 6172716160
	6172716112 -> 6172716448
	6075793792 [label="
 (224, 1344, 1, 1)" fillcolor=lightblue]
	6075793792 -> 6172716112
	6172716112 [label=AccumulateGrad]
	6172716400 -> 6172716592
	6075793872 [label="
 (224)" fillcolor=lightblue]
	6075793872 -> 6172716400
	6172716400 [label=AccumulateGrad]
	6172716736 -> 6172716592
	6075793952 [label="
 (224)" fillcolor=lightblue]
	6075793952 -> 6172716736
	6172716736 [label=AccumulateGrad]
	6172717264 -> 11670918704
	6172716976 -> 6172718128
	6075794432 [label="
 (1344, 224, 1, 1)" fillcolor=lightblue]
	6075794432 -> 6172716976
	6172716976 [label=AccumulateGrad]
	6172718464 -> 6172718752
	6075794512 [label="
 (1344)" fillcolor=lightblue]
	6075794512 -> 6172718464
	6172718464 [label=AccumulateGrad]
	6172719712 -> 6172718752
	6075794592 [label="
 (1344)" fillcolor=lightblue]
	6075794592 -> 6172719712
	6172719712 [label=AccumulateGrad]
	6077005104 -> 6078602976
	6077005104 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	6172719616 -> 6172720432
	6075795152 [label="
 (1344, 1, 5, 5)" fillcolor=lightblue]
	6075795152 -> 6172719616
	6172719616 [label=AccumulateGrad]
	6172720624 -> 11670913712
	6075795072 [label="
 (1344)" fillcolor=lightblue]
	6075795072 -> 6172720624
	6172720624 [label=AccumulateGrad]
	6172721056 -> 11670913712
	6075795232 [label="
 (1344)" fillcolor=lightblue]
	6075795232 -> 6172721056
	6172721056 [label=AccumulateGrad]
	6077004784 -> 6078603200
	6077004784 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	11670914288 -> 11670914528
	6075795792 [label="
 (56, 1344, 1, 1)" fillcolor=lightblue]
	6075795792 -> 11670914288
	11670914288 [label=AccumulateGrad]
	11670914432 -> 11670914528
	6075795872 [label="
 (56)" fillcolor=lightblue]
	6075795872 -> 11670914432
	11670914432 [label=AccumulateGrad]
	6077004544 -> 6078603424
	6077004544 [label="
 (1, 56, 1, 1)" fillcolor=orange]
	11670914960 -> 11670915440
	6075796032 [label="
 (1344, 56, 1, 1)" fillcolor=lightblue]
	6075796032 -> 11670914960
	11670914960 [label=AccumulateGrad]
	11670915248 -> 11670915440
	6075796112 [label="
 (1344)" fillcolor=lightblue]
	6075796112 -> 11670915248
	11670915248 [label=AccumulateGrad]
	6078603200 -> 11670916592
	11670916688 -> 11670917408
	6075796272 [label="
 (224, 1344, 1, 1)" fillcolor=lightblue]
	6075796272 -> 11670916688
	11670916688 [label=AccumulateGrad]
	11670917600 -> 11670917312
	6075796352 [label="
 (224)" fillcolor=lightblue]
	6075796352 -> 11670917600
	11670917600 [label=AccumulateGrad]
	11670918320 -> 11670917312
	6075796432 [label="
 (224)" fillcolor=lightblue]
	6075796432 -> 11670918320
	11670918320 [label=AccumulateGrad]
	11670918704 -> 11670924464
	11670919280 -> 11670919760
	6075796912 [label="
 (1344, 224, 1, 1)" fillcolor=lightblue]
	6075796912 -> 11670919280
	11670919280 [label=AccumulateGrad]
	11670920480 -> 11670920192
	6075796992 [label="
 (1344)" fillcolor=lightblue]
	6075796992 -> 11670920480
	11670920480 [label=AccumulateGrad]
	11670921056 -> 11670920192
	6075797072 [label="
 (1344)" fillcolor=lightblue]
	6075797072 -> 11670921056
	11670921056 [label=AccumulateGrad]
	6077002864 -> 6078603648
	6077002864 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	11670921488 -> 11670921920
	6075797632 [label="
 (1344, 1, 5, 5)" fillcolor=lightblue]
	6075797632 -> 11670921488
	11670921488 [label=AccumulateGrad]
	11670922016 -> 11670922304
	6075797552 [label="
 (1344)" fillcolor=lightblue]
	6075797552 -> 11670922016
	11670922016 [label=AccumulateGrad]
	11670923168 -> 11670922304
	6075797712 [label="
 (1344)" fillcolor=lightblue]
	6075797712 -> 11670923168
	11670923168 [label=AccumulateGrad]
	6077002704 -> 6078603872
	6077002704 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	11670928688 -> 11670928976
	6075798272 [label="
 (56, 1344, 1, 1)" fillcolor=lightblue]
	6075798272 -> 11670928688
	11670928688 [label=AccumulateGrad]
	11670928544 -> 11670928976
	6075798352 [label="
 (56)" fillcolor=lightblue]
	6075798352 -> 11670928544
	11670928544 [label=AccumulateGrad]
	6077002464 -> 6078604096
	6077002464 [label="
 (1, 56, 1, 1)" fillcolor=orange]
	11670928064 -> 11670927776
	6075798512 [label="
 (1344, 56, 1, 1)" fillcolor=lightblue]
	6075798512 -> 11670928064
	11670928064 [label=AccumulateGrad]
	11670928112 -> 11670927776
	6075798592 [label="
 (1344)" fillcolor=lightblue]
	6075798592 -> 11670928112
	11670928112 [label=AccumulateGrad]
	6078603872 -> 11670926912
	11670926960 -> 11670926672
	6075798752 [label="
 (224, 1344, 1, 1)" fillcolor=lightblue]
	6075798752 -> 11670926960
	11670926960 [label=AccumulateGrad]
	11670925664 -> 11670925088
	6075798832 [label="
 (224)" fillcolor=lightblue]
	6075798832 -> 11670925664
	11670925664 [label=AccumulateGrad]
	11670925376 -> 11670925088
	6075798912 [label="
 (224)" fillcolor=lightblue]
	6075798912 -> 11670925376
	11670925376 [label=AccumulateGrad]
	11670924464 -> 6078836224
	11670924224 -> 6078946784
	6075799392 [label="
 (1344, 224, 1, 1)" fillcolor=lightblue]
	6075799392 -> 11670924224
	11670924224 [label=AccumulateGrad]
	6078945920 -> 6078945488
	6075799472 [label="
 (1344)" fillcolor=lightblue]
	6075799472 -> 6078945920
	6078945920 [label=AccumulateGrad]
	6078944576 -> 6078945488
	6075799552 [label="
 (1344)" fillcolor=lightblue]
	6075799552 -> 6078944576
	6078944576 [label=AccumulateGrad]
	6077000624 -> 6078604320
	6077000624 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	6078944096 -> 6078943136
	6075800112 [label="
 (1344, 1, 5, 5)" fillcolor=lightblue]
	6075800112 -> 6078944096
	6078944096 [label=AccumulateGrad]
	6078942608 -> 6078942848
	6075800032 [label="
 (1344)" fillcolor=lightblue]
	6075800032 -> 6078942608
	6078942608 [label=AccumulateGrad]
	6078941408 -> 6078942848
	6075800192 [label="
 (1344)" fillcolor=lightblue]
	6075800192 -> 6078941408
	6078941408 [label=AccumulateGrad]
	6077000464 -> 6078604544
	6077000464 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	6078940736 -> 6078939632
	6075800752 [label="
 (56, 1344, 1, 1)" fillcolor=lightblue]
	6075800752 -> 6078940736
	6078940736 [label=AccumulateGrad]
	6078940256 -> 6078939632
	6075800832 [label="
 (56)" fillcolor=lightblue]
	6075800832 -> 6078940256
	6078940256 [label=AccumulateGrad]
	6077000224 -> 6078604768
	6077000224 [label="
 (1, 56, 1, 1)" fillcolor=orange]
	6078946352 -> 6078839920
	6075800992 [label="
 (1344, 56, 1, 1)" fillcolor=lightblue]
	6075800992 -> 6078946352
	6078946352 [label=AccumulateGrad]
	6078946640 -> 6078839920
	6075801072 [label="
 (1344)" fillcolor=lightblue]
	6075801072 -> 6078946640
	6078946640 [label=AccumulateGrad]
	6078604544 -> 6078839680
	6078839152 -> 6078838192
	6075801232 [label="
 (224, 1344, 1, 1)" fillcolor=lightblue]
	6075801232 -> 6078839152
	6078839152 [label=AccumulateGrad]
	6078838096 -> 6078837856
	6075801312 [label="
 (224)" fillcolor=lightblue]
	6075801312 -> 6078838096
	6078838096 [label=AccumulateGrad]
	6078836656 -> 6078837856
	6075801392 [label="
 (224)" fillcolor=lightblue]
	6075801392 -> 6078836656
	6078836656 [label=AccumulateGrad]
	6078836224 -> 6078789280
	6078836464 -> 6078834976
	6075801872 [label="
 (1344, 224, 1, 1)" fillcolor=lightblue]
	6075801872 -> 6078836464
	6078836464 [label=AccumulateGrad]
	6078834640 -> 6078833968
	6075801952 [label="
 (1344)" fillcolor=lightblue]
	6075801952 -> 6078834640
	6078834640 [label=AccumulateGrad]
	6078832960 -> 6078833968
	6075802032 [label="
 (1344)" fillcolor=lightblue]
	6075802032 -> 6078832960
	6078832960 [label=AccumulateGrad]
	6076998304 -> 6078604992
	6076998304 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	6078831520 -> 6078831664
	6075802592 [label="
 (1344, 1, 5, 5)" fillcolor=lightblue]
	6075802592 -> 6078831520
	6078831520 [label=AccumulateGrad]
	6078831424 -> 6078830896
	6075802512 [label="
 (1344)" fillcolor=lightblue]
	6075802512 -> 6078831424
	6078831424 [label=AccumulateGrad]
	6078829936 -> 6078830896
	6075802672 [label="
 (1344)" fillcolor=lightblue]
	6075802672 -> 6078829936
	6078829936 [label=AccumulateGrad]
	6076998224 -> 6078605216
	6076998224 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	6078829072 -> 6078828304
	6075803232 [label="
 (56, 1344, 1, 1)" fillcolor=lightblue]
	6075803232 -> 6078829072
	6078829072 [label=AccumulateGrad]
	6078827920 -> 6078828304
	6075803312 [label="
 (56)" fillcolor=lightblue]
	6075803312 -> 6078827920
	6078827920 [label=AccumulateGrad]
	6076997904 -> 6078605440
	6076997904 [label="
 (1, 56, 1, 1)" fillcolor=orange]
	6078827680 -> 6078826864
	6075803472 [label="
 (1344, 56, 1, 1)" fillcolor=lightblue]
	6075803472 -> 6078827680
	6078827680 [label=AccumulateGrad]
	6078826624 -> 6078826864
	6075803552 [label="
 (1344)" fillcolor=lightblue]
	6075803552 -> 6078826624
	6078826624 [label=AccumulateGrad]
	6078605216 -> 6078826432
	6078824944 -> 6078789664
	6075803712 [label="
 (224, 1344, 1, 1)" fillcolor=lightblue]
	6075803712 -> 6078824944
	6078824944 [label=AccumulateGrad]
	6078824560 -> 6078791056
	6075803792 [label="
 (224)" fillcolor=lightblue]
	6075803792 -> 6078824560
	6078824560 [label=AccumulateGrad]
	6078831904 -> 6078791056
	6075803872 [label="
 (224)" fillcolor=lightblue]
	6075803872 -> 6078831904
	6078831904 [label=AccumulateGrad]
	6078789280 -> 6078777472
	6078788608 -> 6078788080
	6075804352 [label="
 (1344, 224, 1, 1)" fillcolor=lightblue]
	6075804352 -> 6078788608
	6078788608 [label=AccumulateGrad]
	6078787840 -> 6078787360
	6075804432 [label="
 (1344)" fillcolor=lightblue]
	6075804432 -> 6078787840
	6078787840 [label=AccumulateGrad]
	6078786304 -> 6078787360
	6075804512 [label="
 (1344)" fillcolor=lightblue]
	6075804512 -> 6078786304
	6078786304 [label=AccumulateGrad]
	6076996384 -> 6078605664
	6076996384 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	6078785296 -> 6078784816
	6075805072 [label="
 (1344, 1, 5, 5)" fillcolor=lightblue]
	6075805072 -> 6078785296
	6078785296 [label=AccumulateGrad]
	6078784768 -> 6078784096
	6075804992 [label="
 (1344)" fillcolor=lightblue]
	6075804992 -> 6078784768
	6078784768 [label=AccumulateGrad]
	6078783088 -> 6078784096
	6075805152 [label="
 (1344)" fillcolor=lightblue]
	6075805152 -> 6078783088
	6078783088 [label=AccumulateGrad]
	6076996224 -> 6078605888
	6076996224 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	6078782272 -> 6078782032
	6075805712 [label="
 (56, 1344, 1, 1)" fillcolor=lightblue]
	6075805712 -> 6078782272
	6078782272 [label=AccumulateGrad]
	6078780784 -> 6078782032
	6075805792 [label="
 (56)" fillcolor=lightblue]
	6075805792 -> 6078780784
	6078780784 [label=AccumulateGrad]
	6076995984 -> 6078606112
	6076995984 [label="
 (1, 56, 1, 1)" fillcolor=orange]
	6078783760 -> 6078780256
	6075805952 [label="
 (1344, 56, 1, 1)" fillcolor=lightblue]
	6075805952 -> 6078783760
	6078783760 [label=AccumulateGrad]
	6078780496 -> 6078780256
	6075806032 [label="
 (1344)" fillcolor=lightblue]
	6075806032 -> 6078780496
	6078780496 [label=AccumulateGrad]
	6078605888 -> 6078778096
	6078778528 -> 6078777712
	6075806192 [label="
 (224, 1344, 1, 1)" fillcolor=lightblue]
	6075806192 -> 6078778528
	6078778528 [label=AccumulateGrad]
	6078777520 -> 6078777376
	6075806272 [label="
 (224)" fillcolor=lightblue]
	6075806272 -> 6078777520
	6078777520 [label=AccumulateGrad]
	6078775984 -> 6078777376
	6075806352 [label="
 (224)" fillcolor=lightblue]
	6075806352 -> 6078775984
	6078775984 [label=AccumulateGrad]
	6078777472 -> 6078663072
	6078675888 -> 6078676128
	6075806832 [label="
 (1344, 224, 1, 1)" fillcolor=lightblue]
	6075806832 -> 6078675888
	6078675888 [label=AccumulateGrad]
	6078675024 -> 6078675408
	6075806752 [label="
 (1344)" fillcolor=lightblue]
	6075806752 -> 6078675024
	6078675024 [label=AccumulateGrad]
	6078674304 -> 6078675408
	6075806912 [label="
 (1344)" fillcolor=lightblue]
	6075806912 -> 6078674304
	6078674304 [label=AccumulateGrad]
	6076994464 -> 6078606336
	6076994464 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	6078673632 -> 6078672576
	6075807472 [label="
 (1344, 1, 5, 5)" fillcolor=lightblue]
	6075807472 -> 6078673632
	6078673632 [label=AccumulateGrad]
	6078672384 -> 6078671808
	6075807392 [label="
 (1344)" fillcolor=lightblue]
	6075807392 -> 6078672384
	6078672384 [label=AccumulateGrad]
	6078671376 -> 6078671808
	6075807552 [label="
 (1344)" fillcolor=lightblue]
	6075807552 -> 6078671376
	6078671376 [label=AccumulateGrad]
	6076994384 -> 6078606560
	6076994384 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	6078670128 -> 6078670752
	6075808112 [label="
 (56, 1344, 1, 1)" fillcolor=lightblue]
	6075808112 -> 6078670128
	6078670128 [label=AccumulateGrad]
	6078669312 -> 6078670752
	6075808192 [label="
 (56)" fillcolor=lightblue]
	6075808192 -> 6078669312
	6078669312 [label=AccumulateGrad]
	6076994064 -> 6078606784
	6076994064 [label="
 (1, 56, 1, 1)" fillcolor=orange]
	6078668688 -> 6078668064
	6075808352 [label="
 (1344, 56, 1, 1)" fillcolor=lightblue]
	6075808352 -> 6078668688
	6078668688 [label=AccumulateGrad]
	6078668544 -> 6078668064
	6075808432 [label="
 (1344)" fillcolor=lightblue]
	6075808432 -> 6078668544
	6078668544 [label=AccumulateGrad]
	6078606560 -> 6078666576
	6078665616 -> 6078665808
	6075808592 [label="
 (224, 1344, 1, 1)" fillcolor=lightblue]
	6075808592 -> 6078665616
	6078665616 [label=AccumulateGrad]
	6078664800 -> 6078665040
	6075808672 [label="
 (224)" fillcolor=lightblue]
	6075808672 -> 6078664800
	6078664800 [label=AccumulateGrad]
	6078666816 -> 6078665040
	6075808752 [label="
 (224)" fillcolor=lightblue]
	6075808752 -> 6078666816
	6078666816 [label=AccumulateGrad]
	6078663072 -> 6078662112
	6078661680 -> 6078661440
	6077460576 [label="
 (256, 224, 1, 1)" fillcolor=lightblue]
	6077460576 -> 6078661680
	6078661680 [label=AccumulateGrad]
	6078661296 -> 6078661440
	6077460416 [label="
 (256)" fillcolor=lightblue]
	6077460416 -> 6078661296
	6078661296 [label=AccumulateGrad]
	6078661344 -> 6078660960
	6078661344 [label="UpsampleNearest2DBackward0
--------------------------------
output_size   :         (38, 38)
scales_h      :             None
scales_w      :             None
self_sym_sizes: (1, 256, 19, 19)"]
	6078664608 -> 6078661344
	6078664608 -> 6076887056 [dir=none]
	6076887056 [label="input
 (1, 640, 19, 19)" fillcolor=orange]
	6078664608 -> 6077460976 [dir=none]
	6077460976 [label="weight
 (256, 640, 1, 1)" fillcolor=orange]
	6078664608 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (256,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078666336 -> 6078664608
	6078666336 [label="AddBackward0
------------
alpha: 1"]
	6078667488 -> 6078666336
	6078667488 -> 6076885856 [dir=none]
	6076885856 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6078667488 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078670320 -> 6078667488
	6078670320 -> 6079091456 [dir=none]
	6079091456 [label="other
 ()" fillcolor=orange]
	6078670320 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078672144 -> 6078670320
	6078672144 -> 6076888496 [dir=none]
	6076888496 [label="input
 (1, 640, 19, 19)" fillcolor=orange]
	6078672144 -> 6079098176 [dir=none]
	6079098176 [label="result1
 (640)" fillcolor=orange]
	6078672144 -> 6079094016 [dir=none]
	6079094016 [label="result2
 (640)" fillcolor=orange]
	6078672144 -> 6076636416 [dir=none]
	6076636416 [label="running_mean
 (640)" fillcolor=orange]
	6078672144 -> 6076636736 [dir=none]
	6076636736 [label="running_var
 (640)" fillcolor=orange]
	6078672144 -> 6076636576 [dir=none]
	6076636576 [label="weight
 (640)" fillcolor=orange]
	6078672144 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078676464 -> 6078672144
	6078676464 -> 6076889136 [dir=none]
	6076889136 [label="input
 (1, 3840, 19, 19)" fillcolor=orange]
	6078676464 -> 6076636496 [dir=none]
	6076636496 [label="weight
 (640, 3840, 1, 1)" fillcolor=orange]
	6078676464 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078676512 -> 6078676464
	6078676512 -> 6076875296 [dir=none]
	6076875296 [label="other
 (1, 3840, 19, 19)" fillcolor=orange]
	6078676512 -> 6076890416 [dir=none]
	6076890416 [label="self
 (1, 3840, 1, 1)" fillcolor=orange]
	6078676512 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6078778144 -> 6078676512
	6078778144 -> 6079095056 [dir=none]
	6079095056 [label="result
 (1, 3840, 1, 1)" fillcolor=orange]
	6078778144 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6078782320 -> 6078778144
	6078782320 -> 6076889456 [dir=none]
	6076889456 [label="input
 (1, 160, 1, 1)" fillcolor=orange]
	6078782320 -> 6076636256 [dir=none]
	6076636256 [label="weight
 (3840, 160, 1, 1)" fillcolor=orange]
	6078782320 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (3840,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079159136 -> 6078782320
	6079159136 [label=SwishImplementationBackward]
	6078783568 -> 6079159136
	6078783568 -> 6076876976 [dir=none]
	6076876976 [label="input
 (1, 3840, 1, 1)" fillcolor=orange]
	6078783568 -> 6076636016 [dir=none]
	6076636016 [label="weight
 (160, 3840, 1, 1)" fillcolor=orange]
	6078783568 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (160,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078786784 -> 6078783568
	6078786784 -> 6076875296 [dir=none]
	6076875296 [label="self
 (1, 3840, 19, 19)" fillcolor=orange]
	6078786784 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 3840, 19, 19)"]
	6079158912 -> 6078786784
	6079158912 [label=SwishImplementationBackward]
	6078789856 -> 6079158912
	6078789856 -> 6076881616 [dir=none]
	6076881616 [label="input
 (1, 3840, 19, 19)" fillcolor=orange]
	6078789856 -> 6079094416 [dir=none]
	6079094416 [label="result1
 (3840)" fillcolor=orange]
	6078789856 -> 6079098976 [dir=none]
	6079098976 [label="result2
 (3840)" fillcolor=orange]
	6078789856 -> 6076633776 [dir=none]
	6076633776 [label="running_mean
 (3840)" fillcolor=orange]
	6078789856 -> 6076635536 [dir=none]
	6076635536 [label="running_var
 (3840)" fillcolor=orange]
	6078789856 -> 6076635296 [dir=none]
	6076635296 [label="weight
 (3840)" fillcolor=orange]
	6078789856 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078789328 -> 6078789856
	6078789328 -> 6076881936 [dir=none]
	6076881936 [label="input
 (1, 3840, 21, 21)" fillcolor=orange]
	6078789328 -> 6076635376 [dir=none]
	6076635376 [label="weight
 (3840, 1, 3, 3)" fillcolor=orange]
	6078789328 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           3840
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078825808 -> 6078789328
	6078825808 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6079158688 -> 6078825808
	6079158688 [label=SwishImplementationBackward]
	6078832432 -> 6079158688
	6078832432 -> 6076886656 [dir=none]
	6076886656 [label="input
 (1, 3840, 19, 19)" fillcolor=orange]
	6078832432 -> 6079095296 [dir=none]
	6079095296 [label="result1
 (3840)" fillcolor=orange]
	6078832432 -> 6079092976 [dir=none]
	6079092976 [label="result2
 (3840)" fillcolor=orange]
	6078832432 -> 6076634576 [dir=none]
	6076634576 [label="running_mean
 (3840)" fillcolor=orange]
	6078832432 -> 6076634896 [dir=none]
	6076634896 [label="running_var
 (3840)" fillcolor=orange]
	6078832432 -> 6076634736 [dir=none]
	6076634736 [label="weight
 (3840)" fillcolor=orange]
	6078832432 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078834784 -> 6078832432
	6078834784 -> 6076884656 [dir=none]
	6076884656 [label="input
 (1, 640, 19, 19)" fillcolor=orange]
	6078834784 -> 6076634656 [dir=none]
	6076634656 [label="weight
 (3840, 640, 1, 1)" fillcolor=orange]
	6078834784 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078667344 -> 6078834784
	6078667344 [label="AddBackward0
------------
alpha: 1"]
	6078835696 -> 6078667344
	6078835696 -> 6076883696 [dir=none]
	6076883696 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6078835696 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078840400 -> 6078835696
	6078840400 -> 6079087296 [dir=none]
	6079087296 [label="other
 ()" fillcolor=orange]
	6078840400 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078838960 -> 6078840400
	6078838960 -> 6076884896 [dir=none]
	6076884896 [label="input
 (1, 640, 19, 19)" fillcolor=orange]
	6078838960 -> 6079094256 [dir=none]
	6079094256 [label="result1
 (640)" fillcolor=orange]
	6078838960 -> 6079097456 [dir=none]
	6079097456 [label="result2
 (640)" fillcolor=orange]
	6078838960 -> 6076634016 [dir=none]
	6076634016 [label="running_mean
 (640)" fillcolor=orange]
	6078838960 -> 6076634336 [dir=none]
	6076634336 [label="running_var
 (640)" fillcolor=orange]
	6078838960 -> 6076634176 [dir=none]
	6076634176 [label="weight
 (640)" fillcolor=orange]
	6078838960 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078940976 -> 6078838960
	6078940976 -> 6076885136 [dir=none]
	6076885136 [label="input
 (1, 3840, 19, 19)" fillcolor=orange]
	6078940976 -> 6076634096 [dir=none]
	6076634096 [label="weight
 (640, 3840, 1, 1)" fillcolor=orange]
	6078940976 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078944624 -> 6078940976
	6078944624 -> 6076886896 [dir=none]
	6076886896 [label="other
 (1, 3840, 19, 19)" fillcolor=orange]
	6078944624 -> 6076886416 [dir=none]
	6076886416 [label="self
 (1, 3840, 1, 1)" fillcolor=orange]
	6078944624 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6078945104 -> 6078944624
	6078945104 -> 6079094096 [dir=none]
	6079094096 [label="result
 (1, 3840, 1, 1)" fillcolor=orange]
	6078945104 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11670925232 -> 6078945104
	11670925232 -> 6076886176 [dir=none]
	6076886176 [label="input
 (1, 160, 1, 1)" fillcolor=orange]
	11670925232 -> 6076633856 [dir=none]
	6076633856 [label="weight
 (3840, 160, 1, 1)" fillcolor=orange]
	11670925232 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (3840,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079158464 -> 11670925232
	6079158464 [label=SwishImplementationBackward]
	11670929264 -> 6079158464
	11670929264 -> 6076880496 [dir=none]
	6076880496 [label="input
 (1, 3840, 1, 1)" fillcolor=orange]
	11670929264 -> 6076633616 [dir=none]
	6076633616 [label="weight
 (160, 3840, 1, 1)" fillcolor=orange]
	11670929264 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (160,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11670926096 -> 11670929264
	11670926096 -> 6076886896 [dir=none]
	6076886896 [label="self
 (1, 3840, 19, 19)" fillcolor=orange]
	11670926096 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 3840, 19, 19)"]
	6079158240 -> 11670926096
	6079158240 [label=SwishImplementationBackward]
	11670919568 -> 6079158240
	11670919568 -> 6076884336 [dir=none]
	6076884336 [label="input
 (1, 3840, 19, 19)" fillcolor=orange]
	11670919568 -> 6079097696 [dir=none]
	6079097696 [label="result1
 (3840)" fillcolor=orange]
	11670919568 -> 6079096736 [dir=none]
	6079096736 [label="result2
 (3840)" fillcolor=orange]
	11670919568 -> 6076631456 [dir=none]
	6076631456 [label="running_mean
 (3840)" fillcolor=orange]
	11670919568 -> 6076633136 [dir=none]
	6076633136 [label="running_var
 (3840)" fillcolor=orange]
	11670919568 -> 6076632896 [dir=none]
	6076632896 [label="weight
 (3840)" fillcolor=orange]
	11670919568 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11670920576 -> 11670919568
	11670920576 -> 6076890896 [dir=none]
	6076890896 [label="input
 (1, 3840, 21, 21)" fillcolor=orange]
	11670920576 -> 6076632976 [dir=none]
	6076632976 [label="weight
 (3840, 1, 3, 3)" fillcolor=orange]
	11670920576 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           3840
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11670919472 -> 11670920576
	11670919472 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6079158016 -> 11670919472
	6079158016 [label=SwishImplementationBackward]
	11670916400 -> 6079158016
	11670916400 -> 6076887616 [dir=none]
	6076887616 [label="input
 (1, 3840, 19, 19)" fillcolor=orange]
	11670916400 -> 6172568096 [dir=none]
	6172568096 [label="result1
 (3840)" fillcolor=orange]
	11670916400 -> 6172568416 [dir=none]
	6172568416 [label="result2
 (3840)" fillcolor=orange]
	11670916400 -> 6076632176 [dir=none]
	6076632176 [label="running_mean
 (3840)" fillcolor=orange]
	11670916400 -> 6076632496 [dir=none]
	6076632496 [label="running_var
 (3840)" fillcolor=orange]
	11670916400 -> 6076632336 [dir=none]
	6076632336 [label="weight
 (3840)" fillcolor=orange]
	11670916400 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11670913808 -> 11670916400
	11670913808 -> 6076883376 [dir=none]
	6076883376 [label="input
 (1, 640, 19, 19)" fillcolor=orange]
	11670913808 -> 6076632256 [dir=none]
	6076632256 [label="weight
 (3840, 640, 1, 1)" fillcolor=orange]
	11670913808 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078837328 -> 11670913808
	6078837328 [label="AddBackward0
------------
alpha: 1"]
	6172719328 -> 6078837328
	6172719328 -> 6076875616 [dir=none]
	6076875616 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6172719328 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172716544 -> 6172719328
	6172716544 -> 6172562496 [dir=none]
	6172562496 [label="other
 ()" fillcolor=orange]
	6172716544 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172717888 -> 6172716544
	6172717888 -> 6076884016 [dir=none]
	6076884016 [label="input
 (1, 640, 19, 19)" fillcolor=orange]
	6172717888 -> 6172568896 [dir=none]
	6172568896 [label="result1
 (640)" fillcolor=orange]
	6172717888 -> 6172569616 [dir=none]
	6172569616 [label="result2
 (640)" fillcolor=orange]
	6172717888 -> 6076631696 [dir=none]
	6076631696 [label="running_mean
 (640)" fillcolor=orange]
	6172717888 -> 6076632016 [dir=none]
	6076632016 [label="running_var
 (640)" fillcolor=orange]
	6172717888 -> 6076631856 [dir=none]
	6076631856 [label="weight
 (640)" fillcolor=orange]
	6172717888 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172716304 -> 6172717888
	6172716304 -> 6076888096 [dir=none]
	6076888096 [label="input
 (1, 3840, 19, 19)" fillcolor=orange]
	6172716304 -> 6076631776 [dir=none]
	6076631776 [label="weight
 (640, 3840, 1, 1)" fillcolor=orange]
	6172716304 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172715440 -> 6172716304
	6172715440 -> 6076879856 [dir=none]
	6076879856 [label="other
 (1, 3840, 19, 19)" fillcolor=orange]
	6172715440 -> 6076879216 [dir=none]
	6076879216 [label="self
 (1, 3840, 1, 1)" fillcolor=orange]
	6172715440 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6172714864 -> 6172715440
	6172714864 -> 6172568736 [dir=none]
	6172568736 [label="result
 (1, 3840, 1, 1)" fillcolor=orange]
	6172714864 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6172714384 -> 6172714864
	6172714384 -> 6076888336 [dir=none]
	6076888336 [label="input
 (1, 160, 1, 1)" fillcolor=orange]
	6172714384 -> 6076631536 [dir=none]
	6076631536 [label="weight
 (3840, 160, 1, 1)" fillcolor=orange]
	6172714384 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (3840,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079157792 -> 6172714384
	6079157792 [label=SwishImplementationBackward]
	6172713280 -> 6079157792
	6172713280 -> 6076887856 [dir=none]
	6076887856 [label="input
 (1, 3840, 1, 1)" fillcolor=orange]
	6172713280 -> 6076631296 [dir=none]
	6076631296 [label="weight
 (160, 3840, 1, 1)" fillcolor=orange]
	6172713280 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (160,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172712848 -> 6172713280
	6172712848 -> 6076879856 [dir=none]
	6076879856 [label="self
 (1, 3840, 19, 19)" fillcolor=orange]
	6172712848 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 3840, 19, 19)"]
	6079157568 -> 6172712848
	6079157568 [label=SwishImplementationBackward]
	6172711504 -> 6079157568
	6172711504 -> 6076888816 [dir=none]
	6076888816 [label="input
 (1, 3840, 19, 19)" fillcolor=orange]
	6172711504 -> 6172563536 [dir=none]
	6172563536 [label="result1
 (3840)" fillcolor=orange]
	6172711504 -> 6172563376 [dir=none]
	6172563376 [label="result2
 (3840)" fillcolor=orange]
	6172711504 -> 6076629056 [dir=none]
	6076629056 [label="running_mean
 (3840)" fillcolor=orange]
	6172711504 -> 6076630896 [dir=none]
	6076630896 [label="running_var
 (3840)" fillcolor=orange]
	6172711504 -> 6076630656 [dir=none]
	6076630656 [label="weight
 (3840)" fillcolor=orange]
	6172711504 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172711216 -> 6172711504
	6172711216 -> 6076890096 [dir=none]
	6076890096 [label="input
 (1, 3840, 21, 21)" fillcolor=orange]
	6172711216 -> 6076630736 [dir=none]
	6076630736 [label="weight
 (3840, 1, 3, 3)" fillcolor=orange]
	6172711216 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           3840
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172710544 -> 6172711216
	6172710544 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6079157344 -> 6172710544
	6079157344 [label=SwishImplementationBackward]
	6172710064 -> 6079157344
	6172710064 -> 6076941152 [dir=none]
	6076941152 [label="input
 (1, 3840, 19, 19)" fillcolor=orange]
	6172710064 -> 6172561536 [dir=none]
	6172561536 [label="result1
 (3840)" fillcolor=orange]
	6172710064 -> 6172560336 [dir=none]
	6172560336 [label="result2
 (3840)" fillcolor=orange]
	6172710064 -> 6076629936 [dir=none]
	6076629936 [label="running_mean
 (3840)" fillcolor=orange]
	6172710064 -> 6076630256 [dir=none]
	6076630256 [label="running_var
 (3840)" fillcolor=orange]
	6172710064 -> 6076630096 [dir=none]
	6076630096 [label="weight
 (3840)" fillcolor=orange]
	6172710064 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172709248 -> 6172710064
	6172709248 -> 6042185744 [dir=none]
	6042185744 [label="input
 (1, 640, 19, 19)" fillcolor=orange]
	6172709248 -> 6076630016 [dir=none]
	6076630016 [label="weight
 (3840, 640, 1, 1)" fillcolor=orange]
	6172709248 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172718176 -> 6172709248
	6172718176 -> 6076940432 [dir=none]
	6076940432 [label="input
 (1, 640, 19, 19)" fillcolor=orange]
	6172718176 -> 6172562016 [dir=none]
	6172562016 [label="result1
 (640)" fillcolor=orange]
	6172718176 -> 6172563056 [dir=none]
	6172563056 [label="result2
 (640)" fillcolor=orange]
	6172718176 -> 6076629296 [dir=none]
	6076629296 [label="running_mean
 (640)" fillcolor=orange]
	6172718176 -> 6076629616 [dir=none]
	6076629616 [label="running_var
 (640)" fillcolor=orange]
	6172718176 -> 6076629456 [dir=none]
	6076629456 [label="weight
 (640)" fillcolor=orange]
	6172718176 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172707760 -> 6172718176
	6172707760 -> 6076940592 [dir=none]
	6076940592 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6172707760 -> 6076629376 [dir=none]
	6076629376 [label="weight
 (640, 2304, 1, 1)" fillcolor=orange]
	6172707760 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172706608 -> 6172707760
	6172706608 -> 6076941232 [dir=none]
	6076941232 [label="other
 (1, 2304, 19, 19)" fillcolor=orange]
	6172706608 -> 6076940992 [dir=none]
	6076940992 [label="self
 (1, 2304, 1, 1)" fillcolor=orange]
	6172706608 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6172706464 -> 6172706608
	6172706464 -> 6172573536 [dir=none]
	6172573536 [label="result
 (1, 2304, 1, 1)" fillcolor=orange]
	6172706464 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6172706224 -> 6172706464
	6172706224 -> 6076940832 [dir=none]
	6076940832 [label="input
 (1, 96, 1, 1)" fillcolor=orange]
	6172706224 -> 6076629136 [dir=none]
	6076629136 [label="weight
 (2304, 96, 1, 1)" fillcolor=orange]
	6172706224 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (2304,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079157120 -> 6172706224
	6079157120 [label=SwishImplementationBackward]
	6172704928 -> 6079157120
	6172704928 -> 6076941472 [dir=none]
	6076941472 [label="input
 (1, 2304, 1, 1)" fillcolor=orange]
	6172704928 -> 6076366688 [dir=none]
	6076366688 [label="weight
 (96, 2304, 1, 1)" fillcolor=orange]
	6172704928 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (96,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172705360 -> 6172704928
	6172705360 -> 6076941232 [dir=none]
	6076941232 [label="self
 (1, 2304, 19, 19)" fillcolor=orange]
	6172705360 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 2304, 19, 19)"]
	6079156896 -> 6172705360
	6079156896 [label=SwishImplementationBackward]
	6172620880 -> 6079156896
	6172620880 -> 6076941952 [dir=none]
	6076941952 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6172620880 -> 6172571696 [dir=none]
	6172571696 [label="result1
 (2304)" fillcolor=orange]
	6172620880 -> 6172571536 [dir=none]
	6172571536 [label="result2
 (2304)" fillcolor=orange]
	6172620880 -> 6076364368 [dir=none]
	6076364368 [label="running_mean
 (2304)" fillcolor=orange]
	6172620880 -> 6076366208 [dir=none]
	6076366208 [label="running_var
 (2304)" fillcolor=orange]
	6172620880 -> 6076365968 [dir=none]
	6076365968 [label="weight
 (2304)" fillcolor=orange]
	6172620880 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172621312 -> 6172620880
	6172621312 -> 6076942192 [dir=none]
	6076942192 [label="input
 (1, 2304, 21, 21)" fillcolor=orange]
	6172621312 -> 6076366048 [dir=none]
	6076366048 [label="weight
 (2304, 1, 3, 3)" fillcolor=orange]
	6172621312 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           2304
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172620208 -> 6172621312
	6172620208 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6079156672 -> 6172620208
	6079156672 [label=SwishImplementationBackward]
	6172619200 -> 6079156672
	6172619200 -> 6076943152 [dir=none]
	6076943152 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6172619200 -> 6172567696 [dir=none]
	6172567696 [label="result1
 (2304)" fillcolor=orange]
	6172619200 -> 6172566016 [dir=none]
	6172566016 [label="result2
 (2304)" fillcolor=orange]
	6172619200 -> 6076365248 [dir=none]
	6076365248 [label="running_mean
 (2304)" fillcolor=orange]
	6172619200 -> 6076365568 [dir=none]
	6076365568 [label="running_var
 (2304)" fillcolor=orange]
	6172619200 -> 6076365408 [dir=none]
	6076365408 [label="weight
 (2304)" fillcolor=orange]
	6172619200 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172618720 -> 6172619200
	6172618720 -> 6076942512 [dir=none]
	6076942512 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6172618720 -> 6076365328 [dir=none]
	6076365328 [label="weight
 (2304, 384, 1, 1)" fillcolor=orange]
	6172618720 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172617856 -> 6172618720
	6172617856 [label="AddBackward0
------------
alpha: 1"]
	6172618048 -> 6172617856
	6172618048 -> 6076942352 [dir=none]
	6076942352 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6172618048 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172616896 -> 6172618048
	6172616896 -> 6172559616 [dir=none]
	6172559616 [label="other
 ()" fillcolor=orange]
	6172616896 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172616704 -> 6172616896
	6172616704 -> 6076942592 [dir=none]
	6076942592 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6172616704 -> 6172558736 [dir=none]
	6172558736 [label="result1
 (384)" fillcolor=orange]
	6172616704 -> 6172558896 [dir=none]
	6172558896 [label="result2
 (384)" fillcolor=orange]
	6172616704 -> 6076364608 [dir=none]
	6076364608 [label="running_mean
 (384)" fillcolor=orange]
	6172616704 -> 6076364928 [dir=none]
	6076364928 [label="running_var
 (384)" fillcolor=orange]
	6172616704 -> 6076364768 [dir=none]
	6076364768 [label="weight
 (384)" fillcolor=orange]
	6172616704 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172615840 -> 6172616704
	6172615840 -> 6076942752 [dir=none]
	6076942752 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6172615840 -> 6076364688 [dir=none]
	6076364688 [label="weight
 (384, 2304, 1, 1)" fillcolor=orange]
	6172615840 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172615312 -> 6172615840
	6172615312 -> 6076943232 [dir=none]
	6076943232 [label="other
 (1, 2304, 19, 19)" fillcolor=orange]
	6172615312 -> 6076942992 [dir=none]
	6076942992 [label="self
 (1, 2304, 1, 1)" fillcolor=orange]
	6172615312 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6172614832 -> 6172615312
	6172614832 -> 6172558576 [dir=none]
	6172558576 [label="result
 (1, 2304, 1, 1)" fillcolor=orange]
	6172614832 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6172613824 -> 6172614832
	6172613824 -> 6076942912 [dir=none]
	6076942912 [label="input
 (1, 96, 1, 1)" fillcolor=orange]
	6172613824 -> 6076364448 [dir=none]
	6076364448 [label="weight
 (2304, 96, 1, 1)" fillcolor=orange]
	6172613824 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (2304,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079156448 -> 6172613824
	6079156448 [label=SwishImplementationBackward]
	6172613152 -> 6079156448
	6172613152 -> 6076943472 [dir=none]
	6076943472 [label="input
 (1, 2304, 1, 1)" fillcolor=orange]
	6172613152 -> 6076364208 [dir=none]
	6076364208 [label="weight
 (96, 2304, 1, 1)" fillcolor=orange]
	6172613152 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (96,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172612720 -> 6172613152
	6172612720 -> 6076943232 [dir=none]
	6076943232 [label="self
 (1, 2304, 19, 19)" fillcolor=orange]
	6172612720 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 2304, 19, 19)"]
	6079156224 -> 6172612720
	6079156224 [label=SwishImplementationBackward]
	6172610944 -> 6079156224
	6172610944 -> 6076944112 [dir=none]
	6076944112 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6172610944 -> 6172573296 [dir=none]
	6172573296 [label="result1
 (2304)" fillcolor=orange]
	6172610944 -> 6172573136 [dir=none]
	6172573136 [label="result2
 (2304)" fillcolor=orange]
	6172610944 -> 6076361888 [dir=none]
	6076361888 [label="running_mean
 (2304)" fillcolor=orange]
	6172610944 -> 6076363728 [dir=none]
	6076363728 [label="running_var
 (2304)" fillcolor=orange]
	6172610944 -> 6076363488 [dir=none]
	6076363488 [label="weight
 (2304)" fillcolor=orange]
	6172610944 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172611424 -> 6172610944
	6172611424 -> 6076944272 [dir=none]
	6076944272 [label="input
 (1, 2304, 23, 23)" fillcolor=orange]
	6172611424 -> 6076363568 [dir=none]
	6076363568 [label="weight
 (2304, 1, 5, 5)" fillcolor=orange]
	6172611424 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           2304
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172610992 -> 6172611424
	6172610992 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6079156000 -> 6172610992
	6079156000 [label=SwishImplementationBackward]
	6172609648 -> 6079156000
	6172609648 -> 6076945312 [dir=none]
	6076945312 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6172609648 -> 6172572256 [dir=none]
	6172572256 [label="result1
 (2304)" fillcolor=orange]
	6172609648 -> 11670942112 [dir=none]
	11670942112 [label="result2
 (2304)" fillcolor=orange]
	6172609648 -> 6076362768 [dir=none]
	6076362768 [label="running_mean
 (2304)" fillcolor=orange]
	6172609648 -> 6076363088 [dir=none]
	6076363088 [label="running_var
 (2304)" fillcolor=orange]
	6172609648 -> 6076362928 [dir=none]
	6076362928 [label="weight
 (2304)" fillcolor=orange]
	6172609648 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172608784 -> 6172609648
	6172608784 -> 6076944592 [dir=none]
	6076944592 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6172608784 -> 6076362848 [dir=none]
	6076362848 [label="weight
 (2304, 384, 1, 1)" fillcolor=orange]
	6172608784 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172617616 -> 6172608784
	6172617616 [label="AddBackward0
------------
alpha: 1"]
	6172607824 -> 6172617616
	6172607824 -> 6076944352 [dir=none]
	6076944352 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6172607824 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172606768 -> 6172607824
	6172606768 -> 6172572816 [dir=none]
	6172572816 [label="other
 ()" fillcolor=orange]
	6172606768 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172607344 -> 6172606768
	6172607344 -> 6076944752 [dir=none]
	6076944752 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6172607344 -> 6172571056 [dir=none]
	6172571056 [label="result1
 (384)" fillcolor=orange]
	6172607344 -> 6172571136 [dir=none]
	6172571136 [label="result2
 (384)" fillcolor=orange]
	6172607344 -> 6076362128 [dir=none]
	6076362128 [label="running_mean
 (384)" fillcolor=orange]
	6172607344 -> 6076362448 [dir=none]
	6076362448 [label="running_var
 (384)" fillcolor=orange]
	6172607344 -> 6076362288 [dir=none]
	6076362288 [label="weight
 (384)" fillcolor=orange]
	6172607344 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172606528 -> 6172607344
	6172606528 -> 6076944912 [dir=none]
	6076944912 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6172606528 -> 6076362208 [dir=none]
	6076362208 [label="weight
 (384, 2304, 1, 1)" fillcolor=orange]
	6172606528 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172540064 -> 6172606528
	6172540064 -> 6076945392 [dir=none]
	6076945392 [label="other
 (1, 2304, 19, 19)" fillcolor=orange]
	6172540064 -> 6076945152 [dir=none]
	6076945152 [label="self
 (1, 2304, 1, 1)" fillcolor=orange]
	6172540064 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6172539488 -> 6172540064
	6172539488 -> 6172570896 [dir=none]
	6172570896 [label="result
 (1, 2304, 1, 1)" fillcolor=orange]
	6172539488 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6172539008 -> 6172539488
	6172539008 -> 6076944992 [dir=none]
	6076944992 [label="input
 (1, 96, 1, 1)" fillcolor=orange]
	6172539008 -> 6076361968 [dir=none]
	6076361968 [label="weight
 (2304, 96, 1, 1)" fillcolor=orange]
	6172539008 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (2304,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079155776 -> 6172539008
	6079155776 [label=SwishImplementationBackward]
	6172537904 -> 6079155776
	6172537904 -> 6076945712 [dir=none]
	6076945712 [label="input
 (1, 2304, 1, 1)" fillcolor=orange]
	6172537904 -> 6076361728 [dir=none]
	6076361728 [label="weight
 (96, 2304, 1, 1)" fillcolor=orange]
	6172537904 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (96,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172537472 -> 6172537904
	6172537472 -> 6076945392 [dir=none]
	6076945392 [label="self
 (1, 2304, 19, 19)" fillcolor=orange]
	6172537472 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 2304, 19, 19)"]
	6079155552 -> 6172537472
	6079155552 [label=SwishImplementationBackward]
	6172536128 -> 6079155552
	6172536128 -> 6076946192 [dir=none]
	6076946192 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6172536128 -> 6172569536 [dir=none]
	6172569536 [label="result1
 (2304)" fillcolor=orange]
	6172536128 -> 6172569376 [dir=none]
	6172569376 [label="result2
 (2304)" fillcolor=orange]
	6172536128 -> 6076359408 [dir=none]
	6076359408 [label="running_mean
 (2304)" fillcolor=orange]
	6172536128 -> 6076361248 [dir=none]
	6076361248 [label="running_var
 (2304)" fillcolor=orange]
	6172536128 -> 6076361008 [dir=none]
	6076361008 [label="weight
 (2304)" fillcolor=orange]
	6172536128 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172535840 -> 6172536128
	6172535840 -> 6076946352 [dir=none]
	6076946352 [label="input
 (1, 2304, 23, 23)" fillcolor=orange]
	6172535840 -> 6076361088 [dir=none]
	6076361088 [label="weight
 (2304, 1, 5, 5)" fillcolor=orange]
	6172535840 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           2304
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172535168 -> 6172535840
	6172535168 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6079155328 -> 6172535168
	6079155328 [label=SwishImplementationBackward]
	6172534688 -> 6079155328
	6172534688 -> 6076947472 [dir=none]
	6076947472 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6172534688 -> 6172568496 [dir=none]
	6172568496 [label="result1
 (2304)" fillcolor=orange]
	6172534688 -> 6172568336 [dir=none]
	6172568336 [label="result2
 (2304)" fillcolor=orange]
	6172534688 -> 6076360288 [dir=none]
	6076360288 [label="running_mean
 (2304)" fillcolor=orange]
	6172534688 -> 6076360608 [dir=none]
	6076360608 [label="running_var
 (2304)" fillcolor=orange]
	6172534688 -> 6076360448 [dir=none]
	6076360448 [label="weight
 (2304)" fillcolor=orange]
	6172534688 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172533872 -> 6172534688
	6172533872 -> 6076946592 [dir=none]
	6076946592 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6172533872 -> 6076360368 [dir=none]
	6076360368 [label="weight
 (2304, 384, 1, 1)" fillcolor=orange]
	6172533872 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172607536 -> 6172533872
	6172607536 [label="AddBackward0
------------
alpha: 1"]
	6172532384 -> 6172607536
	6172532384 -> 6076946512 [dir=none]
	6076946512 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6172532384 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172531952 -> 6172532384
	6172531952 -> 6172567776 [dir=none]
	6172567776 [label="other
 ()" fillcolor=orange]
	6172531952 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172531520 -> 6172531952
	6172531520 -> 6076946752 [dir=none]
	6076946752 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6172531520 -> 6172567136 [dir=none]
	6172567136 [label="result1
 (384)" fillcolor=orange]
	6172531520 -> 6172567296 [dir=none]
	6172567296 [label="result2
 (384)" fillcolor=orange]
	6172531520 -> 6076359648 [dir=none]
	6076359648 [label="running_mean
 (384)" fillcolor=orange]
	6172531520 -> 6076359968 [dir=none]
	6076359968 [label="running_var
 (384)" fillcolor=orange]
	6172531520 -> 6076359808 [dir=none]
	6076359808 [label="weight
 (384)" fillcolor=orange]
	6172531520 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172531088 -> 6172531520
	6172531088 -> 6076946832 [dir=none]
	6076946832 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6172531088 -> 6076359728 [dir=none]
	6076359728 [label="weight
 (384, 2304, 1, 1)" fillcolor=orange]
	6172531088 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172530416 -> 6172531088
	6172530416 -> 6076947632 [dir=none]
	6076947632 [label="other
 (1, 2304, 19, 19)" fillcolor=orange]
	6172530416 -> 6076947312 [dir=none]
	6076947312 [label="self
 (1, 2304, 1, 1)" fillcolor=orange]
	6172530416 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6172529792 -> 6172530416
	6172529792 -> 6172566976 [dir=none]
	6172566976 [label="result
 (1, 2304, 1, 1)" fillcolor=orange]
	6172529792 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6172529360 -> 6172529792
	6172529360 -> 6076947072 [dir=none]
	6076947072 [label="input
 (1, 96, 1, 1)" fillcolor=orange]
	6172529360 -> 6076359488 [dir=none]
	6076359488 [label="weight
 (2304, 96, 1, 1)" fillcolor=orange]
	6172529360 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (2304,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079155104 -> 6172529360
	6079155104 [label=SwishImplementationBackward]
	6172527824 -> 6079155104
	6172527824 -> 6076947872 [dir=none]
	6076947872 [label="input
 (1, 2304, 1, 1)" fillcolor=orange]
	6172527824 -> 6076359248 [dir=none]
	6076359248 [label="weight
 (96, 2304, 1, 1)" fillcolor=orange]
	6172527824 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (96,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172528064 -> 6172527824
	6172528064 -> 6076947632 [dir=none]
	6076947632 [label="self
 (1, 2304, 19, 19)" fillcolor=orange]
	6172528064 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 2304, 19, 19)"]
	6079154880 -> 6172528064
	6079154880 [label=SwishImplementationBackward]
	6172526816 -> 6079154880
	6172526816 -> 6076948192 [dir=none]
	6076948192 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6172526816 -> 6172565616 [dir=none]
	6172565616 [label="result1
 (2304)" fillcolor=orange]
	6172526816 -> 6172565456 [dir=none]
	6172565456 [label="result2
 (2304)" fillcolor=orange]
	6172526816 -> 6076356928 [dir=none]
	6076356928 [label="running_mean
 (2304)" fillcolor=orange]
	6172526816 -> 6076358768 [dir=none]
	6076358768 [label="running_var
 (2304)" fillcolor=orange]
	6172526816 -> 6076358528 [dir=none]
	6076358528 [label="weight
 (2304)" fillcolor=orange]
	6172526816 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172526384 -> 6172526816
	6172526384 -> 6076948432 [dir=none]
	6076948432 [label="input
 (1, 2304, 23, 23)" fillcolor=orange]
	6172526384 -> 6076358608 [dir=none]
	6076358608 [label="weight
 (2304, 1, 5, 5)" fillcolor=orange]
	6172526384 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           2304
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172525328 -> 6172526384
	6172525328 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6079154656 -> 6172525328
	6079154656 [label=SwishImplementationBackward]
	6172524656 -> 6079154656
	6172524656 -> 6076949552 [dir=none]
	6076949552 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6172524656 -> 6172564576 [dir=none]
	6172564576 [label="result1
 (2304)" fillcolor=orange]
	6172524656 -> 6172564416 [dir=none]
	6172564416 [label="result2
 (2304)" fillcolor=orange]
	6172524656 -> 6076357808 [dir=none]
	6076357808 [label="running_mean
 (2304)" fillcolor=orange]
	6172524656 -> 6076358128 [dir=none]
	6076358128 [label="running_var
 (2304)" fillcolor=orange]
	6172524656 -> 6076357968 [dir=none]
	6076357968 [label="weight
 (2304)" fillcolor=orange]
	6172524656 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172442048 -> 6172524656
	6172442048 -> 6076948752 [dir=none]
	6076948752 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6172442048 -> 6076357888 [dir=none]
	6076357888 [label="weight
 (2304, 384, 1, 1)" fillcolor=orange]
	6172442048 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172532720 -> 6172442048
	6172532720 [label="AddBackward0
------------
alpha: 1"]
	6172440944 -> 6172532720
	6172440944 -> 6076948512 [dir=none]
	6076948512 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6172440944 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172440368 -> 6172440944
	6172440368 -> 6172563776 [dir=none]
	6172563776 [label="other
 ()" fillcolor=orange]
	6172440368 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172439888 -> 6172440368
	6172439888 -> 6076948912 [dir=none]
	6076948912 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6172439888 -> 6172563136 [dir=none]
	6172563136 [label="result1
 (384)" fillcolor=orange]
	6172439888 -> 6172563296 [dir=none]
	6172563296 [label="result2
 (384)" fillcolor=orange]
	6172439888 -> 6076357168 [dir=none]
	6076357168 [label="running_mean
 (384)" fillcolor=orange]
	6172439888 -> 6076357488 [dir=none]
	6076357488 [label="running_var
 (384)" fillcolor=orange]
	6172439888 -> 6076357328 [dir=none]
	6076357328 [label="weight
 (384)" fillcolor=orange]
	6172439888 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172439456 -> 6172439888
	6172439456 -> 6076949072 [dir=none]
	6076949072 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6172439456 -> 6076357248 [dir=none]
	6076357248 [label="weight
 (384, 2304, 1, 1)" fillcolor=orange]
	6172439456 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172438880 -> 6172439456
	6172438880 -> 6076949712 [dir=none]
	6076949712 [label="other
 (1, 2304, 19, 19)" fillcolor=orange]
	6172438880 -> 6076949392 [dir=none]
	6076949392 [label="self
 (1, 2304, 1, 1)" fillcolor=orange]
	6172438880 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6172438784 -> 6172438880
	6172438784 -> 6172562976 [dir=none]
	6172562976 [label="result
 (1, 2304, 1, 1)" fillcolor=orange]
	6172438784 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6172438640 -> 6172438784
	6172438640 -> 6076949152 [dir=none]
	6076949152 [label="input
 (1, 96, 1, 1)" fillcolor=orange]
	6172438640 -> 6076357008 [dir=none]
	6076357008 [label="weight
 (2304, 96, 1, 1)" fillcolor=orange]
	6172438640 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (2304,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079154432 -> 6172438640
	6079154432 [label=SwishImplementationBackward]
	6172438208 -> 6079154432
	6172438208 -> 6076950032 [dir=none]
	6076950032 [label="input
 (1, 2304, 1, 1)" fillcolor=orange]
	6172438208 -> 6076356768 [dir=none]
	6076356768 [label="weight
 (96, 2304, 1, 1)" fillcolor=orange]
	6172438208 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (96,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172438064 -> 6172438208
	6172438064 -> 6076949712 [dir=none]
	6076949712 [label="self
 (1, 2304, 19, 19)" fillcolor=orange]
	6172438064 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 2304, 19, 19)"]
	6079154208 -> 6172438064
	6079154208 [label=SwishImplementationBackward]
	6172437632 -> 6079154208
	6172437632 -> 6076950432 [dir=none]
	6076950432 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6172437632 -> 6172561616 [dir=none]
	6172561616 [label="result1
 (2304)" fillcolor=orange]
	6172437632 -> 6172561456 [dir=none]
	6172561456 [label="result2
 (2304)" fillcolor=orange]
	6172437632 -> 6076354448 [dir=none]
	6076354448 [label="running_mean
 (2304)" fillcolor=orange]
	6172437632 -> 6076356288 [dir=none]
	6076356288 [label="running_var
 (2304)" fillcolor=orange]
	6172437632 -> 6076356048 [dir=none]
	6076356048 [label="weight
 (2304)" fillcolor=orange]
	6172437632 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172437488 -> 6172437632
	6172437488 -> 6076950592 [dir=none]
	6076950592 [label="input
 (1, 2304, 23, 23)" fillcolor=orange]
	6172437488 -> 6076356128 [dir=none]
	6076356128 [label="weight
 (2304, 1, 5, 5)" fillcolor=orange]
	6172437488 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           2304
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172437200 -> 6172437488
	6172437200 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6079153984 -> 6172437200
	6079153984 [label=SwishImplementationBackward]
	6172436720 -> 6079153984
	6172436720 -> 6076951552 [dir=none]
	6076951552 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6172436720 -> 6172560576 [dir=none]
	6172560576 [label="result1
 (2304)" fillcolor=orange]
	6172436720 -> 6172560416 [dir=none]
	6172560416 [label="result2
 (2304)" fillcolor=orange]
	6172436720 -> 6076355328 [dir=none]
	6076355328 [label="running_mean
 (2304)" fillcolor=orange]
	6172436720 -> 6076355648 [dir=none]
	6076355648 [label="running_var
 (2304)" fillcolor=orange]
	6172436720 -> 6076355488 [dir=none]
	6076355488 [label="weight
 (2304)" fillcolor=orange]
	6172436720 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172436576 -> 6172436720
	6172436576 -> 6076950832 [dir=none]
	6076950832 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6172436576 -> 6076355408 [dir=none]
	6076355408 [label="weight
 (2304, 384, 1, 1)" fillcolor=orange]
	6172436576 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172441520 -> 6172436576
	6172441520 [label="AddBackward0
------------
alpha: 1"]
	6172436144 -> 6172441520
	6172436144 -> 6076950672 [dir=none]
	6076950672 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6172436144 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172436048 -> 6172436144
	6172436048 -> 6172559776 [dir=none]
	6172559776 [label="other
 ()" fillcolor=orange]
	6172436048 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172435904 -> 6172436048
	6172435904 -> 6076950912 [dir=none]
	6076950912 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6172435904 -> 6172559296 [dir=none]
	6172559296 [label="result1
 (384)" fillcolor=orange]
	6172435904 -> 6172559376 [dir=none]
	6172559376 [label="result2
 (384)" fillcolor=orange]
	6172435904 -> 6076354688 [dir=none]
	6076354688 [label="running_mean
 (384)" fillcolor=orange]
	6172435904 -> 6076355008 [dir=none]
	6076355008 [label="running_var
 (384)" fillcolor=orange]
	6172435904 -> 6076354848 [dir=none]
	6076354848 [label="weight
 (384)" fillcolor=orange]
	6172435904 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172435760 -> 6172435904
	6172435760 -> 6076951072 [dir=none]
	6076951072 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6172435760 -> 6076354768 [dir=none]
	6076354768 [label="weight
 (384, 2304, 1, 1)" fillcolor=orange]
	6172435760 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172435472 -> 6172435760
	6172435472 -> 6076951712 [dir=none]
	6076951712 [label="other
 (1, 2304, 19, 19)" fillcolor=orange]
	6172435472 -> 6076951312 [dir=none]
	6076951312 [label="self
 (1, 2304, 1, 1)" fillcolor=orange]
	6172435472 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6172435136 -> 6172435472
	6172435136 -> 6172559136 [dir=none]
	6172559136 [label="result
 (1, 2304, 1, 1)" fillcolor=orange]
	6172435136 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6172434992 -> 6172435136
	6172434992 -> 6076951232 [dir=none]
	6076951232 [label="input
 (1, 96, 1, 1)" fillcolor=orange]
	6172434992 -> 6076354528 [dir=none]
	6076354528 [label="weight
 (2304, 96, 1, 1)" fillcolor=orange]
	6172434992 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (2304,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079153760 -> 6172434992
	6079153760 [label=SwishImplementationBackward]
	6172434560 -> 6079153760
	6172434560 -> 6076951952 [dir=none]
	6076951952 [label="input
 (1, 2304, 1, 1)" fillcolor=orange]
	6172434560 -> 6076354288 [dir=none]
	6076354288 [label="weight
 (96, 2304, 1, 1)" fillcolor=orange]
	6172434560 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (96,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172434416 -> 6172434560
	6172434416 -> 6076951712 [dir=none]
	6076951712 [label="self
 (1, 2304, 19, 19)" fillcolor=orange]
	6172434416 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 2304, 19, 19)"]
	6079153536 -> 6172434416
	6079153536 [label=SwishImplementationBackward]
	6172433984 -> 6079153536
	6172433984 -> 6076952352 [dir=none]
	6076952352 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6172433984 -> 6172557776 [dir=none]
	6172557776 [label="result1
 (2304)" fillcolor=orange]
	6172433984 -> 6172557616 [dir=none]
	6172557616 [label="result2
 (2304)" fillcolor=orange]
	6172433984 -> 6076351968 [dir=none]
	6076351968 [label="running_mean
 (2304)" fillcolor=orange]
	6172433984 -> 6076353808 [dir=none]
	6076353808 [label="running_var
 (2304)" fillcolor=orange]
	6172433984 -> 6076353568 [dir=none]
	6076353568 [label="weight
 (2304)" fillcolor=orange]
	6172433984 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172433840 -> 6172433984
	6172433840 -> 6076952432 [dir=none]
	6076952432 [label="input
 (1, 2304, 23, 23)" fillcolor=orange]
	6172433840 -> 6076353648 [dir=none]
	6076353648 [label="weight
 (2304, 1, 5, 5)" fillcolor=orange]
	6172433840 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           2304
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172433552 -> 6172433840
	6172433552 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6079153312 -> 6172433552
	6079153312 [label=SwishImplementationBackward]
	6172433312 -> 6079153312
	6172433312 -> 6076953472 [dir=none]
	6076953472 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6172433312 -> 6172357024 [dir=none]
	6172357024 [label="result1
 (2304)" fillcolor=orange]
	6172433312 -> 6172349664 [dir=none]
	6172349664 [label="result2
 (2304)" fillcolor=orange]
	6172433312 -> 6076352848 [dir=none]
	6076352848 [label="running_mean
 (2304)" fillcolor=orange]
	6172433312 -> 6076353168 [dir=none]
	6076353168 [label="running_var
 (2304)" fillcolor=orange]
	6172433312 -> 6076353008 [dir=none]
	6076353008 [label="weight
 (2304)" fillcolor=orange]
	6172433312 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172433168 -> 6172433312
	6172433168 -> 6076952752 [dir=none]
	6076952752 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6172433168 -> 6076352928 [dir=none]
	6076352928 [label="weight
 (2304, 384, 1, 1)" fillcolor=orange]
	6172433168 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172436336 -> 6172433168
	6172436336 [label="AddBackward0
------------
alpha: 1"]
	6172432736 -> 6172436336
	6172432736 -> 6076952592 [dir=none]
	6076952592 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6172432736 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172432400 -> 6172432736
	6172432400 -> 6172349024 [dir=none]
	6172349024 [label="other
 ()" fillcolor=orange]
	6172432400 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172432256 -> 6172432400
	6172432256 -> 6076952992 [dir=none]
	6076952992 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6172432256 -> 6172360224 [dir=none]
	6172360224 [label="result1
 (384)" fillcolor=orange]
	6172432256 -> 6172360464 [dir=none]
	6172360464 [label="result2
 (384)" fillcolor=orange]
	6172432256 -> 6076352208 [dir=none]
	6076352208 [label="running_mean
 (384)" fillcolor=orange]
	6172432256 -> 6076352528 [dir=none]
	6076352528 [label="running_var
 (384)" fillcolor=orange]
	6172432256 -> 6076352368 [dir=none]
	6076352368 [label="weight
 (384)" fillcolor=orange]
	6172432256 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172432112 -> 6172432256
	6172432112 -> 6076953152 [dir=none]
	6076953152 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6172432112 -> 6076352288 [dir=none]
	6076352288 [label="weight
 (384, 2304, 1, 1)" fillcolor=orange]
	6172432112 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172431824 -> 6172432112
	6172431824 -> 6076953632 [dir=none]
	6076953632 [label="other
 (1, 2304, 19, 19)" fillcolor=orange]
	6172431824 -> 6076953392 [dir=none]
	6076953392 [label="self
 (1, 2304, 1, 1)" fillcolor=orange]
	6172431824 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6172431728 -> 6172431824
	6172431728 -> 6172359984 [dir=none]
	6172359984 [label="result
 (1, 2304, 1, 1)" fillcolor=orange]
	6172431728 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6172431584 -> 6172431728
	6172431584 -> 6076953232 [dir=none]
	6076953232 [label="input
 (1, 96, 1, 1)" fillcolor=orange]
	6172431584 -> 6076352048 [dir=none]
	6076352048 [label="weight
 (2304, 96, 1, 1)" fillcolor=orange]
	6172431584 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (2304,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079153088 -> 6172431584
	6079153088 [label=SwishImplementationBackward]
	6172431152 -> 6079153088
	6172431152 -> 6076953872 [dir=none]
	6076953872 [label="input
 (1, 2304, 1, 1)" fillcolor=orange]
	6172431152 -> 6076351808 [dir=none]
	6076351808 [label="weight
 (96, 2304, 1, 1)" fillcolor=orange]
	6172431152 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (96,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172431008 -> 6172431152
	6172431008 -> 6076953632 [dir=none]
	6076953632 [label="self
 (1, 2304, 19, 19)" fillcolor=orange]
	6172431008 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 2304, 19, 19)"]
	6079152864 -> 6172431008
	6079152864 [label=SwishImplementationBackward]
	6172430576 -> 6079152864
	6172430576 -> 6076954352 [dir=none]
	6076954352 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6172430576 -> 6172350784 [dir=none]
	6172350784 [label="result1
 (2304)" fillcolor=orange]
	6172430576 -> 6172350544 [dir=none]
	6172350544 [label="result2
 (2304)" fillcolor=orange]
	6172430576 -> 6076087280 [dir=none]
	6076087280 [label="running_mean
 (2304)" fillcolor=orange]
	6172430576 -> 6076351328 [dir=none]
	6076351328 [label="running_var
 (2304)" fillcolor=orange]
	6172430576 -> 6076351088 [dir=none]
	6076351088 [label="weight
 (2304)" fillcolor=orange]
	6172430576 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172430432 -> 6172430576
	6172430432 -> 6076954512 [dir=none]
	6076954512 [label="input
 (1, 2304, 23, 23)" fillcolor=orange]
	6172430432 -> 6076351168 [dir=none]
	6076351168 [label="weight
 (2304, 1, 5, 5)" fillcolor=orange]
	6172430432 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           2304
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172430144 -> 6172430432
	6172430144 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6079152640 -> 6172430144
	6079152640 [label=SwishImplementationBackward]
	6172429664 -> 6079152640
	6172429664 -> 6076955632 [dir=none]
	6076955632 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6172429664 -> 6172345584 [dir=none]
	6172345584 [label="result1
 (2304)" fillcolor=orange]
	6172429664 -> 6172344864 [dir=none]
	6172344864 [label="result2
 (2304)" fillcolor=orange]
	6172429664 -> 6076088160 [dir=none]
	6076088160 [label="running_mean
 (2304)" fillcolor=orange]
	6172429664 -> 6076350688 [dir=none]
	6076350688 [label="running_var
 (2304)" fillcolor=orange]
	6172429664 -> 6076350528 [dir=none]
	6076350528 [label="weight
 (2304)" fillcolor=orange]
	6172429664 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172429520 -> 6172429664
	6172429520 -> 6076954752 [dir=none]
	6076954752 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6172429520 -> 6076088240 [dir=none]
	6076088240 [label="weight
 (2304, 384, 1, 1)" fillcolor=orange]
	6172429520 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172432688 -> 6172429520
	6172432688 [label="AddBackward0
------------
alpha: 1"]
	6172429088 -> 6172432688
	6172429088 -> 6076954672 [dir=none]
	6076954672 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6172429088 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172428992 -> 6172429088
	6172428992 -> 6172358464 [dir=none]
	6172358464 [label="other
 ()" fillcolor=orange]
	6172428992 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6172428848 -> 6172428992
	6172428848 -> 6076954992 [dir=none]
	6076954992 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6172428848 -> 6172356864 [dir=none]
	6172356864 [label="result1
 (384)" fillcolor=orange]
	6172428848 -> 6172357584 [dir=none]
	6172357584 [label="result2
 (384)" fillcolor=orange]
	6172428848 -> 6076087520 [dir=none]
	6076087520 [label="running_mean
 (384)" fillcolor=orange]
	6172428848 -> 6076087840 [dir=none]
	6076087840 [label="running_var
 (384)" fillcolor=orange]
	6172428848 -> 6076087680 [dir=none]
	6076087680 [label="weight
 (384)" fillcolor=orange]
	6172428848 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172428704 -> 6172428848
	6172428704 -> 6076955152 [dir=none]
	6076955152 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6172428704 -> 6076087600 [dir=none]
	6076087600 [label="weight
 (384, 2304, 1, 1)" fillcolor=orange]
	6172428704 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172428416 -> 6172428704
	6172428416 -> 6076955792 [dir=none]
	6076955792 [label="other
 (1, 2304, 19, 19)" fillcolor=orange]
	6172428416 -> 6076955392 [dir=none]
	6076955392 [label="self
 (1, 2304, 1, 1)" fillcolor=orange]
	6172428416 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6172428080 -> 6172428416
	6172428080 -> 6172356704 [dir=none]
	6172356704 [label="result
 (1, 2304, 1, 1)" fillcolor=orange]
	6172428080 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6172427936 -> 6172428080
	6172427936 -> 6076955312 [dir=none]
	6076955312 [label="input
 (1, 96, 1, 1)" fillcolor=orange]
	6172427936 -> 6076087360 [dir=none]
	6076087360 [label="weight
 (2304, 96, 1, 1)" fillcolor=orange]
	6172427936 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (2304,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079152416 -> 6172427936
	6079152416 [label=SwishImplementationBackward]
	6172427504 -> 6079152416
	6172427504 -> 6076956032 [dir=none]
	6076956032 [label="input
 (1, 2304, 1, 1)" fillcolor=orange]
	6172427504 -> 6076087120 [dir=none]
	6076087120 [label="weight
 (96, 2304, 1, 1)" fillcolor=orange]
	6172427504 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (96,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172427360 -> 6172427504
	6172427360 -> 6076955792 [dir=none]
	6076955792 [label="self
 (1, 2304, 19, 19)" fillcolor=orange]
	6172427360 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 2304, 19, 19)"]
	6079152192 -> 6172427360
	6079152192 [label=SwishImplementationBackward]
	6172426928 -> 6079152192
	6172426928 -> 6076956432 [dir=none]
	6076956432 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6172426928 -> 6172354544 [dir=none]
	6172354544 [label="result1
 (2304)" fillcolor=orange]
	6172426928 -> 6172354384 [dir=none]
	6172354384 [label="result2
 (2304)" fillcolor=orange]
	6172426928 -> 6076084880 [dir=none]
	6076084880 [label="running_mean
 (2304)" fillcolor=orange]
	6172426928 -> 6076086640 [dir=none]
	6076086640 [label="running_var
 (2304)" fillcolor=orange]
	6172426928 -> 6076086400 [dir=none]
	6076086400 [label="weight
 (2304)" fillcolor=orange]
	6172426928 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6172426784 -> 6172426928
	6172426784 -> 6076956512 [dir=none]
	6076956512 [label="input
 (1, 2304, 23, 23)" fillcolor=orange]
	6172426784 -> 6076086480 [dir=none]
	6076086480 [label="weight
 (2304, 1, 5, 5)" fillcolor=orange]
	6172426784 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           2304
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172426496 -> 6172426784
	6172426496 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6078611040 -> 6172426496
	6078611040 [label=SwishImplementationBackward]
	6172426544 -> 6078611040
	6172426544 -> 6076944192 [dir=none]
	6076944192 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6172426544 -> 6172351984 [dir=none]
	6172351984 [label="result1
 (2304)" fillcolor=orange]
	6172426544 -> 6172351824 [dir=none]
	6172351824 [label="result2
 (2304)" fillcolor=orange]
	6172426544 -> 6076085680 [dir=none]
	6076085680 [label="running_mean
 (2304)" fillcolor=orange]
	6172426544 -> 6076086000 [dir=none]
	6076086000 [label="running_var
 (2304)" fillcolor=orange]
	6172426544 -> 6076085840 [dir=none]
	6076085840 [label="weight
 (2304)" fillcolor=orange]
	6172426544 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6079135552 -> 6172426544
	6079135552 -> 6076941792 [dir=none]
	6076941792 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6079135552 -> 6076085760 [dir=none]
	6076085760 [label="weight
 (2304, 384, 1, 1)" fillcolor=orange]
	6079135552 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6172429280 -> 6079135552
	6172429280 [label="AddBackward0
------------
alpha: 1"]
	6079135120 -> 6172429280
	6079135120 -> 6076940752 [dir=none]
	6076940752 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6079135120 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6079134784 -> 6079135120
	6079134784 -> 6172351184 [dir=none]
	6172351184 [label="other
 ()" fillcolor=orange]
	6079134784 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6079134640 -> 6079134784
	6079134640 -> 6076942432 [dir=none]
	6076942432 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6079134640 -> 6172348384 [dir=none]
	6172348384 [label="result1
 (384)" fillcolor=orange]
	6079134640 -> 6172349824 [dir=none]
	6172349824 [label="result2
 (384)" fillcolor=orange]
	6079134640 -> 6076085120 [dir=none]
	6076085120 [label="running_mean
 (384)" fillcolor=orange]
	6079134640 -> 6076085440 [dir=none]
	6076085440 [label="running_var
 (384)" fillcolor=orange]
	6079134640 -> 6076085280 [dir=none]
	6076085280 [label="weight
 (384)" fillcolor=orange]
	6079134640 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6079134496 -> 6079134640
	6079134496 -> 6076942832 [dir=none]
	6076942832 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6079134496 -> 6076085200 [dir=none]
	6076085200 [label="weight
 (384, 2304, 1, 1)" fillcolor=orange]
	6079134496 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079134208 -> 6079134496
	6079134208 -> 6076944832 [dir=none]
	6076944832 [label="other
 (1, 2304, 19, 19)" fillcolor=orange]
	6079134208 -> 6076943952 [dir=none]
	6076943952 [label="self
 (1, 2304, 1, 1)" fillcolor=orange]
	6079134208 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6079134112 -> 6079134208
	6079134112 -> 6172346224 [dir=none]
	6172346224 [label="result
 (1, 2304, 1, 1)" fillcolor=orange]
	6079134112 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6079133968 -> 6079134112
	6079133968 -> 6076943712 [dir=none]
	6076943712 [label="input
 (1, 96, 1, 1)" fillcolor=orange]
	6079133968 -> 6076084960 [dir=none]
	6076084960 [label="weight
 (2304, 96, 1, 1)" fillcolor=orange]
	6079133968 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (2304,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078610816 -> 6079133968
	6078610816 [label=SwishImplementationBackward]
	6079133536 -> 6078610816
	6079133536 -> 6076946672 [dir=none]
	6076946672 [label="input
 (1, 2304, 1, 1)" fillcolor=orange]
	6079133536 -> 6076084720 [dir=none]
	6076084720 [label="weight
 (96, 2304, 1, 1)" fillcolor=orange]
	6079133536 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (96,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079133392 -> 6079133536
	6079133392 -> 6076944832 [dir=none]
	6076944832 [label="self
 (1, 2304, 19, 19)" fillcolor=orange]
	6079133392 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 2304, 19, 19)"]
	6078610592 -> 6079133392
	6078610592 [label=SwishImplementationBackward]
	6079132960 -> 6078610592
	6079132960 -> 6076948272 [dir=none]
	6076948272 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6079132960 -> 6172359904 [dir=none]
	6172359904 [label="result1
 (2304)" fillcolor=orange]
	6079132960 -> 6172359744 [dir=none]
	6172359744 [label="result2
 (2304)" fillcolor=orange]
	6079132960 -> 6076082480 [dir=none]
	6076082480 [label="running_mean
 (2304)" fillcolor=orange]
	6079132960 -> 6076084240 [dir=none]
	6076084240 [label="running_var
 (2304)" fillcolor=orange]
	6079132960 -> 6076084000 [dir=none]
	6076084000 [label="weight
 (2304)" fillcolor=orange]
	6079132960 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6079132816 -> 6079132960
	6079132816 -> 6076949952 [dir=none]
	6076949952 [label="input
 (1, 2304, 23, 23)" fillcolor=orange]
	6079132816 -> 6076084080 [dir=none]
	6076084080 [label="weight
 (2304, 1, 5, 5)" fillcolor=orange]
	6079132816 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           2304
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079132528 -> 6079132816
	6079132528 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6078610368 -> 6079132528
	6078610368 [label=SwishImplementationBackward]
	6079132048 -> 6078610368
	6079132048 -> 6076955232 [dir=none]
	6076955232 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6079132048 -> 6172359024 [dir=none]
	6172359024 [label="result1
 (2304)" fillcolor=orange]
	6079132048 -> 6172358864 [dir=none]
	6172358864 [label="result2
 (2304)" fillcolor=orange]
	6079132048 -> 6076083360 [dir=none]
	6076083360 [label="running_mean
 (2304)" fillcolor=orange]
	6079132048 -> 6076083680 [dir=none]
	6076083680 [label="running_var
 (2304)" fillcolor=orange]
	6079132048 -> 6076083520 [dir=none]
	6076083520 [label="weight
 (2304)" fillcolor=orange]
	6079132048 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6079131904 -> 6079132048
	6079131904 -> 6076950512 [dir=none]
	6076950512 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6079131904 -> 6076083440 [dir=none]
	6076083440 [label="weight
 (2304, 384, 1, 1)" fillcolor=orange]
	6079131904 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079135072 -> 6079131904
	6079135072 [label="AddBackward0
------------
alpha: 1"]
	6079131472 -> 6079135072
	6079131472 -> 6076950272 [dir=none]
	6076950272 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6079131472 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6079131376 -> 6079131472
	6079131376 -> 6172358224 [dir=none]
	6172358224 [label="other
 ()" fillcolor=orange]
	6079131376 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6079131232 -> 6079131376
	6079131232 -> 6076950752 [dir=none]
	6076950752 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6079131232 -> 6172357664 [dir=none]
	6172357664 [label="result1
 (384)" fillcolor=orange]
	6079131232 -> 6172357744 [dir=none]
	6172357744 [label="result2
 (384)" fillcolor=orange]
	6079131232 -> 6076082720 [dir=none]
	6076082720 [label="running_mean
 (384)" fillcolor=orange]
	6079131232 -> 6076083040 [dir=none]
	6076083040 [label="running_var
 (384)" fillcolor=orange]
	6079131232 -> 6076082880 [dir=none]
	6076082880 [label="weight
 (384)" fillcolor=orange]
	6079131232 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6079131088 -> 6079131232
	6079131088 -> 6076953552 [dir=none]
	6076953552 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6079131088 -> 6076082800 [dir=none]
	6076082800 [label="weight
 (384, 2304, 1, 1)" fillcolor=orange]
	6079131088 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079130800 -> 6079131088
	6079130800 -> 6076956112 [dir=none]
	6076956112 [label="other
 (1, 2304, 19, 19)" fillcolor=orange]
	6079130800 -> 6076954272 [dir=none]
	6076954272 [label="self
 (1, 2304, 1, 1)" fillcolor=orange]
	6079130800 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6079130464 -> 6079130800
	6079130464 -> 6172357504 [dir=none]
	6172357504 [label="result
 (1, 2304, 1, 1)" fillcolor=orange]
	6079130464 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6079130320 -> 6079130464
	6079130320 -> 6076953792 [dir=none]
	6076953792 [label="input
 (1, 96, 1, 1)" fillcolor=orange]
	6079130320 -> 6076082560 [dir=none]
	6076082560 [label="weight
 (2304, 96, 1, 1)" fillcolor=orange]
	6079130320 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (2304,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078610144 -> 6079130320
	6078610144 [label=SwishImplementationBackward]
	6079129888 -> 6078610144
	6079129888 -> 6076956592 [dir=none]
	6076956592 [label="input
 (1, 2304, 1, 1)" fillcolor=orange]
	6079129888 -> 6076082320 [dir=none]
	6076082320 [label="weight
 (96, 2304, 1, 1)" fillcolor=orange]
	6079129888 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (96,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079129744 -> 6079129888
	6079129744 -> 6076956112 [dir=none]
	6076956112 [label="self
 (1, 2304, 19, 19)" fillcolor=orange]
	6079129744 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 2304, 19, 19)"]
	6078609920 -> 6079129744
	6078609920 [label=SwishImplementationBackward]
	6079129312 -> 6078609920
	6079129312 -> 6076945952 [dir=none]
	6076945952 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6079129312 -> 6172356144 [dir=none]
	6172356144 [label="result1
 (2304)" fillcolor=orange]
	6079129312 -> 6172355984 [dir=none]
	6172355984 [label="result2
 (2304)" fillcolor=orange]
	6079129312 -> 6076080240 [dir=none]
	6076080240 [label="running_mean
 (2304)" fillcolor=orange]
	6079129312 -> 6076081920 [dir=none]
	6076081920 [label="running_var
 (2304)" fillcolor=orange]
	6079129312 -> 6076081680 [dir=none]
	6076081680 [label="weight
 (2304)" fillcolor=orange]
	6079129312 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6079129168 -> 6079129312
	6079129168 -> 6076946992 [dir=none]
	6076946992 [label="input
 (1, 2304, 23, 23)" fillcolor=orange]
	6079129168 -> 6076081760 [dir=none]
	6076081760 [label="weight
 (2304, 1, 5, 5)" fillcolor=orange]
	6079129168 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           2304
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079128880 -> 6079129168
	6079128880 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6078609696 -> 6079128880
	6078609696 [label=SwishImplementationBackward]
	6079128640 -> 6078609696
	6079128640 -> 6076953952 [dir=none]
	6076953952 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6079128640 -> 6172355264 [dir=none]
	6172355264 [label="result1
 (2304)" fillcolor=orange]
	6079128640 -> 6172355104 [dir=none]
	6172355104 [label="result2
 (2304)" fillcolor=orange]
	6079128640 -> 6076081040 [dir=none]
	6076081040 [label="running_mean
 (2304)" fillcolor=orange]
	6079128640 -> 6076081360 [dir=none]
	6076081360 [label="running_var
 (2304)" fillcolor=orange]
	6079128640 -> 6076081200 [dir=none]
	6076081200 [label="weight
 (2304)" fillcolor=orange]
	6079128640 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6079128496 -> 6079128640
	6079128496 -> 6076948032 [dir=none]
	6076948032 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6079128496 -> 6076081120 [dir=none]
	6076081120 [label="weight
 (2304, 384, 1, 1)" fillcolor=orange]
	6079128496 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079131664 -> 6079128496
	6079131664 [label="AddBackward0
------------
alpha: 1"]
	6079128064 -> 6079131664
	6079128064 -> 6076947792 [dir=none]
	6076947792 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6079128064 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6079127728 -> 6079128064
	6079127728 -> 6172354624 [dir=none]
	6172354624 [label="other
 ()" fillcolor=orange]
	6079127728 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6079127584 -> 6079127728
	6079127584 -> 6076948672 [dir=none]
	6076948672 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6079127584 -> 6172353984 [dir=none]
	6172353984 [label="result1
 (384)" fillcolor=orange]
	6079127584 -> 6172354144 [dir=none]
	6172354144 [label="result2
 (384)" fillcolor=orange]
	6079127584 -> 6076080480 [dir=none]
	6076080480 [label="running_mean
 (384)" fillcolor=orange]
	6079127584 -> 6076080800 [dir=none]
	6076080800 [label="running_var
 (384)" fillcolor=orange]
	6079127584 -> 6076080640 [dir=none]
	6076080640 [label="weight
 (384)" fillcolor=orange]
	6079127584 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6079127440 -> 6079127584
	6079127440 -> 6076948992 [dir=none]
	6076948992 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6079127440 -> 6076080560 [dir=none]
	6076080560 [label="weight
 (384, 2304, 1, 1)" fillcolor=orange]
	6079127440 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079127152 -> 6079127440
	6079127152 -> 6076942112 [dir=none]
	6076942112 [label="other
 (1, 2304, 19, 19)" fillcolor=orange]
	6079127152 -> 6076951152 [dir=none]
	6076951152 [label="self
 (1, 2304, 1, 1)" fillcolor=orange]
	6079127152 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6079127056 -> 6079127152
	6079127056 -> 6172353904 [dir=none]
	6172353904 [label="result
 (1, 2304, 1, 1)" fillcolor=orange]
	6079127056 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6079126912 -> 6079127056
	6079126912 -> 6076949632 [dir=none]
	6076949632 [label="input
 (1, 96, 1, 1)" fillcolor=orange]
	6079126912 -> 6076080320 [dir=none]
	6076080320 [label="weight
 (2304, 96, 1, 1)" fillcolor=orange]
	6079126912 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (2304,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078609472 -> 6079126912
	6078609472 [label=SwishImplementationBackward]
	6079126480 -> 6078609472
	6079126480 -> 6076947232 [dir=none]
	6076947232 [label="input
 (1, 2304, 1, 1)" fillcolor=orange]
	6079126480 -> 6076080080 [dir=none]
	6076080080 [label="weight
 (96, 2304, 1, 1)" fillcolor=orange]
	6079126480 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (96,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079126336 -> 6079126480
	6079126336 -> 6076942112 [dir=none]
	6076942112 [label="self
 (1, 2304, 19, 19)" fillcolor=orange]
	6079126336 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 2304, 19, 19)"]
	6078609248 -> 6079126336
	6078609248 [label=SwishImplementationBackward]
	6079125904 -> 6078609248
	6079125904 -> 6076941552 [dir=none]
	6076941552 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6079125904 -> 6172352624 [dir=none]
	6172352624 [label="result1
 (2304)" fillcolor=orange]
	6079125904 -> 6172352464 [dir=none]
	6172352464 [label="result2
 (2304)" fillcolor=orange]
	6079125904 -> 6076077840 [dir=none]
	6076077840 [label="running_mean
 (2304)" fillcolor=orange]
	6079125904 -> 6076079600 [dir=none]
	6076079600 [label="running_var
 (2304)" fillcolor=orange]
	6079125904 -> 6076079360 [dir=none]
	6076079360 [label="weight
 (2304)" fillcolor=orange]
	6079125904 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6079125760 -> 6079125904
	6079125760 -> 6076941872 [dir=none]
	6076941872 [label="input
 (1, 2304, 23, 23)" fillcolor=orange]
	6079125760 -> 6076079440 [dir=none]
	6076079440 [label="weight
 (2304, 1, 5, 5)" fillcolor=orange]
	6079125760 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           2304
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079125472 -> 6079125760
	6079125472 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6078609024 -> 6079125472
	6078609024 [label=SwishImplementationBackward]
	6079124992 -> 6078609024
	6079124992 -> 6076948352 [dir=none]
	6076948352 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6079124992 -> 6172351584 [dir=none]
	6172351584 [label="result1
 (2304)" fillcolor=orange]
	6079124992 -> 6172351424 [dir=none]
	6172351424 [label="result2
 (2304)" fillcolor=orange]
	6079124992 -> 6076078720 [dir=none]
	6076078720 [label="running_mean
 (2304)" fillcolor=orange]
	6079124992 -> 6076079040 [dir=none]
	6076079040 [label="running_var
 (2304)" fillcolor=orange]
	6079124992 -> 6076078880 [dir=none]
	6076078880 [label="weight
 (2304)" fillcolor=orange]
	6079124992 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6079124848 -> 6079124992
	6079124848 -> 6076945632 [dir=none]
	6076945632 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6079124848 -> 6076078800 [dir=none]
	6076078800 [label="weight
 (2304, 384, 1, 1)" fillcolor=orange]
	6079124848 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079128016 -> 6079124848
	6079128016 [label="AddBackward0
------------
alpha: 1"]
	6079124416 -> 6079128016
	6079124416 -> 6076944512 [dir=none]
	6076944512 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6079124416 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6079124320 -> 6079124416
	6079124320 -> 6172350864 [dir=none]
	6172350864 [label="other
 ()" fillcolor=orange]
	6079124320 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6079124176 -> 6079124320
	6079124176 -> 6076949312 [dir=none]
	6076949312 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6079124176 -> 6172350384 [dir=none]
	6172350384 [label="result1
 (384)" fillcolor=orange]
	6079124176 -> 6172350464 [dir=none]
	6172350464 [label="result2
 (384)" fillcolor=orange]
	6079124176 -> 6076078080 [dir=none]
	6076078080 [label="running_mean
 (384)" fillcolor=orange]
	6079124176 -> 6076078400 [dir=none]
	6076078400 [label="running_var
 (384)" fillcolor=orange]
	6079124176 -> 6076078240 [dir=none]
	6076078240 [label="weight
 (384)" fillcolor=orange]
	6079124176 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6079124032 -> 6079124176
	6079124032 -> 6076952032 [dir=none]
	6076952032 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6079124032 -> 6076078160 [dir=none]
	6076078160 [label="weight
 (384, 2304, 1, 1)" fillcolor=orange]
	6079124032 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079123744 -> 6079124032
	6079123744 -> 6076950992 [dir=none]
	6076950992 [label="other
 (1, 2304, 19, 19)" fillcolor=orange]
	6079123744 -> 6076941072 [dir=none]
	6076941072 [label="self
 (1, 2304, 1, 1)" fillcolor=orange]
	6079123744 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6079123408 -> 6079123744
	6079123408 -> 6172350304 [dir=none]
	6172350304 [label="result
 (1, 2304, 1, 1)" fillcolor=orange]
	6079123408 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6079123264 -> 6079123408
	6079123264 -> 6076940512 [dir=none]
	6076940512 [label="input
 (1, 96, 1, 1)" fillcolor=orange]
	6079123264 -> 6076077920 [dir=none]
	6076077920 [label="weight
 (2304, 96, 1, 1)" fillcolor=orange]
	6079123264 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (2304,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078608800 -> 6079123264
	6078608800 [label=SwishImplementationBackward]
	6079119808 -> 6078608800
	6079119808 -> 6076953312 [dir=none]
	6076953312 [label="input
 (1, 2304, 1, 1)" fillcolor=orange]
	6079119808 -> 6076077680 [dir=none]
	6076077680 [label="weight
 (96, 2304, 1, 1)" fillcolor=orange]
	6079119808 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (96,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079119904 -> 6079119808
	6079119904 -> 6076950992 [dir=none]
	6076950992 [label="self
 (1, 2304, 19, 19)" fillcolor=orange]
	6079119904 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 2304, 19, 19)"]
	6078608576 -> 6079119904
	6078608576 [label=SwishImplementationBackward]
	6079121056 -> 6078608576
	6079121056 -> 6076954912 [dir=none]
	6076954912 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6079121056 -> 6172349104 [dir=none]
	6172349104 [label="result1
 (2304)" fillcolor=orange]
	6079121056 -> 6172348944 [dir=none]
	6172348944 [label="result2
 (2304)" fillcolor=orange]
	6079121056 -> 6076075440 [dir=none]
	6076075440 [label="running_mean
 (2304)" fillcolor=orange]
	6079121056 -> 6076077200 [dir=none]
	6076077200 [label="running_var
 (2304)" fillcolor=orange]
	6079121056 -> 6076076960 [dir=none]
	6076076960 [label="weight
 (2304)" fillcolor=orange]
	6079121056 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6079121248 -> 6079121056
	6079121248 -> 6076955872 [dir=none]
	6076955872 [label="input
 (1, 2304, 23, 23)" fillcolor=orange]
	6079121248 -> 6076077040 [dir=none]
	6076077040 [label="weight
 (2304, 1, 5, 5)" fillcolor=orange]
	6079121248 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           2304
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079121776 -> 6079121248
	6079121776 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6078608352 -> 6079121776
	6078608352 [label=SwishImplementationBackward]
	6079122544 -> 6078608352
	6079122544 -> 6076989744 [dir=none]
	6076989744 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6079122544 -> 6172348224 [dir=none]
	6172348224 [label="result1
 (2304)" fillcolor=orange]
	6079122544 -> 6172348064 [dir=none]
	6172348064 [label="result2
 (2304)" fillcolor=orange]
	6079122544 -> 6076076240 [dir=none]
	6076076240 [label="running_mean
 (2304)" fillcolor=orange]
	6079122544 -> 6076076560 [dir=none]
	6076076560 [label="running_var
 (2304)" fillcolor=orange]
	6079122544 -> 6076076400 [dir=none]
	6076076400 [label="weight
 (2304)" fillcolor=orange]
	6079122544 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6079122640 -> 6079122544
	6079122640 -> 6076946272 [dir=none]
	6076946272 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6079122640 -> 6076076320 [dir=none]
	6076076320 [label="weight
 (2304, 384, 1, 1)" fillcolor=orange]
	6079122640 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6079124608 -> 6079122640
	6079124608 [label="AddBackward0
------------
alpha: 1"]
	6076728896 -> 6079124608
	6076728896 -> 6076940352 [dir=none]
	6076940352 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6076728896 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6076730096 -> 6076728896
	6076730096 -> 6172347504 [dir=none]
	6172347504 [label="other
 ()" fillcolor=orange]
	6076730096 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6076730288 -> 6076730096
	6076730288 -> 6076945072 [dir=none]
	6076945072 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6076730288 -> 6172347024 [dir=none]
	6172347024 [label="result1
 (384)" fillcolor=orange]
	6076730288 -> 6172347184 [dir=none]
	6172347184 [label="result2
 (384)" fillcolor=orange]
	6076730288 -> 6076075680 [dir=none]
	6076075680 [label="running_mean
 (384)" fillcolor=orange]
	6076730288 -> 6076076000 [dir=none]
	6076076000 [label="running_var
 (384)" fillcolor=orange]
	6076730288 -> 6076075840 [dir=none]
	6076075840 [label="weight
 (384)" fillcolor=orange]
	6076730288 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6076730816 -> 6076730288
	6076730816 -> 6076953072 [dir=none]
	6076953072 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6076730816 -> 6076075760 [dir=none]
	6076075760 [label="weight
 (384, 2304, 1, 1)" fillcolor=orange]
	6076730816 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6076731440 -> 6076730816
	6076731440 -> 6076989984 [dir=none]
	6076989984 [label="other
 (1, 2304, 19, 19)" fillcolor=orange]
	6076731440 -> 6076989664 [dir=none]
	6076989664 [label="self
 (1, 2304, 1, 1)" fillcolor=orange]
	6076731440 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6076731680 -> 6076731440
	6076731680 -> 6172346944 [dir=none]
	6172346944 [label="result
 (1, 2304, 1, 1)" fillcolor=orange]
	6076731680 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6076731872 -> 6076731680
	6076731872 -> 6076989504 [dir=none]
	6076989504 [label="input
 (1, 96, 1, 1)" fillcolor=orange]
	6076731872 -> 6076075520 [dir=none]
	6076075520 [label="weight
 (2304, 96, 1, 1)" fillcolor=orange]
	6076731872 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (2304,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078608128 -> 6076731872
	6078608128 [label=SwishImplementationBackward]
	6076732832 -> 6078608128
	6076732832 -> 6076990304 [dir=none]
	6076990304 [label="input
 (1, 2304, 1, 1)" fillcolor=orange]
	6076732832 -> 6076075280 [dir=none]
	6076075280 [label="weight
 (96, 2304, 1, 1)" fillcolor=orange]
	6076732832 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (96,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6076732928 -> 6076732832
	6076732928 -> 6076989984 [dir=none]
	6076989984 [label="self
 (1, 2304, 19, 19)" fillcolor=orange]
	6076732928 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 2304, 19, 19)"]
	6078607904 -> 6076732928
	6078607904 [label=SwishImplementationBackward]
	6076734080 -> 6078607904
	6076734080 -> 6076990544 [dir=none]
	6076990544 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6076734080 -> 6172345904 [dir=none]
	6172345904 [label="result1
 (2304)" fillcolor=orange]
	6076734080 -> 6172345744 [dir=none]
	6172345744 [label="result2
 (2304)" fillcolor=orange]
	6076734080 -> 6076072960 [dir=none]
	6076072960 [label="running_mean
 (2304)" fillcolor=orange]
	6076734080 -> 6076074800 [dir=none]
	6076074800 [label="running_var
 (2304)" fillcolor=orange]
	6076734080 -> 6076074560 [dir=none]
	6076074560 [label="weight
 (2304)" fillcolor=orange]
	6076734080 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6076734176 -> 6076734080
	6076734176 -> 6076990704 [dir=none]
	6076990704 [label="input
 (1, 2304, 23, 23)" fillcolor=orange]
	6076734176 -> 6076074640 [dir=none]
	6076074640 [label="weight
 (2304, 1, 5, 5)" fillcolor=orange]
	6076734176 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           2304
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6076734896 -> 6076734176
	6076734896 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6078607680 -> 6076734896
	6078607680 [label=SwishImplementationBackward]
	6076735808 -> 6078607680
	6076735808 -> 6076991744 [dir=none]
	6076991744 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6076735808 -> 6172345024 [dir=none]
	6172345024 [label="result1
 (2304)" fillcolor=orange]
	6076735808 -> 6172344944 [dir=none]
	6172344944 [label="result2
 (2304)" fillcolor=orange]
	6076735808 -> 6076073840 [dir=none]
	6076073840 [label="running_mean
 (2304)" fillcolor=orange]
	6076735808 -> 6076074160 [dir=none]
	6076074160 [label="running_var
 (2304)" fillcolor=orange]
	6076735808 -> 6076074000 [dir=none]
	6076074000 [label="weight
 (2304)" fillcolor=orange]
	6076735808 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6076736240 -> 6076735808
	6076736240 -> 6076990944 [dir=none]
	6076990944 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6076736240 -> 6076073920 [dir=none]
	6076073920 [label="weight
 (2304, 384, 1, 1)" fillcolor=orange]
	6076736240 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6076729616 -> 6076736240
	6076729616 -> 6076991104 [dir=none]
	6076991104 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6076729616 -> 6172345424 [dir=none]
	6172345424 [label="result1
 (384)" fillcolor=orange]
	6076729616 -> 6172345504 [dir=none]
	6172345504 [label="result2
 (384)" fillcolor=orange]
	6076729616 -> 6076073200 [dir=none]
	6076073200 [label="running_mean
 (384)" fillcolor=orange]
	6076729616 -> 6076073520 [dir=none]
	6076073520 [label="running_var
 (384)" fillcolor=orange]
	6076729616 -> 6076073360 [dir=none]
	6076073360 [label="weight
 (384)" fillcolor=orange]
	6076729616 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6076737152 -> 6076729616
	6076737152 -> 6076991344 [dir=none]
	6076991344 [label="input
 (1, 1344, 19, 19)" fillcolor=orange]
	6076737152 -> 6076073280 [dir=none]
	6076073280 [label="weight
 (384, 1344, 1, 1)" fillcolor=orange]
	6076737152 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6076737680 -> 6076737152
	6076737680 -> 6076991904 [dir=none]
	6076991904 [label="other
 (1, 1344, 19, 19)" fillcolor=orange]
	6076737680 -> 6076991664 [dir=none]
	6076991664 [label="self
 (1, 1344, 1, 1)" fillcolor=orange]
	6076737680 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6076737920 -> 6076737680
	6076737920 -> 6172349264 [dir=none]
	6172349264 [label="result
 (1, 1344, 1, 1)" fillcolor=orange]
	6076737920 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6076738448 -> 6076737920
	6076738448 -> 6076991504 [dir=none]
	6076991504 [label="input
 (1, 56, 1, 1)" fillcolor=orange]
	6076738448 -> 6076073040 [dir=none]
	6076073040 [label="weight
 (1344, 56, 1, 1)" fillcolor=orange]
	6076738448 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (1344,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078607456 -> 6076738448
	6078607456 [label=SwishImplementationBackward]
	6076739072 -> 6078607456
	6076739072 -> 6076992064 [dir=none]
	6076992064 [label="input
 (1, 1344, 1, 1)" fillcolor=orange]
	6076739072 -> 6076072800 [dir=none]
	6076072800 [label="weight
 (56, 1344, 1, 1)" fillcolor=orange]
	6076739072 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (56,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6076739504 -> 6076739072
	6076739504 -> 6076991904 [dir=none]
	6076991904 [label="self
 (1, 1344, 19, 19)" fillcolor=orange]
	6076739504 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 1344, 19, 19)"]
	6078607232 -> 6076739504
	6078607232 [label=SwishImplementationBackward]
	6076740416 -> 6078607232
	6076740416 -> 6076992464 [dir=none]
	6076992464 [label="input
 (1, 1344, 19, 19)" fillcolor=orange]
	6076740416 -> 6077252768 [dir=none]
	6077252768 [label="result1
 (1344)" fillcolor=orange]
	6076740416 -> 6077252928 [dir=none]
	6077252928 [label="result2
 (1344)" fillcolor=orange]
	6076740416 -> 6075808272 [dir=none]
	6075808272 [label="running_mean
 (1344)" fillcolor=orange]
	6076740416 -> 6076072320 [dir=none]
	6076072320 [label="running_var
 (1344)" fillcolor=orange]
	6076740416 -> 6076072080 [dir=none]
	6076072080 [label="weight
 (1344)" fillcolor=orange]
	6076740416 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6076740752 -> 6076740416
	6076740752 -> 6076992544 [dir=none]
	6076992544 [label="input
 (1, 1344, 41, 41)" fillcolor=orange]
	6076740752 -> 6076072160 [dir=none]
	6076072160 [label="weight
 (1344, 1, 5, 5)" fillcolor=orange]
	6076740752 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1344
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	6076741472 -> 6076740752
	6076741472 [label="ConstantPadNdBackward0
----------------------
pad: (1, 2, 1, 2)"]
	6078607008 -> 6076741472
	6078607008 [label=SwishImplementationBackward]
	6076742384 -> 6078607008
	6076742384 -> 6076993744 [dir=none]
	6076993744 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6076742384 -> 6077256528 [dir=none]
	6077256528 [label="result1
 (1344)" fillcolor=orange]
	6076742384 -> 6077257168 [dir=none]
	6077257168 [label="result2
 (1344)" fillcolor=orange]
	6076742384 -> 6075809152 [dir=none]
	6075809152 [label="running_mean
 (1344)" fillcolor=orange]
	6076742384 -> 6075809472 [dir=none]
	6075809472 [label="running_var
 (1344)" fillcolor=orange]
	6076742384 -> 6075809312 [dir=none]
	6075809312 [label="weight
 (1344)" fillcolor=orange]
	6076742384 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6076742576 -> 6076742384
	6076742576 -> 6076992944 [dir=none]
	6076992944 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6076742576 -> 6075809232 [dir=none]
	6075809232 [label="weight
 (1344, 224, 1, 1)" fillcolor=orange]
	6076742576 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078662112 -> 6076742576
	6076743200 -> 6076742576
	6075809232 [label="
 (1344, 224, 1, 1)" fillcolor=lightblue]
	6075809232 -> 6076743200
	6076743200 [label=AccumulateGrad]
	6076742192 -> 6076742384
	6075809312 [label="
 (1344)" fillcolor=lightblue]
	6075809312 -> 6076742192
	6076742192 [label=AccumulateGrad]
	6076741856 -> 6076742384
	6075809392 [label="
 (1344)" fillcolor=lightblue]
	6075809392 -> 6076741856
	6076741856 [label=AccumulateGrad]
	6076992304 -> 6078607008
	6076992304 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	6076741424 -> 6076740752
	6076072160 [label="
 (1344, 1, 5, 5)" fillcolor=lightblue]
	6076072160 -> 6076741424
	6076741424 [label=AccumulateGrad]
	6076740704 -> 6076740416
	6076072080 [label="
 (1344)" fillcolor=lightblue]
	6076072080 -> 6076740704
	6076740704 [label=AccumulateGrad]
	6076739696 -> 6076740416
	6076072240 [label="
 (1344)" fillcolor=lightblue]
	6076072240 -> 6076739696
	6076739696 [label=AccumulateGrad]
	6076992144 -> 6078607232
	6076992144 [label="
 (1, 1344, 19, 19)" fillcolor=orange]
	6076739456 -> 6076739072
	6076072800 [label="
 (56, 1344, 1, 1)" fillcolor=lightblue]
	6076072800 -> 6076739456
	6076739456 [label=AccumulateGrad]
	6076738976 -> 6076739072
	6076072880 [label="
 (56)" fillcolor=lightblue]
	6076072880 -> 6076738976
	6076738976 [label=AccumulateGrad]
	6076991984 -> 6078607456
	6076991984 [label="
 (1, 56, 1, 1)" fillcolor=orange]
	6076738544 -> 6076738448
	6076073040 [label="
 (1344, 56, 1, 1)" fillcolor=lightblue]
	6076073040 -> 6076738544
	6076738544 [label=AccumulateGrad]
	6076738736 -> 6076738448
	6076073120 [label="
 (1344)" fillcolor=lightblue]
	6076073120 -> 6076738736
	6076738736 [label=AccumulateGrad]
	6078607232 -> 6076737680
	6076737296 -> 6076737152
	6076073280 [label="
 (384, 1344, 1, 1)" fillcolor=lightblue]
	6076073280 -> 6076737296
	6076737296 [label=AccumulateGrad]
	6076736672 -> 6076729616
	6076073360 [label="
 (384)" fillcolor=lightblue]
	6076073360 -> 6076736672
	6076736672 [label=AccumulateGrad]
	6076736432 -> 6076729616
	6076073440 [label="
 (384)" fillcolor=lightblue]
	6076073440 -> 6076736432
	6076736432 [label=AccumulateGrad]
	6076736960 -> 6076736240
	6076073920 [label="
 (2304, 384, 1, 1)" fillcolor=lightblue]
	6076073920 -> 6076736960
	6076736960 [label=AccumulateGrad]
	6076735856 -> 6076735808
	6076074000 [label="
 (2304)" fillcolor=lightblue]
	6076074000 -> 6076735856
	6076735856 [label=AccumulateGrad]
	6076735280 -> 6076735808
	6076074080 [label="
 (2304)" fillcolor=lightblue]
	6076074080 -> 6076735280
	6076735280 [label=AccumulateGrad]
	6076990784 -> 6078607680
	6076990784 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6076735184 -> 6076734176
	6076074640 [label="
 (2304, 1, 5, 5)" fillcolor=lightblue]
	6076074640 -> 6076735184
	6076735184 [label=AccumulateGrad]
	6076734464 -> 6076734080
	6076074560 [label="
 (2304)" fillcolor=lightblue]
	6076074560 -> 6076734464
	6076734464 [label=AccumulateGrad]
	6076733456 -> 6076734080
	6076074720 [label="
 (2304)" fillcolor=lightblue]
	6076074720 -> 6076733456
	6076733456 [label=AccumulateGrad]
	6076990464 -> 6078607904
	6076990464 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6076733216 -> 6076732832
	6076075280 [label="
 (96, 2304, 1, 1)" fillcolor=lightblue]
	6076075280 -> 6076733216
	6076733216 [label=AccumulateGrad]
	6076732400 -> 6076732832
	6076075360 [label="
 (96)" fillcolor=lightblue]
	6076075360 -> 6076732400
	6076732400 [label=AccumulateGrad]
	6076990144 -> 6078608128
	6076990144 [label="
 (1, 96, 1, 1)" fillcolor=orange]
	6076732208 -> 6076731872
	6076075520 [label="
 (2304, 96, 1, 1)" fillcolor=lightblue]
	6076075520 -> 6076732208
	6076732208 [label=AccumulateGrad]
	6076732160 -> 6076731872
	6076075600 [label="
 (2304)" fillcolor=lightblue]
	6076075600 -> 6076732160
	6076732160 [label=AccumulateGrad]
	6078607904 -> 6076731440
	6076730960 -> 6076730816
	6076075760 [label="
 (384, 2304, 1, 1)" fillcolor=lightblue]
	6076075760 -> 6076730960
	6076730960 [label=AccumulateGrad]
	6076730336 -> 6076730288
	6076075840 [label="
 (384)" fillcolor=lightblue]
	6076075840 -> 6076730336
	6076730336 [label=AccumulateGrad]
	6076729712 -> 6076730288
	6076075920 [label="
 (384)" fillcolor=lightblue]
	6076075920 -> 6076729712
	6076729712 [label=AccumulateGrad]
	6076729616 -> 6079124608
	6076729328 -> 6079122640
	6076076320 [label="
 (2304, 384, 1, 1)" fillcolor=lightblue]
	6076076320 -> 6076729328
	6076729328 [label=AccumulateGrad]
	6079122832 -> 6079122544
	6076076400 [label="
 (2304)" fillcolor=lightblue]
	6076076400 -> 6079122832
	6079122832 [label=AccumulateGrad]
	6079121824 -> 6079122544
	6076076480 [label="
 (2304)" fillcolor=lightblue]
	6076076480 -> 6079121824
	6079121824 [label=AccumulateGrad]
	6076951792 -> 6078608352
	6076951792 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6079121392 -> 6079121248
	6076077040 [label="
 (2304, 1, 5, 5)" fillcolor=lightblue]
	6076077040 -> 6079121392
	6079121392 [label=AccumulateGrad]
	6079120768 -> 6079121056
	6076076960 [label="
 (2304)" fillcolor=lightblue]
	6076076960 -> 6079120768
	6079120768 [label=AccumulateGrad]
	6079120336 -> 6079121056
	6076077120 [label="
 (2304)" fillcolor=lightblue]
	6076077120 -> 6079120336
	6079120336 [label=AccumulateGrad]
	6076946432 -> 6078608576
	6076946432 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6079119520 -> 6079119808
	6076077680 [label="
 (96, 2304, 1, 1)" fillcolor=lightblue]
	6076077680 -> 6079119520
	6079119520 [label=AccumulateGrad]
	6079119424 -> 6079119808
	6076077760 [label="
 (96)" fillcolor=lightblue]
	6076077760 -> 6079119424
	6079119424 [label=AccumulateGrad]
	6076951472 -> 6078608800
	6076951472 [label="
 (1, 96, 1, 1)" fillcolor=orange]
	6079123120 -> 6079123264
	6076077920 [label="
 (2304, 96, 1, 1)" fillcolor=lightblue]
	6076077920 -> 6079123120
	6079123120 [label=AccumulateGrad]
	6079123312 -> 6079123264
	6076078000 [label="
 (2304)" fillcolor=lightblue]
	6076078000 -> 6079123312
	6079123312 [label=AccumulateGrad]
	6078608576 -> 6079123744
	6079123696 -> 6079124032
	6076078160 [label="
 (384, 2304, 1, 1)" fillcolor=lightblue]
	6076078160 -> 6079123696
	6079123696 [label=AccumulateGrad]
	6079123984 -> 6079124176
	6076078240 [label="
 (384)" fillcolor=lightblue]
	6076078240 -> 6079123984
	6079123984 [label=AccumulateGrad]
	6079124464 -> 6079124176
	6076078320 [label="
 (384)" fillcolor=lightblue]
	6076078320 -> 6079124464
	6079124464 [label=AccumulateGrad]
	6079124608 -> 6079128016
	6079124560 -> 6079124848
	6076078800 [label="
 (2304, 384, 1, 1)" fillcolor=lightblue]
	6076078800 -> 6079124560
	6079124560 [label=AccumulateGrad]
	6079125040 -> 6079124992
	6076078880 [label="
 (2304)" fillcolor=lightblue]
	6076078880 -> 6079125040
	6079125040 [label=AccumulateGrad]
	6079125280 -> 6079124992
	6076078960 [label="
 (2304)" fillcolor=lightblue]
	6076078960 -> 6079125280
	6079125280 [label=AccumulateGrad]
	6076955552 -> 6078609024
	6076955552 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6079125424 -> 6079125760
	6076079440 [label="
 (2304, 1, 5, 5)" fillcolor=lightblue]
	6076079440 -> 6079125424
	6079125424 [label=AccumulateGrad]
	6079125712 -> 6079125904
	6076079360 [label="
 (2304)" fillcolor=lightblue]
	6076079360 -> 6079125712
	6079125712 [label=AccumulateGrad]
	6079126192 -> 6079125904
	6076079520 [label="
 (2304)" fillcolor=lightblue]
	6076079520 -> 6079126192
	6079126192 [label=AccumulateGrad]
	6076952272 -> 6078609248
	6076952272 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6079126288 -> 6079126480
	6076080080 [label="
 (96, 2304, 1, 1)" fillcolor=lightblue]
	6076080080 -> 6079126288
	6079126288 [label=AccumulateGrad]
	6079126624 -> 6079126480
	6076080160 [label="
 (96)" fillcolor=lightblue]
	6076080160 -> 6079126624
	6079126624 [label=AccumulateGrad]
	6076945232 -> 6078609472
	6076945232 [label="
 (1, 96, 1, 1)" fillcolor=orange]
	6079126768 -> 6079126912
	6076080320 [label="
 (2304, 96, 1, 1)" fillcolor=lightblue]
	6076080320 -> 6079126768
	6079126768 [label=AccumulateGrad]
	6079126720 -> 6079126912
	6076080400 [label="
 (2304)" fillcolor=lightblue]
	6076080400 -> 6079126720
	6079126720 [label=AccumulateGrad]
	6078609248 -> 6079127152
	6079127344 -> 6079127440
	6076080560 [label="
 (384, 2304, 1, 1)" fillcolor=lightblue]
	6076080560 -> 6079127344
	6079127344 [label=AccumulateGrad]
	6079127632 -> 6079127584
	6076080640 [label="
 (384)" fillcolor=lightblue]
	6076080640 -> 6079127632
	6079127632 [label=AccumulateGrad]
	6079127872 -> 6079127584
	6076080720 [label="
 (384)" fillcolor=lightblue]
	6076080720 -> 6079127872
	6079127872 [label=AccumulateGrad]
	6079128016 -> 6079131664
	6079128208 -> 6079128496
	6076081120 [label="
 (2304, 384, 1, 1)" fillcolor=lightblue]
	6076081120 -> 6079128208
	6079128208 [label=AccumulateGrad]
	6079128448 -> 6079128640
	6076081200 [label="
 (2304)" fillcolor=lightblue]
	6076081200 -> 6079128448
	6079128448 [label=AccumulateGrad]
	6079128928 -> 6079128640
	6076081280 [label="
 (2304)" fillcolor=lightblue]
	6076081280 -> 6079128928
	6079128928 [label=AccumulateGrad]
	6076943392 -> 6078609696
	6076943392 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6079129072 -> 6079129168
	6076081760 [label="
 (2304, 1, 5, 5)" fillcolor=lightblue]
	6076081760 -> 6079129072
	6079129072 [label=AccumulateGrad]
	6079129360 -> 6079129312
	6076081680 [label="
 (2304)" fillcolor=lightblue]
	6076081680 -> 6079129360
	6079129360 [label=AccumulateGrad]
	6079129600 -> 6079129312
	6076081840 [label="
 (2304)" fillcolor=lightblue]
	6076081840 -> 6079129600
	6079129600 [label=AccumulateGrad]
	6076942672 -> 6078609920
	6076942672 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6079129936 -> 6079129888
	6076082320 [label="
 (96, 2304, 1, 1)" fillcolor=lightblue]
	6076082320 -> 6079129936
	6079129936 [label=AccumulateGrad]
	6079130032 -> 6079129888
	6076082400 [label="
 (96)" fillcolor=lightblue]
	6076082400 -> 6079130032
	6079130032 [label=AccumulateGrad]
	6076956352 -> 6078610144
	6076956352 [label="
 (1, 96, 1, 1)" fillcolor=orange]
	6079130176 -> 6079130320
	6076082560 [label="
 (2304, 96, 1, 1)" fillcolor=lightblue]
	6076082560 -> 6079130176
	6079130176 [label=AccumulateGrad]
	6079130368 -> 6079130320
	6076082640 [label="
 (2304)" fillcolor=lightblue]
	6076082640 -> 6079130368
	6079130368 [label=AccumulateGrad]
	6078609920 -> 6079130800
	6079130752 -> 6079131088
	6076082800 [label="
 (384, 2304, 1, 1)" fillcolor=lightblue]
	6076082800 -> 6079130752
	6079130752 [label=AccumulateGrad]
	6079131040 -> 6079131232
	6076082880 [label="
 (384)" fillcolor=lightblue]
	6076082880 -> 6079131040
	6079131040 [label=AccumulateGrad]
	6079131520 -> 6079131232
	6076082960 [label="
 (384)" fillcolor=lightblue]
	6076082960 -> 6079131520
	6079131520 [label=AccumulateGrad]
	6079131664 -> 6079135072
	6079131616 -> 6079131904
	6076083440 [label="
 (2304, 384, 1, 1)" fillcolor=lightblue]
	6076083440 -> 6079131616
	6079131616 [label=AccumulateGrad]
	6079132096 -> 6079132048
	6076083520 [label="
 (2304)" fillcolor=lightblue]
	6076083520 -> 6079132096
	6079132096 [label=AccumulateGrad]
	6079132336 -> 6079132048
	6076083600 [label="
 (2304)" fillcolor=lightblue]
	6076083600 -> 6079132336
	6079132336 [label=AccumulateGrad]
	6076947552 -> 6078610368
	6076947552 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6079132480 -> 6079132816
	6076084080 [label="
 (2304, 1, 5, 5)" fillcolor=lightblue]
	6076084080 -> 6079132480
	6079132480 [label=AccumulateGrad]
	6079132768 -> 6079132960
	6076084000 [label="
 (2304)" fillcolor=lightblue]
	6076084000 -> 6079132768
	6079132768 [label=AccumulateGrad]
	6079133248 -> 6079132960
	6076084160 [label="
 (2304)" fillcolor=lightblue]
	6076084160 -> 6079133248
	6079133248 [label=AccumulateGrad]
	6076946912 -> 6078610592
	6076946912 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6079133344 -> 6079133536
	6076084720 [label="
 (96, 2304, 1, 1)" fillcolor=lightblue]
	6076084720 -> 6079133344
	6079133344 [label=AccumulateGrad]
	6079133680 -> 6079133536
	6076084800 [label="
 (96)" fillcolor=lightblue]
	6076084800 -> 6079133680
	6079133680 [label=AccumulateGrad]
	6076945472 -> 6078610816
	6076945472 [label="
 (1, 96, 1, 1)" fillcolor=orange]
	6079133824 -> 6079133968
	6076084960 [label="
 (2304, 96, 1, 1)" fillcolor=lightblue]
	6076084960 -> 6079133824
	6079133824 [label=AccumulateGrad]
	6079133776 -> 6079133968
	6076085040 [label="
 (2304)" fillcolor=lightblue]
	6076085040 -> 6079133776
	6079133776 [label=AccumulateGrad]
	6078610592 -> 6079134208
	6079134400 -> 6079134496
	6076085200 [label="
 (384, 2304, 1, 1)" fillcolor=lightblue]
	6076085200 -> 6079134400
	6079134400 [label=AccumulateGrad]
	6079134688 -> 6079134640
	6076085280 [label="
 (384)" fillcolor=lightblue]
	6076085280 -> 6079134688
	6079134688 [label=AccumulateGrad]
	6079134928 -> 6079134640
	6076085360 [label="
 (384)" fillcolor=lightblue]
	6076085360 -> 6079134928
	6079134928 [label=AccumulateGrad]
	6079135072 -> 6172429280
	6079135264 -> 6079135552
	6076085760 [label="
 (2304, 384, 1, 1)" fillcolor=lightblue]
	6076085760 -> 6079135264
	6079135264 [label=AccumulateGrad]
	6079135504 -> 6172426544
	6076085840 [label="
 (2304)" fillcolor=lightblue]
	6076085840 -> 6079135504
	6079135504 [label=AccumulateGrad]
	6079135648 -> 6172426544
	6076085920 [label="
 (2304)" fillcolor=lightblue]
	6076085920 -> 6079135648
	6079135648 [label=AccumulateGrad]
	6076956272 -> 6078611040
	6076956272 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6172426688 -> 6172426784
	6076086480 [label="
 (2304, 1, 5, 5)" fillcolor=lightblue]
	6076086480 -> 6172426688
	6172426688 [label=AccumulateGrad]
	6172426976 -> 6172426928
	6076086400 [label="
 (2304)" fillcolor=lightblue]
	6076086400 -> 6172426976
	6172426976 [label=AccumulateGrad]
	6172427216 -> 6172426928
	6076086560 [label="
 (2304)" fillcolor=lightblue]
	6076086560 -> 6172427216
	6172427216 [label=AccumulateGrad]
	6076956192 -> 6079152192
	6076956192 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6172427552 -> 6172427504
	6076087120 [label="
 (96, 2304, 1, 1)" fillcolor=lightblue]
	6076087120 -> 6172427552
	6172427552 [label=AccumulateGrad]
	6172427648 -> 6172427504
	6076087200 [label="
 (96)" fillcolor=lightblue]
	6076087200 -> 6172427648
	6172427648 [label=AccumulateGrad]
	6076955952 -> 6079152416
	6076955952 [label="
 (1, 96, 1, 1)" fillcolor=orange]
	6172427792 -> 6172427936
	6076087360 [label="
 (2304, 96, 1, 1)" fillcolor=lightblue]
	6076087360 -> 6172427792
	6172427792 [label=AccumulateGrad]
	6172427984 -> 6172427936
	6076087440 [label="
 (2304)" fillcolor=lightblue]
	6076087440 -> 6172427984
	6172427984 [label=AccumulateGrad]
	6079152192 -> 6172428416
	6172428368 -> 6172428704
	6076087600 [label="
 (384, 2304, 1, 1)" fillcolor=lightblue]
	6076087600 -> 6172428368
	6172428368 [label=AccumulateGrad]
	6172428656 -> 6172428848
	6076087680 [label="
 (384)" fillcolor=lightblue]
	6076087680 -> 6172428656
	6172428656 [label=AccumulateGrad]
	6172429136 -> 6172428848
	6076087760 [label="
 (384)" fillcolor=lightblue]
	6076087760 -> 6172429136
	6172429136 [label=AccumulateGrad]
	6172429280 -> 6172432688
	6172429232 -> 6172429520
	6076088240 [label="
 (2304, 384, 1, 1)" fillcolor=lightblue]
	6076088240 -> 6172429232
	6172429232 [label=AccumulateGrad]
	6172429712 -> 6172429664
	6076350528 [label="
 (2304)" fillcolor=lightblue]
	6076350528 -> 6172429712
	6172429712 [label=AccumulateGrad]
	6172429952 -> 6172429664
	6076350608 [label="
 (2304)" fillcolor=lightblue]
	6076350608 -> 6172429952
	6172429952 [label=AccumulateGrad]
	6076954112 -> 6079152640
	6076954112 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6172430096 -> 6172430432
	6076351168 [label="
 (2304, 1, 5, 5)" fillcolor=lightblue]
	6076351168 -> 6172430096
	6172430096 [label=AccumulateGrad]
	6172430384 -> 6172430576
	6076351088 [label="
 (2304)" fillcolor=lightblue]
	6076351088 -> 6172430384
	6172430384 [label=AccumulateGrad]
	6172430864 -> 6172430576
	6076351248 [label="
 (2304)" fillcolor=lightblue]
	6076351248 -> 6172430864
	6172430864 [label=AccumulateGrad]
	6076954032 -> 6079152864
	6076954032 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6172430960 -> 6172431152
	6076351808 [label="
 (96, 2304, 1, 1)" fillcolor=lightblue]
	6076351808 -> 6172430960
	6172430960 [label=AccumulateGrad]
	6172431296 -> 6172431152
	6076351888 [label="
 (96)" fillcolor=lightblue]
	6076351888 -> 6172431296
	6172431296 [label=AccumulateGrad]
	6076953712 -> 6079153088
	6076953712 [label="
 (1, 96, 1, 1)" fillcolor=orange]
	6172431440 -> 6172431584
	6076352048 [label="
 (2304, 96, 1, 1)" fillcolor=lightblue]
	6076352048 -> 6172431440
	6172431440 [label=AccumulateGrad]
	6172431392 -> 6172431584
	6076352128 [label="
 (2304)" fillcolor=lightblue]
	6076352128 -> 6172431392
	6172431392 [label=AccumulateGrad]
	6079152864 -> 6172431824
	6172432016 -> 6172432112
	6076352288 [label="
 (384, 2304, 1, 1)" fillcolor=lightblue]
	6076352288 -> 6172432016
	6172432016 [label=AccumulateGrad]
	6172432304 -> 6172432256
	6076352368 [label="
 (384)" fillcolor=lightblue]
	6076352368 -> 6172432304
	6172432304 [label=AccumulateGrad]
	6172432544 -> 6172432256
	6076352448 [label="
 (384)" fillcolor=lightblue]
	6076352448 -> 6172432544
	6172432544 [label=AccumulateGrad]
	6172432688 -> 6172436336
	6172432880 -> 6172433168
	6076352928 [label="
 (2304, 384, 1, 1)" fillcolor=lightblue]
	6076352928 -> 6172432880
	6172432880 [label=AccumulateGrad]
	6172433120 -> 6172433312
	6076353008 [label="
 (2304)" fillcolor=lightblue]
	6076353008 -> 6172433120
	6172433120 [label=AccumulateGrad]
	6172433600 -> 6172433312
	6076353088 [label="
 (2304)" fillcolor=lightblue]
	6076353088 -> 6172433600
	6172433600 [label=AccumulateGrad]
	6076952192 -> 6079153312
	6076952192 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6172433744 -> 6172433840
	6076353648 [label="
 (2304, 1, 5, 5)" fillcolor=lightblue]
	6076353648 -> 6172433744
	6172433744 [label=AccumulateGrad]
	6172434032 -> 6172433984
	6076353568 [label="
 (2304)" fillcolor=lightblue]
	6076353568 -> 6172434032
	6172434032 [label=AccumulateGrad]
	6172434272 -> 6172433984
	6076353728 [label="
 (2304)" fillcolor=lightblue]
	6076353728 -> 6172434272
	6172434272 [label=AccumulateGrad]
	6076952112 -> 6079153536
	6076952112 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6172434608 -> 6172434560
	6076354288 [label="
 (96, 2304, 1, 1)" fillcolor=lightblue]
	6076354288 -> 6172434608
	6172434608 [label=AccumulateGrad]
	6172434704 -> 6172434560
	6076354368 [label="
 (96)" fillcolor=lightblue]
	6076354368 -> 6172434704
	6172434704 [label=AccumulateGrad]
	6076951872 -> 6079153760
	6076951872 [label="
 (1, 96, 1, 1)" fillcolor=orange]
	6172434848 -> 6172434992
	6076354528 [label="
 (2304, 96, 1, 1)" fillcolor=lightblue]
	6076354528 -> 6172434848
	6172434848 [label=AccumulateGrad]
	6172435040 -> 6172434992
	6076354608 [label="
 (2304)" fillcolor=lightblue]
	6076354608 -> 6172435040
	6172435040 [label=AccumulateGrad]
	6079153536 -> 6172435472
	6172435424 -> 6172435760
	6076354768 [label="
 (384, 2304, 1, 1)" fillcolor=lightblue]
	6076354768 -> 6172435424
	6172435424 [label=AccumulateGrad]
	6172435712 -> 6172435904
	6076354848 [label="
 (384)" fillcolor=lightblue]
	6076354848 -> 6172435712
	6172435712 [label=AccumulateGrad]
	6172436192 -> 6172435904
	6076354928 [label="
 (384)" fillcolor=lightblue]
	6076354928 -> 6172436192
	6172436192 [label=AccumulateGrad]
	6172436336 -> 6172441520
	6172436288 -> 6172436576
	6076355408 [label="
 (2304, 384, 1, 1)" fillcolor=lightblue]
	6076355408 -> 6172436288
	6172436288 [label=AccumulateGrad]
	6172436768 -> 6172436720
	6076355488 [label="
 (2304)" fillcolor=lightblue]
	6076355488 -> 6172436768
	6172436768 [label=AccumulateGrad]
	6172437008 -> 6172436720
	6076355568 [label="
 (2304)" fillcolor=lightblue]
	6076355568 -> 6172437008
	6172437008 [label=AccumulateGrad]
	6076950352 -> 6079153984
	6076950352 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6172437152 -> 6172437488
	6076356128 [label="
 (2304, 1, 5, 5)" fillcolor=lightblue]
	6076356128 -> 6172437152
	6172437152 [label=AccumulateGrad]
	6172437440 -> 6172437632
	6076356048 [label="
 (2304)" fillcolor=lightblue]
	6076356048 -> 6172437440
	6172437440 [label=AccumulateGrad]
	6172437920 -> 6172437632
	6076356208 [label="
 (2304)" fillcolor=lightblue]
	6076356208 -> 6172437920
	6172437920 [label=AccumulateGrad]
	6076950192 -> 6079154208
	6076950192 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6172438016 -> 6172438208
	6076356768 [label="
 (96, 2304, 1, 1)" fillcolor=lightblue]
	6076356768 -> 6172438016
	6172438016 [label=AccumulateGrad]
	6172438352 -> 6172438208
	6076356848 [label="
 (96)" fillcolor=lightblue]
	6076356848 -> 6172438352
	6172438352 [label=AccumulateGrad]
	6076949792 -> 6079154432
	6076949792 [label="
 (1, 96, 1, 1)" fillcolor=orange]
	6172438496 -> 6172438640
	6076357008 [label="
 (2304, 96, 1, 1)" fillcolor=lightblue]
	6076357008 -> 6172438496
	6172438496 [label=AccumulateGrad]
	6172438448 -> 6172438640
	6076357088 [label="
 (2304)" fillcolor=lightblue]
	6076357088 -> 6172438448
	6172438448 [label=AccumulateGrad]
	6079154208 -> 6172438880
	6172438928 -> 6172439456
	6076357248 [label="
 (384, 2304, 1, 1)" fillcolor=lightblue]
	6076357248 -> 6172438928
	6172438928 [label=AccumulateGrad]
	6172439168 -> 6172439888
	6076357328 [label="
 (384)" fillcolor=lightblue]
	6076357328 -> 6172439168
	6172439168 [label=AccumulateGrad]
	6172440656 -> 6172439888
	6076357408 [label="
 (384)" fillcolor=lightblue]
	6076357408 -> 6172440656
	6172440656 [label=AccumulateGrad]
	6172441520 -> 6172532720
	6172441376 -> 6172442048
	6076357888 [label="
 (2304, 384, 1, 1)" fillcolor=lightblue]
	6076357888 -> 6172441376
	6172441376 [label=AccumulateGrad]
	6172442528 -> 6172524656
	6076357968 [label="
 (2304)" fillcolor=lightblue]
	6076357968 -> 6172442528
	6172442528 [label=AccumulateGrad]
	6172442192 -> 6172524656
	6076358048 [label="
 (2304)" fillcolor=lightblue]
	6076358048 -> 6172442192
	6172442192 [label=AccumulateGrad]
	6076948112 -> 6079154656
	6076948112 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6172525664 -> 6172526384
	6076358608 [label="
 (2304, 1, 5, 5)" fillcolor=lightblue]
	6076358608 -> 6172525664
	6172525664 [label=AccumulateGrad]
	6172526480 -> 6172526816
	6076358528 [label="
 (2304)" fillcolor=lightblue]
	6076358528 -> 6172526480
	6172526480 [label=AccumulateGrad]
	6172527056 -> 6172526816
	6076358688 [label="
 (2304)" fillcolor=lightblue]
	6076358688 -> 6172527056
	6172527056 [label=AccumulateGrad]
	6076947952 -> 6079154880
	6076947952 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6172528112 -> 6172527824
	6076359248 [label="
 (96, 2304, 1, 1)" fillcolor=lightblue]
	6076359248 -> 6172528112
	6172528112 [label=AccumulateGrad]
	6172528496 -> 6172527824
	6076359328 [label="
 (96)" fillcolor=lightblue]
	6076359328 -> 6172528496
	6172528496 [label=AccumulateGrad]
	6076947712 -> 6079155104
	6076947712 [label="
 (1, 96, 1, 1)" fillcolor=orange]
	6172528976 -> 6172529360
	6076359488 [label="
 (2304, 96, 1, 1)" fillcolor=lightblue]
	6076359488 -> 6172528976
	6172528976 [label=AccumulateGrad]
	6172529072 -> 6172529360
	6076359568 [label="
 (2304)" fillcolor=lightblue]
	6076359568 -> 6172529072
	6172529072 [label=AccumulateGrad]
	6079154880 -> 6172530416
	6172531280 -> 6172531088
	6076359728 [label="
 (384, 2304, 1, 1)" fillcolor=lightblue]
	6076359728 -> 6172531280
	6172531280 [label=AccumulateGrad]
	6172531712 -> 6172531520
	6076359808 [label="
 (384)" fillcolor=lightblue]
	6076359808 -> 6172531712
	6172531712 [label=AccumulateGrad]
	6172532432 -> 6172531520
	6076359888 [label="
 (384)" fillcolor=lightblue]
	6076359888 -> 6172532432
	6172532432 [label=AccumulateGrad]
	6172532720 -> 6172607536
	6172533008 -> 6172533872
	6076360368 [label="
 (2304, 384, 1, 1)" fillcolor=lightblue]
	6076360368 -> 6172533008
	6172533008 [label=AccumulateGrad]
	6172533824 -> 6172534688
	6076360448 [label="
 (2304)" fillcolor=lightblue]
	6076360448 -> 6172533824
	6172533824 [label=AccumulateGrad]
	6172535120 -> 6172534688
	6076360528 [label="
 (2304)" fillcolor=lightblue]
	6076360528 -> 6172535120
	6172535120 [label=AccumulateGrad]
	6076946032 -> 6079155328
	6076946032 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6172534880 -> 6172535840
	6076361088 [label="
 (2304, 1, 5, 5)" fillcolor=lightblue]
	6076361088 -> 6172534880
	6172534880 [label=AccumulateGrad]
	6172536032 -> 6172536128
	6076361008 [label="
 (2304)" fillcolor=lightblue]
	6076361008 -> 6172536032
	6172536032 [label=AccumulateGrad]
	6172537184 -> 6172536128
	6076361168 [label="
 (2304)" fillcolor=lightblue]
	6076361168 -> 6172537184
	6172537184 [label=AccumulateGrad]
	6076945792 -> 6079155552
	6076945792 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6172538336 -> 6172537904
	6076361728 [label="
 (96, 2304, 1, 1)" fillcolor=lightblue]
	6076361728 -> 6172538336
	6172538336 [label=AccumulateGrad]
	6172538144 -> 6172537904
	6076361808 [label="
 (96)" fillcolor=lightblue]
	6076361808 -> 6172538144
	6172538144 [label=AccumulateGrad]
	6076945552 -> 6079155776
	6076945552 [label="
 (1, 96, 1, 1)" fillcolor=orange]
	6172538576 -> 6172539008
	6076361968 [label="
 (2304, 96, 1, 1)" fillcolor=lightblue]
	6076361968 -> 6172538576
	6172538576 [label=AccumulateGrad]
	6172538288 -> 6172539008
	6076362048 [label="
 (2304)" fillcolor=lightblue]
	6076362048 -> 6172538288
	6172538288 [label=AccumulateGrad]
	6079155552 -> 6172540064
	6172540640 -> 6172606528
	6076362208 [label="
 (384, 2304, 1, 1)" fillcolor=lightblue]
	6076362208 -> 6172540640
	6172540640 [label=AccumulateGrad]
	6172607776 -> 6172607344
	6076362288 [label="
 (384)" fillcolor=lightblue]
	6076362288 -> 6172607776
	6172607776 [label=AccumulateGrad]
	6172540880 -> 6172607344
	6076362368 [label="
 (384)" fillcolor=lightblue]
	6076362368 -> 6172540880
	6172540880 [label=AccumulateGrad]
	6172607536 -> 6172617616
	6172608256 -> 6172608784
	6076362848 [label="
 (2304, 384, 1, 1)" fillcolor=lightblue]
	6076362848 -> 6172608256
	6172608256 [label=AccumulateGrad]
	6172609072 -> 6172609648
	6076362928 [label="
 (2304)" fillcolor=lightblue]
	6076362928 -> 6172609072
	6172609072 [label=AccumulateGrad]
	6172610128 -> 6172609648
	6076363008 [label="
 (2304)" fillcolor=lightblue]
	6076363008 -> 6172610128
	6172610128 [label=AccumulateGrad]
	6076943792 -> 6079156000
	6076943792 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6172610560 -> 6172611424
	6076363568 [label="
 (2304, 1, 5, 5)" fillcolor=lightblue]
	6076363568 -> 6172610560
	6172610560 [label=AccumulateGrad]
	6172611232 -> 6172610944
	6076363488 [label="
 (2304)" fillcolor=lightblue]
	6076363488 -> 6172611232
	6172611232 [label=AccumulateGrad]
	6172612096 -> 6172610944
	6076363648 [label="
 (2304)" fillcolor=lightblue]
	6076363648 -> 6172612096
	6172612096 [label=AccumulateGrad]
	6076943632 -> 6079156224
	6076943632 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6172613296 -> 6172613152
	6076364208 [label="
 (96, 2304, 1, 1)" fillcolor=lightblue]
	6076364208 -> 6172613296
	6172613296 [label=AccumulateGrad]
	6172613584 -> 6172613152
	6076364288 [label="
 (96)" fillcolor=lightblue]
	6076364288 -> 6172613584
	6172613584 [label=AccumulateGrad]
	6076943312 -> 6079156448
	6076943312 [label="
 (1, 96, 1, 1)" fillcolor=orange]
	6172614400 -> 6172613824
	6076364448 [label="
 (2304, 96, 1, 1)" fillcolor=lightblue]
	6076364448 -> 6172614400
	6172614400 [label=AccumulateGrad]
	6172613968 -> 6172613824
	6076364528 [label="
 (2304)" fillcolor=lightblue]
	6076364528 -> 6172613968
	6172613968 [label=AccumulateGrad]
	6079156224 -> 6172615312
	6172615264 -> 6172615840
	6076364688 [label="
 (384, 2304, 1, 1)" fillcolor=lightblue]
	6076364688 -> 6172615264
	6172615264 [label=AccumulateGrad]
	6172616128 -> 6172616704
	6076364768 [label="
 (384)" fillcolor=lightblue]
	6076364768 -> 6172616128
	6172616128 [label=AccumulateGrad]
	6172617184 -> 6172616704
	6076364848 [label="
 (384)" fillcolor=lightblue]
	6076364848 -> 6172617184
	6172617184 [label=AccumulateGrad]
	6172617616 -> 6172617856
	6172618480 -> 6172618720
	6076365328 [label="
 (2304, 384, 1, 1)" fillcolor=lightblue]
	6076365328 -> 6172618480
	6172618480 [label=AccumulateGrad]
	6172618912 -> 6172619200
	6076365408 [label="
 (2304)" fillcolor=lightblue]
	6076365408 -> 6172618912
	6172618912 [label=AccumulateGrad]
	6172620352 -> 6172619200
	6076365488 [label="
 (2304)" fillcolor=lightblue]
	6076365488 -> 6172620352
	6172620352 [label=AccumulateGrad]
	6076941712 -> 6079156672
	6076941712 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6172620304 -> 6172621312
	6076366048 [label="
 (2304, 1, 3, 3)" fillcolor=lightblue]
	6076366048 -> 6172620304
	6172620304 [label=AccumulateGrad]
	6172621024 -> 6172620880
	6076365968 [label="
 (2304)" fillcolor=lightblue]
	6076365968 -> 6172621024
	6172621024 [label=AccumulateGrad]
	6172621600 -> 6172620880
	6076366128 [label="
 (2304)" fillcolor=lightblue]
	6076366128 -> 6172621600
	6172621600 [label=AccumulateGrad]
	6076941632 -> 6079156896
	6076941632 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6172622512 -> 6172704928
	6076366688 [label="
 (96, 2304, 1, 1)" fillcolor=lightblue]
	6076366688 -> 6172622512
	6172622512 [label=AccumulateGrad]
	6172622800 -> 6172704928
	6076366768 [label="
 (96)" fillcolor=lightblue]
	6076366768 -> 6172622800
	6172622800 [label=AccumulateGrad]
	6076941392 -> 6079157120
	6076941392 [label="
 (1, 96, 1, 1)" fillcolor=orange]
	6172705792 -> 6172706224
	6076629136 [label="
 (2304, 96, 1, 1)" fillcolor=lightblue]
	6076629136 -> 6172705792
	6172705792 [label=AccumulateGrad]
	6172706176 -> 6172706224
	6076629216 [label="
 (2304)" fillcolor=lightblue]
	6076629216 -> 6172706176
	6172706176 [label=AccumulateGrad]
	6079156896 -> 6172706608
	6172707328 -> 6172707760
	6076629376 [label="
 (640, 2304, 1, 1)" fillcolor=lightblue]
	6076629376 -> 6172707328
	6172707328 [label=AccumulateGrad]
	6172708096 -> 6172718176
	6076629456 [label="
 (640)" fillcolor=lightblue]
	6076629456 -> 6172708096
	6172708096 [label=AccumulateGrad]
	6172708816 -> 6172718176
	6076629536 [label="
 (640)" fillcolor=lightblue]
	6076629536 -> 6172708816
	6172708816 [label=AccumulateGrad]
	6172708384 -> 6172709248
	6076630016 [label="
 (3840, 640, 1, 1)" fillcolor=lightblue]
	6076630016 -> 6172708384
	6172708384 [label=AccumulateGrad]
	6172709200 -> 6172710064
	6076630096 [label="
 (3840)" fillcolor=lightblue]
	6076630096 -> 6172709200
	6172709200 [label=AccumulateGrad]
	6172710496 -> 6172710064
	6076630176 [label="
 (3840)" fillcolor=lightblue]
	6076630176 -> 6172710496
	6172710496 [label=AccumulateGrad]
	6042180704 -> 6079157344
	6042180704 [label="
 (1, 3840, 19, 19)" fillcolor=orange]
	6172710256 -> 6172711216
	6076630736 [label="
 (3840, 1, 3, 3)" fillcolor=lightblue]
	6076630736 -> 6172710256
	6172710256 [label=AccumulateGrad]
	6172711408 -> 6172711504
	6076630656 [label="
 (3840)" fillcolor=lightblue]
	6076630656 -> 6172711408
	6172711408 [label=AccumulateGrad]
	6172712560 -> 6172711504
	6076630816 [label="
 (3840)" fillcolor=lightblue]
	6076630816 -> 6172712560
	6172712560 [label=AccumulateGrad]
	6076889776 -> 6079157568
	6076889776 [label="
 (1, 3840, 19, 19)" fillcolor=orange]
	6172713712 -> 6172713280
	6076631296 [label="
 (160, 3840, 1, 1)" fillcolor=lightblue]
	6076631296 -> 6172713712
	6172713712 [label=AccumulateGrad]
	6172713520 -> 6172713280
	6076631376 [label="
 (160)" fillcolor=lightblue]
	6076631376 -> 6172713520
	6172713520 [label=AccumulateGrad]
	6076882576 -> 6079157792
	6076882576 [label="
 (1, 160, 1, 1)" fillcolor=orange]
	6172713952 -> 6172714384
	6076631536 [label="
 (3840, 160, 1, 1)" fillcolor=lightblue]
	6076631536 -> 6172713952
	6172713952 [label=AccumulateGrad]
	6172713664 -> 6172714384
	6076631616 [label="
 (3840)" fillcolor=lightblue]
	6076631616 -> 6172713664
	6172713664 [label=AccumulateGrad]
	6079157568 -> 6172715440
	6172716016 -> 6172716304
	6076631776 [label="
 (640, 3840, 1, 1)" fillcolor=lightblue]
	6076631776 -> 6172716016
	6172716016 [label=AccumulateGrad]
	6172716256 -> 6172717888
	6076631856 [label="
 (640)" fillcolor=lightblue]
	6076631856 -> 6172716256
	6172716256 [label=AccumulateGrad]
	6172719184 -> 6172717888
	6076631936 [label="
 (640)" fillcolor=lightblue]
	6076631936 -> 6172719184
	6172719184 [label=AccumulateGrad]
	6172718176 -> 6078837328
	6172720192 -> 11670913808
	6076632256 [label="
 (3840, 640, 1, 1)" fillcolor=lightblue]
	6076632256 -> 6172720192
	6172720192 [label=AccumulateGrad]
	11670914720 -> 11670916400
	6076632336 [label="
 (3840)" fillcolor=lightblue]
	6076632336 -> 11670914720
	11670914720 [label=AccumulateGrad]
	11670917168 -> 11670916400
	6076632416 [label="
 (3840)" fillcolor=lightblue]
	6076632416 -> 11670917168
	11670917168 [label=AccumulateGrad]
	6076882336 -> 6079158016
	6076882336 [label="
 (1, 3840, 19, 19)" fillcolor=orange]
	11670918128 -> 11670920576
	6076632976 [label="
 (3840, 1, 3, 3)" fillcolor=lightblue]
	6076632976 -> 11670918128
	11670918128 [label=AccumulateGrad]
	11670920048 -> 11670919568
	6076632896 [label="
 (3840)" fillcolor=lightblue]
	6076632896 -> 11670920048
	11670920048 [label=AccumulateGrad]
	11670922736 -> 11670919568
	6076633056 [label="
 (3840)" fillcolor=lightblue]
	6076633056 -> 11670922736
	11670922736 [label=AccumulateGrad]
	6076882176 -> 6079158240
	6076882176 [label="
 (1, 3840, 19, 19)" fillcolor=orange]
	11670927344 -> 11670929264
	6076633616 [label="
 (160, 3840, 1, 1)" fillcolor=lightblue]
	6076633616 -> 11670927344
	11670927344 [label=AccumulateGrad]
	11670925472 -> 11670929264
	6076633696 [label="
 (160)" fillcolor=lightblue]
	6076633696 -> 11670925472
	11670925472 [label=AccumulateGrad]
	6076877696 -> 6079158464
	6076877696 [label="
 (1, 160, 1, 1)" fillcolor=orange]
	11670923888 -> 11670925232
	6076633856 [label="
 (3840, 160, 1, 1)" fillcolor=lightblue]
	6076633856 -> 11670923888
	11670923888 [label=AccumulateGrad]
	11670924608 -> 11670925232
	6076633936 [label="
 (3840)" fillcolor=lightblue]
	6076633936 -> 11670924608
	11670924608 [label=AccumulateGrad]
	6079158240 -> 6078944624
	6078943328 -> 6078940976
	6076634096 [label="
 (640, 3840, 1, 1)" fillcolor=lightblue]
	6076634096 -> 6078943328
	6078943328 [label=AccumulateGrad]
	6078940064 -> 6078838960
	6076634176 [label="
 (640)" fillcolor=lightblue]
	6076634176 -> 6078940064
	6078940064 [label=AccumulateGrad]
	6078947168 -> 6078838960
	6076634256 [label="
 (640)" fillcolor=lightblue]
	6076634256 -> 6078947168
	6078947168 [label=AccumulateGrad]
	6078837328 -> 6078667344
	6078839728 -> 6078834784
	6076634656 [label="
 (3840, 640, 1, 1)" fillcolor=lightblue]
	6076634656 -> 6078839728
	6078839728 [label=AccumulateGrad]
	6078832144 -> 6078832432
	6076634736 [label="
 (3840)" fillcolor=lightblue]
	6076634736 -> 6078832144
	6078832144 [label=AccumulateGrad]
	6078828256 -> 6078832432
	6076634816 [label="
 (3840)" fillcolor=lightblue]
	6076634816 -> 6078828256
	6078828256 [label=AccumulateGrad]
	6076881216 -> 6079158688
	6076881216 [label="
 (1, 3840, 19, 19)" fillcolor=orange]
	6078827152 -> 6078789328
	6076635376 [label="
 (3840, 1, 3, 3)" fillcolor=lightblue]
	6076635376 -> 6078827152
	6078827152 [label=AccumulateGrad]
	6078787312 -> 6078789856
	6076635296 [label="
 (3840)" fillcolor=lightblue]
	6076635296 -> 6078787312
	6078787312 [label=AccumulateGrad]
	6078824656 -> 6078789856
	6076635456 [label="
 (3840)" fillcolor=lightblue]
	6076635456 -> 6078824656
	6078824656 [label=AccumulateGrad]
	6076878576 -> 6079158912
	6076878576 [label="
 (1, 3840, 19, 19)" fillcolor=orange]
	6078784336 -> 6078783568
	6076636016 [label="
 (160, 3840, 1, 1)" fillcolor=lightblue]
	6076636016 -> 6078784336
	6078784336 [label=AccumulateGrad]
	6078782704 -> 6078783568
	6076636096 [label="
 (160)" fillcolor=lightblue]
	6076636096 -> 6078782704
	6078782704 [label=AccumulateGrad]
	6076876496 -> 6079159136
	6076876496 [label="
 (1, 160, 1, 1)" fillcolor=orange]
	6078780016 -> 6078782320
	6076636256 [label="
 (3840, 160, 1, 1)" fillcolor=lightblue]
	6076636256 -> 6078780016
	6078780016 [label=AccumulateGrad]
	6078779008 -> 6078782320
	6076636336 [label="
 (3840)" fillcolor=lightblue]
	6076636336 -> 6078779008
	6078779008 [label=AccumulateGrad]
	6079158912 -> 6078676512
	6078674592 -> 6078676464
	6076636496 [label="
 (640, 3840, 1, 1)" fillcolor=lightblue]
	6076636496 -> 6078674592
	6078674592 [label=AccumulateGrad]
	6078673392 -> 6078672144
	6076636576 [label="
 (640)" fillcolor=lightblue]
	6076636576 -> 6078673392
	6078673392 [label=AccumulateGrad]
	6078669552 -> 6078672144
	6076636656 [label="
 (640)" fillcolor=lightblue]
	6076636656 -> 6078669552
	6078669552 [label=AccumulateGrad]
	6078667344 -> 6078666336
	6078665424 -> 6078664608
	6077460976 [label="
 (256, 640, 1, 1)" fillcolor=lightblue]
	6077460976 -> 6078665424
	6078665424 [label=AccumulateGrad]
	6078661824 -> 6078664608
	6077460816 [label="
 (256)" fillcolor=lightblue]
	6077460816 -> 6078661824
	6078661824 [label=AccumulateGrad]
	6077545632 -> 6077545392
	6077449616 [label="
 (256, 256, 3, 3)" fillcolor=lightblue]
	6077449616 -> 6077545632
	6077545632 [label=AccumulateGrad]
	6077545344 -> 6077545392
	6077460496 [label="
 (256)" fillcolor=lightblue]
	6077460496 -> 6077545344
	6077545344 [label=AccumulateGrad]
	6077545104 -> 6077544864
	6077459696 [label="
 (256)" fillcolor=lightblue]
	6077459696 -> 6077545104
	6077545104 [label=AccumulateGrad]
	6077544912 -> 6077544864
	6077459536 [label="
 (256)" fillcolor=lightblue]
	6077459536 -> 6077544912
	6077544912 [label=AccumulateGrad]
	6077544384 -> 6077544144
	6077451216 [label="
 (256, 256, 3, 3)" fillcolor=lightblue]
	6077451216 -> 6077544384
	6077544384 [label=AccumulateGrad]
	6077544288 -> 6077544144
	6077449376 [label="
 (256)" fillcolor=lightblue]
	6077449376 -> 6077544288
	6077544288 [label=AccumulateGrad]
	6077544240 -> 6077543856
	6077449136 [label="
 (256)" fillcolor=lightblue]
	6077449136 -> 6077544240
	6077544240 [label=AccumulateGrad]
	6077543904 -> 6077543856
	6077462416 [label="
 (256)" fillcolor=lightblue]
	6077462416 -> 6077543904
	6077543904 [label=AccumulateGrad]
	6077543424 -> 6077542992
	6077455216 [label="
 (256, 256, 3, 3)" fillcolor=lightblue]
	6077455216 -> 6077543424
	6077543424 [label=AccumulateGrad]
	6077543184 -> 6077542992
	6077454176 [label="
 (256)" fillcolor=lightblue]
	6077454176 -> 6077543184
	6077543184 [label=AccumulateGrad]
	6077542752 -> 6077542656
	6077453696 [label="
 (256)" fillcolor=lightblue]
	6077453696 -> 6077542752
	6077542752 [label=AccumulateGrad]
	6077542416 -> 6077542656
	6077453456 [label="
 (256)" fillcolor=lightblue]
	6077453456 -> 6077542416
	6077542416 [label=AccumulateGrad]
	6077542368 -> 6077542272
	6077464096 [label="
 (1024, 256, 3, 3)" fillcolor=lightblue]
	6077464096 -> 6077542368
	6077542368 [label=AccumulateGrad]
	6077541888 -> 6077542272
	6077463936 [label="
 (1024)" fillcolor=lightblue]
	6077463936 -> 6077541888
	6077541888 [label=AccumulateGrad]
	6077541600 -> 6077541360
	6077541600 -> 6171779664 [dir=none]
	6171779664 [label="result
 (1, 256, 150, 150)" fillcolor=orange]
	6077541600 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	6077542800 -> 6077541600
	6077542800 -> 6076877136 [dir=none]
	6076877136 [label="input
 (1, 256, 150, 150)" fillcolor=orange]
	6077542800 -> 6171779904 [dir=none]
	6171779904 [label="result1
 (256)" fillcolor=orange]
	6077542800 -> 6171779984 [dir=none]
	6171779984 [label="result2
 (256)" fillcolor=orange]
	6077542800 -> 6077454976 [dir=none]
	6077454976 [label="running_mean
 (256)" fillcolor=orange]
	6077542800 -> 6077448496 [dir=none]
	6077448496 [label="running_var
 (256)" fillcolor=orange]
	6077542800 -> 6077450496 [dir=none]
	6077450496 [label="weight
 (256)" fillcolor=orange]
	6077542800 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6077543616 -> 6077542800
	6077543616 -> 6076878176 [dir=none]
	6076878176 [label="input
 (1, 256, 150, 150)" fillcolor=orange]
	6077543616 -> 6077454496 [dir=none]
	6077454496 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	6077543616 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (256,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6077545152 -> 6077543616
	6077545152 -> 6171780304 [dir=none]
	6171780304 [label="result
 (1, 256, 150, 150)" fillcolor=orange]
	6077545152 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	6077545680 -> 6077545152
	6077545680 -> 6076878416 [dir=none]
	6076878416 [label="input
 (1, 256, 150, 150)" fillcolor=orange]
	6077545680 -> 6171780464 [dir=none]
	6171780464 [label="result1
 (256)" fillcolor=orange]
	6077545680 -> 6171780544 [dir=none]
	6171780544 [label="result2
 (256)" fillcolor=orange]
	6077545680 -> 6077457936 [dir=none]
	6077457936 [label="running_mean
 (256)" fillcolor=orange]
	6077545680 -> 6077456336 [dir=none]
	6077456336 [label="running_var
 (256)" fillcolor=orange]
	6077545680 -> 6077456656 [dir=none]
	6077456656 [label="weight
 (256)" fillcolor=orange]
	6077545680 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078662928 -> 6077545680
	6078662928 -> 6076879536 [dir=none]
	6076879536 [label="input
 (1, 256, 150, 150)" fillcolor=orange]
	6078662928 -> 6077457616 [dir=none]
	6077457616 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	6078662928 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (256,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078671952 -> 6078662928
	6078671952 -> 6171780864 [dir=none]
	6171780864 [label="result
 (1, 256, 150, 150)" fillcolor=orange]
	6078671952 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	6078778960 -> 6078671952
	6078778960 -> 6076880736 [dir=none]
	6076880736 [label="input
 (1, 256, 150, 150)" fillcolor=orange]
	6078778960 -> 6171780944 [dir=none]
	6171780944 [label="result1
 (256)" fillcolor=orange]
	6078778960 -> 6171781024 [dir=none]
	6171781024 [label="result2
 (256)" fillcolor=orange]
	6078778960 -> 6077451056 [dir=none]
	6077451056 [label="running_mean
 (256)" fillcolor=orange]
	6078778960 -> 6077460896 [dir=none]
	6077460896 [label="running_var
 (256)" fillcolor=orange]
	6078778960 -> 6077463216 [dir=none]
	6077463216 [label="weight
 (256)" fillcolor=orange]
	6078778960 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6078783808 -> 6078778960
	6078783808 -> 6076877936 [dir=none]
	6076877936 [label="input
 (1, 256, 150, 150)" fillcolor=orange]
	6078783808 -> 6077450336 [dir=none]
	6077450336 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	6078783808 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (256,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078790336 -> 6078783808
	6078790336 [label="AddBackward0
------------
alpha: 1"]
	6078830320 -> 6078790336
	6078830320 -> 6077343648 [dir=none]
	6077343648 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	6078830320 -> 6077459456 [dir=none]
	6077459456 [label="weight
 (256, 48, 1, 1)" fillcolor=orange]
	6078830320 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (256,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6078826144 -> 6078830320
	6078836704 -> 6078830320
	6077459456 [label="
 (256, 48, 1, 1)" fillcolor=lightblue]
	6077459456 -> 6078836704
	6078836704 [label=AccumulateGrad]
	6078838720 -> 6078830320
	6077459136 [label="
 (256)" fillcolor=lightblue]
	6077459136 -> 6078838720
	6078838720 [label=AccumulateGrad]
	6078831712 -> 6078790336
	6078831712 [label="UpsampleNearest2DBackward0
--------------------------------
output_size   :       (150, 150)
scales_h      :             None
scales_w      :             None
self_sym_sizes: (1, 256, 75, 75)"]
	6077545536 -> 6078831712
	6078788800 -> 6078783808
	6077450336 [label="
 (256, 256, 3, 3)" fillcolor=lightblue]
	6077450336 -> 6078788800
	6078788800 [label=AccumulateGrad]
	6078825184 -> 6078783808
	6077449856 [label="
 (256)" fillcolor=lightblue]
	6077449856 -> 6078825184
	6078825184 [label=AccumulateGrad]
	6078776128 -> 6078778960
	6077463216 [label="
 (256)" fillcolor=lightblue]
	6077463216 -> 6078776128
	6078776128 [label=AccumulateGrad]
	6078776944 -> 6078778960
	6077461696 [label="
 (256)" fillcolor=lightblue]
	6077461696 -> 6078776944
	6078776944 [label=AccumulateGrad]
	6078670704 -> 6078662928
	6077457616 [label="
 (256, 256, 3, 3)" fillcolor=lightblue]
	6077457616 -> 6078670704
	6078670704 [label=AccumulateGrad]
	6078669936 -> 6078662928
	6077457136 [label="
 (256)" fillcolor=lightblue]
	6077457136 -> 6078669936
	6078669936 [label=AccumulateGrad]
	6078660768 -> 6077545680
	6077456656 [label="
 (256)" fillcolor=lightblue]
	6077456656 -> 6078660768
	6078660768 [label=AccumulateGrad]
	6078674640 -> 6077545680
	6077456496 [label="
 (256)" fillcolor=lightblue]
	6077456496 -> 6078674640
	6078674640 [label=AccumulateGrad]
	6077544672 -> 6077543616
	6077454496 [label="
 (256, 256, 3, 3)" fillcolor=lightblue]
	6077454496 -> 6077544672
	6077544672 [label=AccumulateGrad]
	6077544432 -> 6077543616
	6077451856 [label="
 (256)" fillcolor=lightblue]
	6077451856 -> 6077544432
	6077544432 [label=AccumulateGrad]
	6077543040 -> 6077542800
	6077450496 [label="
 (256)" fillcolor=lightblue]
	6077450496 -> 6077543040
	6077543040 [label=AccumulateGrad]
	6077542080 -> 6077542800
	6077448816 [label="
 (256)" fillcolor=lightblue]
	6077448816 -> 6077542080
	6077542080 [label=AccumulateGrad]
	6077541120 -> 6077540832
	6077541120 -> 6077349808 [dir=none]
	6077349808 [label="input
 (1, 32, 300, 300)" fillcolor=orange]
	6077541120 -> 6077463696 [dir=none]
	6077463696 [label="weight
 (256, 32, 1, 1)" fillcolor=orange]
	6077541120 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (256,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11670920432 -> 6077541120
	6077542608 -> 6077541120
	6077463696 [label="
 (256, 32, 1, 1)" fillcolor=lightblue]
	6077463696 -> 6077542608
	6077542608 [label=AccumulateGrad]
	6077541408 -> 6077541120
	6077463376 [label="
 (256)" fillcolor=lightblue]
	6077463376 -> 6077541408
	6077541408 [label=AccumulateGrad]
	6077540592 -> 6077540640
	6077540592 [label="UnsqueezeBackward0
------------------
dim: 2"]
	6077541648 -> 6077540592
	6077541648 [label="SliceBackward0
-----------------------------------
dim           :                   1
end           : 9223372036854775807
self_sym_sizes:            (1, 256)
start         :                   0
step          :                   1"]
	6077545920 -> 6077541648
	6077545920 [label="UnsqueezeBackward0
------------------
dim: 0"]
	6078675648 -> 6077545920
	6078675648 [label="SelectBackward0
------------------------
dim           :        0
index         :        0
self_sym_sizes: (5, 256)"]
	6078788320 -> 6078675648
	6077456416 [label="
 (5, 256)" fillcolor=lightblue]
	6077456416 -> 6078788320
	6078788320 [label=AccumulateGrad]
	6077539632 -> 6077539776
	6077539632 [label=TBackward0]
	6077538672 -> 6077539632
	6077537712 -> 6077539344
	6077536320 -> 6077536128
	6077536320 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	6078666000 -> 6077536320
	6078666000 [label="ViewBackward0
-------------------------------
self_sym_sizes: (90000, 1, 256)"]
	6077537616 -> 6078666000
	6077537616 [label="AddBackward0
------------
alpha: 1"]
	6077538288 -> 6077537616
	6077538288 [label="UnsafeViewBackward0
----------------------------
self_sym_sizes: (90000, 256)"]
	6077538480 -> 6077538288
	6077538480 -> 6171785344 [dir=none]
	6171785344 [label="mat2
 (256, 256)" fillcolor=orange]
	6077538480 -> 6171784944 [dir=none]
	6171784944 [label="self
 (90000, 256)" fillcolor=orange]
	6077538480 [label="MmBackward0
--------------------------------
mat2            : [saved tensor]
mat2_sym_sizes  :     (256, 256)
mat2_sym_strides:       (1, 256)
self            : [saved tensor]
self_sym_sizes  :   (90000, 256)
self_sym_strides:     (1, 90000)"]
	6077537136 -> 6077538480
	6077537136 [label="ReshapeAliasBackward0
-------------------------------
self_sym_sizes: (90000, 1, 256)"]
	6077540112 -> 6077537136
	6077539392 -> 6077538480
	6077539392 [label=TBackward0]
	6077538672 -> 6077539392
	6077537712 -> 6077537616
	6077534640 -> 6077535264
	6077534640 [label=TBackward0]
	6078775696 -> 6077534640
	6077458576 [label="
 (256, 256)" fillcolor=lightblue]
	6077458576 -> 6078775696
	6078775696 [label=AccumulateGrad]
	6077534016 -> 6077533728
	6077462816 [label="
 (256)" fillcolor=lightblue]
	6077462816 -> 6077534016
	6077534016 [label=AccumulateGrad]
	6077533776 -> 6077533728
	6077463776 [label="
 (256)" fillcolor=lightblue]
	6077463776 -> 6077533776
	6077533776 [label=AccumulateGrad]
	6077533584 -> 6077533248
	6077533584 [label="ViewBackward0
--------------------------
self_sym_sizes: (100, 256)"]
	6077534592 -> 6077533584
	6077534592 -> 6076885296 [dir=none]
	6076885296 [label="mat1
 (100, 256)" fillcolor=orange]
	6077534592 -> 6171786544 [dir=none]
	6171786544 [label="mat2
 (256, 256)" fillcolor=orange]
	6077534592 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (100, 256)
mat1_sym_strides:       (256, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (256, 256)
mat2_sym_strides:       (1, 256)"]
	6077535648 -> 6077534592
	6077452896 [label="
 (256)" fillcolor=lightblue]
	6077452896 -> 6077535648
	6077535648 [label=AccumulateGrad]
	6077535408 -> 6077534592
	6077535408 [label="ViewBackward0
----------------------------
self_sym_sizes: (100, 8, 32)"]
	6077535840 -> 6077535408
	6077535840 [label=CloneBackward0]
	6077538864 -> 6077535840
	6077538864 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	6077539920 -> 6077538864
	6077539920 -> 6076883536 [dir=none]
	6076883536 [label="mat2
 (8, 100, 32)" fillcolor=orange]
	6077539920 -> 6076885456 [dir=none]
	6076885456 [label="self
 (8, 100, 100)" fillcolor=orange]
	6077539920 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	6077543664 -> 6077539920
	6077543664 -> 6171689184 [dir=none]
	6171689184 [label="result
 (8, 100, 100)" fillcolor=orange]
	6077543664 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	6077545488 -> 6077543664
	6077545488 -> 6076883456 [dir=none]
	6076883456 [label="mat2
 (8, 32, 100)" fillcolor=orange]
	6077545488 -> 6076883296 [dir=none]
	6076883296 [label="self
 (8, 100, 32)" fillcolor=orange]
	6077545488 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	6077541168 -> 6077545488
	6077541168 -> 6171689264 [dir=none]
	6171689264 [label="other
 ()" fillcolor=orange]
	6077541168 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6078835456 -> 6077541168
	6078835456 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	6078944864 -> 6078835456
	6078944864 [label="ViewBackward0
-----------------------------
self_sym_sizes: (100, 1, 256)"]
	6078944384 -> 6078944864
	6078944384 [label="ViewBackward0
--------------------------
self_sym_sizes: (100, 256)"]
	11670927248 -> 6078944384
	11670927248 -> 6171689664 [dir=none]
	6171689664 [label="mat1
 (100, 256)" fillcolor=orange]
	11670927248 -> 6171689344 [dir=none]
	6171689344 [label="mat2
 (256, 256)" fillcolor=orange]
	11670927248 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (100, 256)
mat1_sym_strides:       (256, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (256, 256)
mat2_sym_strides:       (1, 256)"]
	11670921728 -> 11670927248
	11670921728 [label="SplitBackward0
----------------------
dim           :      0
self_sym_sizes: (768,)
split_size    :    256"]
	11670913520 -> 11670921728
	6075492576 [label="
 (768)" fillcolor=lightblue]
	6075492576 -> 11670913520
	11670913520 [label=AccumulateGrad]
	11670923072 -> 11670927248
	11670923072 [label="ViewBackward0
-----------------------------
self_sym_sizes: (100, 1, 256)"]
	11670915536 -> 11670923072
	11670915536 [label="AddBackward0
------------
alpha: 1"]
	6077533728 -> 11670915536
	6077538624 -> 11670915536
	11670926192 -> 11670927248
	11670926192 [label=TBackward0]
	11670917888 -> 11670926192
	11670917888 [label="SplitBackward0
--------------------------
dim           :          0
self_sym_sizes: (768, 256)
split_size    :        256"]
	11670916256 -> 11670917888
	6072810720 [label="
 (768, 256)" fillcolor=lightblue]
	6072810720 -> 11670916256
	11670916256 [label=AccumulateGrad]
	6077539872 -> 6077545488
	6077539872 [label="TransposeBackward0
--------------------------
dim0: 18446744073709551614
dim1: 18446744073709551615"]
	6078939392 -> 6077539872
	6078939392 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	11670919136 -> 6078939392
	11670919136 [label="ViewBackward0
-----------------------------
self_sym_sizes: (100, 1, 256)"]
	11670924368 -> 11670919136
	11670924368 [label="ViewBackward0
--------------------------
self_sym_sizes: (100, 256)"]
	6172720144 -> 11670924368
	6172720144 -> 6171691024 [dir=none]
	6171691024 [label="mat1
 (100, 256)" fillcolor=orange]
	6172720144 -> 6171690864 [dir=none]
	6171690864 [label="mat2
 (256, 256)" fillcolor=orange]
	6172720144 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (100, 256)
mat1_sym_strides:       (256, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (256, 256)
mat2_sym_strides:       (1, 256)"]
	11670921728 -> 6172720144
	6172715872 -> 6172720144
	6172715872 [label="ViewBackward0
-----------------------------
self_sym_sizes: (100, 1, 256)"]
	11670915536 -> 6172715872
	6172715968 -> 6172720144
	6172715968 [label=TBackward0]
	11670917888 -> 6172715968
	6077540400 -> 6077539920
	6077540400 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	6078941888 -> 6077540400
	6078941888 [label="ViewBackward0
-----------------------------
self_sym_sizes: (100, 1, 256)"]
	11670921440 -> 6078941888
	11670921440 [label="ViewBackward0
--------------------------
self_sym_sizes: (100, 256)"]
	6078833296 -> 11670921440
	6078833296 -> 6171691904 [dir=none]
	6171691904 [label="mat1
 (100, 256)" fillcolor=orange]
	6078833296 -> 6171692064 [dir=none]
	6171692064 [label="mat2
 (256, 256)" fillcolor=orange]
	6078833296 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (100, 256)
mat1_sym_strides:       (256, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (256, 256)
mat2_sym_strides:       (1, 256)"]
	11670921728 -> 6078833296
	6172715152 -> 6078833296
	6172715152 [label="ViewBackward0
-----------------------------
self_sym_sizes: (100, 1, 256)"]
	6077533728 -> 6172715152
	6172716688 -> 6078833296
	6172716688 [label=TBackward0]
	11670917888 -> 6172716688
	6077533968 -> 6077534592
	6077533968 [label=TBackward0]
	6077536656 -> 6077533968
	6075799712 [label="
 (256, 256)" fillcolor=lightblue]
	6075799712 -> 6077536656
	6077536656 [label=AccumulateGrad]
	6077533344 -> 6077533200
	5124387152 [label="
 (256)" fillcolor=lightblue]
	5124387152 -> 6077533344
	6077533344 [label=AccumulateGrad]
	6077533056 -> 6077533200
	5126830048 [label="
 (256)" fillcolor=lightblue]
	5126830048 -> 6077533056
	6077533056 [label=AccumulateGrad]
	6077533104 -> 6077532624
	6077533104 [label="ViewBackward0
--------------------------
self_sym_sizes: (100, 256)"]
	6077537328 -> 6077533104
	6077537328 -> 6171693424 [dir=none]
	6171693424 [label="mat1
 (100, 2048)" fillcolor=orange]
	6077537328 -> 6171693584 [dir=none]
	6171693584 [label="mat2
 (2048, 256)" fillcolor=orange]
	6077537328 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :    (100, 2048)
mat1_sym_strides:      (2048, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (2048, 256)
mat2_sym_strides:      (1, 2048)"]
	6077537904 -> 6077537328
	6077456896 [label="
 (256)" fillcolor=lightblue]
	6077456896 -> 6077537904
	6077537904 [label=AccumulateGrad]
	6077535600 -> 6077537328
	6077535600 [label="ViewBackward0
------------------------------
self_sym_sizes: (100, 1, 2048)"]
	6077536464 -> 6077535600
	6077536464 -> 6171694064 [dir=none]
	6171694064 [label="result
 (100, 1, 2048)" fillcolor=orange]
	6077536464 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	6078825616 -> 6077536464
	6078825616 [label="ViewBackward0
---------------------------
self_sym_sizes: (100, 2048)"]
	6172714816 -> 6078825616
	6172714816 -> 6171694304 [dir=none]
	6171694304 [label="mat1
 (100, 256)" fillcolor=orange]
	6172714816 -> 6171693744 [dir=none]
	6171693744 [label="mat2
 (256, 2048)" fillcolor=orange]
	6172714816 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (100, 256)
mat1_sym_strides:       (256, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (256, 2048)
mat2_sym_strides:       (1, 256)"]
	6172712656 -> 6172714816
	6077457456 [label="
 (2048)" fillcolor=lightblue]
	6077457456 -> 6172712656
	6172712656 [label=AccumulateGrad]
	6172713136 -> 6172714816
	6172713136 [label="ViewBackward0
-----------------------------
self_sym_sizes: (100, 1, 256)"]
	6077533200 -> 6172713136
	6172717696 -> 6172714816
	6172717696 [label=TBackward0]
	6172710976 -> 6172717696
	6077457296 [label="
 (2048, 256)" fillcolor=lightblue]
	6077457296 -> 6172710976
	6172710976 [label=AccumulateGrad]
	6077533632 -> 6077537328
	6077533632 [label=TBackward0]
	6077535360 -> 6077533632
	6077456976 [label="
 (256, 2048)" fillcolor=lightblue]
	6077456976 -> 6077535360
	6077535360 [label=AccumulateGrad]
	6077532576 -> 6077532336
	6077456736 [label="
 (256)" fillcolor=lightblue]
	6077456736 -> 6077532576
	6077532576 [label=AccumulateGrad]
	6077532384 -> 6077532336
	6077456576 [label="
 (256)" fillcolor=lightblue]
	6077456576 -> 6077532384
	6077532384 [label=AccumulateGrad]
	6077531616 -> 6077531328
	6077531616 [label=TBackward0]
	6077535888 -> 6077531616
	6077451536 [label="
 (101, 256)" fillcolor=lightblue]
	6077451536 -> 6077535888
	6077535888 [label=AccumulateGrad]
	6077530848 -> 6077455856
}
