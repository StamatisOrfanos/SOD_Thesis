digraph {
	graph [size="1438.8,1438.8"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	6140273872 [label="
 ()" fillcolor=darkolivegreen1]
	6140445408 -> 6139859632 [dir=none]
	6139859632 [label="self
 (1, 100, 101)" fillcolor=orange]
	6140445408 [label="MeanBackward0
------------------------------
self          : [saved tensor]
self_sym_sizes:  (1, 100, 101)"]
	6140446560 -> 6140445408
	6140446560 [label="ViewBackward0
--------------------------
self_sym_sizes: (100, 101)"]
	6140445792 -> 6140446560
	6140445792 -> 6140433792 [dir=none]
	6140433792 [label="mat1
 (100, 256)" fillcolor=orange]
	6140445792 -> 6140429632 [dir=none]
	6140429632 [label="mat2
 (256, 101)" fillcolor=orange]
	6140445792 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (100, 256)
mat1_sym_strides:       (256, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (256, 101)
mat2_sym_strides:       (1, 256)"]
	6140445840 -> 6140445792
	6141603216 [label="
 (101)" fillcolor=lightblue]
	6141603216 -> 6140445840
	6140445840 [label=AccumulateGrad]
	6140445600 -> 6140445792
	6140445600 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 100, 256)"]
	6140446272 -> 6140445600
	6140446272 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	6140446800 -> 6140446272
	6140446800 -> 6141599136 [dir=none]
	6141599136 [label="bias
 (256)" fillcolor=orange]
	6140446800 -> 6139860512 [dir=none]
	6139860512 [label="input
 (100, 1, 256)" fillcolor=orange]
	6140446800 -> 6140430592 [dir=none]
	6140430592 [label="result1
 (100, 1, 1)" fillcolor=orange]
	6140446800 -> 6140432912 [dir=none]
	6140432912 [label="result2
 (100, 1, 1)" fillcolor=orange]
	6140446800 -> 6141599296 [dir=none]
	6141599296 [label="weight
 (256)" fillcolor=orange]
	6140446800 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	6140447088 -> 6140446800
	6140447088 [label="AddBackward0
------------
alpha: 1"]
	6140447760 -> 6140447088
	6140447760 -> 5491947088 [dir=none]
	5491947088 [label="bias
 (256)" fillcolor=orange]
	6140447760 -> 6139859472 [dir=none]
	6139859472 [label="input
 (100, 1, 256)" fillcolor=orange]
	6140447760 -> 6140435952 [dir=none]
	6140435952 [label="result1
 (100, 1, 1)" fillcolor=orange]
	6140447760 -> 6140434752 [dir=none]
	6140434752 [label="result2
 (100, 1, 1)" fillcolor=orange]
	6140447760 -> 4620175216 [dir=none]
	4620175216 [label="weight
 (256)" fillcolor=orange]
	6140447760 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	6140447808 -> 6140447760
	6140447808 [label="AddBackward0
------------
alpha: 1"]
	6140448288 -> 6140447808
	6140448288 -> 6141600176 [dir=none]
	6141600176 [label="bias
 (256)" fillcolor=orange]
	6140448288 -> 6139860592 [dir=none]
	6139860592 [label="input
 (100, 1, 256)" fillcolor=orange]
	6140448288 -> 6140434432 [dir=none]
	6140434432 [label="result1
 (100, 1, 1)" fillcolor=orange]
	6140448288 -> 6140441552 [dir=none]
	6140441552 [label="result2
 (100, 1, 1)" fillcolor=orange]
	6140448288 -> 6141600336 [dir=none]
	6141600336 [label="weight
 (256)" fillcolor=orange]
	6140448288 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:         (256,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	6140448720 -> 6140448288
	6140448720 [label="AddBackward0
------------
alpha: 1"]
	6140448816 -> 6140448720
	6140448816 [label="RepeatBackward0
-----------------------------
repeats       :     (1, 1, 1)
self_sym_sizes: (100, 1, 256)"]
	6140449584 -> 6140448816
	6140449584 [label="UnsqueezeBackward0
------------------
dim: 1"]
	6140449536 -> 6140449584
	6141598816 [label="
 (100, 256)" fillcolor=lightblue]
	6141598816 -> 6140449536
	6140449536 [label=AccumulateGrad]
	6140448864 -> 6140448720
	6140448864 [label="ViewBackward0
--------------------------
self_sym_sizes: (100, 256)"]
	6140449824 -> 6140448864
	6140449824 -> 6139861232 [dir=none]
	6139861232 [label="mat1
 (100, 256)" fillcolor=orange]
	6140449824 -> 6140442432 [dir=none]
	6140442432 [label="mat2
 (256, 256)" fillcolor=orange]
	6140449824 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (100, 256)
mat1_sym_strides:       (256, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (256, 256)
mat2_sym_strides:       (1, 256)"]
	6140449344 -> 6140449824
	6141600416 [label="
 (256)" fillcolor=lightblue]
	6141600416 -> 6140449344
	6140449344 [label=AccumulateGrad]
	6140449296 -> 6140449824
	6140449296 [label="ViewBackward0
----------------------------
self_sym_sizes: (100, 8, 32)"]
	6140449776 -> 6140449296
	6140449776 [label=CloneBackward0]
	6140453376 -> 6140449776
	6140453376 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	6140450592 -> 6140453376
	6140450592 -> 6139862352 [dir=none]
	6139862352 [label="mat2
 (8, 90000, 32)" fillcolor=orange]
	6140450592 -> 6139862512 [dir=none]
	6139862512 [label="self
 (8, 100, 90000)" fillcolor=orange]
	6140450592 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	6140450544 -> 6140450592
	6140450544 -> 6140438672 [dir=none]
	6140438672 [label="result
 (8, 100, 90000)" fillcolor=orange]
	6140450544 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	6140451072 -> 6140450544
	6140451072 -> 6139861872 [dir=none]
	6139861872 [label="batch1
 (8, 100, 32)" fillcolor=orange]
	6140451072 -> 6139862432 [dir=none]
	6139862432 [label="batch2
 (8, 32, 90000)" fillcolor=orange]
	6140451072 [label="BaddbmmBackward0
----------------------
alpha :              1
batch1: [saved tensor]
batch2: [saved tensor]
beta  :              1"]
	6140451312 -> 6140451072
	6140451312 -> 6140440832 [dir=none]
	6140440832 [label="other
 ()" fillcolor=orange]
	6140451312 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6140451840 -> 6140451312
	6140451840 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	6140454816 -> 6140451840
	6140454816 [label="ViewBackward0
-----------------------------
self_sym_sizes: (100, 1, 256)"]
	6140452032 -> 6140454816
	6140452032 [label="ViewBackward0
--------------------------
self_sym_sizes: (100, 256)"]
	6140452320 -> 6140452032
	6140452320 -> 6140432592 [dir=none]
	6140432592 [label="mat1
 (100, 256)" fillcolor=orange]
	6140452320 -> 6140436352 [dir=none]
	6140436352 [label="mat2
 (256, 256)" fillcolor=orange]
	6140452320 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (100, 256)
mat1_sym_strides:       (256, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (256, 256)
mat2_sym_strides:       (1, 256)"]
	6140452272 -> 6140452320
	6140452272 [label="SplitBackward0
----------------------
dim           :      0
self_sym_sizes: (768,)
split_size    :    256"]
	6140452992 -> 6140452272
	6137551088 [label="
 (768)" fillcolor=lightblue]
	6137551088 -> 6140452992
	6140452992 [label=AccumulateGrad]
	6140452608 -> 6140452320
	6140452608 [label="ViewBackward0
-----------------------------
self_sym_sizes: (100, 1, 256)"]
	6140452800 -> 6140452608
	6140452800 [label="AddBackward0
------------
alpha: 1"]
	6140448816 -> 6140452800
	6140453184 -> 6140452800
	6140453184 [label="RepeatBackward0
-----------------------------
repeats       :     (1, 1, 1)
self_sym_sizes: (100, 1, 256)"]
	6140456592 -> 6140453184
	6140456592 [label="UnsqueezeBackward0
------------------
dim: 1"]
	6140453616 -> 6140456592
	4397995872 [label="
 (100, 256)" fillcolor=lightblue]
	4397995872 -> 6140453616
	6140453616 [label=AccumulateGrad]
	6140451360 -> 6140452320
	6140451360 [label=TBackward0]
	6140453232 -> 6140451360
	6140453232 [label="SplitBackward0
--------------------------
dim           :          0
self_sym_sizes: (768, 256)
split_size    :        256"]
	6140453568 -> 6140453232
	5500384528 [label="
 (768, 256)" fillcolor=lightblue]
	5500384528 -> 6140453568
	6140453568 [label=AccumulateGrad]
	6140451168 -> 6140451072
	6140451168 [label="TransposeBackward0
--------------------------
dim0: 18446744073709551614
dim1: 18446744073709551615"]
	6140452560 -> 6140451168
	6140452560 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	6140452416 -> 6140452560
	6140452416 [label="ViewBackward0
-------------------------------
self_sym_sizes: (90000, 1, 256)"]
	6140453808 -> 6140452416
	6140453808 [label="AddBackward0
------------
alpha: 1"]
	6140454048 -> 6140453808
	6140454048 [label="UnsafeViewBackward0
----------------------------
self_sym_sizes: (90000, 256)"]
	6140454336 -> 6140454048
	6140454336 -> 6141766416 [dir=none]
	6141766416 [label="mat2
 (256, 256)" fillcolor=orange]
	6140454336 -> 6141760496 [dir=none]
	6141760496 [label="self
 (90000, 256)" fillcolor=orange]
	6140454336 [label="MmBackward0
--------------------------------
mat2            : [saved tensor]
mat2_sym_sizes  :     (256, 256)
mat2_sym_strides:       (1, 256)
self            : [saved tensor]
self_sym_sizes  :   (90000, 256)
self_sym_strides:     (1, 90000)"]
	6140454288 -> 6140454336
	6140454288 [label="ReshapeAliasBackward0
-------------------------------
self_sym_sizes: (90000, 1, 256)"]
	6140454624 -> 6140454288
	6140454624 [label="AddBackward0
------------
alpha: 1"]
	6140454576 -> 6140454624
	6140454576 [label="PermuteBackward0
----------------
dims: (2, 0, 1)"]
	6140455104 -> 6140454576
	6140455104 [label="AddBackward0
------------
alpha: 1"]
	6140455584 -> 6140455104
	6140455584 [label="ReshapeAliasBackward0
----------------------------------
self_sym_sizes: (1, 256, 300, 300)"]
	6140455296 -> 6140455584
	6140455296 [label="AddBackward0
------------
alpha: 1"]
	6140455536 -> 6140455296
	6140455536 [label="UpsampleNearest2DBackward0
----------------------------------
output_size   :         (300, 300)
scales_h      :                2.0
scales_w      :                2.0
self_sym_sizes: (1, 256, 150, 150)"]
	6140455824 -> 6140455536
	6140455824 [label="AddBackward0
------------
alpha: 1"]
	6140456304 -> 6140455824
	6140456304 [label="PixelShuffleBackward0
---------------------
upscale_factor: 2"]
	6140456832 -> 6140456304
	6140456832 -> 6139869232 [dir=none]
	6139869232 [label="input
 (1, 256, 75, 75)" fillcolor=orange]
	6140456832 -> 6141606976 [dir=none]
	6141606976 [label="weight
 (1024, 256, 3, 3)" fillcolor=orange]
	6140456832 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (1024,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6140456784 -> 6140456832
	6140456784 -> 6141762416 [dir=none]
	6141762416 [label="result
 (1, 256, 75, 75)" fillcolor=orange]
	6140456784 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	6140457120 -> 6140456784
	6140457120 -> 6139869312 [dir=none]
	6139869312 [label="input
 (1, 256, 75, 75)" fillcolor=orange]
	6140457120 -> 6141760016 [dir=none]
	6141760016 [label="result1
 (256)" fillcolor=orange]
	6140457120 -> 6141768976 [dir=none]
	6141768976 [label="result2
 (256)" fillcolor=orange]
	6140457120 -> 6141599216 [dir=none]
	6141599216 [label="running_mean
 (256)" fillcolor=orange]
	6140457120 -> 6141593296 [dir=none]
	6141593296 [label="running_var
 (256)" fillcolor=orange]
	6140457120 -> 6141595136 [dir=none]
	6141595136 [label="weight
 (256)" fillcolor=orange]
	6140457120 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6140457456 -> 6140457120
	6140457456 -> 6139869472 [dir=none]
	6139869472 [label="input
 (1, 256, 75, 75)" fillcolor=orange]
	6140457456 -> 6141596016 [dir=none]
	6141596016 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	6140457456 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (256,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6140457696 -> 6140457456
	6140457696 -> 6138404496 [dir=none]
	6138404496 [label="result
 (1, 256, 75, 75)" fillcolor=orange]
	6140457696 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	6140458320 -> 6140457696
	6140458320 -> 6139869552 [dir=none]
	6139869552 [label="input
 (1, 256, 75, 75)" fillcolor=orange]
	6140458320 -> 6138405696 [dir=none]
	6138405696 [label="result1
 (256)" fillcolor=orange]
	6140458320 -> 6138410576 [dir=none]
	6138410576 [label="result2
 (256)" fillcolor=orange]
	6140458320 -> 6141604496 [dir=none]
	6141604496 [label="running_mean
 (256)" fillcolor=orange]
	6140458320 -> 6141600576 [dir=none]
	6141600576 [label="running_var
 (256)" fillcolor=orange]
	6140458320 -> 6141602656 [dir=none]
	6141602656 [label="weight
 (256)" fillcolor=orange]
	6140458320 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6140458608 -> 6140458320
	6140458608 -> 6139869712 [dir=none]
	6139869712 [label="input
 (1, 256, 75, 75)" fillcolor=orange]
	6140458608 -> 6141603936 [dir=none]
	6141603936 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	6140458608 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (256,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6140459088 -> 6140458608
	6140459088 -> 6142011216 [dir=none]
	6142011216 [label="result
 (1, 256, 75, 75)" fillcolor=orange]
	6140459088 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	6140459328 -> 6140459088
	6140459328 -> 6139869792 [dir=none]
	6139869792 [label="input
 (1, 256, 75, 75)" fillcolor=orange]
	6140459328 -> 6142012256 [dir=none]
	6142012256 [label="result1
 (256)" fillcolor=orange]
	6140459328 -> 6142005696 [dir=none]
	6142005696 [label="result2
 (256)" fillcolor=orange]
	6140459328 -> 6137544928 [dir=none]
	6137544928 [label="running_mean
 (256)" fillcolor=orange]
	6140459328 -> 6141606496 [dir=none]
	6141606496 [label="running_var
 (256)" fillcolor=orange]
	6140459328 -> 6141592976 [dir=none]
	6141592976 [label="weight
 (256)" fillcolor=orange]
	6140459328 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6140459856 -> 6140459328
	6140459856 -> 6139870352 [dir=none]
	6139870352 [label="input
 (1, 256, 75, 75)" fillcolor=orange]
	6140459856 -> 6117679536 [dir=none]
	6117679536 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	6140459856 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (256,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6140460096 -> 6140459856
	6140460096 [label="AddBackward0
------------
alpha: 1"]
	6140460576 -> 6140460096
	6140460576 -> 6140265792 [dir=none]
	6140265792 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6140460576 -> 6141602736 [dir=none]
	6141602736 [label="weight
 (256, 80, 1, 1)" fillcolor=orange]
	6140460576 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (256,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6140460816 -> 6140460576
	6140460816 [label="AddBackward0
------------
alpha: 1"]
	6141575280 -> 6140460816
	6141575280 -> 6140265392 [dir=none]
	6140265392 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6141575280 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141575472 -> 6141575280
	6141575472 -> 6142015616 [dir=none]
	6142015616 [label="other
 ()" fillcolor=orange]
	6141575472 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141575664 -> 6141575472
	6141575664 -> 6140266832 [dir=none]
	6140266832 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6141575664 -> 6140366496 [dir=none]
	6140366496 [label="result1
 (80)" fillcolor=orange]
	6141575664 -> 6142016816 [dir=none]
	6142016816 [label="result2
 (80)" fillcolor=orange]
	6141575664 -> 6137838656 [dir=none]
	6137838656 [label="running_mean
 (80)" fillcolor=orange]
	6141575664 -> 6137838976 [dir=none]
	6137838976 [label="running_var
 (80)" fillcolor=orange]
	6141575664 -> 6137838816 [dir=none]
	6137838816 [label="weight
 (80)" fillcolor=orange]
	6141575664 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141575616 -> 6141575664
	6141575616 -> 6140267232 [dir=none]
	6140267232 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6141575616 -> 6137838736 [dir=none]
	6137838736 [label="weight
 (80, 480, 1, 1)" fillcolor=orange]
	6141575616 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141576432 -> 6141575616
	6141576432 -> 6140270272 [dir=none]
	6140270272 [label="other
 (1, 480, 75, 75)" fillcolor=orange]
	6141576432 -> 6140268272 [dir=none]
	6140268272 [label="self
 (1, 480, 1, 1)" fillcolor=orange]
	6141576432 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6141576528 -> 6141576432
	6141576528 -> 6142001536 [dir=none]
	6142001536 [label="result
 (1, 480, 1, 1)" fillcolor=orange]
	6141576528 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6141580032 -> 6141576528
	6141580032 -> 6140267792 [dir=none]
	6140267792 [label="input
 (1, 20, 1, 1)" fillcolor=orange]
	6141580032 -> 6137838496 [dir=none]
	6137838496 [label="weight
 (480, 20, 1, 1)" fillcolor=orange]
	6141580032 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (480,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141950464 -> 6141580032
	6141950464 [label=SwishImplementationBackward]
	6141577296 -> 6141950464
	6141577296 -> 6140270992 [dir=none]
	6140270992 [label="input
 (1, 480, 1, 1)" fillcolor=orange]
	6141577296 -> 6137838176 [dir=none]
	6137838176 [label="weight
 (20, 480, 1, 1)" fillcolor=orange]
	6141577296 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (20,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141577536 -> 6141577296
	6141577536 -> 6140270272 [dir=none]
	6140270272 [label="self
 (1, 480, 75, 75)" fillcolor=orange]
	6141577536 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 480, 75, 75)"]
	6141950240 -> 6141577536
	6141950240 [label=SwishImplementationBackward]
	6141578544 -> 6141950240
	6141578544 -> 6140266112 [dir=none]
	6140266112 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6141578544 -> 6142005056 [dir=none]
	6142005056 [label="result1
 (480)" fillcolor=orange]
	6141578544 -> 6142002976 [dir=none]
	6142002976 [label="result2
 (480)" fillcolor=orange]
	6141578544 -> 6137835856 [dir=none]
	6137835856 [label="running_mean
 (480)" fillcolor=orange]
	6141578544 -> 6137837696 [dir=none]
	6137837696 [label="running_var
 (480)" fillcolor=orange]
	6141578544 -> 6137837456 [dir=none]
	6137837456 [label="weight
 (480)" fillcolor=orange]
	6141578544 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141578784 -> 6141578544
	6141578784 -> 6140266592 [dir=none]
	6140266592 [label="input
 (1, 480, 79, 79)" fillcolor=orange]
	6141578784 -> 6137837536 [dir=none]
	6137837536 [label="weight
 (480, 1, 5, 5)" fillcolor=orange]
	6141578784 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            480
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141578880 -> 6141578784
	6141578880 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6141950016 -> 6141578880
	6141950016 [label=SwishImplementationBackward]
	6141579744 -> 6141950016
	6141579744 -> 6140273392 [dir=none]
	6140273392 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6141579744 -> 6142007376 [dir=none]
	6142007376 [label="result1
 (480)" fillcolor=orange]
	6141579744 -> 6142009696 [dir=none]
	6142009696 [label="result2
 (480)" fillcolor=orange]
	6141579744 -> 6137836736 [dir=none]
	6137836736 [label="running_mean
 (480)" fillcolor=orange]
	6141579744 -> 6137837056 [dir=none]
	6137837056 [label="running_var
 (480)" fillcolor=orange]
	6141579744 -> 6137836896 [dir=none]
	6137836896 [label="weight
 (480)" fillcolor=orange]
	6141579744 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141583056 -> 6141579744
	6141583056 -> 6140267552 [dir=none]
	6140267552 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6141583056 -> 6137836816 [dir=none]
	6137836816 [label="weight
 (480, 80, 1, 1)" fillcolor=orange]
	6141583056 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141576816 -> 6141583056
	6141576816 [label="AddBackward0
------------
alpha: 1"]
	6141580320 -> 6141576816
	6141580320 -> 6140267072 [dir=none]
	6140267072 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6141580320 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141580656 -> 6141580320
	6141580656 -> 6142010976 [dir=none]
	6142010976 [label="other
 ()" fillcolor=orange]
	6141580656 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141580944 -> 6141580656
	6141580944 -> 6140269072 [dir=none]
	6140269072 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6141580944 -> 6142013136 [dir=none]
	6142013136 [label="result1
 (80)" fillcolor=orange]
	6141580944 -> 6142009776 [dir=none]
	6142009776 [label="result2
 (80)" fillcolor=orange]
	6141580944 -> 6137836096 [dir=none]
	6137836096 [label="running_mean
 (80)" fillcolor=orange]
	6141580944 -> 6137836416 [dir=none]
	6137836416 [label="running_var
 (80)" fillcolor=orange]
	6141580944 -> 6137836256 [dir=none]
	6137836256 [label="weight
 (80)" fillcolor=orange]
	6141580944 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141581328 -> 6141580944
	6141581328 -> 6140271152 [dir=none]
	6140271152 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6141581328 -> 6137836176 [dir=none]
	6137836176 [label="weight
 (80, 480, 1, 1)" fillcolor=orange]
	6141581328 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141581520 -> 6141581328
	6141581520 -> 6140273552 [dir=none]
	6140273552 [label="other
 (1, 480, 75, 75)" fillcolor=orange]
	6141581520 -> 6140272352 [dir=none]
	6140272352 [label="self
 (1, 480, 1, 1)" fillcolor=orange]
	6141581520 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6141582192 -> 6141581520
	6141582192 -> 6142014256 [dir=none]
	6142014256 [label="result
 (1, 480, 1, 1)" fillcolor=orange]
	6141582192 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6141582144 -> 6141582192
	6141582144 -> 6140271872 [dir=none]
	6140271872 [label="input
 (1, 20, 1, 1)" fillcolor=orange]
	6141582144 -> 6137835936 [dir=none]
	6137835936 [label="weight
 (480, 20, 1, 1)" fillcolor=orange]
	6141582144 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (480,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141949792 -> 6141582144
	6141949792 [label=SwishImplementationBackward]
	6141582768 -> 6141949792
	6141582768 -> 6140274592 [dir=none]
	6140274592 [label="input
 (1, 480, 1, 1)" fillcolor=orange]
	6141582768 -> 6137835696 [dir=none]
	6137835696 [label="weight
 (20, 480, 1, 1)" fillcolor=orange]
	6141582768 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (20,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141586080 -> 6141582768
	6141586080 -> 6140273552 [dir=none]
	6140273552 [label="self
 (1, 480, 75, 75)" fillcolor=orange]
	6141586080 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 480, 75, 75)"]
	6141949568 -> 6141586080
	6141949568 [label=SwishImplementationBackward]
	6141583440 -> 6141949568
	6141583440 -> 6140278192 [dir=none]
	6140278192 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6141583440 -> 6142014416 [dir=none]
	6142014416 [label="result1
 (480)" fillcolor=orange]
	6141583440 -> 6139801136 [dir=none]
	6139801136 [label="result2
 (480)" fillcolor=orange]
	6141583440 -> 6137833376 [dir=none]
	6137833376 [label="running_mean
 (480)" fillcolor=orange]
	6141583440 -> 6137835216 [dir=none]
	6137835216 [label="running_var
 (480)" fillcolor=orange]
	6141583440 -> 6137834976 [dir=none]
	6137834976 [label="weight
 (480)" fillcolor=orange]
	6141583440 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141583584 -> 6141583440
	6141583584 -> 6140265072 [dir=none]
	6140265072 [label="input
 (1, 480, 79, 79)" fillcolor=orange]
	6141583584 -> 6137835056 [dir=none]
	6137835056 [label="weight
 (480, 1, 5, 5)" fillcolor=orange]
	6141583584 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            480
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141584304 -> 6141583584
	6141584304 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6141949344 -> 6141584304
	6141949344 [label=SwishImplementationBackward]
	6141584640 -> 6141949344
	6141584640 -> 6140268832 [dir=none]
	6140268832 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6141584640 -> 6139790816 [dir=none]
	6139790816 [label="result1
 (480)" fillcolor=orange]
	6141584640 -> 6139789616 [dir=none]
	6139789616 [label="result2
 (480)" fillcolor=orange]
	6141584640 -> 6137834256 [dir=none]
	6137834256 [label="running_mean
 (480)" fillcolor=orange]
	6141584640 -> 6137834576 [dir=none]
	6137834576 [label="running_var
 (480)" fillcolor=orange]
	6141584640 -> 6137834416 [dir=none]
	6137834416 [label="weight
 (480)" fillcolor=orange]
	6141584640 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141584832 -> 6141584640
	6141584832 -> 6140271552 [dir=none]
	6140271552 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6141584832 -> 6137834336 [dir=none]
	6137834336 [label="weight
 (480, 80, 1, 1)" fillcolor=orange]
	6141584832 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141580512 -> 6141584832
	6141580512 [label="AddBackward0
------------
alpha: 1"]
	6141585600 -> 6141580512
	6141585600 -> 6140271312 [dir=none]
	6140271312 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6141585600 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141585792 -> 6141585600
	6141585792 -> 6139792096 [dir=none]
	6139792096 [label="other
 ()" fillcolor=orange]
	6141585792 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141587520 -> 6141585792
	6141587520 -> 6140272832 [dir=none]
	6140272832 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6141587520 -> 6139794496 [dir=none]
	6139794496 [label="result1
 (80)" fillcolor=orange]
	6141587520 -> 6139796176 [dir=none]
	6139796176 [label="result2
 (80)" fillcolor=orange]
	6141587520 -> 6137833616 [dir=none]
	6137833616 [label="running_mean
 (80)" fillcolor=orange]
	6141587520 -> 6137833936 [dir=none]
	6137833936 [label="running_var
 (80)" fillcolor=orange]
	6141587520 -> 6137833776 [dir=none]
	6137833776 [label="weight
 (80)" fillcolor=orange]
	6141587520 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141586320 -> 6141587520
	6141586320 -> 6140273072 [dir=none]
	6140273072 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6141586320 -> 6137833696 [dir=none]
	6137833696 [label="weight
 (80, 480, 1, 1)" fillcolor=orange]
	6141586320 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141586560 -> 6141586320
	6141586560 -> 6140278432 [dir=none]
	6140278432 [label="other
 (1, 480, 75, 75)" fillcolor=orange]
	6141586560 -> 6140272592 [dir=none]
	6140272592 [label="self
 (1, 480, 1, 1)" fillcolor=orange]
	6141586560 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6141586800 -> 6141586560
	6141586800 -> 6139800256 [dir=none]
	6139800256 [label="result
 (1, 480, 1, 1)" fillcolor=orange]
	6141586800 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6141587088 -> 6141586800
	6141587088 -> 6140275072 [dir=none]
	6140275072 [label="input
 (1, 20, 1, 1)" fillcolor=orange]
	6141587088 -> 6137833456 [dir=none]
	6137833456 [label="weight
 (480, 20, 1, 1)" fillcolor=orange]
	6141587088 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (480,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141949120 -> 6141587088
	6141949120 [label=SwishImplementationBackward]
	6141588048 -> 6141949120
	6141588048 -> 6139013424 [dir=none]
	6139013424 [label="input
 (1, 480, 1, 1)" fillcolor=orange]
	6141588048 -> 6137833216 [dir=none]
	6137833216 [label="weight
 (20, 480, 1, 1)" fillcolor=orange]
	6141588048 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (20,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141588288 -> 6141588048
	6141588288 -> 6140278432 [dir=none]
	6140278432 [label="self
 (1, 480, 75, 75)" fillcolor=orange]
	6141588288 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 480, 75, 75)"]
	6141948896 -> 6141588288
	6141948896 [label=SwishImplementationBackward]
	6141588816 -> 6141948896
	6141588816 -> 6140276912 [dir=none]
	6140276912 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6141588816 -> 6139799936 [dir=none]
	6139799936 [label="result1
 (480)" fillcolor=orange]
	6141588816 -> 6139797776 [dir=none]
	6139797776 [label="result2
 (480)" fillcolor=orange]
	6141588816 -> 6137829776 [dir=none]
	6137829776 [label="running_mean
 (480)" fillcolor=orange]
	6141588816 -> 6137832736 [dir=none]
	6137832736 [label="running_var
 (480)" fillcolor=orange]
	6141588816 -> 6137832496 [dir=none]
	6137832496 [label="weight
 (480)" fillcolor=orange]
	6141588816 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141590544 -> 6141588816
	6141590544 -> 6140279152 [dir=none]
	6140279152 [label="input
 (1, 480, 79, 79)" fillcolor=orange]
	6141590544 -> 6137832576 [dir=none]
	6137832576 [label="weight
 (480, 1, 5, 5)" fillcolor=orange]
	6141590544 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            480
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141589536 -> 6141590544
	6141589536 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6141948672 -> 6141589536
	6141948672 [label=SwishImplementationBackward]
	6141589728 -> 6141948672
	6141589728 -> 6140363856 [dir=none]
	6140363856 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6141589728 -> 6139802976 [dir=none]
	6139802976 [label="result1
 (480)" fillcolor=orange]
	6141589728 -> 6139801216 [dir=none]
	6139801216 [label="result2
 (480)" fillcolor=orange]
	6141589728 -> 6137831776 [dir=none]
	6137831776 [label="running_mean
 (480)" fillcolor=orange]
	6141589728 -> 6137832096 [dir=none]
	6137832096 [label="running_var
 (480)" fillcolor=orange]
	6141589728 -> 6137831936 [dir=none]
	6137831936 [label="weight
 (480)" fillcolor=orange]
	6141589728 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141590064 -> 6141589728
	6141590064 -> 6140362896 [dir=none]
	6140362896 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6141590064 -> 6137831856 [dir=none]
	6137831856 [label="weight
 (480, 80, 1, 1)" fillcolor=orange]
	6141590064 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141585456 -> 6141590064
	6141585456 [label="AddBackward0
------------
alpha: 1"]
	6141590784 -> 6141585456
	6141590784 -> 6140272112 [dir=none]
	6140272112 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6141590784 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141591360 -> 6141590784
	6141591360 -> 6139801936 [dir=none]
	6139801936 [label="other
 ()" fillcolor=orange]
	6141591360 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141591312 -> 6141591360
	6141591312 -> 6140363056 [dir=none]
	6140363056 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6141591312 -> 6139799616 [dir=none]
	6139799616 [label="result1
 (80)" fillcolor=orange]
	6141591312 -> 6139794016 [dir=none]
	6139794016 [label="result2
 (80)" fillcolor=orange]
	6141591312 -> 6137831216 [dir=none]
	6137831216 [label="running_mean
 (80)" fillcolor=orange]
	6141591312 -> 6137831536 [dir=none]
	6137831536 [label="running_var
 (80)" fillcolor=orange]
	6141591312 -> 6137831376 [dir=none]
	6137831376 [label="weight
 (80)" fillcolor=orange]
	6141591312 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141591168 -> 6141591312
	6141591168 -> 6140363376 [dir=none]
	6140363376 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6141591168 -> 6137831296 [dir=none]
	6137831296 [label="weight
 (80, 480, 1, 1)" fillcolor=orange]
	6141591168 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141673824 -> 6141591168
	6141673824 -> 6140364016 [dir=none]
	6140364016 [label="other
 (1, 480, 75, 75)" fillcolor=orange]
	6141673824 -> 6140363696 [dir=none]
	6140363696 [label="self
 (1, 480, 1, 1)" fillcolor=orange]
	6141673824 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6141674016 -> 6141673824
	6141674016 -> 6139800336 [dir=none]
	6139800336 [label="result
 (1, 480, 1, 1)" fillcolor=orange]
	6141674016 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6141677328 -> 6141674016
	6141677328 -> 6140363536 [dir=none]
	6140363536 [label="input
 (1, 20, 1, 1)" fillcolor=orange]
	6141677328 -> 6137831056 [dir=none]
	6137831056 [label="weight
 (480, 20, 1, 1)" fillcolor=orange]
	6141677328 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (480,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141948448 -> 6141677328
	6141948448 [label=SwishImplementationBackward]
	6141674592 -> 6141948448
	6141674592 -> 6140364416 [dir=none]
	6140364416 [label="input
 (1, 480, 1, 1)" fillcolor=orange]
	6141674592 -> 6137830816 [dir=none]
	6137830816 [label="weight
 (20, 480, 1, 1)" fillcolor=orange]
	6141674592 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (20,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141674832 -> 6141674592
	6141674832 -> 6140364016 [dir=none]
	6140364016 [label="self
 (1, 480, 75, 75)" fillcolor=orange]
	6141674832 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 480, 75, 75)"]
	6141948224 -> 6141674832
	6141948224 [label=SwishImplementationBackward]
	6141675504 -> 6141948224
	6141675504 -> 6140364896 [dir=none]
	6140364896 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6141675504 -> 6139796976 [dir=none]
	6139796976 [label="result1
 (480)" fillcolor=orange]
	6141675504 -> 6139571920 [dir=none]
	6139571920 [label="result2
 (480)" fillcolor=orange]
	6141675504 -> 6137828496 [dir=none]
	6137828496 [label="running_mean
 (480)" fillcolor=orange]
	6141675504 -> 6137830336 [dir=none]
	6137830336 [label="running_var
 (480)" fillcolor=orange]
	6141675504 -> 6137830096 [dir=none]
	6137830096 [label="weight
 (480)" fillcolor=orange]
	6141675504 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141675840 -> 6141675504
	6141675840 -> 6140365056 [dir=none]
	6140365056 [label="input
 (1, 480, 79, 79)" fillcolor=orange]
	6141675840 -> 6137830176 [dir=none]
	6137830176 [label="weight
 (480, 1, 5, 5)" fillcolor=orange]
	6141675840 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            480
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141676464 -> 6141675840
	6141676464 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6141948000 -> 6141676464
	6141948000 [label=SwishImplementationBackward]
	6141676848 -> 6141948000
	6141676848 -> 6140365856 [dir=none]
	6140365856 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6141676848 -> 6139570640 [dir=none]
	6139570640 [label="result1
 (480)" fillcolor=orange]
	6141676848 -> 6139570720 [dir=none]
	6139570720 [label="result2
 (480)" fillcolor=orange]
	6141676848 -> 6137829376 [dir=none]
	6137829376 [label="running_mean
 (480)" fillcolor=orange]
	6141676848 -> 6137829696 [dir=none]
	6137829696 [label="running_var
 (480)" fillcolor=orange]
	6141676848 -> 6137829536 [dir=none]
	6137829536 [label="weight
 (480)" fillcolor=orange]
	6141676848 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141676800 -> 6141676848
	6141676800 -> 6140365456 [dir=none]
	6140365456 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6141676800 -> 6137829456 [dir=none]
	6137829456 [label="weight
 (480, 80, 1, 1)" fillcolor=orange]
	6141676800 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141590832 -> 6141676800
	6141590832 [label="AddBackward0
------------
alpha: 1"]
	6141677664 -> 6141590832
	6141677664 -> 6140365296 [dir=none]
	6140365296 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6141677664 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141677712 -> 6141677664
	6141677712 -> 6139572560 [dir=none]
	6139572560 [label="other
 ()" fillcolor=orange]
	6141677712 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141677856 -> 6141677712
	6141677856 -> 6140365536 [dir=none]
	6140365536 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6141677856 -> 6139572800 [dir=none]
	6139572800 [label="result1
 (80)" fillcolor=orange]
	6141677856 -> 6139573840 [dir=none]
	6139573840 [label="result2
 (80)" fillcolor=orange]
	6141677856 -> 6137828736 [dir=none]
	6137828736 [label="running_mean
 (80)" fillcolor=orange]
	6141677856 -> 6137829056 [dir=none]
	6137829056 [label="running_var
 (80)" fillcolor=orange]
	6141677856 -> 6137828896 [dir=none]
	6137828896 [label="weight
 (80)" fillcolor=orange]
	6141677856 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141678288 -> 6141677856
	6141678288 -> 6140365616 [dir=none]
	6140365616 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6141678288 -> 6137828816 [dir=none]
	6137828816 [label="weight
 (80, 480, 1, 1)" fillcolor=orange]
	6141678288 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141678528 -> 6141678288
	6141678528 -> 6140365936 [dir=none]
	6140365936 [label="other
 (1, 480, 75, 75)" fillcolor=orange]
	6141678528 -> 6140365776 [dir=none]
	6140365776 [label="self
 (1, 480, 1, 1)" fillcolor=orange]
	6141678528 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6141678912 -> 6141678528
	6141678912 -> 6139570000 [dir=none]
	6139570000 [label="result
 (1, 480, 1, 1)" fillcolor=orange]
	6141678912 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6141679104 -> 6141678912
	6141679104 -> 6140365696 [dir=none]
	6140365696 [label="input
 (1, 20, 1, 1)" fillcolor=orange]
	6141679104 -> 6137828576 [dir=none]
	6137828576 [label="weight
 (480, 20, 1, 1)" fillcolor=orange]
	6141679104 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (480,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141947776 -> 6141679104
	6141947776 [label=SwishImplementationBackward]
	6141680112 -> 6141947776
	6141680112 -> 6140365216 [dir=none]
	6140365216 [label="input
 (1, 480, 1, 1)" fillcolor=orange]
	6141680112 -> 6137828336 [dir=none]
	6137828336 [label="weight
 (20, 480, 1, 1)" fillcolor=orange]
	6141680112 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (20,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141680064 -> 6141680112
	6141680064 -> 6140365936 [dir=none]
	6140365936 [label="self
 (1, 480, 75, 75)" fillcolor=orange]
	6141680064 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 480, 75, 75)"]
	6141947552 -> 6141680064
	6141947552 [label=SwishImplementationBackward]
	6141680736 -> 6141947552
	6141680736 -> 6140366576 [dir=none]
	6140366576 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6141680736 -> 6139571760 [dir=none]
	6139571760 [label="result1
 (480)" fillcolor=orange]
	6141680736 -> 6139574400 [dir=none]
	6139574400 [label="result2
 (480)" fillcolor=orange]
	6141680736 -> 6137826016 [dir=none]
	6137826016 [label="running_mean
 (480)" fillcolor=orange]
	6141680736 -> 6137827856 [dir=none]
	6137827856 [label="running_var
 (480)" fillcolor=orange]
	6141680736 -> 6137827616 [dir=none]
	6137827616 [label="weight
 (480)" fillcolor=orange]
	6141680736 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141680976 -> 6141680736
	6141680976 -> 6140366656 [dir=none]
	6140366656 [label="input
 (1, 480, 79, 79)" fillcolor=orange]
	6141680976 -> 6137827696 [dir=none]
	6137827696 [label="weight
 (480, 1, 5, 5)" fillcolor=orange]
	6141680976 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            480
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141681120 -> 6141680976
	6141681120 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6141947328 -> 6141681120
	6141947328 [label=SwishImplementationBackward]
	6141681600 -> 6141947328
	6141681600 -> 6140368016 [dir=none]
	6140368016 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6141681600 -> 6138735376 [dir=none]
	6138735376 [label="result1
 (480)" fillcolor=orange]
	6141681600 -> 6138736016 [dir=none]
	6138736016 [label="result2
 (480)" fillcolor=orange]
	6141681600 -> 6137826896 [dir=none]
	6137826896 [label="running_mean
 (480)" fillcolor=orange]
	6141681600 -> 6137827216 [dir=none]
	6137827216 [label="running_var
 (480)" fillcolor=orange]
	6141681600 -> 6137827056 [dir=none]
	6137827056 [label="weight
 (480)" fillcolor=orange]
	6141681600 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141682128 -> 6141681600
	6141682128 -> 6140367136 [dir=none]
	6140367136 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6141682128 -> 6137826976 [dir=none]
	6137826976 [label="weight
 (480, 80, 1, 1)" fillcolor=orange]
	6141682128 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141677568 -> 6141682128
	6141677568 [label="AddBackward0
------------
alpha: 1"]
	6141682608 -> 6141677568
	6141682608 -> 6140366976 [dir=none]
	6140366976 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6141682608 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141683136 -> 6141682608
	6141683136 -> 6138732896 [dir=none]
	6138732896 [label="other
 ()" fillcolor=orange]
	6141683136 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141683088 -> 6141683136
	6141683088 -> 6140367456 [dir=none]
	6140367456 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6141683088 -> 6138729376 [dir=none]
	6138729376 [label="result1
 (80)" fillcolor=orange]
	6141683088 -> 6137547968 [dir=none]
	6137547968 [label="result2
 (80)" fillcolor=orange]
	6141683088 -> 6137826256 [dir=none]
	6137826256 [label="running_mean
 (80)" fillcolor=orange]
	6141683088 -> 6137826576 [dir=none]
	6137826576 [label="running_var
 (80)" fillcolor=orange]
	6141683088 -> 6137826416 [dir=none]
	6137826416 [label="weight
 (80)" fillcolor=orange]
	6141683088 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141683376 -> 6141683088
	6141683376 -> 6140367616 [dir=none]
	6140367616 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6141683376 -> 6137826336 [dir=none]
	6137826336 [label="weight
 (80, 480, 1, 1)" fillcolor=orange]
	6141683376 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141683856 -> 6141683376
	6141683856 -> 6140368176 [dir=none]
	6140368176 [label="other
 (1, 480, 75, 75)" fillcolor=orange]
	6141683856 -> 6140367936 [dir=none]
	6140367936 [label="self
 (1, 480, 1, 1)" fillcolor=orange]
	6141683856 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6141683904 -> 6141683856
	6141683904 -> 6137560208 [dir=none]
	6137560208 [label="result
 (1, 480, 1, 1)" fillcolor=orange]
	6141683904 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6141684144 -> 6141683904
	6141684144 -> 6140367776 [dir=none]
	6140367776 [label="input
 (1, 20, 1, 1)" fillcolor=orange]
	6141684144 -> 6137826096 [dir=none]
	6137826096 [label="weight
 (480, 20, 1, 1)" fillcolor=orange]
	6141684144 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (480,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141947104 -> 6141684144
	6141947104 [label=SwishImplementationBackward]
	6141684720 -> 6141947104
	6141684720 -> 6140368576 [dir=none]
	6140368576 [label="input
 (1, 480, 1, 1)" fillcolor=orange]
	6141684720 -> 6137825856 [dir=none]
	6137825856 [label="weight
 (20, 480, 1, 1)" fillcolor=orange]
	6141684720 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (20,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141685296 -> 6141684720
	6141685296 -> 6140368176 [dir=none]
	6140368176 [label="self
 (1, 480, 75, 75)" fillcolor=orange]
	6141685296 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 480, 75, 75)"]
	6141946880 -> 6141685296
	6141946880 [label=SwishImplementationBackward]
	6141685680 -> 6141946880
	6141685680 -> 6140368896 [dir=none]
	6140368896 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6141685680 -> 6140101872 [dir=none]
	6140101872 [label="result1
 (480)" fillcolor=orange]
	6141685680 -> 6140109472 [dir=none]
	6140109472 [label="result2
 (480)" fillcolor=orange]
	6141685680 -> 6137560848 [dir=none]
	6137560848 [label="running_mean
 (480)" fillcolor=orange]
	6141685680 -> 6137825376 [dir=none]
	6137825376 [label="running_var
 (480)" fillcolor=orange]
	6141685680 -> 6137825136 [dir=none]
	6137825136 [label="weight
 (480)" fillcolor=orange]
	6141685680 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141686112 -> 6141685680
	6141686112 -> 6140369056 [dir=none]
	6140369056 [label="input
 (1, 480, 79, 79)" fillcolor=orange]
	6141686112 -> 6137825216 [dir=none]
	6137825216 [label="weight
 (480, 1, 5, 5)" fillcolor=orange]
	6141686112 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            480
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141686352 -> 6141686112
	6141686352 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6141946656 -> 6141686352
	6141946656 [label=SwishImplementationBackward]
	6141686736 -> 6141946656
	6141686736 -> 6140370176 [dir=none]
	6140370176 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	6141686736 -> 6140103952 [dir=none]
	6140103952 [label="result1
 (480)" fillcolor=orange]
	6141686736 -> 6140102752 [dir=none]
	6140102752 [label="result2
 (480)" fillcolor=orange]
	6141686736 -> 6137824416 [dir=none]
	6137824416 [label="running_mean
 (480)" fillcolor=orange]
	6141686736 -> 6137824736 [dir=none]
	6137824736 [label="running_var
 (480)" fillcolor=orange]
	6141686736 -> 6137824576 [dir=none]
	6137824576 [label="weight
 (480)" fillcolor=orange]
	6141686736 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141686928 -> 6141686736
	6141686928 -> 6140369296 [dir=none]
	6140369296 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6141686928 -> 6137824496 [dir=none]
	6137824496 [label="weight
 (480, 80, 1, 1)" fillcolor=orange]
	6141686928 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141682224 -> 6141686928
	6141682224 -> 6140369376 [dir=none]
	6140369376 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	6141682224 -> 6140104832 [dir=none]
	6140104832 [label="result1
 (80)" fillcolor=orange]
	6141682224 -> 6140107232 [dir=none]
	6140107232 [label="result2
 (80)" fillcolor=orange]
	6141682224 -> 6137823856 [dir=none]
	6137823856 [label="running_mean
 (80)" fillcolor=orange]
	6141682224 -> 6137824176 [dir=none]
	6137824176 [label="running_var
 (80)" fillcolor=orange]
	6141682224 -> 6137824016 [dir=none]
	6137824016 [label="weight
 (80)" fillcolor=orange]
	6141682224 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141687888 -> 6141682224
	6141687888 -> 6140369696 [dir=none]
	6140369696 [label="input
 (1, 288, 75, 75)" fillcolor=orange]
	6141687888 -> 6137823936 [dir=none]
	6137823936 [label="weight
 (80, 288, 1, 1)" fillcolor=orange]
	6141687888 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141688128 -> 6141687888
	6141688128 -> 6140370336 [dir=none]
	6140370336 [label="other
 (1, 288, 75, 75)" fillcolor=orange]
	6141688128 -> 6140370016 [dir=none]
	6140370016 [label="self
 (1, 288, 1, 1)" fillcolor=orange]
	6141688128 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6141688896 -> 6141688128
	6141688896 -> 6140109072 [dir=none]
	6140109072 [label="result
 (1, 288, 1, 1)" fillcolor=orange]
	6141688896 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6141688848 -> 6141688896
	6141688848 -> 6140369856 [dir=none]
	6140369856 [label="input
 (1, 12, 1, 1)" fillcolor=orange]
	6141688848 -> 6137823696 [dir=none]
	6137823696 [label="weight
 (288, 12, 1, 1)" fillcolor=orange]
	6141688848 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (288,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141946432 -> 6141688848
	6141946432 [label=SwishImplementationBackward]
	6141689376 -> 6141946432
	6141689376 -> 6140370736 [dir=none]
	6140370736 [label="input
 (1, 288, 1, 1)" fillcolor=orange]
	6141689376 -> 6137823456 [dir=none]
	6137823456 [label="weight
 (12, 288, 1, 1)" fillcolor=orange]
	6141689376 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (12,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141689616 -> 6141689376
	6141689616 -> 6140370336 [dir=none]
	6140370336 [label="self
 (1, 288, 75, 75)" fillcolor=orange]
	6141689616 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 288, 75, 75)"]
	6141946208 -> 6141689616
	6141946208 [label=SwishImplementationBackward]
	6141739216 -> 6141946208
	6141739216 -> 6140371376 [dir=none]
	6140371376 [label="input
 (1, 288, 75, 75)" fillcolor=orange]
	6141739216 -> 6140115472 [dir=none]
	6140115472 [label="result1
 (288)" fillcolor=orange]
	6141739216 -> 6140105232 [dir=none]
	6140105232 [label="result2
 (288)" fillcolor=orange]
	6141739216 -> 6137558928 [dir=none]
	6137558928 [label="running_mean
 (288)" fillcolor=orange]
	6141739216 -> 6137560768 [dir=none]
	6137560768 [label="running_var
 (288)" fillcolor=orange]
	6141739216 -> 6137560528 [dir=none]
	6137560528 [label="weight
 (288)" fillcolor=orange]
	6141739216 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141739264 -> 6141739216
	6141739264 -> 6138133168 [dir=none]
	6138133168 [label="input
 (1, 288, 153, 153)" fillcolor=orange]
	6141739264 -> 6137560608 [dir=none]
	6137560608 [label="weight
 (288, 1, 5, 5)" fillcolor=orange]
	6141739264 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            288
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	6141739840 -> 6141739264
	6141739840 [label="ConstantPadNdBackward0
----------------------
pad: (1, 2, 1, 2)"]
	6141945984 -> 6141739840
	6141945984 [label=SwishImplementationBackward]
	6141743344 -> 6141945984
	6141743344 -> 6140372736 [dir=none]
	6140372736 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6141743344 -> 6140113072 [dir=none]
	6140113072 [label="result1
 (288)" fillcolor=orange]
	6141743344 -> 6140111632 [dir=none]
	6140111632 [label="result2
 (288)" fillcolor=orange]
	6141743344 -> 6137559808 [dir=none]
	6137559808 [label="running_mean
 (288)" fillcolor=orange]
	6141743344 -> 6137560128 [dir=none]
	6137560128 [label="running_var
 (288)" fillcolor=orange]
	6141743344 -> 6137559968 [dir=none]
	6137559968 [label="weight
 (288)" fillcolor=orange]
	6141743344 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141740464 -> 6141743344
	6141740464 -> 6140371856 [dir=none]
	6140371856 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	6141740464 -> 6137559888 [dir=none]
	6137559888 [label="weight
 (288, 48, 1, 1)" fillcolor=orange]
	6141740464 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141740608 -> 6141740464
	6141740608 [label="AddBackward0
------------
alpha: 1"]
	6141741376 -> 6141740608
	6141741376 -> 6140371696 [dir=none]
	6140371696 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6141741376 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141741568 -> 6141741376
	6141741568 -> 6140101232 [dir=none]
	6140101232 [label="other
 ()" fillcolor=orange]
	6141741568 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141741760 -> 6141741568
	6141741760 -> 6140372016 [dir=none]
	6140372016 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	6141741760 -> 6140106432 [dir=none]
	6140106432 [label="result1
 (48)" fillcolor=orange]
	6141741760 -> 6140105552 [dir=none]
	6140105552 [label="result2
 (48)" fillcolor=orange]
	6141741760 -> 6137559168 [dir=none]
	6137559168 [label="running_mean
 (48)" fillcolor=orange]
	6141741760 -> 6137559488 [dir=none]
	6137559488 [label="running_var
 (48)" fillcolor=orange]
	6141741760 -> 6137559328 [dir=none]
	6137559328 [label="weight
 (48)" fillcolor=orange]
	6141741760 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141741856 -> 6141741760
	6141741856 -> 6140372176 [dir=none]
	6140372176 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6141741856 -> 6137559248 [dir=none]
	6137559248 [label="weight
 (48, 288, 1, 1)" fillcolor=orange]
	6141741856 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141742576 -> 6141741856
	6141742576 -> 6140372896 [dir=none]
	6140372896 [label="other
 (1, 288, 150, 150)" fillcolor=orange]
	6141742576 -> 6140372416 [dir=none]
	6140372416 [label="self
 (1, 288, 1, 1)" fillcolor=orange]
	6141742576 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6141742624 -> 6141742576
	6141742624 -> 6140102672 [dir=none]
	6140102672 [label="result
 (1, 288, 1, 1)" fillcolor=orange]
	6141742624 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6141743008 -> 6141742624
	6141743008 -> 6140372336 [dir=none]
	6140372336 [label="input
 (1, 12, 1, 1)" fillcolor=orange]
	6141743008 -> 6137559008 [dir=none]
	6137559008 [label="weight
 (288, 12, 1, 1)" fillcolor=orange]
	6141743008 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (288,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141945760 -> 6141743008
	6141945760 [label=SwishImplementationBackward]
	6141743488 -> 6141945760
	6141743488 -> 6140373216 [dir=none]
	6140373216 [label="input
 (1, 288, 1, 1)" fillcolor=orange]
	6141743488 -> 6137558768 [dir=none]
	6137558768 [label="weight
 (12, 288, 1, 1)" fillcolor=orange]
	6141743488 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (12,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141743776 -> 6141743488
	6141743776 -> 6140372896 [dir=none]
	6140372896 [label="self
 (1, 288, 150, 150)" fillcolor=orange]
	6141743776 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                           (1, 288, 150, 150)"]
	6141945536 -> 6141743776
	6141945536 [label=SwishImplementationBackward]
	6141744640 -> 6141945536
	6141744640 -> 6140373856 [dir=none]
	6140373856 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6141744640 -> 6140116032 [dir=none]
	6140116032 [label="result1
 (288)" fillcolor=orange]
	6141744640 -> 6140113312 [dir=none]
	6140113312 [label="result2
 (288)" fillcolor=orange]
	6141744640 -> 6137556448 [dir=none]
	6137556448 [label="running_mean
 (288)" fillcolor=orange]
	6141744640 -> 6137558288 [dir=none]
	6137558288 [label="running_var
 (288)" fillcolor=orange]
	6141744640 -> 6137558048 [dir=none]
	6137558048 [label="weight
 (288)" fillcolor=orange]
	6141744640 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141744592 -> 6141744640
	6141744592 -> 6139004784 [dir=none]
	6139004784 [label="input
 (1, 288, 152, 152)" fillcolor=orange]
	6141744592 -> 6137558128 [dir=none]
	6137558128 [label="weight
 (288, 1, 3, 3)" fillcolor=orange]
	6141744592 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            288
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141745120 -> 6141744592
	6141745120 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6141945312 -> 6141745120
	6141945312 [label=SwishImplementationBackward]
	6141745840 -> 6141945312
	6141745840 -> 6140374976 [dir=none]
	6140374976 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6141745840 -> 6140033952 [dir=none]
	6140033952 [label="result1
 (288)" fillcolor=orange]
	6141745840 -> 6140022672 [dir=none]
	6140022672 [label="result2
 (288)" fillcolor=orange]
	6141745840 -> 6137557328 [dir=none]
	6137557328 [label="running_mean
 (288)" fillcolor=orange]
	6141745840 -> 6137557648 [dir=none]
	6137557648 [label="running_var
 (288)" fillcolor=orange]
	6141745840 -> 6137557488 [dir=none]
	6137557488 [label="weight
 (288)" fillcolor=orange]
	6141745840 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141746128 -> 6141745840
	6141746128 -> 6140374176 [dir=none]
	6140374176 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	6141746128 -> 6137557408 [dir=none]
	6137557408 [label="weight
 (288, 48, 1, 1)" fillcolor=orange]
	6141746128 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141740848 -> 6141746128
	6141740848 [label="AddBackward0
------------
alpha: 1"]
	6141749488 -> 6141740848
	6141749488 -> 6140374016 [dir=none]
	6140374016 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6141749488 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141747136 -> 6141749488
	6141747136 -> 6140020432 [dir=none]
	6140020432 [label="other
 ()" fillcolor=orange]
	6141747136 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141747376 -> 6141747136
	6141747376 -> 6140374336 [dir=none]
	6140374336 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	6141747376 -> 6140023072 [dir=none]
	6140023072 [label="result1
 (48)" fillcolor=orange]
	6141747376 -> 6140025552 [dir=none]
	6140025552 [label="result2
 (48)" fillcolor=orange]
	6141747376 -> 6137556688 [dir=none]
	6137556688 [label="running_mean
 (48)" fillcolor=orange]
	6141747376 -> 6137557008 [dir=none]
	6137557008 [label="running_var
 (48)" fillcolor=orange]
	6141747376 -> 6137556848 [dir=none]
	6137556848 [label="weight
 (48)" fillcolor=orange]
	6141747376 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141747328 -> 6141747376
	6141747328 -> 6140374416 [dir=none]
	6140374416 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6141747328 -> 6137556768 [dir=none]
	6137556768 [label="weight
 (48, 288, 1, 1)" fillcolor=orange]
	6141747328 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141747472 -> 6141747328
	6141747472 -> 6140375216 [dir=none]
	6140375216 [label="other
 (1, 288, 150, 150)" fillcolor=orange]
	6141747472 -> 6140374896 [dir=none]
	6140374896 [label="self
 (1, 288, 1, 1)" fillcolor=orange]
	6141747472 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6141747904 -> 6141747472
	6141747904 -> 6140024032 [dir=none]
	6140024032 [label="result
 (1, 288, 1, 1)" fillcolor=orange]
	6141747904 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6141748000 -> 6141747904
	6141748000 -> 6140374736 [dir=none]
	6140374736 [label="input
 (1, 12, 1, 1)" fillcolor=orange]
	6141748000 -> 6137556528 [dir=none]
	6137556528 [label="weight
 (288, 12, 1, 1)" fillcolor=orange]
	6141748000 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (288,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141945088 -> 6141748000
	6141945088 [label=SwishImplementationBackward]
	6141748912 -> 6141945088
	6141748912 -> 6140375696 [dir=none]
	6140375696 [label="input
 (1, 288, 1, 1)" fillcolor=orange]
	6141748912 -> 6137556288 [dir=none]
	6137556288 [label="weight
 (12, 288, 1, 1)" fillcolor=orange]
	6141748912 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (12,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141748864 -> 6141748912
	6141748864 -> 6140375216 [dir=none]
	6140375216 [label="self
 (1, 288, 150, 150)" fillcolor=orange]
	6141748864 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                           (1, 288, 150, 150)"]
	6141944864 -> 6141748864
	6141944864 [label=SwishImplementationBackward]
	6141752512 -> 6141944864
	6141752512 -> 6140376176 [dir=none]
	6140376176 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6141752512 -> 6140019552 [dir=none]
	6140019552 [label="result1
 (288)" fillcolor=orange]
	6141752512 -> 6140028832 [dir=none]
	6140028832 [label="result2
 (288)" fillcolor=orange]
	6141752512 -> 6137554048 [dir=none]
	6137554048 [label="running_mean
 (288)" fillcolor=orange]
	6141752512 -> 6137555808 [dir=none]
	6137555808 [label="running_var
 (288)" fillcolor=orange]
	6141752512 -> 6137555568 [dir=none]
	6137555568 [label="weight
 (288)" fillcolor=orange]
	6141752512 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141749632 -> 6141752512
	6141749632 -> 6140376256 [dir=none]
	6140376256 [label="input
 (1, 288, 152, 152)" fillcolor=orange]
	6141749632 -> 6137555648 [dir=none]
	6137555648 [label="weight
 (288, 1, 3, 3)" fillcolor=orange]
	6141749632 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            288
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141749872 -> 6141749632
	6141749872 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6141944640 -> 6141749872
	6141944640 [label=SwishImplementationBackward]
	6141750592 -> 6141944640
	6141750592 -> 6140377456 [dir=none]
	6140377456 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6141750592 -> 6140029072 [dir=none]
	6140029072 [label="result1
 (288)" fillcolor=orange]
	6141750592 -> 6140032752 [dir=none]
	6140032752 [label="result2
 (288)" fillcolor=orange]
	6141750592 -> 6137554848 [dir=none]
	6137554848 [label="running_mean
 (288)" fillcolor=orange]
	6141750592 -> 6137555168 [dir=none]
	6137555168 [label="running_var
 (288)" fillcolor=orange]
	6141750592 -> 6137555008 [dir=none]
	6137555008 [label="weight
 (288)" fillcolor=orange]
	6141750592 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141750880 -> 6141750592
	6141750880 -> 6140376496 [dir=none]
	6140376496 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	6141750880 -> 6137554928 [dir=none]
	6137554928 [label="weight
 (288, 48, 1, 1)" fillcolor=orange]
	6141750880 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141746416 -> 6141750880
	6141746416 [label="AddBackward0
------------
alpha: 1"]
	6141751360 -> 6141746416
	6141751360 -> 6140376416 [dir=none]
	6140376416 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6141751360 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141752032 -> 6141751360
	6141752032 -> 6140034672 [dir=none]
	6140034672 [label="other
 ()" fillcolor=orange]
	6141752032 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141751984 -> 6141752032
	6141751984 -> 6140376816 [dir=none]
	6140376816 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	6141751984 -> 6140028912 [dir=none]
	6140028912 [label="result1
 (48)" fillcolor=orange]
	6141751984 -> 6140024672 [dir=none]
	6140024672 [label="result2
 (48)" fillcolor=orange]
	6141751984 -> 6137554288 [dir=none]
	6137554288 [label="running_mean
 (48)" fillcolor=orange]
	6141751984 -> 6137554608 [dir=none]
	6137554608 [label="running_var
 (48)" fillcolor=orange]
	6141751984 -> 6137554448 [dir=none]
	6137554448 [label="weight
 (48)" fillcolor=orange]
	6141751984 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141752176 -> 6141751984
	6141752176 -> 6140376976 [dir=none]
	6140376976 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6141752176 -> 6137554368 [dir=none]
	6137554368 [label="weight
 (48, 288, 1, 1)" fillcolor=orange]
	6141752176 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141752800 -> 6141752176
	6141752800 -> 6140377696 [dir=none]
	6140377696 [label="other
 (1, 288, 150, 150)" fillcolor=orange]
	6141752800 -> 6140377296 [dir=none]
	6140377296 [label="self
 (1, 288, 1, 1)" fillcolor=orange]
	6141752800 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6141752944 -> 6141752800
	6141752944 -> 6140031392 [dir=none]
	6140031392 [label="result
 (1, 288, 1, 1)" fillcolor=orange]
	6141752944 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6141752896 -> 6141752944
	6141752896 -> 6140377136 [dir=none]
	6140377136 [label="input
 (1, 12, 1, 1)" fillcolor=orange]
	6141752896 -> 6137554128 [dir=none]
	6137554128 [label="weight
 (288, 12, 1, 1)" fillcolor=orange]
	6141752896 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (288,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141944416 -> 6141752896
	6141944416 [label=SwishImplementationBackward]
	6141753856 -> 6141944416
	6141753856 -> 6140378016 [dir=none]
	6140378016 [label="input
 (1, 288, 1, 1)" fillcolor=orange]
	6141753856 -> 6137553888 [dir=none]
	6137553888 [label="weight
 (12, 288, 1, 1)" fillcolor=orange]
	6141753856 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (12,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141754048 -> 6141753856
	6141754048 -> 6140377696 [dir=none]
	6140377696 [label="self
 (1, 288, 150, 150)" fillcolor=orange]
	6141754048 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                           (1, 288, 150, 150)"]
	6141944192 -> 6141754048
	6141944192 [label=SwishImplementationBackward]
	6141754672 -> 6141944192
	6141754672 -> 6140378496 [dir=none]
	6140378496 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6141754672 -> 6140033632 [dir=none]
	6140033632 [label="result1
 (288)" fillcolor=orange]
	6141754672 -> 6140027632 [dir=none]
	6140027632 [label="result2
 (288)" fillcolor=orange]
	6141754672 -> 6137551648 [dir=none]
	6137551648 [label="running_mean
 (288)" fillcolor=orange]
	6141754672 -> 6137553408 [dir=none]
	6137553408 [label="running_var
 (288)" fillcolor=orange]
	6141754672 -> 6137553168 [dir=none]
	6137553168 [label="weight
 (288)" fillcolor=orange]
	6141754672 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141754912 -> 6141754672
	6141754912 -> 6140378576 [dir=none]
	6140378576 [label="input
 (1, 288, 152, 152)" fillcolor=orange]
	6141754912 -> 6137553248 [dir=none]
	6137553248 [label="weight
 (288, 1, 3, 3)" fillcolor=orange]
	6141754912 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            288
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141755296 -> 6141754912
	6141755296 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6141943968 -> 6141755296
	6141943968 [label=SwishImplementationBackward]
	6141860864 -> 6141943968
	6141860864 -> 6140364816 [dir=none]
	6140364816 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6141860864 -> 6139018384 [dir=none]
	6139018384 [label="result1
 (288)" fillcolor=orange]
	6141860864 -> 6139007824 [dir=none]
	6139007824 [label="result2
 (288)" fillcolor=orange]
	6141860864 -> 6137552448 [dir=none]
	6137552448 [label="running_mean
 (288)" fillcolor=orange]
	6141860864 -> 6137552768 [dir=none]
	6137552768 [label="running_var
 (288)" fillcolor=orange]
	6141860864 -> 6137552608 [dir=none]
	6137552608 [label="weight
 (288)" fillcolor=orange]
	6141860864 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141854048 -> 6141860864
	6141854048 -> 6140378976 [dir=none]
	6140378976 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	6141854048 -> 6137552528 [dir=none]
	6137552528 [label="weight
 (288, 48, 1, 1)" fillcolor=orange]
	6141854048 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141751600 -> 6141854048
	6141751600 [label="AddBackward0
------------
alpha: 1"]
	6141854576 -> 6141751600
	6141854576 -> 6140378656 [dir=none]
	6140378656 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6141854576 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141854912 -> 6141854576
	6141854912 -> 6139855632 [dir=none]
	6139855632 [label="other
 ()" fillcolor=orange]
	6141854912 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141855104 -> 6141854912
	6141855104 -> 6140362976 [dir=none]
	6140362976 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	6141855104 -> 6139857712 [dir=none]
	6139857712 [label="result1
 (48)" fillcolor=orange]
	6141855104 -> 6139856672 [dir=none]
	6139856672 [label="result2
 (48)" fillcolor=orange]
	6141855104 -> 6137551888 [dir=none]
	6137551888 [label="running_mean
 (48)" fillcolor=orange]
	6141855104 -> 6137552208 [dir=none]
	6137552208 [label="running_var
 (48)" fillcolor=orange]
	6141855104 -> 6137552048 [dir=none]
	6137552048 [label="weight
 (48)" fillcolor=orange]
	6141855104 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141855056 -> 6141855104
	6141855056 -> 6140363216 [dir=none]
	6140363216 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6141855056 -> 6137551968 [dir=none]
	6137551968 [label="weight
 (48, 288, 1, 1)" fillcolor=orange]
	6141855056 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141856976 -> 6141855056
	6141856976 -> 6140364976 [dir=none]
	6140364976 [label="other
 (1, 288, 150, 150)" fillcolor=orange]
	6141856976 -> 6140364256 [dir=none]
	6140364256 [label="self
 (1, 288, 1, 1)" fillcolor=orange]
	6141856976 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6141855680 -> 6141856976
	6141855680 -> 6139859232 [dir=none]
	6139859232 [label="result
 (1, 288, 1, 1)" fillcolor=orange]
	6141855680 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6141856064 -> 6141855680
	6141856064 -> 6140363456 [dir=none]
	6140363456 [label="input
 (1, 12, 1, 1)" fillcolor=orange]
	6141856064 -> 6137551728 [dir=none]
	6137551728 [label="weight
 (288, 12, 1, 1)" fillcolor=orange]
	6141856064 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (288,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141943744 -> 6141856064
	6141943744 [label=SwishImplementationBackward]
	6141856544 -> 6141943744
	6141856544 -> 6140366816 [dir=none]
	6140366816 [label="input
 (1, 288, 1, 1)" fillcolor=orange]
	6141856544 -> 6137551488 [dir=none]
	6137551488 [label="weight
 (12, 288, 1, 1)" fillcolor=orange]
	6141856544 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (12,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141856832 -> 6141856544
	6141856832 -> 6140364976 [dir=none]
	6140364976 [label="self
 (1, 288, 150, 150)" fillcolor=orange]
	6141856832 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                           (1, 288, 150, 150)"]
	6141943520 -> 6141856832
	6141943520 [label=SwishImplementationBackward]
	6141857552 -> 6141943520
	6141857552 -> 6140367536 [dir=none]
	6140367536 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6141857552 -> 6139864992 [dir=none]
	6139864992 [label="result1
 (288)" fillcolor=orange]
	6141857552 -> 6139912544 [dir=none]
	6139912544 [label="result2
 (288)" fillcolor=orange]
	6141857552 -> 6137549168 [dir=none]
	6137549168 [label="running_mean
 (288)" fillcolor=orange]
	6141857552 -> 6137551008 [dir=none]
	6137551008 [label="running_var
 (288)" fillcolor=orange]
	6141857552 -> 6137550768 [dir=none]
	6137550768 [label="weight
 (288)" fillcolor=orange]
	6141857552 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141857840 -> 6141857552
	6141857840 -> 6140368096 [dir=none]
	6140368096 [label="input
 (1, 288, 152, 152)" fillcolor=orange]
	6141857840 -> 6137550848 [dir=none]
	6137550848 [label="weight
 (288, 1, 3, 3)" fillcolor=orange]
	6141857840 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            288
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141858080 -> 6141857840
	6141858080 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6141943296 -> 6141858080
	6141943296 [label=SwishImplementationBackward]
	6141858320 -> 6141943296
	6141858320 -> 6140370256 [dir=none]
	6140370256 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6141858320 -> 6139909744 [dir=none]
	6139909744 [label="result1
 (288)" fillcolor=orange]
	6141858320 -> 6139906064 [dir=none]
	6139906064 [label="result2
 (288)" fillcolor=orange]
	6141858320 -> 6137550048 [dir=none]
	6137550048 [label="running_mean
 (288)" fillcolor=orange]
	6141858320 -> 6137550368 [dir=none]
	6137550368 [label="running_var
 (288)" fillcolor=orange]
	6141858320 -> 6137550208 [dir=none]
	6137550208 [label="weight
 (288)" fillcolor=orange]
	6141858320 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141858608 -> 6141858320
	6141858608 -> 6140368976 [dir=none]
	6140368976 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	6141858608 -> 6137550128 [dir=none]
	6137550128 [label="weight
 (288, 48, 1, 1)" fillcolor=orange]
	6141858608 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141854288 -> 6141858608
	6141854288 [label="AddBackward0
------------
alpha: 1"]
	6141860624 -> 6141854288
	6141860624 -> 6140368816 [dir=none]
	6140368816 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6141860624 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141860000 -> 6141860624
	6141860000 -> 6139907664 [dir=none]
	6139907664 [label="other
 ()" fillcolor=orange]
	6141860000 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141860240 -> 6141860000
	6141860240 -> 6140369536 [dir=none]
	6140369536 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	6141860240 -> 6139909904 [dir=none]
	6139909904 [label="result1
 (48)" fillcolor=orange]
	6141860240 -> 6139907984 [dir=none]
	6139907984 [label="result2
 (48)" fillcolor=orange]
	6141860240 -> 6137549408 [dir=none]
	6137549408 [label="running_mean
 (48)" fillcolor=orange]
	6141860240 -> 6137549728 [dir=none]
	6137549728 [label="running_var
 (48)" fillcolor=orange]
	6141860240 -> 6137549568 [dir=none]
	6137549568 [label="weight
 (48)" fillcolor=orange]
	6141860240 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141860192 -> 6141860240
	6141860192 -> 6140369776 [dir=none]
	6140369776 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	6141860192 -> 6137549488 [dir=none]
	6137549488 [label="weight
 (48, 288, 1, 1)" fillcolor=orange]
	6141860192 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141860336 -> 6141860192
	6141860336 -> 6140370576 [dir=none]
	6140370576 [label="other
 (1, 288, 150, 150)" fillcolor=orange]
	6141860336 -> 6140370096 [dir=none]
	6140370096 [label="self
 (1, 288, 1, 1)" fillcolor=orange]
	6141860336 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6141861488 -> 6141860336
	6141861488 -> 6139907024 [dir=none]
	6139907024 [label="result
 (1, 288, 1, 1)" fillcolor=orange]
	6141861488 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6141861056 -> 6141861488
	6141861056 -> 6140369936 [dir=none]
	6140369936 [label="input
 (1, 12, 1, 1)" fillcolor=orange]
	6141861056 -> 6137549248 [dir=none]
	6137549248 [label="weight
 (288, 12, 1, 1)" fillcolor=orange]
	6141861056 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (288,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141943072 -> 6141861056
	6141943072 [label=SwishImplementationBackward]
	11135954144 -> 6141943072
	11135954144 -> 6140371056 [dir=none]
	6140371056 [label="input
 (1, 288, 1, 1)" fillcolor=orange]
	11135954144 -> 6137549008 [dir=none]
	6137549008 [label="weight
 (12, 288, 1, 1)" fillcolor=orange]
	11135954144 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (12,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135953664 -> 11135954144
	11135953664 -> 6140370576 [dir=none]
	6140370576 [label="self
 (1, 288, 150, 150)" fillcolor=orange]
	11135953664 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                           (1, 288, 150, 150)"]
	6141942848 -> 11135953664
	6141942848 [label=SwishImplementationBackward]
	11135954528 -> 6141942848
	11135954528 -> 6140371776 [dir=none]
	6140371776 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	11135954528 -> 6139910544 [dir=none]
	6139910544 [label="result1
 (288)" fillcolor=orange]
	11135954528 -> 6139915504 [dir=none]
	6139915504 [label="result2
 (288)" fillcolor=orange]
	11135954528 -> 6137546768 [dir=none]
	6137546768 [label="running_mean
 (288)" fillcolor=orange]
	11135954528 -> 6137548528 [dir=none]
	6137548528 [label="running_var
 (288)" fillcolor=orange]
	11135954528 -> 6137548288 [dir=none]
	6137548288 [label="weight
 (288)" fillcolor=orange]
	11135954528 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135955584 -> 11135954528
	11135955584 -> 6140371936 [dir=none]
	6140371936 [label="input
 (1, 288, 152, 152)" fillcolor=orange]
	11135955584 -> 6137548368 [dir=none]
	6137548368 [label="weight
 (288, 1, 3, 3)" fillcolor=orange]
	11135955584 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            288
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135954384 -> 11135955584
	11135954384 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6141942624 -> 11135954384
	6141942624 [label=SwishImplementationBackward]
	11135954816 -> 6141942624
	11135954816 -> 6138123888 [dir=none]
	6138123888 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	11135954816 -> 6139915664 [dir=none]
	6139915664 [label="result1
 (288)" fillcolor=orange]
	11135954816 -> 6139918704 [dir=none]
	6139918704 [label="result2
 (288)" fillcolor=orange]
	11135954816 -> 6137547568 [dir=none]
	6137547568 [label="running_mean
 (288)" fillcolor=orange]
	11135954816 -> 6137547888 [dir=none]
	6137547888 [label="running_var
 (288)" fillcolor=orange]
	11135954816 -> 6137547728 [dir=none]
	6137547728 [label="weight
 (288)" fillcolor=orange]
	11135954816 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135955440 -> 11135954816
	11135955440 -> 6140372256 [dir=none]
	6140372256 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	11135955440 -> 6137547648 [dir=none]
	6137547648 [label="weight
 (288, 48, 1, 1)" fillcolor=orange]
	11135955440 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141859328 -> 11135955440
	6141859328 [label="AddBackward0
------------
alpha: 1"]
	11135956112 -> 6141859328
	11135956112 -> 6140372096 [dir=none]
	6140372096 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11135956112 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135956160 -> 11135956112
	11135956160 -> 6139904224 [dir=none]
	6139904224 [label="other
 ()" fillcolor=orange]
	11135956160 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135956256 -> 11135956160
	11135956256 -> 6140372576 [dir=none]
	6140372576 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	11135956256 -> 6139915584 [dir=none]
	6139915584 [label="result1
 (48)" fillcolor=orange]
	11135956256 -> 6139912784 [dir=none]
	6139912784 [label="result2
 (48)" fillcolor=orange]
	11135956256 -> 6137547008 [dir=none]
	6137547008 [label="running_mean
 (48)" fillcolor=orange]
	11135956256 -> 6137547328 [dir=none]
	6137547328 [label="running_var
 (48)" fillcolor=orange]
	11135956256 -> 6137547168 [dir=none]
	6137547168 [label="weight
 (48)" fillcolor=orange]
	11135956256 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135956400 -> 11135956256
	11135956400 -> 6140372816 [dir=none]
	6140372816 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	11135956400 -> 6137547088 [dir=none]
	6137547088 [label="weight
 (48, 288, 1, 1)" fillcolor=orange]
	11135956400 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135956688 -> 11135956400
	11135956688 -> 6140373296 [dir=none]
	6140373296 [label="other
 (1, 288, 150, 150)" fillcolor=orange]
	11135956688 -> 6140373136 [dir=none]
	6140373136 [label="self
 (1, 288, 1, 1)" fillcolor=orange]
	11135956688 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135957024 -> 11135956688
	11135957024 -> 6139919264 [dir=none]
	6139919264 [label="result
 (1, 288, 1, 1)" fillcolor=orange]
	11135957024 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135957168 -> 11135957024
	11135957168 -> 6140372976 [dir=none]
	6140372976 [label="input
 (1, 12, 1, 1)" fillcolor=orange]
	11135957168 -> 6137546848 [dir=none]
	6137546848 [label="weight
 (288, 12, 1, 1)" fillcolor=orange]
	11135957168 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (288,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141942400 -> 11135957168
	6141942400 [label=SwishImplementationBackward]
	11135957840 -> 6141942400
	11135957840 -> 6140373776 [dir=none]
	6140373776 [label="input
 (1, 288, 1, 1)" fillcolor=orange]
	11135957840 -> 6137546608 [dir=none]
	6137546608 [label="weight
 (12, 288, 1, 1)" fillcolor=orange]
	11135957840 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (12,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135957456 -> 11135957840
	11135957456 -> 6140373296 [dir=none]
	6140373296 [label="self
 (1, 288, 150, 150)" fillcolor=orange]
	11135957456 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                           (1, 288, 150, 150)"]
	6141942176 -> 11135957456
	6141942176 [label=SwishImplementationBackward]
	11135957888 -> 6141942176
	11135957888 -> 6140374096 [dir=none]
	6140374096 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	11135957888 -> 6139919584 [dir=none]
	6139919584 [label="result1
 (288)" fillcolor=orange]
	11135957888 -> 11136093216 [dir=none]
	11136093216 [label="result2
 (288)" fillcolor=orange]
	11135957888 -> 6137298464 [dir=none]
	6137298464 [label="running_mean
 (288)" fillcolor=orange]
	11135957888 -> 6137546128 [dir=none]
	6137546128 [label="running_var
 (288)" fillcolor=orange]
	11135957888 -> 6137545888 [dir=none]
	6137545888 [label="weight
 (288)" fillcolor=orange]
	11135957888 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135958704 -> 11135957888
	11135958704 -> 6140374256 [dir=none]
	6140374256 [label="input
 (1, 288, 152, 152)" fillcolor=orange]
	11135958704 -> 6137545968 [dir=none]
	6137545968 [label="weight
 (288, 1, 3, 3)" fillcolor=orange]
	11135958704 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            288
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135958032 -> 11135958704
	11135958032 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6141941952 -> 11135958032
	6141941952 [label=SwishImplementationBackward]
	11135958560 -> 6141941952
	11135958560 -> 6140376096 [dir=none]
	6140376096 [label="input
 (1, 288, 150, 150)" fillcolor=orange]
	11135958560 -> 11136099296 [dir=none]
	11136099296 [label="result1
 (288)" fillcolor=orange]
	11135958560 -> 11136090976 [dir=none]
	11136090976 [label="result2
 (288)" fillcolor=orange]
	11135958560 -> 6137545168 [dir=none]
	6137545168 [label="running_mean
 (288)" fillcolor=orange]
	11135958560 -> 6137545488 [dir=none]
	6137545488 [label="running_var
 (288)" fillcolor=orange]
	11135958560 -> 6137545328 [dir=none]
	6137545328 [label="weight
 (288)" fillcolor=orange]
	11135958560 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135955680 -> 11135958560
	11135955680 -> 6140375056 [dir=none]
	6140375056 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	11135955680 -> 6137545248 [dir=none]
	6137545248 [label="weight
 (288, 48, 1, 1)" fillcolor=orange]
	11135955680 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135955536 -> 11135955680
	11135955536 -> 6140375296 [dir=none]
	6140375296 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	11135955536 -> 11136104656 [dir=none]
	11136104656 [label="result1
 (48)" fillcolor=orange]
	11135955536 -> 11136094736 [dir=none]
	11136094736 [label="result2
 (48)" fillcolor=orange]
	11135955536 -> 6137298704 [dir=none]
	6137298704 [label="running_mean
 (48)" fillcolor=orange]
	11135955536 -> 6137544848 [dir=none]
	6137544848 [label="running_var
 (48)" fillcolor=orange]
	11135955536 -> 6137298864 [dir=none]
	6137298864 [label="weight
 (48)" fillcolor=orange]
	11135955536 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135952944 -> 11135955536
	11135952944 -> 6140375536 [dir=none]
	6140375536 [label="input
 (1, 192, 150, 150)" fillcolor=orange]
	11135952944 -> 6137298784 [dir=none]
	6137298784 [label="weight
 (48, 192, 1, 1)" fillcolor=orange]
	11135952944 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135952656 -> 11135952944
	11135952656 -> 6140377216 [dir=none]
	6140377216 [label="other
 (1, 192, 150, 150)" fillcolor=orange]
	11135952656 -> 6140375936 [dir=none]
	6140375936 [label="self
 (1, 192, 1, 1)" fillcolor=orange]
	11135952656 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135952560 -> 11135952656
	11135952560 -> 11136104416 [dir=none]
	11136104416 [label="result
 (1, 192, 1, 1)" fillcolor=orange]
	11135952560 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135952416 -> 11135952560
	11135952416 -> 6140375776 [dir=none]
	6140375776 [label="input
 (1, 8, 1, 1)" fillcolor=orange]
	11135952416 -> 6137298544 [dir=none]
	6137298544 [label="weight
 (192, 8, 1, 1)" fillcolor=orange]
	11135952416 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (192,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141941728 -> 11135952416
	6141941728 [label=SwishImplementationBackward]
	11135951984 -> 6141941728
	11135951984 -> 6140377616 [dir=none]
	6140377616 [label="input
 (1, 192, 1, 1)" fillcolor=orange]
	11135951984 -> 6137298304 [dir=none]
	6137298304 [label="weight
 (8, 192, 1, 1)" fillcolor=orange]
	11135951984 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (8,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135951840 -> 11135951984
	11135951840 -> 6140377216 [dir=none]
	6140377216 [label="self
 (1, 192, 150, 150)" fillcolor=orange]
	11135951840 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                           (1, 192, 150, 150)"]
	6141941504 -> 11135951840
	6141941504 [label=SwishImplementationBackward]
	11135951408 -> 6141941504
	11135951408 -> 6140368656 [dir=none]
	6140368656 [label="input
 (1, 192, 150, 150)" fillcolor=orange]
	11135951408 -> 11136104496 [dir=none]
	11136104496 [label="result1
 (192)" fillcolor=orange]
	11135951408 -> 11136103776 [dir=none]
	11136103776 [label="result2
 (192)" fillcolor=orange]
	11135951408 -> 6137295984 [dir=none]
	6137295984 [label="running_mean
 (192)" fillcolor=orange]
	11135951408 -> 6137297824 [dir=none]
	6137297824 [label="running_var
 (192)" fillcolor=orange]
	11135951408 -> 6137297584 [dir=none]
	6137297584 [label="weight
 (192)" fillcolor=orange]
	11135951408 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135951264 -> 11135951408
	11135951264 -> 6140363616 [dir=none]
	6140363616 [label="input
 (1, 192, 301, 301)" fillcolor=orange]
	11135951264 -> 6137297664 [dir=none]
	6137297664 [label="weight
 (192, 1, 3, 3)" fillcolor=orange]
	11135951264 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            192
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	11135950976 -> 11135951264
	11135950976 [label="ConstantPadNdBackward0
----------------------
pad: (0, 1, 0, 1)"]
	6141941280 -> 11135950976
	6141941280 [label=SwishImplementationBackward]
	11135950496 -> 6141941280
	11135950496 -> 6141593856 [dir=none]
	6141593856 [label="input
 (1, 192, 300, 300)" fillcolor=orange]
	11135950496 -> 11136103696 [dir=none]
	11136103696 [label="result1
 (192)" fillcolor=orange]
	11135950496 -> 11136103216 [dir=none]
	11136103216 [label="result2
 (192)" fillcolor=orange]
	11135950496 -> 6137296864 [dir=none]
	6137296864 [label="running_mean
 (192)" fillcolor=orange]
	11135950496 -> 6137297184 [dir=none]
	6137297184 [label="running_var
 (192)" fillcolor=orange]
	11135950496 -> 6137297024 [dir=none]
	6137297024 [label="weight
 (192)" fillcolor=orange]
	11135950496 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135950352 -> 11135950496
	11135950352 -> 6140376656 [dir=none]
	6140376656 [label="input
 (1, 32, 300, 300)" fillcolor=orange]
	11135950352 -> 6137296944 [dir=none]
	6137296944 [label="weight
 (192, 32, 1, 1)" fillcolor=orange]
	11135950352 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135950064 -> 11135950352
	11135950064 [label="AddBackward0
------------
alpha: 1"]
	11135949968 -> 11135950064
	11135949968 -> 6140369216 [dir=none]
	6140369216 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11135949968 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135949632 -> 11135949968
	11135949632 -> 11136102896 [dir=none]
	11136102896 [label="other
 ()" fillcolor=orange]
	11135949632 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135949488 -> 11135949632
	11135949488 -> 6140378256 [dir=none]
	6140378256 [label="input
 (1, 32, 300, 300)" fillcolor=orange]
	11135949488 -> 11136102576 [dir=none]
	11136102576 [label="result1
 (32)" fillcolor=orange]
	11135949488 -> 11136102656 [dir=none]
	11136102656 [label="result2
 (32)" fillcolor=orange]
	11135949488 -> 6137296224 [dir=none]
	6137296224 [label="running_mean
 (32)" fillcolor=orange]
	11135949488 -> 6137296544 [dir=none]
	6137296544 [label="running_var
 (32)" fillcolor=orange]
	11135949488 -> 6137296384 [dir=none]
	6137296384 [label="weight
 (32)" fillcolor=orange]
	11135949488 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135949344 -> 11135949488
	11135949344 -> 6140378816 [dir=none]
	6140378816 [label="input
 (1, 32, 300, 300)" fillcolor=orange]
	11135949344 -> 6137296304 [dir=none]
	6137296304 [label="weight
 (32, 32, 1, 1)" fillcolor=orange]
	11135949344 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135949056 -> 11135949344
	11135949056 -> 6140364656 [dir=none]
	6140364656 [label="other
 (1, 32, 300, 300)" fillcolor=orange]
	11135949056 -> 6140378416 [dir=none]
	6140378416 [label="self
 (1, 32, 1, 1)" fillcolor=orange]
	11135949056 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135948960 -> 11135949056
	11135948960 -> 11136102416 [dir=none]
	11136102416 [label="result
 (1, 32, 1, 1)" fillcolor=orange]
	11135948960 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135948816 -> 11135948960
	11135948816 -> 6140363936 [dir=none]
	6140363936 [label="input
 (1, 8, 1, 1)" fillcolor=orange]
	11135948816 -> 6137296064 [dir=none]
	6137296064 [label="weight
 (32, 8, 1, 1)" fillcolor=orange]
	11135948816 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (32,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141941056 -> 11135948816
	6141941056 [label=SwishImplementationBackward]
	11135948384 -> 6141941056
	11135948384 -> 6140367856 [dir=none]
	6140367856 [label="input
 (1, 32, 1, 1)" fillcolor=orange]
	11135948384 -> 6137295824 [dir=none]
	6137295824 [label="weight
 (8, 32, 1, 1)" fillcolor=orange]
	11135948384 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (8,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135948240 -> 11135948384
	11135948240 -> 6140364656 [dir=none]
	6140364656 [label="self
 (1, 32, 300, 300)" fillcolor=orange]
	11135948240 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 32, 300, 300)"]
	6141940832 -> 11135948240
	6141940832 [label=SwishImplementationBackward]
	11135947808 -> 6141940832
	11135947808 -> 6141596656 [dir=none]
	6141596656 [label="input
 (1, 32, 300, 300)" fillcolor=orange]
	11135947808 -> 11136101776 [dir=none]
	11136101776 [label="result1
 (32)" fillcolor=orange]
	11135947808 -> 11136102176 [dir=none]
	11136102176 [label="result2
 (32)" fillcolor=orange]
	11135947808 -> 6137294944 [dir=none]
	6137294944 [label="running_mean
 (32)" fillcolor=orange]
	11135947808 -> 6137295344 [dir=none]
	6137295344 [label="running_var
 (32)" fillcolor=orange]
	11135947808 -> 6137295104 [dir=none]
	6137295104 [label="weight
 (32)" fillcolor=orange]
	11135947808 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135947664 -> 11135947808
	11135947664 -> 6138122608 [dir=none]
	6138122608 [label="input
 (1, 32, 302, 302)" fillcolor=orange]
	11135947664 -> 6137295184 [dir=none]
	6137295184 [label="weight
 (32, 1, 3, 3)" fillcolor=orange]
	11135947664 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :             32
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135947376 -> 11135947664
	11135947376 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	11135949920 -> 11135947376
	11135949920 [label="AddBackward0
------------
alpha: 1"]
	11135947088 -> 11135949920
	11135947088 -> 6141593776 [dir=none]
	6141593776 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11135947088 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135946752 -> 11135947088
	11135946752 -> 11136101216 [dir=none]
	11136101216 [label="other
 ()" fillcolor=orange]
	11135946752 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135946608 -> 11135946752
	11135946608 -> 6141594016 [dir=none]
	6141594016 [label="input
 (1, 32, 300, 300)" fillcolor=orange]
	11135946608 -> 11136100896 [dir=none]
	11136100896 [label="result1
 (32)" fillcolor=orange]
	11135946608 -> 11136100976 [dir=none]
	11136100976 [label="result2
 (32)" fillcolor=orange]
	11135946608 -> 6137294384 [dir=none]
	6137294384 [label="running_mean
 (32)" fillcolor=orange]
	11135946608 -> 6137294704 [dir=none]
	6137294704 [label="running_var
 (32)" fillcolor=orange]
	11135946608 -> 6137294544 [dir=none]
	6137294544 [label="weight
 (32)" fillcolor=orange]
	11135946608 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135946464 -> 11135946608
	11135946464 -> 6141594176 [dir=none]
	6141594176 [label="input
 (1, 32, 300, 300)" fillcolor=orange]
	11135946464 -> 6137294464 [dir=none]
	6137294464 [label="weight
 (32, 32, 1, 1)" fillcolor=orange]
	11135946464 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135946176 -> 11135946464
	11135946176 -> 6141594736 [dir=none]
	6141594736 [label="other
 (1, 32, 300, 300)" fillcolor=orange]
	11135946176 -> 6141594576 [dir=none]
	6141594576 [label="self
 (1, 32, 1, 1)" fillcolor=orange]
	11135946176 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135946080 -> 11135946176
	11135946080 -> 11136100736 [dir=none]
	11136100736 [label="result
 (1, 32, 1, 1)" fillcolor=orange]
	11135946080 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135945936 -> 11135946080
	11135945936 -> 6141594256 [dir=none]
	6141594256 [label="input
 (1, 8, 1, 1)" fillcolor=orange]
	11135945936 -> 6137154992 [dir=none]
	6137154992 [label="weight
 (32, 8, 1, 1)" fillcolor=orange]
	11135945936 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (32,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141940608 -> 11135945936
	6141940608 [label=SwishImplementationBackward]
	11135945504 -> 6141940608
	11135945504 -> 6141598416 [dir=none]
	6141598416 [label="input
 (1, 32, 1, 1)" fillcolor=orange]
	11135945504 -> 6137294304 [dir=none]
	6137294304 [label="weight
 (8, 32, 1, 1)" fillcolor=orange]
	11135945504 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (8,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135945360 -> 11135945504
	11135945360 -> 6141594736 [dir=none]
	6141594736 [label="self
 (1, 32, 300, 300)" fillcolor=orange]
	11135945360 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 32, 300, 300)"]
	6141940384 -> 11135945360
	6141940384 [label=SwishImplementationBackward]
	11135944928 -> 6141940384
	11135944928 -> 6141595056 [dir=none]
	6141595056 [label="input
 (1, 32, 300, 300)" fillcolor=orange]
	11135944928 -> 11136100816 [dir=none]
	11136100816 [label="result1
 (32)" fillcolor=orange]
	11135944928 -> 11136100576 [dir=none]
	11136100576 [label="result2
 (32)" fillcolor=orange]
	11135944928 -> 6137293424 [dir=none]
	6137293424 [label="running_mean
 (32)" fillcolor=orange]
	11135944928 -> 6137293824 [dir=none]
	6137293824 [label="running_var
 (32)" fillcolor=orange]
	11135944928 -> 6137293584 [dir=none]
	6137293584 [label="weight
 (32)" fillcolor=orange]
	11135944928 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135944784 -> 11135944928
	11135944784 -> 6141596816 [dir=none]
	6141596816 [label="input
 (1, 32, 302, 302)" fillcolor=orange]
	11135944784 -> 6137293664 [dir=none]
	6137293664 [label="weight
 (32, 1, 3, 3)" fillcolor=orange]
	11135944784 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :             32
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135944496 -> 11135944784
	11135944496 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	11135947184 -> 11135944496
	11135947184 [label="AddBackward0
------------
alpha: 1"]
	11135944208 -> 11135947184
	11135944208 -> 6141596336 [dir=none]
	6141596336 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11135944208 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135943872 -> 11135944208
	11135943872 -> 11136021296 [dir=none]
	11136021296 [label="other
 ()" fillcolor=orange]
	11135943872 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135943728 -> 11135943872
	11135943728 -> 6141595856 [dir=none]
	6141595856 [label="input
 (1, 32, 300, 300)" fillcolor=orange]
	11135943728 -> 11136013856 [dir=none]
	11136013856 [label="result1
 (32)" fillcolor=orange]
	11135943728 -> 11136022816 [dir=none]
	11136022816 [label="result2
 (32)" fillcolor=orange]
	11135943728 -> 6137292864 [dir=none]
	6137292864 [label="running_mean
 (32)" fillcolor=orange]
	11135943728 -> 6137293184 [dir=none]
	6137293184 [label="running_var
 (32)" fillcolor=orange]
	11135943728 -> 6137293024 [dir=none]
	6137293024 [label="weight
 (32)" fillcolor=orange]
	11135943728 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135943584 -> 11135943728
	11135943584 -> 6141596176 [dir=none]
	6141596176 [label="input
 (1, 32, 300, 300)" fillcolor=orange]
	11135943584 -> 6137292944 [dir=none]
	6137292944 [label="weight
 (32, 32, 1, 1)" fillcolor=orange]
	11135943584 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135943296 -> 11135943584
	11135943296 -> 6141595216 [dir=none]
	6141595216 [label="other
 (1, 32, 300, 300)" fillcolor=orange]
	11135943296 -> 6141592016 [dir=none]
	6141592016 [label="self
 (1, 32, 1, 1)" fillcolor=orange]
	11135943296 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135943200 -> 11135943296
	11135943200 -> 11136014176 [dir=none]
	11136014176 [label="result
 (1, 32, 1, 1)" fillcolor=orange]
	11135943200 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135943056 -> 11135943200
	11135943056 -> 6141596976 [dir=none]
	6141596976 [label="input
 (1, 8, 1, 1)" fillcolor=orange]
	11135943056 -> 6137292704 [dir=none]
	6137292704 [label="weight
 (32, 8, 1, 1)" fillcolor=orange]
	11135943056 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (32,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141940160 -> 11135943056
	6141940160 [label=SwishImplementationBackward]
	11135942768 -> 6141940160
	11135942768 -> 6141595536 [dir=none]
	6141595536 [label="input
 (1, 32, 1, 1)" fillcolor=orange]
	11135942768 -> 6137292464 [dir=none]
	6137292464 [label="weight
 (8, 32, 1, 1)" fillcolor=orange]
	11135942768 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (8,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135876880 -> 11135942768
	11135876880 -> 6141595216 [dir=none]
	6141595216 [label="self
 (1, 32, 300, 300)" fillcolor=orange]
	11135876880 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 32, 300, 300)"]
	6141939936 -> 11135876880
	6141939936 [label=SwishImplementationBackward]
	11135876448 -> 6141939936
	11135876448 -> 6141593456 [dir=none]
	6141593456 [label="input
 (1, 32, 300, 300)" fillcolor=orange]
	11135876448 -> 11136015536 [dir=none]
	11136015536 [label="result1
 (32)" fillcolor=orange]
	11135876448 -> 11136097376 [dir=none]
	11136097376 [label="result2
 (32)" fillcolor=orange]
	11135876448 -> 6137291664 [dir=none]
	6137291664 [label="running_mean
 (32)" fillcolor=orange]
	11135876448 -> 6137292064 [dir=none]
	6137292064 [label="running_var
 (32)" fillcolor=orange]
	11135876448 -> 6137291824 [dir=none]
	6137291824 [label="weight
 (32)" fillcolor=orange]
	11135876448 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135876304 -> 11135876448
	11135876304 -> 6141592416 [dir=none]
	6141592416 [label="input
 (1, 32, 302, 302)" fillcolor=orange]
	11135876304 -> 6137291904 [dir=none]
	6137291904 [label="weight
 (32, 1, 3, 3)" fillcolor=orange]
	11135876304 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :             32
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135876016 -> 11135876304
	11135876016 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	11135944304 -> 11135876016
	11135944304 -> 6141597136 [dir=none]
	6141597136 [label="input
 (1, 32, 300, 300)" fillcolor=orange]
	11135944304 -> 11136024176 [dir=none]
	11136024176 [label="result1
 (32)" fillcolor=orange]
	11135944304 -> 11136023856 [dir=none]
	11136023856 [label="result2
 (32)" fillcolor=orange]
	11135944304 -> 6137291104 [dir=none]
	6137291104 [label="running_mean
 (32)" fillcolor=orange]
	11135944304 -> 6137291424 [dir=none]
	6137291424 [label="running_var
 (32)" fillcolor=orange]
	11135944304 -> 6137291264 [dir=none]
	6137291264 [label="weight
 (32)" fillcolor=orange]
	11135944304 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135875728 -> 11135944304
	11135875728 -> 6141597216 [dir=none]
	6141597216 [label="input
 (1, 64, 300, 300)" fillcolor=orange]
	11135875728 -> 6137291184 [dir=none]
	6137291184 [label="weight
 (32, 64, 1, 1)" fillcolor=orange]
	11135875728 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135875440 -> 11135875728
	11135875440 -> 6141593136 [dir=none]
	6141593136 [label="other
 (1, 64, 300, 300)" fillcolor=orange]
	11135875440 -> 6141591936 [dir=none]
	6141591936 [label="self
 (1, 64, 1, 1)" fillcolor=orange]
	11135875440 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135875104 -> 11135875440
	11135875104 -> 11136023056 [dir=none]
	11136023056 [label="result
 (1, 64, 1, 1)" fillcolor=orange]
	11135875104 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135874960 -> 11135875104
	11135874960 -> 6141591776 [dir=none]
	6141591776 [label="input
 (1, 16, 1, 1)" fillcolor=orange]
	11135874960 -> 6137290944 [dir=none]
	6137290944 [label="weight
 (64, 16, 1, 1)" fillcolor=orange]
	11135874960 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (64,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141939712 -> 11135874960
	6141939712 [label=SwishImplementationBackward]
	11135874528 -> 6141939712
	11135874528 -> 6139012784 [dir=none]
	6139012784 [label="input
 (1, 64, 1, 1)" fillcolor=orange]
	11135874528 -> 6137290704 [dir=none]
	6137290704 [label="weight
 (16, 64, 1, 1)" fillcolor=orange]
	11135874528 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (16,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135874384 -> 11135874528
	11135874384 -> 6141593136 [dir=none]
	6141593136 [label="self
 (1, 64, 300, 300)" fillcolor=orange]
	11135874384 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 64, 300, 300)"]
	6141939264 -> 11135874384
	6141939264 [label=SwishImplementationBackward]
	11135873952 -> 6141939264
	11135873952 -> 6141592096 [dir=none]
	6141592096 [label="input
 (1, 64, 300, 300)" fillcolor=orange]
	11135873952 -> 11136023216 [dir=none]
	11136023216 [label="result1
 (64)" fillcolor=orange]
	11135873952 -> 11136022736 [dir=none]
	11136022736 [label="result2
 (64)" fillcolor=orange]
	11135873952 -> 6137289744 [dir=none]
	6137289744 [label="running_mean
 (64)" fillcolor=orange]
	11135873952 -> 6137290304 [dir=none]
	6137290304 [label="running_var
 (64)" fillcolor=orange]
	11135873952 -> 6137289984 [dir=none]
	6137289984 [label="weight
 (64)" fillcolor=orange]
	11135873952 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135873808 -> 11135873952
	11135873808 -> 6141592576 [dir=none]
	6141592576 [label="input
 (1, 64, 302, 302)" fillcolor=orange]
	11135873808 -> 6137290224 [dir=none]
	6137290224 [label="weight
 (64, 1, 3, 3)" fillcolor=orange]
	11135873808 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :             64
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135873520 -> 11135873808
	11135873520 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6141939488 -> 11135873520
	6141939488 [label=SwishImplementationBackward]
	11135873280 -> 6141939488
	11135873280 -> 6138725616 [dir=none]
	6138725616 [label="input
 (1, 64, 300, 300)" fillcolor=orange]
	11135873280 -> 11136020976 [dir=none]
	11136020976 [label="result1
 (64)" fillcolor=orange]
	11135873280 -> 11136021216 [dir=none]
	11136021216 [label="result2
 (64)" fillcolor=orange]
	11135873280 -> 6137289424 [dir=none]
	6137289424 [label="running_mean
 (64)" fillcolor=orange]
	11135873280 -> 6137289664 [dir=none]
	6137289664 [label="running_var
 (64)" fillcolor=orange]
	11135873280 -> 6137289504 [dir=none]
	6137289504 [label="weight
 (64)" fillcolor=orange]
	11135873280 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135873136 -> 11135873280
	11135873136 -> 6139005424 [dir=none]
	6139005424 [label="input
 (1, 3, 601, 601)" fillcolor=orange]
	11135873136 -> 6137289264 [dir=none]
	6137289264 [label="weight
 (64, 3, 3, 3)" fillcolor=orange]
	11135873136 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	11135872848 -> 11135873136
	6137289264 [label="
 (64, 3, 3, 3)" fillcolor=lightblue]
	6137289264 -> 11135872848
	11135872848 [label=AccumulateGrad]
	11135873088 -> 11135873280
	6137289504 [label="
 (64)" fillcolor=lightblue]
	6137289504 -> 11135873088
	11135873088 [label=AccumulateGrad]
	11135873568 -> 11135873280
	6137289584 [label="
 (64)" fillcolor=lightblue]
	6137289584 -> 11135873568
	11135873568 [label=AccumulateGrad]
	6141601216 -> 6141939488
	6141601216 [label="
 (1, 64, 300, 300)" fillcolor=orange]
	11135873712 -> 11135873808
	6137290224 [label="
 (64, 1, 3, 3)" fillcolor=lightblue]
	6137290224 -> 11135873712
	11135873712 [label=AccumulateGrad]
	11135874000 -> 11135873952
	6137289984 [label="
 (64)" fillcolor=lightblue]
	6137289984 -> 11135874000
	11135874000 [label=AccumulateGrad]
	11135874240 -> 11135873952
	6137290144 [label="
 (64)" fillcolor=lightblue]
	6137290144 -> 11135874240
	11135874240 [label=AccumulateGrad]
	6141592736 -> 6141939264
	6141592736 [label="
 (1, 64, 300, 300)" fillcolor=orange]
	11135874576 -> 11135874528
	6137290704 [label="
 (16, 64, 1, 1)" fillcolor=lightblue]
	6137290704 -> 11135874576
	11135874576 [label=AccumulateGrad]
	11135874672 -> 11135874528
	6137290784 [label="
 (16)" fillcolor=lightblue]
	6137290784 -> 11135874672
	11135874672 [label=AccumulateGrad]
	6141605616 -> 6141939712
	6141605616 [label="
 (1, 16, 1, 1)" fillcolor=orange]
	11135874816 -> 11135874960
	6137290944 [label="
 (64, 16, 1, 1)" fillcolor=lightblue]
	6137290944 -> 11135874816
	11135874816 [label=AccumulateGrad]
	11135875008 -> 11135874960
	6137291024 [label="
 (64)" fillcolor=lightblue]
	6137291024 -> 11135875008
	11135875008 [label=AccumulateGrad]
	6141939264 -> 11135875440
	11135875392 -> 11135875728
	6137291184 [label="
 (32, 64, 1, 1)" fillcolor=lightblue]
	6137291184 -> 11135875392
	11135875392 [label=AccumulateGrad]
	11135875824 -> 11135944304
	6137291264 [label="
 (32)" fillcolor=lightblue]
	6137291264 -> 11135875824
	11135875824 [label=AccumulateGrad]
	11135875872 -> 11135944304
	6137291344 [label="
 (32)" fillcolor=lightblue]
	6137291344 -> 11135875872
	11135875872 [label=AccumulateGrad]
	11135875968 -> 11135876304
	6137291904 [label="
 (32, 1, 3, 3)" fillcolor=lightblue]
	6137291904 -> 11135875968
	11135875968 [label=AccumulateGrad]
	11135876256 -> 11135876448
	6137291824 [label="
 (32)" fillcolor=lightblue]
	6137291824 -> 11135876256
	11135876256 [label=AccumulateGrad]
	11135876736 -> 11135876448
	6137291984 [label="
 (32)" fillcolor=lightblue]
	6137291984 -> 11135876736
	11135876736 [label=AccumulateGrad]
	6141595696 -> 6141939936
	6141595696 [label="
 (1, 32, 300, 300)" fillcolor=orange]
	11135876832 -> 11135942768
	6137292464 [label="
 (8, 32, 1, 1)" fillcolor=lightblue]
	6137292464 -> 11135876832
	11135876832 [label=AccumulateGrad]
	11135876976 -> 11135942768
	6137292544 [label="
 (8)" fillcolor=lightblue]
	6137292544 -> 11135876976
	11135876976 [label=AccumulateGrad]
	6141595296 -> 6141940160
	6141595296 [label="
 (1, 8, 1, 1)" fillcolor=orange]
	11135942912 -> 11135943056
	6137292704 [label="
 (32, 8, 1, 1)" fillcolor=lightblue]
	6137292704 -> 11135942912
	11135942912 [label=AccumulateGrad]
	11135942864 -> 11135943056
	6137292784 [label="
 (32)" fillcolor=lightblue]
	6137292784 -> 11135942864
	11135942864 [label=AccumulateGrad]
	6141939936 -> 11135943296
	11135943488 -> 11135943584
	6137292944 [label="
 (32, 32, 1, 1)" fillcolor=lightblue]
	6137292944 -> 11135943488
	11135943488 [label=AccumulateGrad]
	11135943776 -> 11135943728
	6137293024 [label="
 (32)" fillcolor=lightblue]
	6137293024 -> 11135943776
	11135943776 [label=AccumulateGrad]
	11135944016 -> 11135943728
	6137293104 [label="
 (32)" fillcolor=lightblue]
	6137293104 -> 11135944016
	11135944016 [label=AccumulateGrad]
	11135944304 -> 11135947184
	11135944448 -> 11135944784
	6137293664 [label="
 (32, 1, 3, 3)" fillcolor=lightblue]
	6137293664 -> 11135944448
	11135944448 [label=AccumulateGrad]
	11135944736 -> 11135944928
	6137293584 [label="
 (32)" fillcolor=lightblue]
	6137293584 -> 11135944736
	11135944736 [label=AccumulateGrad]
	11135945216 -> 11135944928
	6137293744 [label="
 (32)" fillcolor=lightblue]
	6137293744 -> 11135945216
	11135945216 [label=AccumulateGrad]
	6141594896 -> 6141940384
	6141594896 [label="
 (1, 32, 300, 300)" fillcolor=orange]
	11135945312 -> 11135945504
	6137294304 [label="
 (8, 32, 1, 1)" fillcolor=lightblue]
	6137294304 -> 11135945312
	11135945312 [label=AccumulateGrad]
	11135945648 -> 11135945504
	6137165552 [label="
 (8)" fillcolor=lightblue]
	6137165552 -> 11135945648
	11135945648 [label=AccumulateGrad]
	6141597376 -> 6141940608
	6141597376 [label="
 (1, 8, 1, 1)" fillcolor=orange]
	11135945792 -> 11135945936
	6137154992 [label="
 (32, 8, 1, 1)" fillcolor=lightblue]
	6137154992 -> 11135945792
	11135945792 [label=AccumulateGrad]
	11135945744 -> 11135945936
	6137294144 [label="
 (32)" fillcolor=lightblue]
	6137294144 -> 11135945744
	11135945744 [label=AccumulateGrad]
	6141940384 -> 11135946176
	11135946368 -> 11135946464
	6137294464 [label="
 (32, 32, 1, 1)" fillcolor=lightblue]
	6137294464 -> 11135946368
	11135946368 [label=AccumulateGrad]
	11135946656 -> 11135946608
	6137294544 [label="
 (32)" fillcolor=lightblue]
	6137294544 -> 11135946656
	11135946656 [label=AccumulateGrad]
	11135946896 -> 11135946608
	6137294624 [label="
 (32)" fillcolor=lightblue]
	6137294624 -> 11135946896
	11135946896 [label=AccumulateGrad]
	11135947184 -> 11135949920
	11135947328 -> 11135947664
	6137295184 [label="
 (32, 1, 3, 3)" fillcolor=lightblue]
	6137295184 -> 11135947328
	11135947328 [label=AccumulateGrad]
	11135947616 -> 11135947808
	6137295104 [label="
 (32)" fillcolor=lightblue]
	6137295104 -> 11135947616
	11135947616 [label=AccumulateGrad]
	11135948096 -> 11135947808
	6137295264 [label="
 (32)" fillcolor=lightblue]
	6137295264 -> 11135948096
	11135948096 [label=AccumulateGrad]
	6141593616 -> 6141940832
	6141593616 [label="
 (1, 32, 300, 300)" fillcolor=orange]
	11135948192 -> 11135948384
	6137295824 [label="
 (8, 32, 1, 1)" fillcolor=lightblue]
	6137295824 -> 11135948192
	11135948192 [label=AccumulateGrad]
	11135948528 -> 11135948384
	6137295904 [label="
 (8)" fillcolor=lightblue]
	6137295904 -> 11135948528
	11135948528 [label=AccumulateGrad]
	6140379056 -> 6141941056
	6140379056 [label="
 (1, 8, 1, 1)" fillcolor=orange]
	11135948672 -> 11135948816
	6137296064 [label="
 (32, 8, 1, 1)" fillcolor=lightblue]
	6137296064 -> 11135948672
	11135948672 [label=AccumulateGrad]
	11135948624 -> 11135948816
	6137296144 [label="
 (32)" fillcolor=lightblue]
	6137296144 -> 11135948624
	11135948624 [label=AccumulateGrad]
	6141940832 -> 11135949056
	11135949248 -> 11135949344
	6137296304 [label="
 (32, 32, 1, 1)" fillcolor=lightblue]
	6137296304 -> 11135949248
	11135949248 [label=AccumulateGrad]
	11135949536 -> 11135949488
	6137296384 [label="
 (32)" fillcolor=lightblue]
	6137296384 -> 11135949536
	11135949536 [label=AccumulateGrad]
	11135949776 -> 11135949488
	6137296464 [label="
 (32)" fillcolor=lightblue]
	6137296464 -> 11135949776
	11135949776 [label=AccumulateGrad]
	11135949920 -> 11135950064
	11135950256 -> 11135950352
	6137296944 [label="
 (192, 32, 1, 1)" fillcolor=lightblue]
	6137296944 -> 11135950256
	11135950256 [label=AccumulateGrad]
	11135950544 -> 11135950496
	6137297024 [label="
 (192)" fillcolor=lightblue]
	6137297024 -> 11135950544
	11135950544 [label=AccumulateGrad]
	11135950784 -> 11135950496
	6137297104 [label="
 (192)" fillcolor=lightblue]
	6137297104 -> 11135950784
	11135950784 [label=AccumulateGrad]
	6140364496 -> 6141941280
	6140364496 [label="
 (1, 192, 300, 300)" fillcolor=orange]
	11135950928 -> 11135951264
	6137297664 [label="
 (192, 1, 3, 3)" fillcolor=lightblue]
	6137297664 -> 11135950928
	11135950928 [label=AccumulateGrad]
	11135951216 -> 11135951408
	6137297584 [label="
 (192)" fillcolor=lightblue]
	6137297584 -> 11135951216
	11135951216 [label=AccumulateGrad]
	11135951696 -> 11135951408
	6137297744 [label="
 (192)" fillcolor=lightblue]
	6137297744 -> 11135951696
	11135951696 [label=AccumulateGrad]
	6140367696 -> 6141941504
	6140367696 [label="
 (1, 192, 150, 150)" fillcolor=orange]
	11135951792 -> 11135951984
	6137298304 [label="
 (8, 192, 1, 1)" fillcolor=lightblue]
	6137298304 -> 11135951792
	11135951792 [label=AccumulateGrad]
	11135952128 -> 11135951984
	6137298384 [label="
 (8)" fillcolor=lightblue]
	6137298384 -> 11135952128
	11135952128 [label=AccumulateGrad]
	6140377376 -> 6141941728
	6140377376 [label="
 (1, 8, 1, 1)" fillcolor=orange]
	11135952272 -> 11135952416
	6137298544 [label="
 (192, 8, 1, 1)" fillcolor=lightblue]
	6137298544 -> 11135952272
	11135952272 [label=AccumulateGrad]
	11135952224 -> 11135952416
	6137298624 [label="
 (192)" fillcolor=lightblue]
	6137298624 -> 11135952224
	11135952224 [label=AccumulateGrad]
	6141941504 -> 11135952656
	11135952848 -> 11135952944
	6137298784 [label="
 (48, 192, 1, 1)" fillcolor=lightblue]
	6137298784 -> 11135952848
	11135952848 [label=AccumulateGrad]
	11135953136 -> 11135955536
	6137298864 [label="
 (48)" fillcolor=lightblue]
	6137298864 -> 11135953136
	11135953136 [label=AccumulateGrad]
	11135955872 -> 11135955536
	6137544768 [label="
 (48)" fillcolor=lightblue]
	6137544768 -> 11135955872
	11135955872 [label=AccumulateGrad]
	11135953376 -> 11135955680
	6137545248 [label="
 (288, 48, 1, 1)" fillcolor=lightblue]
	6137545248 -> 11135953376
	11135953376 [label=AccumulateGrad]
	11135958848 -> 11135958560
	6137545328 [label="
 (288)" fillcolor=lightblue]
	6137545328 -> 11135958848
	11135958848 [label=AccumulateGrad]
	11135958128 -> 11135958560
	6137545408 [label="
 (288)" fillcolor=lightblue]
	6137545408 -> 11135958128
	11135958128 [label=AccumulateGrad]
	6140374576 -> 6141941952
	6140374576 [label="
 (1, 288, 150, 150)" fillcolor=orange]
	11135958272 -> 11135958704
	6137545968 [label="
 (288, 1, 3, 3)" fillcolor=lightblue]
	6137545968 -> 11135958272
	11135958272 [label=AccumulateGrad]
	11135957984 -> 11135957888
	6137545888 [label="
 (288)" fillcolor=lightblue]
	6137545888 -> 11135957984
	11135957984 [label=AccumulateGrad]
	11135957600 -> 11135957888
	6137546048 [label="
 (288)" fillcolor=lightblue]
	6137546048 -> 11135957600
	11135957600 [label=AccumulateGrad]
	6140373936 -> 6141942176
	6140373936 [label="
 (1, 288, 150, 150)" fillcolor=orange]
	11135957264 -> 11135957840
	6137546608 [label="
 (12, 288, 1, 1)" fillcolor=lightblue]
	6137546608 -> 11135957264
	11135957264 [label=AccumulateGrad]
	11135957120 -> 11135957840
	6137546688 [label="
 (12)" fillcolor=lightblue]
	6137546688 -> 11135957120
	11135957120 [label=AccumulateGrad]
	6140373536 -> 6141942400
	6140373536 [label="
 (1, 12, 1, 1)" fillcolor=orange]
	11135958752 -> 11135957168
	6137546848 [label="
 (288, 12, 1, 1)" fillcolor=lightblue]
	6137546848 -> 11135958752
	11135958752 [label=AccumulateGrad]
	11135957312 -> 11135957168
	6137546928 [label="
 (288)" fillcolor=lightblue]
	6137546928 -> 11135957312
	11135957312 [label=AccumulateGrad]
	6141942176 -> 11135956688
	11135956736 -> 11135956400
	6137547088 [label="
 (48, 288, 1, 1)" fillcolor=lightblue]
	6137547088 -> 11135956736
	11135956736 [label=AccumulateGrad]
	11135956448 -> 11135956256
	6137547168 [label="
 (48)" fillcolor=lightblue]
	6137547168 -> 11135956448
	11135956448 [label=AccumulateGrad]
	11135956016 -> 11135956256
	6137547248 [label="
 (48)" fillcolor=lightblue]
	6137547248 -> 11135956016
	11135956016 [label=AccumulateGrad]
	11135955536 -> 6141859328
	11135955152 -> 11135955440
	6137547648 [label="
 (288, 48, 1, 1)" fillcolor=lightblue]
	6137547648 -> 11135955152
	11135955152 [label=AccumulateGrad]
	11135954672 -> 11135954816
	6137547728 [label="
 (288)" fillcolor=lightblue]
	6137547728 -> 11135954672
	11135954672 [label=AccumulateGrad]
	11135954576 -> 11135954816
	6137547808 [label="
 (288)" fillcolor=lightblue]
	6137547808 -> 11135954576
	11135954576 [label=AccumulateGrad]
	6140371536 -> 6141942624
	6140371536 [label="
 (1, 288, 150, 150)" fillcolor=orange]
	11135954432 -> 11135955584
	6137548368 [label="
 (288, 1, 3, 3)" fillcolor=lightblue]
	6137548368 -> 11135954432
	11135954432 [label=AccumulateGrad]
	11135955392 -> 11135954528
	6137548288 [label="
 (288)" fillcolor=lightblue]
	6137548288 -> 11135955392
	11135955392 [label=AccumulateGrad]
	11135953808 -> 11135954528
	6137548448 [label="
 (288)" fillcolor=lightblue]
	6137548448 -> 11135953808
	11135953808 [label=AccumulateGrad]
	6140371296 -> 6141942848
	6140371296 [label="
 (1, 288, 150, 150)" fillcolor=orange]
	11135953712 -> 11135954144
	6137549008 [label="
 (12, 288, 1, 1)" fillcolor=lightblue]
	6137549008 -> 11135953712
	11135953712 [label=AccumulateGrad]
	11135953232 -> 11135954144
	6137549088 [label="
 (12)" fillcolor=lightblue]
	6137549088 -> 11135953232
	11135953232 [label=AccumulateGrad]
	6140370816 -> 6141943072
	6140370816 [label="
 (1, 12, 1, 1)" fillcolor=orange]
	11135953088 -> 6141861056
	6137549248 [label="
 (288, 12, 1, 1)" fillcolor=lightblue]
	6137549248 -> 11135953088
	11135953088 [label=AccumulateGrad]
	11135953424 -> 6141861056
	6137549328 [label="
 (288)" fillcolor=lightblue]
	6137549328 -> 11135953424
	11135953424 [label=AccumulateGrad]
	6141942848 -> 6141860336
	6141860576 -> 6141860192
	6137549488 [label="
 (48, 288, 1, 1)" fillcolor=lightblue]
	6137549488 -> 6141860576
	6141860576 [label=AccumulateGrad]
	6141859808 -> 6141860240
	6137549568 [label="
 (48)" fillcolor=lightblue]
	6137549568 -> 6141859808
	6141859808 [label=AccumulateGrad]
	6141859616 -> 6141860240
	6137549648 [label="
 (48)" fillcolor=lightblue]
	6137549648 -> 6141859616
	6141859616 [label=AccumulateGrad]
	6141859328 -> 6141854288
	6141859280 -> 6141858608
	6137550128 [label="
 (288, 48, 1, 1)" fillcolor=lightblue]
	6137550128 -> 6141859280
	6141859280 [label=AccumulateGrad]
	6141858800 -> 6141858320
	6137550208 [label="
 (288)" fillcolor=lightblue]
	6137550208 -> 6141858800
	6141858800 [label=AccumulateGrad]
	6141859472 -> 6141858320
	6137550288 [label="
 (288)" fillcolor=lightblue]
	6137550288 -> 6141859472
	6141859472 [label=AccumulateGrad]
	6140367296 -> 6141943296
	6140367296 [label="
 (1, 288, 150, 150)" fillcolor=orange]
	6141858032 -> 6141857840
	6137550848 [label="
 (288, 1, 3, 3)" fillcolor=lightblue]
	6137550848 -> 6141858032
	6141858032 [label=AccumulateGrad]
	6141857360 -> 6141857552
	6137550768 [label="
 (288)" fillcolor=lightblue]
	6137550768 -> 6141857360
	6141857360 [label=AccumulateGrad]
	6141856928 -> 6141857552
	6137550928 [label="
 (288)" fillcolor=lightblue]
	6137550928 -> 6141856928
	6141856928 [label=AccumulateGrad]
	6140367056 -> 6141943520
	6140367056 [label="
 (1, 288, 150, 150)" fillcolor=orange]
	6141856784 -> 6141856544
	6137551488 [label="
 (12, 288, 1, 1)" fillcolor=lightblue]
	6137551488 -> 6141856784
	6141856784 [label=AccumulateGrad]
	6141856592 -> 6141856544
	6137551568 [label="
 (12)" fillcolor=lightblue]
	6137551568 -> 6141856592
	6141856592 [label=AccumulateGrad]
	6140366256 -> 6141943744
	6140366256 [label="
 (1, 12, 1, 1)" fillcolor=orange]
	6141856304 -> 6141856064
	6137551728 [label="
 (288, 12, 1, 1)" fillcolor=lightblue]
	6137551728 -> 6141856304
	6141856304 [label=AccumulateGrad]
	6141855824 -> 6141856064
	6137551808 [label="
 (288)" fillcolor=lightblue]
	6137551808 -> 6141855824
	6141855824 [label=AccumulateGrad]
	6141943520 -> 6141856976
	6141855488 -> 6141855056
	6137551968 [label="
 (48, 288, 1, 1)" fillcolor=lightblue]
	6137551968 -> 6141855488
	6141855488 [label=AccumulateGrad]
	6141854960 -> 6141855104
	6137552048 [label="
 (48)" fillcolor=lightblue]
	6137552048 -> 6141854960
	6141854960 [label=AccumulateGrad]
	6141854768 -> 6141855104
	6137552128 [label="
 (48)" fillcolor=lightblue]
	6137552128 -> 6141854768
	6141854768 [label=AccumulateGrad]
	6141854288 -> 6141751600
	6141855728 -> 6141854048
	6137552528 [label="
 (288, 48, 1, 1)" fillcolor=lightblue]
	6137552528 -> 6141855728
	6141855728 [label=AccumulateGrad]
	6141854336 -> 6141860864
	6137552608 [label="
 (288)" fillcolor=lightblue]
	6137552608 -> 6141854336
	6141854336 [label=AccumulateGrad]
	6141861296 -> 6141860864
	6137552688 [label="
 (288)" fillcolor=lightblue]
	6137552688 -> 6141861296
	6141861296 [label=AccumulateGrad]
	6140378336 -> 6141943968
	6140378336 [label="
 (1, 288, 150, 150)" fillcolor=orange]
	6141755248 -> 6141754912
	6137553248 [label="
 (288, 1, 3, 3)" fillcolor=lightblue]
	6137553248 -> 6141755248
	6141755248 [label=AccumulateGrad]
	6141755152 -> 6141754672
	6137553168 [label="
 (288)" fillcolor=lightblue]
	6137553168 -> 6141755152
	6141755152 [label=AccumulateGrad]
	6141754432 -> 6141754672
	6137553328 [label="
 (288)" fillcolor=lightblue]
	6137553328 -> 6141754432
	6141754432 [label=AccumulateGrad]
	6140378176 -> 6141944192
	6140378176 [label="
 (1, 288, 150, 150)" fillcolor=orange]
	6141754000 -> 6141753856
	6137553888 [label="
 (12, 288, 1, 1)" fillcolor=lightblue]
	6137553888 -> 6141754000
	6141754000 [label=AccumulateGrad]
	6141753904 -> 6141753856
	6137553968 [label="
 (12)" fillcolor=lightblue]
	6137553968 -> 6141753904
	6141753904 [label=AccumulateGrad]
	6140377856 -> 6141944416
	6140377856 [label="
 (1, 12, 1, 1)" fillcolor=orange]
	6141753136 -> 6141752896
	6137554128 [label="
 (288, 12, 1, 1)" fillcolor=lightblue]
	6137554128 -> 6141753136
	6141753136 [label=AccumulateGrad]
	6141753376 -> 6141752896
	6137554208 [label="
 (288)" fillcolor=lightblue]
	6137554208 -> 6141753376
	6141753376 [label=AccumulateGrad]
	6141944192 -> 6141752800
	6141752368 -> 6141752176
	6137554368 [label="
 (48, 288, 1, 1)" fillcolor=lightblue]
	6137554368 -> 6141752368
	6141752368 [label=AccumulateGrad]
	6141752128 -> 6141751984
	6137554448 [label="
 (48)" fillcolor=lightblue]
	6137554448 -> 6141752128
	6141752128 [label=AccumulateGrad]
	6141751840 -> 6141751984
	6137554528 [label="
 (48)" fillcolor=lightblue]
	6137554528 -> 6141751840
	6141751840 [label=AccumulateGrad]
	6141751600 -> 6141746416
	6141751408 -> 6141750880
	6137554928 [label="
 (288, 48, 1, 1)" fillcolor=lightblue]
	6137554928 -> 6141751408
	6141751408 [label=AccumulateGrad]
	6141750736 -> 6141750592
	6137555008 [label="
 (288)" fillcolor=lightblue]
	6137555008 -> 6141750736
	6141750736 [label=AccumulateGrad]
	6141750352 -> 6141750592
	6137555088 [label="
 (288)" fillcolor=lightblue]
	6137555088 -> 6141750352
	6141750352 [label=AccumulateGrad]
	6140376016 -> 6141944640
	6140376016 [label="
 (1, 288, 150, 150)" fillcolor=orange]
	6141750400 -> 6141749632
	6137555648 [label="
 (288, 1, 3, 3)" fillcolor=lightblue]
	6137555648 -> 6141750400
	6141750400 [label=AccumulateGrad]
	6141749680 -> 6141752512
	6137555568 [label="
 (288)" fillcolor=lightblue]
	6137555568 -> 6141749680
	6141749680 [label=AccumulateGrad]
	6141749152 -> 6141752512
	6137555728 [label="
 (288)" fillcolor=lightblue]
	6137555728 -> 6141749152
	6141749152 [label=AccumulateGrad]
	6140375856 -> 6141944864
	6140375856 [label="
 (1, 288, 150, 150)" fillcolor=orange]
	6141748672 -> 6141748912
	6137556288 [label="
 (12, 288, 1, 1)" fillcolor=lightblue]
	6137556288 -> 6141748672
	6141748672 [label=AccumulateGrad]
	6141748624 -> 6141748912
	6137556368 [label="
 (12)" fillcolor=lightblue]
	6137556368 -> 6141748624
	6141748624 [label=AccumulateGrad]
	6140375376 -> 6141945088
	6140375376 [label="
 (1, 12, 1, 1)" fillcolor=orange]
	6141748384 -> 6141748000
	6137556528 [label="
 (288, 12, 1, 1)" fillcolor=lightblue]
	6137556528 -> 6141748384
	6141748384 [label=AccumulateGrad]
	6141748288 -> 6141748000
	6137556608 [label="
 (288)" fillcolor=lightblue]
	6137556608 -> 6141748288
	6141748288 [label=AccumulateGrad]
	6141944864 -> 6141747472
	6141747664 -> 6141747328
	6137556768 [label="
 (48, 288, 1, 1)" fillcolor=lightblue]
	6137556768 -> 6141747664
	6141747664 [label=AccumulateGrad]
	6141746848 -> 6141747376
	6137556848 [label="
 (48)" fillcolor=lightblue]
	6137556848 -> 6141746848
	6141746848 [label=AccumulateGrad]
	6141746656 -> 6141747376
	6137556928 [label="
 (48)" fillcolor=lightblue]
	6137556928 -> 6141746656
	6141746656 [label=AccumulateGrad]
	6141746416 -> 6141740848
	6141748048 -> 6141746128
	6137557408 [label="
 (288, 48, 1, 1)" fillcolor=lightblue]
	6137557408 -> 6141748048
	6141748048 [label=AccumulateGrad]
	6141745600 -> 6141745840
	6137557488 [label="
 (288)" fillcolor=lightblue]
	6137557488 -> 6141745600
	6141745600 [label=AccumulateGrad]
	6141745648 -> 6141745840
	6137557568 [label="
 (288)" fillcolor=lightblue]
	6137557568 -> 6141745648
	6141745648 [label=AccumulateGrad]
	6140373376 -> 6141945312
	6140373376 [label="
 (1, 288, 150, 150)" fillcolor=orange]
	6141745168 -> 6141744592
	6137558128 [label="
 (288, 1, 3, 3)" fillcolor=lightblue]
	6137558128 -> 6141745168
	6141745168 [label=AccumulateGrad]
	6141744352 -> 6141744640
	6137558048 [label="
 (288)" fillcolor=lightblue]
	6137558048 -> 6141744352
	6141744352 [label=AccumulateGrad]
	6141743728 -> 6141744640
	6137558208 [label="
 (288)" fillcolor=lightblue]
	6137558208 -> 6141743728
	6141743728 [label=AccumulateGrad]
	6140373696 -> 6141945536
	6140373696 [label="
 (1, 288, 150, 150)" fillcolor=orange]
	6141743920 -> 6141743488
	6137558768 [label="
 (12, 288, 1, 1)" fillcolor=lightblue]
	6137558768 -> 6141743920
	6141743920 [label=AccumulateGrad]
	6141745024 -> 6141743488
	6137558848 [label="
 (12)" fillcolor=lightblue]
	6137558848 -> 6141745024
	6141745024 [label=AccumulateGrad]
	6140373056 -> 6141945760
	6140373056 [label="
 (1, 12, 1, 1)" fillcolor=orange]
	6141743392 -> 6141743008
	6137559008 [label="
 (288, 12, 1, 1)" fillcolor=lightblue]
	6137559008 -> 6141743392
	6141743392 [label=AccumulateGrad]
	6141743152 -> 6141743008
	6137559088 [label="
 (288)" fillcolor=lightblue]
	6137559088 -> 6141743152
	6141743152 [label=AccumulateGrad]
	6141945536 -> 6141742576
	6141742096 -> 6141741856
	6137559248 [label="
 (48, 288, 1, 1)" fillcolor=lightblue]
	6137559248 -> 6141742096
	6141742096 [label=AccumulateGrad]
	6141744976 -> 6141741760
	6137559328 [label="
 (48)" fillcolor=lightblue]
	6137559328 -> 6141744976
	6141744976 [label=AccumulateGrad]
	6141741616 -> 6141741760
	6137559408 [label="
 (48)" fillcolor=lightblue]
	6137559408 -> 6141741616
	6141741616 [label=AccumulateGrad]
	6141740848 -> 6141740608
	6141741136 -> 6141740464
	6137559888 [label="
 (288, 48, 1, 1)" fillcolor=lightblue]
	6137559888 -> 6141741136
	6141741136 [label=AccumulateGrad]
	6141740512 -> 6141743344
	6137559968 [label="
 (288)" fillcolor=lightblue]
	6137559968 -> 6141740512
	6141740512 [label=AccumulateGrad]
	6141739888 -> 6141743344
	6137560048 [label="
 (288)" fillcolor=lightblue]
	6137560048 -> 6141739888
	6141739888 [label=AccumulateGrad]
	6140370896 -> 6141945984
	6140370896 [label="
 (1, 288, 150, 150)" fillcolor=orange]
	6141739600 -> 6141739264
	6137560608 [label="
 (288, 1, 5, 5)" fillcolor=lightblue]
	6137560608 -> 6141739600
	6141739600 [label=AccumulateGrad]
	6141739360 -> 6141739216
	6137560528 [label="
 (288)" fillcolor=lightblue]
	6137560528 -> 6141739360
	6141739360 [label=AccumulateGrad]
	6141746368 -> 6141739216
	6137560688 [label="
 (288)" fillcolor=lightblue]
	6137560688 -> 6141746368
	6141746368 [label=AccumulateGrad]
	6140371216 -> 6141946208
	6140371216 [label="
 (1, 288, 75, 75)" fillcolor=orange]
	6141689424 -> 6141689376
	6137823456 [label="
 (12, 288, 1, 1)" fillcolor=lightblue]
	6137823456 -> 6141689424
	6141689424 [label=AccumulateGrad]
	6141689088 -> 6141689376
	6137823536 [label="
 (12)" fillcolor=lightblue]
	6137823536 -> 6141689088
	6141689088 [label=AccumulateGrad]
	6140370416 -> 6141946432
	6140370416 [label="
 (1, 12, 1, 1)" fillcolor=orange]
	6141689136 -> 6141688848
	6137823696 [label="
 (288, 12, 1, 1)" fillcolor=lightblue]
	6137823696 -> 6141689136
	6141689136 [label=AccumulateGrad]
	6141688608 -> 6141688848
	6137823776 [label="
 (288)" fillcolor=lightblue]
	6137823776 -> 6141688608
	6141688608 [label=AccumulateGrad]
	6141946208 -> 6141688128
	6141688176 -> 6141687888
	6137823936 [label="
 (80, 288, 1, 1)" fillcolor=lightblue]
	6137823936 -> 6141688176
	6141688176 [label=AccumulateGrad]
	6141687648 -> 6141682224
	6137824016 [label="
 (80)" fillcolor=lightblue]
	6137824016 -> 6141687648
	6141687648 [label=AccumulateGrad]
	6141687168 -> 6141682224
	6137824096 [label="
 (80)" fillcolor=lightblue]
	6137824096 -> 6141687168
	6141687168 [label=AccumulateGrad]
	6141687600 -> 6141686928
	6137824496 [label="
 (480, 80, 1, 1)" fillcolor=lightblue]
	6137824496 -> 6141687600
	6141687600 [label=AccumulateGrad]
	6141687120 -> 6141686736
	6137824576 [label="
 (480)" fillcolor=lightblue]
	6137824576 -> 6141687120
	6141687120 [label=AccumulateGrad]
	6141689664 -> 6141686736
	6137824656 [label="
 (480)" fillcolor=lightblue]
	6137824656 -> 6141689664
	6141689664 [label=AccumulateGrad]
	6140369136 -> 6141946656
	6140369136 [label="
 (1, 480, 75, 75)" fillcolor=orange]
	6141687984 -> 6141686112
	6137825216 [label="
 (480, 1, 5, 5)" fillcolor=lightblue]
	6137825216 -> 6141687984
	6141687984 [label=AccumulateGrad]
	6141685872 -> 6141685680
	6137825136 [label="
 (480)" fillcolor=lightblue]
	6137825136 -> 6141685872
	6141685872 [label=AccumulateGrad]
	6141685248 -> 6141685680
	6137825296 [label="
 (480)" fillcolor=lightblue]
	6137825296 -> 6141685248
	6141685248 [label=AccumulateGrad]
	6140368736 -> 6141946880
	6140368736 [label="
 (1, 480, 75, 75)" fillcolor=orange]
	6141685104 -> 6141684720
	6137825856 [label="
 (20, 480, 1, 1)" fillcolor=lightblue]
	6137825856 -> 6141685104
	6141685104 [label=AccumulateGrad]
	6141684768 -> 6141684720
	6137825936 [label="
 (20)" fillcolor=lightblue]
	6137825936 -> 6141684768
	6141684768 [label=AccumulateGrad]
	6140368256 -> 6141947104
	6140368256 [label="
 (1, 20, 1, 1)" fillcolor=orange]
	6141684576 -> 6141684144
	6137826096 [label="
 (480, 20, 1, 1)" fillcolor=lightblue]
	6137826096 -> 6141684576
	6141684576 [label=AccumulateGrad]
	6141684336 -> 6141684144
	6137826176 [label="
 (480)" fillcolor=lightblue]
	6137826176 -> 6141684336
	6141684336 [label=AccumulateGrad]
	6141946880 -> 6141683856
	6141683664 -> 6141683376
	6137826336 [label="
 (80, 480, 1, 1)" fillcolor=lightblue]
	6137826336 -> 6141683664
	6141683664 [label=AccumulateGrad]
	6141683328 -> 6141683088
	6137826416 [label="
 (80)" fillcolor=lightblue]
	6137826416 -> 6141683328
	6141683328 [label=AccumulateGrad]
	6141682368 -> 6141683088
	6137826496 [label="
 (80)" fillcolor=lightblue]
	6137826496 -> 6141682368
	6141682368 [label=AccumulateGrad]
	6141682224 -> 6141677568
	6141682656 -> 6141682128
	6137826976 [label="
 (480, 80, 1, 1)" fillcolor=lightblue]
	6137826976 -> 6141682656
	6141682656 [label=AccumulateGrad]
	6141685152 -> 6141681600
	6137827056 [label="
 (480)" fillcolor=lightblue]
	6137827056 -> 6141685152
	6141685152 [label=AccumulateGrad]
	6141681360 -> 6141681600
	6137827136 [label="
 (480)" fillcolor=lightblue]
	6137827136 -> 6141681360
	6141681360 [label=AccumulateGrad]
	6140366416 -> 6141947328
	6140366416 [label="
 (1, 480, 75, 75)" fillcolor=orange]
	6141681024 -> 6141680976
	6137827696 [label="
 (480, 1, 5, 5)" fillcolor=lightblue]
	6137827696 -> 6141681024
	6141681024 [label=AccumulateGrad]
	6141680592 -> 6141680736
	6137827616 [label="
 (480)" fillcolor=lightblue]
	6137827616 -> 6141680592
	6141680592 [label=AccumulateGrad]
	6141680256 -> 6141680736
	6137827776 [label="
 (480)" fillcolor=lightblue]
	6137827776 -> 6141680256
	6141680256 [label=AccumulateGrad]
	6140366096 -> 6141947552
	6140366096 [label="
 (1, 480, 75, 75)" fillcolor=orange]
	6141679824 -> 6141680112
	6137828336 [label="
 (20, 480, 1, 1)" fillcolor=lightblue]
	6137828336 -> 6141679824
	6141679824 [label=AccumulateGrad]
	6141679296 -> 6141680112
	6137828416 [label="
 (20)" fillcolor=lightblue]
	6137828416 -> 6141679296
	6141679296 [label=AccumulateGrad]
	6140366016 -> 6141947776
	6140366016 [label="
 (1, 20, 1, 1)" fillcolor=orange]
	6141679056 -> 6141679104
	6137828576 [label="
 (480, 20, 1, 1)" fillcolor=lightblue]
	6137828576 -> 6141679056
	6141679056 [label=AccumulateGrad]
	6141679632 -> 6141679104
	6137828656 [label="
 (480)" fillcolor=lightblue]
	6137828656 -> 6141679632
	6141679632 [label=AccumulateGrad]
	6141947552 -> 6141678528
	6141678816 -> 6141678288
	6137828816 [label="
 (80, 480, 1, 1)" fillcolor=lightblue]
	6137828816 -> 6141678816
	6141678816 [label=AccumulateGrad]
	6141678048 -> 6141677856
	6137828896 [label="
 (80)" fillcolor=lightblue]
	6137828896 -> 6141678048
	6141678048 [label=AccumulateGrad]
	6141677520 -> 6141677856
	6137828976 [label="
 (80)" fillcolor=lightblue]
	6137828976 -> 6141677520
	6141677520 [label=AccumulateGrad]
	6141677568 -> 6141590832
	6141677280 -> 6141676800
	6137829456 [label="
 (480, 80, 1, 1)" fillcolor=lightblue]
	6137829456 -> 6141677280
	6141677280 [label=AccumulateGrad]
	6141676560 -> 6141676848
	6137829536 [label="
 (480)" fillcolor=lightblue]
	6137829536 -> 6141676560
	6141676560 [label=AccumulateGrad]
	6141676032 -> 6141676848
	6137829616 [label="
 (480)" fillcolor=lightblue]
	6137829616 -> 6141676032
	6141676032 [label=AccumulateGrad]
	6140364736 -> 6141948000
	6140364736 [label="
 (1, 480, 75, 75)" fillcolor=orange]
	6141676080 -> 6141675840
	6137830176 [label="
 (480, 1, 5, 5)" fillcolor=lightblue]
	6137830176 -> 6141676080
	6141676080 [label=AccumulateGrad]
	6141678768 -> 6141675504
	6137830096 [label="
 (480)" fillcolor=lightblue]
	6137830096 -> 6141678768
	6141678768 [label=AccumulateGrad]
	6141675264 -> 6141675504
	6137830256 [label="
 (480)" fillcolor=lightblue]
	6137830256 -> 6141675264
	6141675264 [label=AccumulateGrad]
	6140364576 -> 6141948224
	6140364576 [label="
 (1, 480, 75, 75)" fillcolor=orange]
	6141675072 -> 6141674592
	6137830816 [label="
 (20, 480, 1, 1)" fillcolor=lightblue]
	6137830816 -> 6141675072
	6141675072 [label=AccumulateGrad]
	6141674400 -> 6141674592
	6137830896 [label="
 (20)" fillcolor=lightblue]
	6137830896 -> 6141674400
	6141674400 [label=AccumulateGrad]
	6140364096 -> 6141948448
	6140364096 [label="
 (1, 20, 1, 1)" fillcolor=orange]
	6141674448 -> 6141677328
	6137831056 [label="
 (480, 20, 1, 1)" fillcolor=lightblue]
	6137831056 -> 6141674448
	6141674448 [label=AccumulateGrad]
	6141674256 -> 6141677328
	6137831136 [label="
 (480)" fillcolor=lightblue]
	6137831136 -> 6141674256
	6141674256 [label=AccumulateGrad]
	6141948224 -> 6141673824
	6141673584 -> 6141591168
	6137831296 [label="
 (80, 480, 1, 1)" fillcolor=lightblue]
	6137831296 -> 6141673584
	6141673584 [label=AccumulateGrad]
	6141591216 -> 6141591312
	6137831376 [label="
 (80)" fillcolor=lightblue]
	6137831376 -> 6141591216
	6141591216 [label=AccumulateGrad]
	6141686640 -> 6141591312
	6137831456 [label="
 (80)" fillcolor=lightblue]
	6137831456 -> 6141686640
	6141686640 [label=AccumulateGrad]
	6141590832 -> 6141585456
	6141590304 -> 6141590064
	6137831856 [label="
 (480, 80, 1, 1)" fillcolor=lightblue]
	6137831856 -> 6141590304
	6141590304 [label=AccumulateGrad]
	6141589920 -> 6141589728
	6137831936 [label="
 (480)" fillcolor=lightblue]
	6137831936 -> 6141589920
	6141589920 [label=AccumulateGrad]
	6141589296 -> 6141589728
	6137832016 [label="
 (480)" fillcolor=lightblue]
	6137832016 -> 6141589296
	6141589296 [label=AccumulateGrad]
	6140277872 -> 6141948672
	6140277872 [label="
 (1, 480, 75, 75)" fillcolor=orange]
	6141589344 -> 6141590544
	6137832576 [label="
 (480, 1, 5, 5)" fillcolor=lightblue]
	6137832576 -> 6141589344
	6141589344 [label=AccumulateGrad]
	6141589056 -> 6141588816
	6137832496 [label="
 (480)" fillcolor=lightblue]
	6137832496 -> 6141589056
	6141589056 [label=AccumulateGrad]
	6141588576 -> 6141588816
	6137832656 [label="
 (480)" fillcolor=lightblue]
	6137832656 -> 6141588576
	6141588576 [label=AccumulateGrad]
	6140270432 -> 6141948896
	6140270432 [label="
 (1, 480, 75, 75)" fillcolor=orange]
	6141587904 -> 6141588048
	6137833216 [label="
 (20, 480, 1, 1)" fillcolor=lightblue]
	6137833216 -> 6141587904
	6141587904 [label=AccumulateGrad]
	6141587760 -> 6141588048
	6137833296 [label="
 (20)" fillcolor=lightblue]
	6137833296 -> 6141587760
	6141587760 [label=AccumulateGrad]
	6140270752 -> 6141949120
	6140270752 [label="
 (1, 20, 1, 1)" fillcolor=orange]
	6141587568 -> 6141587088
	6137833456 [label="
 (480, 20, 1, 1)" fillcolor=lightblue]
	6137833456 -> 6141587568
	6141587568 [label=AccumulateGrad]
	6141587328 -> 6141587088
	6137833536 [label="
 (480)" fillcolor=lightblue]
	6137833536 -> 6141587328
	6141587328 [label=AccumulateGrad]
	6141948896 -> 6141586560
	6141586656 -> 6141586320
	6137833696 [label="
 (80, 480, 1, 1)" fillcolor=lightblue]
	6137833696 -> 6141586656
	6141586656 [label=AccumulateGrad]
	6141586032 -> 6141587520
	6137833776 [label="
 (80)" fillcolor=lightblue]
	6137833776 -> 6141586032
	6141586032 [label=AccumulateGrad]
	6141585408 -> 6141587520
	6137833856 [label="
 (80)" fillcolor=lightblue]
	6137833856 -> 6141585408
	6141585408 [label=AccumulateGrad]
	6141585456 -> 6141580512
	6141585024 -> 6141584832
	6137834336 [label="
 (480, 80, 1, 1)" fillcolor=lightblue]
	6137834336 -> 6141585024
	6141585024 [label=AccumulateGrad]
	6141585072 -> 6141584640
	6137834416 [label="
 (480)" fillcolor=lightblue]
	6137834416 -> 6141585072
	6141585072 [label=AccumulateGrad]
	6141584544 -> 6141584640
	6137834496 [label="
 (480)" fillcolor=lightblue]
	6137834496 -> 6141584544
	6141584544 [label=AccumulateGrad]
	6140277712 -> 6141949344
	6140277712 [label="
 (1, 480, 75, 75)" fillcolor=orange]
	6141584064 -> 6141583584
	6137835056 [label="
 (480, 1, 5, 5)" fillcolor=lightblue]
	6137835056 -> 6141584064
	6141584064 [label=AccumulateGrad]
	6141583824 -> 6141583440
	6137834976 [label="
 (480)" fillcolor=lightblue]
	6137834976 -> 6141583824
	6141583824 [label=AccumulateGrad]
	6141583296 -> 6141583440
	6137835136 [label="
 (480)" fillcolor=lightblue]
	6137835136 -> 6141583296
	6141583296 [label=AccumulateGrad]
	6140276192 -> 6141949568
	6140276192 [label="
 (1, 480, 75, 75)" fillcolor=orange]
	6141582816 -> 6141582768
	6137835696 [label="
 (20, 480, 1, 1)" fillcolor=lightblue]
	6137835696 -> 6141582816
	6141582816 [label=AccumulateGrad]
	6141582288 -> 6141582768
	6137835776 [label="
 (20)" fillcolor=lightblue]
	6137835776 -> 6141582288
	6141582288 [label=AccumulateGrad]
	6140274432 -> 6141949792
	6140274432 [label="
 (1, 20, 1, 1)" fillcolor=orange]
	6141582336 -> 6141582144
	6137835936 [label="
 (480, 20, 1, 1)" fillcolor=lightblue]
	6137835936 -> 6141582336
	6141582336 [label=AccumulateGrad]
	6141582000 -> 6141582144
	6137836016 [label="
 (480)" fillcolor=lightblue]
	6137836016 -> 6141582000
	6141582000 [label=AccumulateGrad]
	6141949568 -> 6141581520
	6141581568 -> 6141581328
	6137836176 [label="
 (80, 480, 1, 1)" fillcolor=lightblue]
	6137836176 -> 6141581568
	6141581568 [label=AccumulateGrad]
	6141581088 -> 6141580944
	6137836256 [label="
 (80)" fillcolor=lightblue]
	6137836256 -> 6141581088
	6141581088 [label=AccumulateGrad]
	6141580704 -> 6141580944
	6137836336 [label="
 (80)" fillcolor=lightblue]
	6137836336 -> 6141580704
	6141580704 [label=AccumulateGrad]
	6141580512 -> 6141576816
	6141580128 -> 6141583056
	6137836816 [label="
 (480, 80, 1, 1)" fillcolor=lightblue]
	6137836816 -> 6141580128
	6141580128 [label=AccumulateGrad]
	6141579792 -> 6141579744
	6137836896 [label="
 (480)" fillcolor=lightblue]
	6137836896 -> 6141579792
	6141579792 [label=AccumulateGrad]
	6141579312 -> 6141579744
	6137836976 [label="
 (480)" fillcolor=lightblue]
	6137836976 -> 6141579312
	6141579312 [label=AccumulateGrad]
	6140264592 -> 6141950016
	6140264592 [label="
 (1, 480, 75, 75)" fillcolor=orange]
	6141579024 -> 6141578784
	6137837536 [label="
 (480, 1, 5, 5)" fillcolor=lightblue]
	6137837536 -> 6141579024
	6141579024 [label=AccumulateGrad]
	6141578496 -> 6141578544
	6137837456 [label="
 (480)" fillcolor=lightblue]
	6137837456 -> 6141578496
	6141578496 [label=AccumulateGrad]
	6141577776 -> 6141578544
	6137837616 [label="
 (480)" fillcolor=lightblue]
	6137837616 -> 6141577776
	6141577776 [label=AccumulateGrad]
	6140279552 -> 6141950240
	6140279552 [label="
 (1, 480, 75, 75)" fillcolor=orange]
	6141577680 -> 6141577296
	6137838176 [label="
 (20, 480, 1, 1)" fillcolor=lightblue]
	6137838176 -> 6141577680
	6141577680 [label=AccumulateGrad]
	6141577008 -> 6141577296
	6137838336 [label="
 (20)" fillcolor=lightblue]
	6137838336 -> 6141577008
	6141577008 [label=AccumulateGrad]
	6140264752 -> 6141950464
	6140264752 [label="
 (1, 20, 1, 1)" fillcolor=orange]
	6141577056 -> 6141580032
	6137838496 [label="
 (480, 20, 1, 1)" fillcolor=lightblue]
	6137838496 -> 6141577056
	6141577056 [label=AccumulateGrad]
	6141576768 -> 6141580032
	6137838576 [label="
 (480)" fillcolor=lightblue]
	6137838576 -> 6141576768
	6141576768 [label=AccumulateGrad]
	6141950240 -> 6141576432
	6141576192 -> 6141575616
	6137838736 [label="
 (80, 480, 1, 1)" fillcolor=lightblue]
	6137838736 -> 6141576192
	6141576192 [label=AccumulateGrad]
	6141576048 -> 6141575664
	6137838816 [label="
 (80)" fillcolor=lightblue]
	6137838816 -> 6141576048
	6141576048 [label=AccumulateGrad]
	6141578256 -> 6141575664
	6137838896 [label="
 (80)" fillcolor=lightblue]
	6137838896 -> 6141578256
	6141578256 [label=AccumulateGrad]
	6141576816 -> 6140460816
	6140460864 -> 6140460576
	6141602736 [label="
 (256, 80, 1, 1)" fillcolor=lightblue]
	6141602736 -> 6140460864
	6140460864 [label=AccumulateGrad]
	6140460624 -> 6140460576
	6141602576 [label="
 (256)" fillcolor=lightblue]
	6141602576 -> 6140460624
	6140460624 [label=AccumulateGrad]
	6140460336 -> 6140460096
	6140460336 [label="UpsampleNearest2DBackward0
--------------------------------
output_size   :         (75, 75)
scales_h      :             None
scales_w      :             None
self_sym_sizes: (1, 256, 38, 38)"]
	6141575520 -> 6140460336
	6141575520 [label="AddBackward0
------------
alpha: 1"]
	6141576000 -> 6141575520
	6141576000 -> 6140166368 [dir=none]
	6140166368 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6141576000 -> 6141603376 [dir=none]
	6141603376 [label="weight
 (256, 224, 1, 1)" fillcolor=orange]
	6141576000 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (256,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141576576 -> 6141576000
	6141576576 [label="AddBackward0
------------
alpha: 1"]
	6141578016 -> 6141576576
	6141578016 -> 6140166208 [dir=none]
	6140166208 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6141578016 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141578736 -> 6141578016
	6141578736 -> 6142245952 [dir=none]
	6142245952 [label="other
 ()" fillcolor=orange]
	6141578736 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141579504 -> 6141578736
	6141579504 -> 6140166448 [dir=none]
	6140166448 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6141579504 -> 6142246272 [dir=none]
	6142246272 [label="result1
 (224)" fillcolor=orange]
	6141579504 -> 6142246192 [dir=none]
	6142246192 [label="result2
 (224)" fillcolor=orange]
	6141579504 -> 6138739776 [dir=none]
	6138739776 [label="running_mean
 (224)" fillcolor=orange]
	6141579504 -> 6138740096 [dir=none]
	6138740096 [label="running_var
 (224)" fillcolor=orange]
	6141579504 -> 6138739936 [dir=none]
	6138739936 [label="weight
 (224)" fillcolor=orange]
	6141579504 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141580272 -> 6141579504
	6141580272 -> 6140166608 [dir=none]
	6140166608 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6141580272 -> 6138739856 [dir=none]
	6138739856 [label="weight
 (224, 1344, 1, 1)" fillcolor=orange]
	6141580272 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141581040 -> 6141580272
	6141581040 -> 6140167408 [dir=none]
	6140167408 [label="other
 (1, 1344, 38, 38)" fillcolor=orange]
	6141581040 -> 6140167088 [dir=none]
	6140167088 [label="self
 (1, 1344, 1, 1)" fillcolor=orange]
	6141581040 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6141581760 -> 6141581040
	6141581760 -> 6142246352 [dir=none]
	6142246352 [label="result
 (1, 1344, 1, 1)" fillcolor=orange]
	6141581760 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6141582528 -> 6141581760
	6141582528 -> 6140166928 [dir=none]
	6140166928 [label="input
 (1, 56, 1, 1)" fillcolor=orange]
	6141582528 -> 6138739616 [dir=none]
	6138739616 [label="weight
 (1344, 56, 1, 1)" fillcolor=orange]
	6141582528 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (1344,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141521792 -> 6141582528
	6141521792 [label=SwishImplementationBackward]
	6141585216 -> 6141521792
	6141585216 -> 6140167648 [dir=none]
	6140167648 [label="input
 (1, 1344, 1, 1)" fillcolor=orange]
	6141585216 -> 6138739376 [dir=none]
	6138739376 [label="weight
 (56, 1344, 1, 1)" fillcolor=orange]
	6141585216 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (56,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141587808 -> 6141585216
	6141587808 -> 6140167408 [dir=none]
	6140167408 [label="self
 (1, 1344, 38, 38)" fillcolor=orange]
	6141587808 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 1344, 38, 38)"]
	6141521568 -> 6141587808
	6141521568 [label=SwishImplementationBackward]
	6141586272 -> 6141521568
	6141586272 -> 6140168128 [dir=none]
	6140168128 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6141586272 -> 6142263600 [dir=none]
	6142263600 [label="result1
 (1344)" fillcolor=orange]
	6141586272 -> 6142263680 [dir=none]
	6142263680 [label="result2
 (1344)" fillcolor=orange]
	6141586272 -> 6138737136 [dir=none]
	6138737136 [label="running_mean
 (1344)" fillcolor=orange]
	6141586272 -> 6138738896 [dir=none]
	6138738896 [label="running_var
 (1344)" fillcolor=orange]
	6141586272 -> 6138738656 [dir=none]
	6138738656 [label="weight
 (1344)" fillcolor=orange]
	6141586272 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141587040 -> 6141586272
	6141587040 -> 6140168288 [dir=none]
	6140168288 [label="input
 (1, 1344, 42, 42)" fillcolor=orange]
	6141587040 -> 6138738736 [dir=none]
	6138738736 [label="weight
 (1344, 1, 5, 5)" fillcolor=orange]
	6141587040 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1344
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141588528 -> 6141587040
	6141588528 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6141521344 -> 6141588528
	6141521344 [label=SwishImplementationBackward]
	6141589968 -> 6141521344
	6141589968 -> 6140169728 [dir=none]
	6140169728 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6141589968 -> 6142264160 [dir=none]
	6142264160 [label="result1
 (1344)" fillcolor=orange]
	6141589968 -> 6142264240 [dir=none]
	6142264240 [label="result2
 (1344)" fillcolor=orange]
	6141589968 -> 6138738016 [dir=none]
	6138738016 [label="running_mean
 (1344)" fillcolor=orange]
	6141589968 -> 6138738336 [dir=none]
	6138738336 [label="running_var
 (1344)" fillcolor=orange]
	6141589968 -> 6138738176 [dir=none]
	6138738176 [label="weight
 (1344)" fillcolor=orange]
	6141589968 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141590592 -> 6141589968
	6141590592 -> 6140168768 [dir=none]
	6140168768 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6141590592 -> 6138738096 [dir=none]
	6138738096 [label="weight
 (1344, 224, 1, 1)" fillcolor=orange]
	6141590592 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141577632 -> 6141590592
	6141577632 [label="AddBackward0
------------
alpha: 1"]
	6141673536 -> 6141577632
	6141673536 -> 6140168608 [dir=none]
	6140168608 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6141673536 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141674784 -> 6141673536
	6141674784 -> 6142264560 [dir=none]
	6142264560 [label="other
 ()" fillcolor=orange]
	6141674784 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141675552 -> 6141674784
	6141675552 -> 6140169088 [dir=none]
	6140169088 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6141675552 -> 6142264880 [dir=none]
	6142264880 [label="result1
 (224)" fillcolor=orange]
	6141675552 -> 6142264800 [dir=none]
	6142264800 [label="result2
 (224)" fillcolor=orange]
	6141675552 -> 6138737376 [dir=none]
	6138737376 [label="running_mean
 (224)" fillcolor=orange]
	6141675552 -> 6138737696 [dir=none]
	6138737696 [label="running_var
 (224)" fillcolor=orange]
	6141675552 -> 6138737536 [dir=none]
	6138737536 [label="weight
 (224)" fillcolor=orange]
	6141675552 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141675792 -> 6141675552
	6141675792 -> 6140169248 [dir=none]
	6140169248 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6141675792 -> 6138737456 [dir=none]
	6138737456 [label="weight
 (224, 1344, 1, 1)" fillcolor=orange]
	6141675792 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141676176 -> 6141675792
	6141676176 -> 6140169808 [dir=none]
	6140169808 [label="other
 (1, 1344, 38, 38)" fillcolor=orange]
	6141676176 -> 6140169568 [dir=none]
	6140169568 [label="self
 (1, 1344, 1, 1)" fillcolor=orange]
	6141676176 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6141677808 -> 6141676176
	6141677808 -> 6142264960 [dir=none]
	6142264960 [label="result
 (1, 1344, 1, 1)" fillcolor=orange]
	6141677808 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6141678336 -> 6141677808
	6141678336 -> 6140169408 [dir=none]
	6140169408 [label="input
 (1, 56, 1, 1)" fillcolor=orange]
	6141678336 -> 6138737216 [dir=none]
	6138737216 [label="weight
 (1344, 56, 1, 1)" fillcolor=orange]
	6141678336 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (1344,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141521120 -> 6141678336
	6141521120 [label=SwishImplementationBackward]
	6141680208 -> 6141521120
	6141680208 -> 6140170208 [dir=none]
	6140170208 [label="input
 (1, 1344, 1, 1)" fillcolor=orange]
	6141680208 -> 6138736976 [dir=none]
	6138736976 [label="weight
 (56, 1344, 1, 1)" fillcolor=orange]
	6141680208 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (56,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141680640 -> 6141680208
	6141680640 -> 6140169808 [dir=none]
	6140169808 [label="self
 (1, 1344, 38, 38)" fillcolor=orange]
	6141680640 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 1344, 38, 38)"]
	6141520896 -> 6141680640
	6141520896 [label=SwishImplementationBackward]
	6141682272 -> 6141520896
	6141682272 -> 6140170688 [dir=none]
	6140170688 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6141682272 -> 6142265680 [dir=none]
	6142265680 [label="result1
 (1344)" fillcolor=orange]
	6141682272 -> 6142265760 [dir=none]
	6142265760 [label="result2
 (1344)" fillcolor=orange]
	6141682272 -> 6138734736 [dir=none]
	6138734736 [label="running_mean
 (1344)" fillcolor=orange]
	6141682272 -> 6138736576 [dir=none]
	6138736576 [label="running_var
 (1344)" fillcolor=orange]
	6141682272 -> 6138736336 [dir=none]
	6138736336 [label="weight
 (1344)" fillcolor=orange]
	6141682272 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141682896 -> 6141682272
	6141682896 -> 6140170848 [dir=none]
	6140170848 [label="input
 (1, 1344, 42, 42)" fillcolor=orange]
	6141682896 -> 6138736416 [dir=none]
	6138736416 [label="weight
 (1344, 1, 5, 5)" fillcolor=orange]
	6141682896 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1344
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141683616 -> 6141682896
	6141683616 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6141520672 -> 6141683616
	6141520672 [label=SwishImplementationBackward]
	6141685536 -> 6141520672
	6141685536 -> 6140171968 [dir=none]
	6140171968 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6141685536 -> 6142266240 [dir=none]
	6142266240 [label="result1
 (1344)" fillcolor=orange]
	6141685536 -> 6142266320 [dir=none]
	6142266320 [label="result2
 (1344)" fillcolor=orange]
	6141685536 -> 6138735616 [dir=none]
	6138735616 [label="running_mean
 (1344)" fillcolor=orange]
	6141685536 -> 6138735936 [dir=none]
	6138735936 [label="running_var
 (1344)" fillcolor=orange]
	6141685536 -> 6138735776 [dir=none]
	6138735776 [label="weight
 (1344)" fillcolor=orange]
	6141685536 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141686160 -> 6141685536
	6141686160 -> 6140171248 [dir=none]
	6140171248 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6141686160 -> 6138735696 [dir=none]
	6138735696 [label="weight
 (1344, 224, 1, 1)" fillcolor=orange]
	6141686160 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141675648 -> 6141686160
	6141675648 [label="AddBackward0
------------
alpha: 1"]
	6141688656 -> 6141675648
	6141688656 -> 6140170928 [dir=none]
	6140170928 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6141688656 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141688368 -> 6141688656
	6141688368 -> 6142266640 [dir=none]
	6142266640 [label="other
 ()" fillcolor=orange]
	6141688368 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141689232 -> 6141688368
	6141689232 -> 6140171408 [dir=none]
	6140171408 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6141689232 -> 6142266960 [dir=none]
	6142266960 [label="result1
 (224)" fillcolor=orange]
	6141689232 -> 6142266880 [dir=none]
	6142266880 [label="result2
 (224)" fillcolor=orange]
	6141689232 -> 6138734976 [dir=none]
	6138734976 [label="running_mean
 (224)" fillcolor=orange]
	6141689232 -> 6138735296 [dir=none]
	6138735296 [label="running_var
 (224)" fillcolor=orange]
	6141689232 -> 6138735136 [dir=none]
	6138735136 [label="weight
 (224)" fillcolor=orange]
	6141689232 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141689760 -> 6141689232
	6141689760 -> 6140171568 [dir=none]
	6140171568 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6141689760 -> 6138735056 [dir=none]
	6138735056 [label="weight
 (224, 1344, 1, 1)" fillcolor=orange]
	6141689760 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141740896 -> 6141689760
	6141740896 -> 6140172048 [dir=none]
	6140172048 [label="other
 (1, 1344, 38, 38)" fillcolor=orange]
	6141740896 -> 6140171808 [dir=none]
	6140171808 [label="self
 (1, 1344, 1, 1)" fillcolor=orange]
	6141740896 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6141740656 -> 6141740896
	6141740656 -> 6142267040 [dir=none]
	6142267040 [label="result
 (1, 1344, 1, 1)" fillcolor=orange]
	6141740656 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6141741328 -> 6141740656
	6141741328 -> 6140171728 [dir=none]
	6140171728 [label="input
 (1, 56, 1, 1)" fillcolor=orange]
	6141741328 -> 6138734816 [dir=none]
	6138734816 [label="weight
 (1344, 56, 1, 1)" fillcolor=orange]
	6141741328 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (1344,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141520448 -> 6141741328
	6141520448 [label=SwishImplementationBackward]
	6141742864 -> 6141520448
	6141742864 -> 6140172448 [dir=none]
	6140172448 [label="input
 (1, 1344, 1, 1)" fillcolor=orange]
	6141742864 -> 6138734576 [dir=none]
	6138734576 [label="weight
 (56, 1344, 1, 1)" fillcolor=orange]
	6141742864 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (56,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141744160 -> 6141742864
	6141744160 -> 6140172048 [dir=none]
	6140172048 [label="self
 (1, 1344, 38, 38)" fillcolor=orange]
	6141744160 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 1344, 38, 38)"]
	6141520224 -> 6141744160
	6141520224 [label=SwishImplementationBackward]
	6141745360 -> 6141520224
	6141745360 -> 6140173008 [dir=none]
	6140173008 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6141745360 -> 6142267760 [dir=none]
	6142267760 [label="result1
 (1344)" fillcolor=orange]
	6141745360 -> 6142267840 [dir=none]
	6142267840 [label="result2
 (1344)" fillcolor=orange]
	6141745360 -> 6138732256 [dir=none]
	6138732256 [label="running_mean
 (1344)" fillcolor=orange]
	6141745360 -> 6138734096 [dir=none]
	6138734096 [label="running_var
 (1344)" fillcolor=orange]
	6141745360 -> 6138733856 [dir=none]
	6138733856 [label="weight
 (1344)" fillcolor=orange]
	6141745360 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141746224 -> 6141745360
	6141746224 -> 6140173168 [dir=none]
	6140173168 [label="input
 (1, 1344, 42, 42)" fillcolor=orange]
	6141746224 -> 6138733936 [dir=none]
	6138733936 [label="weight
 (1344, 1, 5, 5)" fillcolor=orange]
	6141746224 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1344
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141747088 -> 6141746224
	6141747088 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6141520000 -> 6141747088
	6141520000 [label=SwishImplementationBackward]
	6141748432 -> 6141520000
	6141748432 -> 6140174208 [dir=none]
	6140174208 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6141748432 -> 6142268320 [dir=none]
	6142268320 [label="result1
 (1344)" fillcolor=orange]
	6141748432 -> 6142268400 [dir=none]
	6142268400 [label="result2
 (1344)" fillcolor=orange]
	6141748432 -> 6138733136 [dir=none]
	6138733136 [label="running_mean
 (1344)" fillcolor=orange]
	6141748432 -> 6138733456 [dir=none]
	6138733456 [label="running_var
 (1344)" fillcolor=orange]
	6141748432 -> 6138733296 [dir=none]
	6138733296 [label="weight
 (1344)" fillcolor=orange]
	6141748432 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141749536 -> 6141748432
	6141749536 -> 6140173568 [dir=none]
	6140173568 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6141749536 -> 6138733216 [dir=none]
	6138733216 [label="weight
 (1344, 224, 1, 1)" fillcolor=orange]
	6141749536 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141687360 -> 6141749536
	6141687360 [label="AddBackward0
------------
alpha: 1"]
	6141750640 -> 6141687360
	6141750640 -> 6140173408 [dir=none]
	6140173408 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6141750640 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141751648 -> 6141750640
	6141751648 -> 6142268720 [dir=none]
	6142268720 [label="other
 ()" fillcolor=orange]
	6141751648 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141752416 -> 6141751648
	6141752416 -> 6140173728 [dir=none]
	6140173728 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6141752416 -> 6142269040 [dir=none]
	6142269040 [label="result1
 (224)" fillcolor=orange]
	6141752416 -> 6142268960 [dir=none]
	6142268960 [label="result2
 (224)" fillcolor=orange]
	6141752416 -> 6138732496 [dir=none]
	6138732496 [label="running_mean
 (224)" fillcolor=orange]
	6141752416 -> 6138732816 [dir=none]
	6138732816 [label="running_var
 (224)" fillcolor=orange]
	6141752416 -> 6138732656 [dir=none]
	6138732656 [label="weight
 (224)" fillcolor=orange]
	6141752416 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141752752 -> 6141752416
	6141752752 -> 6140173808 [dir=none]
	6140173808 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6141752752 -> 6138732576 [dir=none]
	6138732576 [label="weight
 (224, 1344, 1, 1)" fillcolor=orange]
	6141752752 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141754144 -> 6141752752
	6141754144 -> 6140174368 [dir=none]
	6140174368 [label="other
 (1, 1344, 38, 38)" fillcolor=orange]
	6141754144 -> 6140174128 [dir=none]
	6140174128 [label="self
 (1, 1344, 1, 1)" fillcolor=orange]
	6141754144 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6141755104 -> 6141754144
	6141755104 -> 6142269120 [dir=none]
	6142269120 [label="result
 (1, 1344, 1, 1)" fillcolor=orange]
	6141755104 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6141754384 -> 6141755104
	6141754384 -> 6140173968 [dir=none]
	6140173968 [label="input
 (1, 56, 1, 1)" fillcolor=orange]
	6141754384 -> 6138732336 [dir=none]
	6138732336 [label="weight
 (1344, 56, 1, 1)" fillcolor=orange]
	6141754384 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (1344,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141519776 -> 6141754384
	6141519776 [label=SwishImplementationBackward]
	6141854096 -> 6141519776
	6141854096 -> 6140174528 [dir=none]
	6140174528 [label="input
 (1, 1344, 1, 1)" fillcolor=orange]
	6141854096 -> 6138732096 [dir=none]
	6138732096 [label="weight
 (56, 1344, 1, 1)" fillcolor=orange]
	6141854096 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (56,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141855344 -> 6141854096
	6141855344 -> 6140174368 [dir=none]
	6140174368 [label="self
 (1, 1344, 38, 38)" fillcolor=orange]
	6141855344 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 1344, 38, 38)"]
	6141519552 -> 6141855344
	6141519552 [label=SwishImplementationBackward]
	6141857312 -> 6141519552
	6141857312 -> 6140175168 [dir=none]
	6140175168 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6141857312 -> 6142269840 [dir=none]
	6142269840 [label="result1
 (1344)" fillcolor=orange]
	6141857312 -> 6142269920 [dir=none]
	6142269920 [label="result2
 (1344)" fillcolor=orange]
	6141857312 -> 6138729936 [dir=none]
	6138729936 [label="running_mean
 (1344)" fillcolor=orange]
	6141857312 -> 6138731696 [dir=none]
	6138731696 [label="running_var
 (1344)" fillcolor=orange]
	6141857312 -> 6138731456 [dir=none]
	6138731456 [label="weight
 (1344)" fillcolor=orange]
	6141857312 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141857600 -> 6141857312
	6141857600 -> 6140175248 [dir=none]
	6140175248 [label="input
 (1, 1344, 42, 42)" fillcolor=orange]
	6141857600 -> 6138731536 [dir=none]
	6138731536 [label="weight
 (1344, 1, 5, 5)" fillcolor=orange]
	6141857600 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1344
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141858368 -> 6141857600
	6141858368 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6141519328 -> 6141858368
	6141519328 [label=SwishImplementationBackward]
	6141859952 -> 6141519328
	6141859952 -> 6140176368 [dir=none]
	6140176368 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6141859952 -> 6142270400 [dir=none]
	6142270400 [label="result1
 (1344)" fillcolor=orange]
	6141859952 -> 6142270480 [dir=none]
	6142270480 [label="result2
 (1344)" fillcolor=orange]
	6141859952 -> 6138730816 [dir=none]
	6138730816 [label="running_mean
 (1344)" fillcolor=orange]
	6141859952 -> 6138731136 [dir=none]
	6138731136 [label="running_var
 (1344)" fillcolor=orange]
	6141859952 -> 6138730976 [dir=none]
	6138730976 [label="weight
 (1344)" fillcolor=orange]
	6141859952 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141861344 -> 6141859952
	6141861344 -> 6140175488 [dir=none]
	6140175488 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6141861344 -> 6138730896 [dir=none]
	6138730896 [label="weight
 (1344, 224, 1, 1)" fillcolor=orange]
	6141861344 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141750784 -> 6141861344
	6141750784 [label="AddBackward0
------------
alpha: 1"]
	11135954288 -> 6141750784
	11135954288 -> 6140175408 [dir=none]
	6140175408 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11135954288 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135954960 -> 11135954288
	11135954960 -> 6142270800 [dir=none]
	6142270800 [label="other
 ()" fillcolor=orange]
	11135954960 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135954720 -> 11135954960
	11135954720 -> 6140175648 [dir=none]
	6140175648 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	11135954720 -> 6142271120 [dir=none]
	6142271120 [label="result1
 (224)" fillcolor=orange]
	11135954720 -> 6142271040 [dir=none]
	6142271040 [label="result2
 (224)" fillcolor=orange]
	11135954720 -> 6138730176 [dir=none]
	6138730176 [label="running_mean
 (224)" fillcolor=orange]
	11135954720 -> 6138730496 [dir=none]
	6138730496 [label="running_var
 (224)" fillcolor=orange]
	11135954720 -> 6138730336 [dir=none]
	6138730336 [label="weight
 (224)" fillcolor=orange]
	11135954720 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135956304 -> 11135954720
	11135956304 -> 6140175968 [dir=none]
	6140175968 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	11135956304 -> 6138730256 [dir=none]
	6138730256 [label="weight
 (224, 1344, 1, 1)" fillcolor=orange]
	11135956304 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135956544 -> 11135956304
	11135956544 -> 6140176528 [dir=none]
	6140176528 [label="other
 (1, 1344, 38, 38)" fillcolor=orange]
	11135956544 -> 6140176208 [dir=none]
	6140176208 [label="self
 (1, 1344, 1, 1)" fillcolor=orange]
	11135956544 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135956832 -> 11135956544
	11135956832 -> 6142271200 [dir=none]
	6142271200 [label="result
 (1, 1344, 1, 1)" fillcolor=orange]
	11135956832 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135957408 -> 11135956832
	11135957408 -> 6140176128 [dir=none]
	6140176128 [label="input
 (1, 56, 1, 1)" fillcolor=orange]
	11135957408 -> 6138730016 [dir=none]
	6138730016 [label="weight
 (1344, 56, 1, 1)" fillcolor=orange]
	11135957408 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (1344,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141519104 -> 11135957408
	6141519104 [label=SwishImplementationBackward]
	11135958608 -> 6141519104
	11135958608 -> 6140176768 [dir=none]
	6140176768 [label="input
 (1, 1344, 1, 1)" fillcolor=orange]
	11135958608 -> 6138729776 [dir=none]
	6138729776 [label="weight
 (56, 1344, 1, 1)" fillcolor=orange]
	11135958608 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (56,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135953568 -> 11135958608
	11135953568 -> 6140176528 [dir=none]
	6140176528 [label="self
 (1, 1344, 38, 38)" fillcolor=orange]
	11135953568 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 1344, 38, 38)"]
	6141518880 -> 11135953568
	6141518880 [label=SwishImplementationBackward]
	11135951936 -> 6141518880
	11135951936 -> 6140177488 [dir=none]
	6140177488 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	11135951936 -> 6142271920 [dir=none]
	6142271920 [label="result1
 (1344)" fillcolor=orange]
	11135951936 -> 6142272000 [dir=none]
	6142272000 [label="result2
 (1344)" fillcolor=orange]
	11135951936 -> 6138727456 [dir=none]
	6138727456 [label="running_mean
 (1344)" fillcolor=orange]
	11135951936 -> 6138729296 [dir=none]
	6138729296 [label="running_var
 (1344)" fillcolor=orange]
	11135951936 -> 6138729056 [dir=none]
	6138729056 [label="weight
 (1344)" fillcolor=orange]
	11135951936 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135951552 -> 11135951936
	11135951552 -> 6140177648 [dir=none]
	6140177648 [label="input
 (1, 1344, 42, 42)" fillcolor=orange]
	11135951552 -> 6138729136 [dir=none]
	6138729136 [label="weight
 (1344, 1, 5, 5)" fillcolor=orange]
	11135951552 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1344
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135950400 -> 11135951552
	11135950400 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6141518656 -> 11135950400
	6141518656 [label=SwishImplementationBackward]
	11135949824 -> 6141518656
	11135949824 -> 6140178608 [dir=none]
	6140178608 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	11135949824 -> 6142272480 [dir=none]
	6142272480 [label="result1
 (1344)" fillcolor=orange]
	11135949824 -> 6142272560 [dir=none]
	6142272560 [label="result2
 (1344)" fillcolor=orange]
	11135949824 -> 6138728336 [dir=none]
	6138728336 [label="running_mean
 (1344)" fillcolor=orange]
	11135949824 -> 6138728656 [dir=none]
	6138728656 [label="running_var
 (1344)" fillcolor=orange]
	11135949824 -> 6138728496 [dir=none]
	6138728496 [label="weight
 (1344)" fillcolor=orange]
	11135949824 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135949392 -> 11135949824
	11135949392 -> 6140178128 [dir=none]
	6140178128 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	11135949392 -> 6138728416 [dir=none]
	6138728416 [label="weight
 (1344, 224, 1, 1)" fillcolor=orange]
	11135949392 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135954096 -> 11135949392
	11135954096 [label="AddBackward0
------------
alpha: 1"]
	11135948048 -> 11135954096
	11135948048 -> 6140177808 [dir=none]
	6140177808 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11135948048 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135947472 -> 11135948048
	11135947472 -> 6142272880 [dir=none]
	6142272880 [label="other
 ()" fillcolor=orange]
	11135947472 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135946944 -> 11135947472
	11135946944 -> 6140178288 [dir=none]
	6140178288 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	11135946944 -> 6142273200 [dir=none]
	6142273200 [label="result1
 (224)" fillcolor=orange]
	11135946944 -> 6142273120 [dir=none]
	6142273120 [label="result2
 (224)" fillcolor=orange]
	11135946944 -> 6138727696 [dir=none]
	6138727696 [label="running_mean
 (224)" fillcolor=orange]
	11135946944 -> 6138728016 [dir=none]
	6138728016 [label="running_var
 (224)" fillcolor=orange]
	11135946944 -> 6138727856 [dir=none]
	6138727856 [label="weight
 (224)" fillcolor=orange]
	11135946944 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135947040 -> 11135946944
	11135947040 -> 6140178368 [dir=none]
	6140178368 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	11135947040 -> 6138727776 [dir=none]
	6138727776 [label="weight
 (224, 1344, 1, 1)" fillcolor=orange]
	11135947040 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135946224 -> 11135947040
	11135946224 -> 6140178688 [dir=none]
	6140178688 [label="other
 (1, 1344, 38, 38)" fillcolor=orange]
	11135946224 -> 6140178528 [dir=none]
	6140178528 [label="self
 (1, 1344, 1, 1)" fillcolor=orange]
	11135946224 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135945456 -> 11135946224
	11135945456 -> 6142273280 [dir=none]
	6142273280 [label="result
 (1, 1344, 1, 1)" fillcolor=orange]
	11135945456 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135945072 -> 11135945456
	11135945072 -> 6140178448 [dir=none]
	6140178448 [label="input
 (1, 56, 1, 1)" fillcolor=orange]
	11135945072 -> 6138727536 [dir=none]
	6138727536 [label="weight
 (1344, 56, 1, 1)" fillcolor=orange]
	11135945072 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (1344,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141518432 -> 11135945072
	6141518432 [label=SwishImplementationBackward]
	11135944160 -> 6141518432
	11135944160 -> 6140178208 [dir=none]
	6140178208 [label="input
 (1, 1344, 1, 1)" fillcolor=orange]
	11135944160 -> 6138727296 [dir=none]
	6138727296 [label="weight
 (56, 1344, 1, 1)" fillcolor=orange]
	11135944160 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (56,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135943632 -> 11135944160
	11135943632 -> 6140178688 [dir=none]
	6140178688 [label="self
 (1, 1344, 38, 38)" fillcolor=orange]
	11135943632 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 1344, 38, 38)"]
	6141518208 -> 11135943632
	6141518208 [label=SwishImplementationBackward]
	11135943344 -> 6141518208
	11135943344 -> 6140179328 [dir=none]
	6140179328 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	11135943344 -> 6142274000 [dir=none]
	6142274000 [label="result1
 (1344)" fillcolor=orange]
	11135943344 -> 6142274080 [dir=none]
	6142274080 [label="result2
 (1344)" fillcolor=orange]
	11135943344 -> 6138724976 [dir=none]
	6138724976 [label="running_mean
 (1344)" fillcolor=orange]
	11135943344 -> 6138726816 [dir=none]
	6138726816 [label="running_var
 (1344)" fillcolor=orange]
	11135943344 -> 6138726576 [dir=none]
	6138726576 [label="weight
 (1344)" fillcolor=orange]
	11135943344 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135876400 -> 11135943344
	11135876400 -> 6140179488 [dir=none]
	6140179488 [label="input
 (1, 1344, 42, 42)" fillcolor=orange]
	11135876400 -> 6138726656 [dir=none]
	6138726656 [label="weight
 (1344, 1, 5, 5)" fillcolor=orange]
	11135876400 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1344
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135875536 -> 11135876400
	11135875536 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6141517984 -> 11135875536
	6141517984 [label=SwishImplementationBackward]
	11135874720 -> 6141517984
	11135874720 -> 6140180528 [dir=none]
	6140180528 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	11135874720 -> 6142274560 [dir=none]
	6142274560 [label="result1
 (1344)" fillcolor=orange]
	11135874720 -> 6142274640 [dir=none]
	6142274640 [label="result2
 (1344)" fillcolor=orange]
	11135874720 -> 6138725856 [dir=none]
	6138725856 [label="running_mean
 (1344)" fillcolor=orange]
	11135874720 -> 6138726176 [dir=none]
	6138726176 [label="running_var
 (1344)" fillcolor=orange]
	11135874720 -> 6138726016 [dir=none]
	6138726016 [label="weight
 (1344)" fillcolor=orange]
	11135874720 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135874096 -> 11135874720
	11135874096 -> 6140179728 [dir=none]
	6140179728 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	11135874096 -> 6138725936 [dir=none]
	6138725936 [label="weight
 (1344, 224, 1, 1)" fillcolor=orange]
	11135874096 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135948336 -> 11135874096
	11135948336 [label="AddBackward0
------------
alpha: 1"]
	11135873424 -> 11135948336
	11135873424 -> 6140179648 [dir=none]
	6140179648 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11135873424 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135872992 -> 11135873424
	11135872992 -> 6142274960 [dir=none]
	6142274960 [label="other
 ()" fillcolor=orange]
	11135872992 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135872560 -> 11135872992
	11135872560 -> 6140179888 [dir=none]
	6140179888 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	11135872560 -> 6142275280 [dir=none]
	6142275280 [label="result1
 (224)" fillcolor=orange]
	11135872560 -> 6142275200 [dir=none]
	6142275200 [label="result2
 (224)" fillcolor=orange]
	11135872560 -> 6138725216 [dir=none]
	6138725216 [label="running_mean
 (224)" fillcolor=orange]
	11135872560 -> 6138725536 [dir=none]
	6138725536 [label="running_var
 (224)" fillcolor=orange]
	11135872560 -> 6138725376 [dir=none]
	6138725376 [label="weight
 (224)" fillcolor=orange]
	11135872560 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135872416 -> 11135872560
	11135872416 -> 6140179968 [dir=none]
	6140179968 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	11135872416 -> 6138725296 [dir=none]
	6138725296 [label="weight
 (224, 1344, 1, 1)" fillcolor=orange]
	11135872416 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135872128 -> 11135872416
	11135872128 -> 6140180688 [dir=none]
	6140180688 [label="other
 (1, 1344, 38, 38)" fillcolor=orange]
	11135872128 -> 6140180368 [dir=none]
	6140180368 [label="self
 (1, 1344, 1, 1)" fillcolor=orange]
	11135872128 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135871792 -> 11135872128
	11135871792 -> 6142275360 [dir=none]
	6142275360 [label="result
 (1, 1344, 1, 1)" fillcolor=orange]
	11135871792 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135871648 -> 11135871792
	11135871648 -> 6140180208 [dir=none]
	6140180208 [label="input
 (1, 56, 1, 1)" fillcolor=orange]
	11135871648 -> 6138725056 [dir=none]
	6138725056 [label="weight
 (1344, 56, 1, 1)" fillcolor=orange]
	11135871648 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (1344,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141517760 -> 11135871648
	6141517760 [label=SwishImplementationBackward]
	11135871216 -> 6141517760
	11135871216 -> 6140180928 [dir=none]
	6140180928 [label="input
 (1, 1344, 1, 1)" fillcolor=orange]
	11135871216 -> 6138724816 [dir=none]
	6138724816 [label="weight
 (56, 1344, 1, 1)" fillcolor=orange]
	11135871216 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (56,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135871072 -> 11135871216
	11135871072 -> 6140180688 [dir=none]
	6140180688 [label="self
 (1, 1344, 38, 38)" fillcolor=orange]
	11135871072 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 1344, 38, 38)"]
	6141517536 -> 11135871072
	6141517536 [label=SwishImplementationBackward]
	11135870640 -> 6141517536
	11135870640 -> 6140181248 [dir=none]
	6140181248 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	11135870640 -> 6142276080 [dir=none]
	6142276080 [label="result1
 (1344)" fillcolor=orange]
	11135870640 -> 6142276160 [dir=none]
	6142276160 [label="result2
 (1344)" fillcolor=orange]
	11135870640 -> 6138411136 [dir=none]
	6138411136 [label="running_mean
 (1344)" fillcolor=orange]
	11135870640 -> 6138412976 [dir=none]
	6138412976 [label="running_var
 (1344)" fillcolor=orange]
	11135870640 -> 6138412736 [dir=none]
	6138412736 [label="weight
 (1344)" fillcolor=orange]
	11135870640 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135870496 -> 11135870640
	11135870496 -> 6140181568 [dir=none]
	6140181568 [label="input
 (1, 1344, 42, 42)" fillcolor=orange]
	11135870496 -> 6138412816 [dir=none]
	6138412816 [label="weight
 (1344, 1, 5, 5)" fillcolor=orange]
	11135870496 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1344
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135870208 -> 11135870496
	11135870208 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6141517312 -> 11135870208
	6141517312 [label=SwishImplementationBackward]
	11135869968 -> 6141517312
	11135869968 -> 6140168928 [dir=none]
	6140168928 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	11135869968 -> 6142276640 [dir=none]
	6142276640 [label="result1
 (1344)" fillcolor=orange]
	11135869968 -> 6142276720 [dir=none]
	6142276720 [label="result2
 (1344)" fillcolor=orange]
	11135869968 -> 6138412016 [dir=none]
	6138412016 [label="running_mean
 (1344)" fillcolor=orange]
	11135869968 -> 6138412336 [dir=none]
	6138412336 [label="running_var
 (1344)" fillcolor=orange]
	11135869968 -> 6138412176 [dir=none]
	6138412176 [label="weight
 (1344)" fillcolor=orange]
	11135869968 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135869824 -> 11135869968
	11135869824 -> 6140182048 [dir=none]
	6140182048 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	11135869824 -> 6138412096 [dir=none]
	6138412096 [label="weight
 (1344, 224, 1, 1)" fillcolor=orange]
	11135869824 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135873232 -> 11135869824
	11135873232 [label="AddBackward0
------------
alpha: 1"]
	11135869392 -> 11135873232
	11135869392 -> 6140181728 [dir=none]
	6140181728 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11135869392 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135869056 -> 11135869392
	11135869056 -> 6142277040 [dir=none]
	6142277040 [label="other
 ()" fillcolor=orange]
	11135869056 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135868912 -> 11135869056
	11135868912 -> 6140182208 [dir=none]
	6140182208 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	11135868912 -> 6142277360 [dir=none]
	6142277360 [label="result1
 (224)" fillcolor=orange]
	11135868912 -> 6142277280 [dir=none]
	6142277280 [label="result2
 (224)" fillcolor=orange]
	11135868912 -> 6138411376 [dir=none]
	6138411376 [label="running_mean
 (224)" fillcolor=orange]
	11135868912 -> 6138411696 [dir=none]
	6138411696 [label="running_var
 (224)" fillcolor=orange]
	11135868912 -> 6138411536 [dir=none]
	6138411536 [label="weight
 (224)" fillcolor=orange]
	11135868912 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135868768 -> 11135868912
	11135868768 -> 6140166288 [dir=none]
	6140166288 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	11135868768 -> 6138411456 [dir=none]
	6138411456 [label="weight
 (224, 1344, 1, 1)" fillcolor=orange]
	11135868768 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135868480 -> 11135868768
	11135868480 -> 6140169488 [dir=none]
	6140169488 [label="other
 (1, 1344, 38, 38)" fillcolor=orange]
	11135868480 -> 6140167328 [dir=none]
	6140167328 [label="self
 (1, 1344, 1, 1)" fillcolor=orange]
	11135868480 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135868384 -> 11135868480
	11135868384 -> 6142277440 [dir=none]
	6142277440 [label="result
 (1, 1344, 1, 1)" fillcolor=orange]
	11135868384 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135868240 -> 11135868384
	11135868240 -> 6140166768 [dir=none]
	6140166768 [label="input
 (1, 56, 1, 1)" fillcolor=orange]
	11135868240 -> 6138411216 [dir=none]
	6138411216 [label="weight
 (1344, 56, 1, 1)" fillcolor=orange]
	11135868240 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (1344,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141517088 -> 11135868240
	6141517088 [label=SwishImplementationBackward]
	11135867808 -> 6141517088
	11135867808 -> 6140170768 [dir=none]
	6140170768 [label="input
 (1, 1344, 1, 1)" fillcolor=orange]
	11135867808 -> 6138410976 [dir=none]
	6138410976 [label="weight
 (56, 1344, 1, 1)" fillcolor=orange]
	11135867808 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (56,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135867664 -> 11135867808
	11135867664 -> 6140169488 [dir=none]
	6140169488 [label="self
 (1, 1344, 38, 38)" fillcolor=orange]
	11135867664 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 1344, 38, 38)"]
	6141516864 -> 11135867664
	6141516864 [label=SwishImplementationBackward]
	11135867232 -> 6141516864
	11135867232 -> 6140174048 [dir=none]
	6140174048 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	11135867232 -> 6142278160 [dir=none]
	6142278160 [label="result1
 (1344)" fillcolor=orange]
	11135867232 -> 6142278240 [dir=none]
	6142278240 [label="result2
 (1344)" fillcolor=orange]
	11135867232 -> 6138408656 [dir=none]
	6138408656 [label="running_mean
 (1344)" fillcolor=orange]
	11135867232 -> 6138410496 [dir=none]
	6138410496 [label="running_var
 (1344)" fillcolor=orange]
	11135867232 -> 6138410256 [dir=none]
	6138410256 [label="weight
 (1344)" fillcolor=orange]
	11135867232 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135867088 -> 11135867232
	11135867088 -> 6140174288 [dir=none]
	6140174288 [label="input
 (1, 1344, 42, 42)" fillcolor=orange]
	11135867088 -> 6138410336 [dir=none]
	6138410336 [label="weight
 (1344, 1, 5, 5)" fillcolor=orange]
	11135867088 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1344
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135866800 -> 11135867088
	11135866800 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6141516640 -> 11135866800
	6141516640 [label=SwishImplementationBackward]
	11135866320 -> 6141516640
	11135866320 -> 6140179408 [dir=none]
	6140179408 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	11135866320 -> 6142278720 [dir=none]
	6142278720 [label="result1
 (1344)" fillcolor=orange]
	11135866320 -> 6142278800 [dir=none]
	6142278800 [label="result2
 (1344)" fillcolor=orange]
	11135866320 -> 6138409536 [dir=none]
	6138409536 [label="running_mean
 (1344)" fillcolor=orange]
	11135866320 -> 6138409856 [dir=none]
	6138409856 [label="running_var
 (1344)" fillcolor=orange]
	11135866320 -> 6138409696 [dir=none]
	6138409696 [label="weight
 (1344)" fillcolor=orange]
	11135866320 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135866176 -> 11135866320
	11135866176 -> 6140175088 [dir=none]
	6140175088 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	11135866176 -> 6138409616 [dir=none]
	6138409616 [label="weight
 (1344, 224, 1, 1)" fillcolor=orange]
	11135866176 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135869344 -> 11135866176
	11135869344 [label="AddBackward0
------------
alpha: 1"]
	11135865744 -> 11135869344
	11135865744 -> 6140174928 [dir=none]
	6140174928 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11135865744 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135865648 -> 11135865744
	11135865648 -> 6142279120 [dir=none]
	6142279120 [label="other
 ()" fillcolor=orange]
	11135865648 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135865504 -> 11135865648
	11135865504 -> 6140175568 [dir=none]
	6140175568 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	11135865504 -> 6142279440 [dir=none]
	6142279440 [label="result1
 (224)" fillcolor=orange]
	11135865504 -> 6142279360 [dir=none]
	6142279360 [label="result2
 (224)" fillcolor=orange]
	11135865504 -> 6138408896 [dir=none]
	6138408896 [label="running_mean
 (224)" fillcolor=orange]
	11135865504 -> 6138409216 [dir=none]
	6138409216 [label="running_var
 (224)" fillcolor=orange]
	11135865504 -> 6138409056 [dir=none]
	6138409056 [label="weight
 (224)" fillcolor=orange]
	11135865504 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135865360 -> 11135865504
	11135865360 -> 6140175808 [dir=none]
	6140175808 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	11135865360 -> 6138408976 [dir=none]
	6138408976 [label="weight
 (224, 1344, 1, 1)" fillcolor=orange]
	11135865360 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135865072 -> 11135865360
	11135865072 -> 6140179568 [dir=none]
	6140179568 [label="other
 (1, 1344, 38, 38)" fillcolor=orange]
	11135865072 -> 6140176928 [dir=none]
	6140176928 [label="self
 (1, 1344, 1, 1)" fillcolor=orange]
	11135865072 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135864736 -> 11135865072
	11135864736 -> 6142279520 [dir=none]
	6142279520 [label="result
 (1, 1344, 1, 1)" fillcolor=orange]
	11135864736 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135864592 -> 11135864736
	11135864592 -> 6140176288 [dir=none]
	6140176288 [label="input
 (1, 56, 1, 1)" fillcolor=orange]
	11135864592 -> 6138408736 [dir=none]
	6138408736 [label="weight
 (1344, 56, 1, 1)" fillcolor=orange]
	11135864592 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (1344,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141516416 -> 11135864592
	6141516416 [label=SwishImplementationBackward]
	11135864160 -> 6141516416
	11135864160 -> 6140180448 [dir=none]
	6140180448 [label="input
 (1, 1344, 1, 1)" fillcolor=orange]
	11135864160 -> 6138408496 [dir=none]
	6138408496 [label="weight
 (56, 1344, 1, 1)" fillcolor=orange]
	11135864160 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (56,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135864016 -> 11135864160
	11135864016 -> 6140179568 [dir=none]
	6140179568 [label="self
 (1, 1344, 38, 38)" fillcolor=orange]
	11135864016 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 1344, 38, 38)"]
	6141516192 -> 11135864016
	6141516192 [label=SwishImplementationBackward]
	11135863584 -> 6141516192
	11135863584 -> 6140180848 [dir=none]
	6140180848 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	11135863584 -> 11135566448 [dir=none]
	11135566448 [label="result1
 (1344)" fillcolor=orange]
	11135863584 -> 6140031712 [dir=none]
	6140031712 [label="result2
 (1344)" fillcolor=orange]
	11135863584 -> 6138406256 [dir=none]
	6138406256 [label="running_mean
 (1344)" fillcolor=orange]
	11135863584 -> 6138408096 [dir=none]
	6138408096 [label="running_var
 (1344)" fillcolor=orange]
	11135863584 -> 6138407856 [dir=none]
	6138407856 [label="weight
 (1344)" fillcolor=orange]
	11135863584 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135863440 -> 11135863584
	11135863440 -> 6140181088 [dir=none]
	6140181088 [label="input
 (1, 1344, 42, 42)" fillcolor=orange]
	11135863440 -> 6138407936 [dir=none]
	6138407936 [label="weight
 (1344, 1, 5, 5)" fillcolor=orange]
	11135863440 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1344
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135863152 -> 11135863440
	11135863152 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6141515968 -> 11135863152
	6141515968 [label=SwishImplementationBackward]
	11135862912 -> 6141515968
	11135862912 -> 6140170448 [dir=none]
	6140170448 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	11135862912 -> 11135566928 [dir=none]
	11135566928 [label="result1
 (1344)" fillcolor=orange]
	11135862912 -> 11135567008 [dir=none]
	11135567008 [label="result2
 (1344)" fillcolor=orange]
	11135862912 -> 6138407136 [dir=none]
	6138407136 [label="running_mean
 (1344)" fillcolor=orange]
	11135862912 -> 6138407456 [dir=none]
	6138407456 [label="running_var
 (1344)" fillcolor=orange]
	11135862912 -> 6138407296 [dir=none]
	6138407296 [label="weight
 (1344)" fillcolor=orange]
	11135862912 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135862768 -> 11135862912
	11135862768 -> 6140167008 [dir=none]
	6140167008 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	11135862768 -> 6138407216 [dir=none]
	6138407216 [label="weight
 (1344, 224, 1, 1)" fillcolor=orange]
	11135862768 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135865936 -> 11135862768
	11135865936 -> 6140167168 [dir=none]
	6140167168 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	11135865936 -> 11135566688 [dir=none]
	11135566688 [label="result1
 (224)" fillcolor=orange]
	11135865936 -> 11135566608 [dir=none]
	11135566608 [label="result2
 (224)" fillcolor=orange]
	11135865936 -> 6138406496 [dir=none]
	6138406496 [label="running_mean
 (224)" fillcolor=orange]
	11135865936 -> 6138406816 [dir=none]
	6138406816 [label="running_var
 (224)" fillcolor=orange]
	11135865936 -> 6138406656 [dir=none]
	6138406656 [label="weight
 (224)" fillcolor=orange]
	11135865936 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135862336 -> 11135865936
	11135862336 -> 6140167888 [dir=none]
	6140167888 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135862336 -> 6138406576 [dir=none]
	6138406576 [label="weight
 (224, 960, 1, 1)" fillcolor=orange]
	11135862336 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135862048 -> 11135862336
	11135862048 -> 6140171488 [dir=none]
	6140171488 [label="other
 (1, 960, 38, 38)" fillcolor=orange]
	11135862048 -> 6140169648 [dir=none]
	6140169648 [label="self
 (1, 960, 1, 1)" fillcolor=orange]
	11135862048 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135861712 -> 11135862048
	11135861712 -> 11135567728 [dir=none]
	11135567728 [label="result
 (1, 960, 1, 1)" fillcolor=orange]
	11135861712 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135861568 -> 11135861712
	11135861568 -> 6140168208 [dir=none]
	6140168208 [label="input
 (1, 40, 1, 1)" fillcolor=orange]
	11135861568 -> 6138406336 [dir=none]
	6138406336 [label="weight
 (960, 40, 1, 1)" fillcolor=orange]
	11135861568 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (960,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141515744 -> 11135861568
	6141515744 [label=SwishImplementationBackward]
	11135861136 -> 6141515744
	11135861136 -> 6140173648 [dir=none]
	6140173648 [label="input
 (1, 960, 1, 1)" fillcolor=orange]
	11135861136 -> 6138406096 [dir=none]
	6138406096 [label="weight
 (40, 960, 1, 1)" fillcolor=orange]
	11135861136 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (40,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135860992 -> 11135861136
	11135860992 -> 6140171488 [dir=none]
	6140171488 [label="self
 (1, 960, 38, 38)" fillcolor=orange]
	11135860992 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 960, 38, 38)"]
	6141515520 -> 11135860992
	6141515520 [label=SwishImplementationBackward]
	11135778576 -> 6141515520
	11135778576 -> 6140177168 [dir=none]
	6140177168 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135778576 -> 11135568128 [dir=none]
	11135568128 [label="result1
 (960)" fillcolor=orange]
	11135778576 -> 11135567168 [dir=none]
	11135567168 [label="result2
 (960)" fillcolor=orange]
	11135778576 -> 6138403856 [dir=none]
	6138403856 [label="running_mean
 (960)" fillcolor=orange]
	11135778576 -> 6138405616 [dir=none]
	6138405616 [label="running_var
 (960)" fillcolor=orange]
	11135778576 -> 6138405376 [dir=none]
	6138405376 [label="weight
 (960)" fillcolor=orange]
	11135778576 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135778432 -> 11135778576
	11135778432 -> 6140177968 [dir=none]
	6140177968 [label="input
 (1, 960, 42, 42)" fillcolor=orange]
	11135778432 -> 6138405456 [dir=none]
	6138405456 [label="weight
 (960, 1, 5, 5)" fillcolor=orange]
	11135778432 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            960
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135778144 -> 11135778432
	11135778144 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6141515296 -> 11135778144
	6141515296 [label=SwishImplementationBackward]
	11135777904 -> 6141515296
	11135777904 -> 6140182368 [dir=none]
	6140182368 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135777904 -> 11135568688 [dir=none]
	11135568688 [label="result1
 (960)" fillcolor=orange]
	11135777904 -> 11135568448 [dir=none]
	11135568448 [label="result2
 (960)" fillcolor=orange]
	11135777904 -> 6138404656 [dir=none]
	6138404656 [label="running_mean
 (960)" fillcolor=orange]
	11135777904 -> 6138404976 [dir=none]
	6138404976 [label="running_var
 (960)" fillcolor=orange]
	11135777904 -> 6138404816 [dir=none]
	6138404816 [label="weight
 (960)" fillcolor=orange]
	11135777904 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135777760 -> 11135777904
	11135777760 -> 6140169168 [dir=none]
	6140169168 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	11135777760 -> 6138404736 [dir=none]
	6138404736 [label="weight
 (960, 160, 1, 1)" fillcolor=orange]
	11135777760 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135777472 -> 11135777760
	11135777472 [label="AddBackward0
------------
alpha: 1"]
	11135777136 -> 11135777472
	11135777136 -> 6140168688 [dir=none]
	6140168688 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11135777136 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135777040 -> 11135777136
	11135777040 -> 11135569088 [dir=none]
	11135569088 [label="other
 ()" fillcolor=orange]
	11135777040 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135776896 -> 11135777040
	11135776896 -> 6140169328 [dir=none]
	6140169328 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	11135776896 -> 11135569408 [dir=none]
	11135569408 [label="result1
 (160)" fillcolor=orange]
	11135776896 -> 11135569328 [dir=none]
	11135569328 [label="result2
 (160)" fillcolor=orange]
	11135776896 -> 6138404096 [dir=none]
	6138404096 [label="running_mean
 (160)" fillcolor=orange]
	11135776896 -> 6138404416 [dir=none]
	6138404416 [label="running_var
 (160)" fillcolor=orange]
	11135776896 -> 6138404256 [dir=none]
	6138404256 [label="weight
 (160)" fillcolor=orange]
	11135776896 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135776752 -> 11135776896
	11135776752 -> 6140171328 [dir=none]
	6140171328 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135776752 -> 6138404176 [dir=none]
	6138404176 [label="weight
 (160, 960, 1, 1)" fillcolor=orange]
	11135776752 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135776464 -> 11135776752
	11135776464 -> 6140166528 [dir=none]
	6140166528 [label="other
 (1, 960, 38, 38)" fillcolor=orange]
	11135776464 -> 6140181408 [dir=none]
	6140181408 [label="self
 (1, 960, 1, 1)" fillcolor=orange]
	11135776464 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135776128 -> 11135776464
	11135776128 -> 11135569728 [dir=none]
	11135569728 [label="result
 (1, 960, 1, 1)" fillcolor=orange]
	11135776128 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135775984 -> 11135776128
	11135775984 -> 6140172528 [dir=none]
	6140172528 [label="input
 (1, 40, 1, 1)" fillcolor=orange]
	11135775984 -> 6138403936 [dir=none]
	6138403936 [label="weight
 (960, 40, 1, 1)" fillcolor=orange]
	11135775984 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (960,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141515072 -> 11135775984
	6141515072 [label=SwishImplementationBackward]
	11135775552 -> 6141515072
	11135775552 -> 6140171888 [dir=none]
	6140171888 [label="input
 (1, 960, 1, 1)" fillcolor=orange]
	11135775552 -> 6138403696 [dir=none]
	6138403696 [label="weight
 (40, 960, 1, 1)" fillcolor=orange]
	11135775552 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (40,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135775408 -> 11135775552
	11135775408 -> 6140166528 [dir=none]
	6140166528 [label="self
 (1, 960, 38, 38)" fillcolor=orange]
	11135775408 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 960, 38, 38)"]
	6141514848 -> 11135775408
	6141514848 [label=SwishImplementationBackward]
	11135774976 -> 6141514848
	11135774976 -> 6140176608 [dir=none]
	6140176608 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135774976 -> 11135570208 [dir=none]
	11135570208 [label="result1
 (960)" fillcolor=orange]
	11135774976 -> 11135569808 [dir=none]
	11135569808 [label="result2
 (960)" fillcolor=orange]
	11135774976 -> 6138401376 [dir=none]
	6138401376 [label="running_mean
 (960)" fillcolor=orange]
	11135774976 -> 6138403216 [dir=none]
	6138403216 [label="running_var
 (960)" fillcolor=orange]
	11135774976 -> 6138402976 [dir=none]
	6138402976 [label="weight
 (960)" fillcolor=orange]
	11135774976 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135774832 -> 11135774976
	11135774832 -> 6140177408 [dir=none]
	6140177408 [label="input
 (1, 960, 40, 40)" fillcolor=orange]
	11135774832 -> 6138403056 [dir=none]
	6138403056 [label="weight
 (960, 1, 3, 3)" fillcolor=orange]
	11135774832 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            960
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135774544 -> 11135774832
	11135774544 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6141514624 -> 11135774544
	6141514624 [label=SwishImplementationBackward]
	11135774304 -> 6141514624
	11135774304 -> 6140179008 [dir=none]
	6140179008 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135774304 -> 11135570768 [dir=none]
	11135570768 [label="result1
 (960)" fillcolor=orange]
	11135774304 -> 11135570528 [dir=none]
	11135570528 [label="result2
 (960)" fillcolor=orange]
	11135774304 -> 6138402256 [dir=none]
	6138402256 [label="running_mean
 (960)" fillcolor=orange]
	11135774304 -> 6138402576 [dir=none]
	6138402576 [label="running_var
 (960)" fillcolor=orange]
	11135774304 -> 6138402416 [dir=none]
	6138402416 [label="weight
 (960)" fillcolor=orange]
	11135774304 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135774160 -> 11135774304
	11135774160 -> 6140181888 [dir=none]
	6140181888 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	11135774160 -> 6138402336 [dir=none]
	6138402336 [label="weight
 (960, 160, 1, 1)" fillcolor=orange]
	11135774160 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135777328 -> 11135774160
	11135777328 [label="AddBackward0
------------
alpha: 1"]
	11135773728 -> 11135777328
	11135773728 -> 6140179248 [dir=none]
	6140179248 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11135773728 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135773392 -> 11135773728
	11135773392 -> 11135571168 [dir=none]
	11135571168 [label="other
 ()" fillcolor=orange]
	11135773392 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135773248 -> 11135773392
	11135773248 -> 6140167568 [dir=none]
	6140167568 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	11135773248 -> 11135571488 [dir=none]
	11135571488 [label="result1
 (160)" fillcolor=orange]
	11135773248 -> 11135571408 [dir=none]
	11135571408 [label="result2
 (160)" fillcolor=orange]
	11135773248 -> 6138401616 [dir=none]
	6138401616 [label="running_mean
 (160)" fillcolor=orange]
	11135773248 -> 6138401936 [dir=none]
	6138401936 [label="running_var
 (160)" fillcolor=orange]
	11135773248 -> 6138401776 [dir=none]
	6138401776 [label="weight
 (160)" fillcolor=orange]
	11135773248 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135773104 -> 11135773248
	11135773104 -> 6140172768 [dir=none]
	6140172768 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135773104 -> 6138401696 [dir=none]
	6138401696 [label="weight
 (160, 960, 1, 1)" fillcolor=orange]
	11135773104 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135772816 -> 11135773104
	11135772816 -> 6140170288 [dir=none]
	6140170288 [label="other
 (1, 960, 38, 38)" fillcolor=orange]
	11135772816 -> 6140177728 [dir=none]
	6140177728 [label="self
 (1, 960, 1, 1)" fillcolor=orange]
	11135772816 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135772720 -> 11135772816
	11135772720 -> 11135571808 [dir=none]
	11135571808 [label="result
 (1, 960, 1, 1)" fillcolor=orange]
	11135772720 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135772576 -> 11135772720
	11135772576 -> 6140176048 [dir=none]
	6140176048 [label="input
 (1, 40, 1, 1)" fillcolor=orange]
	11135772576 -> 6138401456 [dir=none]
	6138401456 [label="weight
 (960, 40, 1, 1)" fillcolor=orange]
	11135772576 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (960,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141514400 -> 11135772576
	6141514400 [label=SwishImplementationBackward]
	11135772144 -> 6141514400
	11135772144 -> 6140264512 [dir=none]
	6140264512 [label="input
 (1, 960, 1, 1)" fillcolor=orange]
	11135772144 -> 6138401216 [dir=none]
	6138401216 [label="weight
 (40, 960, 1, 1)" fillcolor=orange]
	11135772144 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (40,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135772000 -> 11135772144
	11135772000 -> 6140170288 [dir=none]
	6140170288 [label="self
 (1, 960, 38, 38)" fillcolor=orange]
	11135772000 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 960, 38, 38)"]
	6141514176 -> 11135772000
	6141514176 [label=SwishImplementationBackward]
	11135771568 -> 6141514176
	11135771568 -> 6140264992 [dir=none]
	6140264992 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135771568 -> 11135572288 [dir=none]
	11135572288 [label="result1
 (960)" fillcolor=orange]
	11135771568 -> 11135571888 [dir=none]
	11135571888 [label="result2
 (960)" fillcolor=orange]
	11135771568 -> 6138398896 [dir=none]
	6138398896 [label="running_mean
 (960)" fillcolor=orange]
	11135771568 -> 6138400736 [dir=none]
	6138400736 [label="running_var
 (960)" fillcolor=orange]
	11135771568 -> 6138400496 [dir=none]
	6138400496 [label="weight
 (960)" fillcolor=orange]
	11135771568 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135771424 -> 11135771568
	11135771424 -> 6140265152 [dir=none]
	6140265152 [label="input
 (1, 960, 40, 40)" fillcolor=orange]
	11135771424 -> 6138400576 [dir=none]
	6138400576 [label="weight
 (960, 1, 3, 3)" fillcolor=orange]
	11135771424 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            960
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135771136 -> 11135771424
	11135771136 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6141513952 -> 11135771136
	6141513952 [label=SwishImplementationBackward]
	11135770656 -> 6141513952
	11135770656 -> 6140266512 [dir=none]
	6140266512 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135770656 -> 11135572848 [dir=none]
	11135572848 [label="result1
 (960)" fillcolor=orange]
	11135770656 -> 11135572608 [dir=none]
	11135572608 [label="result2
 (960)" fillcolor=orange]
	11135770656 -> 6138399776 [dir=none]
	6138399776 [label="running_mean
 (960)" fillcolor=orange]
	11135770656 -> 6138400096 [dir=none]
	6138400096 [label="running_var
 (960)" fillcolor=orange]
	11135770656 -> 6138399936 [dir=none]
	6138399936 [label="weight
 (960)" fillcolor=orange]
	11135770656 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135770512 -> 11135770656
	11135770512 -> 6140265552 [dir=none]
	6140265552 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	11135770512 -> 6138399856 [dir=none]
	6138399856 [label="weight
 (960, 160, 1, 1)" fillcolor=orange]
	11135770512 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135773680 -> 11135770512
	11135773680 [label="AddBackward0
------------
alpha: 1"]
	11135770080 -> 11135773680
	11135770080 -> 6140265232 [dir=none]
	6140265232 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11135770080 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135769984 -> 11135770080
	11135769984 -> 11135573248 [dir=none]
	11135573248 [label="other
 ()" fillcolor=orange]
	11135769984 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135769840 -> 11135769984
	11135769840 -> 6140265712 [dir=none]
	6140265712 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	11135769840 -> 11135573568 [dir=none]
	11135573568 [label="result1
 (160)" fillcolor=orange]
	11135769840 -> 11135573488 [dir=none]
	11135573488 [label="result2
 (160)" fillcolor=orange]
	11135769840 -> 6138399136 [dir=none]
	6138399136 [label="running_mean
 (160)" fillcolor=orange]
	11135769840 -> 6138399456 [dir=none]
	6138399456 [label="running_var
 (160)" fillcolor=orange]
	11135769840 -> 6138399296 [dir=none]
	6138399296 [label="weight
 (160)" fillcolor=orange]
	11135769840 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135769696 -> 11135769840
	11135769696 -> 6140265872 [dir=none]
	6140265872 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135769696 -> 6138399216 [dir=none]
	6138399216 [label="weight
 (160, 960, 1, 1)" fillcolor=orange]
	11135769696 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135769408 -> 11135769696
	11135769408 -> 6140266672 [dir=none]
	6140266672 [label="other
 (1, 960, 38, 38)" fillcolor=orange]
	11135769408 -> 6140266192 [dir=none]
	6140266192 [label="self
 (1, 960, 1, 1)" fillcolor=orange]
	11135769408 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135769072 -> 11135769408
	11135769072 -> 11135573888 [dir=none]
	11135573888 [label="result
 (1, 960, 1, 1)" fillcolor=orange]
	11135769072 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135768928 -> 11135769072
	11135768928 -> 6140266032 [dir=none]
	6140266032 [label="input
 (1, 40, 1, 1)" fillcolor=orange]
	11135768928 -> 6138398976 [dir=none]
	6138398976 [label="weight
 (960, 40, 1, 1)" fillcolor=orange]
	11135768928 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (960,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141513728 -> 11135768928
	6141513728 [label=SwishImplementationBackward]
	11135768496 -> 6141513728
	11135768496 -> 6140266912 [dir=none]
	6140266912 [label="input
 (1, 960, 1, 1)" fillcolor=orange]
	11135768496 -> 6138398736 [dir=none]
	6138398736 [label="weight
 (40, 960, 1, 1)" fillcolor=orange]
	11135768496 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (40,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135768352 -> 11135768496
	11135768352 -> 6140266672 [dir=none]
	6140266672 [label="self
 (1, 960, 38, 38)" fillcolor=orange]
	11135768352 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 960, 38, 38)"]
	6141513504 -> 11135768352
	6141513504 [label=SwishImplementationBackward]
	11135767920 -> 6141513504
	11135767920 -> 6140267312 [dir=none]
	6140267312 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135767920 -> 11135574368 [dir=none]
	11135574368 [label="result1
 (960)" fillcolor=orange]
	11135767920 -> 11135573968 [dir=none]
	11135573968 [label="result2
 (960)" fillcolor=orange]
	11135767920 -> 6138134368 [dir=none]
	6138134368 [label="running_mean
 (960)" fillcolor=orange]
	11135767920 -> 6138398256 [dir=none]
	6138398256 [label="running_var
 (960)" fillcolor=orange]
	11135767920 -> 6138398016 [dir=none]
	6138398016 [label="weight
 (960)" fillcolor=orange]
	11135767920 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135767776 -> 11135767920
	11135767776 -> 6140267392 [dir=none]
	6140267392 [label="input
 (1, 960, 40, 40)" fillcolor=orange]
	11135767776 -> 6138398096 [dir=none]
	6138398096 [label="weight
 (960, 1, 3, 3)" fillcolor=orange]
	11135767776 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            960
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135767488 -> 11135767776
	11135767488 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6141513280 -> 11135767488
	6141513280 [label=SwishImplementationBackward]
	11135767248 -> 6141513280
	11135767248 -> 6140268912 [dir=none]
	6140268912 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135767248 -> 11135574928 [dir=none]
	11135574928 [label="result1
 (960)" fillcolor=orange]
	11135767248 -> 11135574688 [dir=none]
	11135574688 [label="result2
 (960)" fillcolor=orange]
	11135767248 -> 6138397296 [dir=none]
	6138397296 [label="running_mean
 (960)" fillcolor=orange]
	11135767248 -> 6138397616 [dir=none]
	6138397616 [label="running_var
 (960)" fillcolor=orange]
	11135767248 -> 6138397456 [dir=none]
	6138397456 [label="weight
 (960)" fillcolor=orange]
	11135767248 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135767104 -> 11135767248
	11135767104 -> 6140267872 [dir=none]
	6140267872 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	11135767104 -> 6138397376 [dir=none]
	6138397376 [label="weight
 (960, 160, 1, 1)" fillcolor=orange]
	11135767104 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135770272 -> 11135767104
	11135770272 [label="AddBackward0
------------
alpha: 1"]
	11135766672 -> 11135770272
	11135766672 -> 6140267712 [dir=none]
	6140267712 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11135766672 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135766336 -> 11135766672
	11135766336 -> 11135575328 [dir=none]
	11135575328 [label="other
 ()" fillcolor=orange]
	11135766336 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135766192 -> 11135766336
	11135766192 -> 6140268192 [dir=none]
	6140268192 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	11135766192 -> 11135575648 [dir=none]
	11135575648 [label="result1
 (160)" fillcolor=orange]
	11135766192 -> 11135575568 [dir=none]
	11135575568 [label="result2
 (160)" fillcolor=orange]
	11135766192 -> 6138133808 [dir=none]
	6138133808 [label="running_mean
 (160)" fillcolor=orange]
	11135766192 -> 6138397056 [dir=none]
	6138397056 [label="running_var
 (160)" fillcolor=orange]
	11135766192 -> 6138396816 [dir=none]
	6138396816 [label="weight
 (160)" fillcolor=orange]
	11135766192 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135766048 -> 11135766192
	11135766048 -> 6140268352 [dir=none]
	6140268352 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135766048 -> 6138396896 [dir=none]
	6138396896 [label="weight
 (160, 960, 1, 1)" fillcolor=orange]
	11135766048 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135765760 -> 11135766048
	11135765760 -> 6140268992 [dir=none]
	6140268992 [label="other
 (1, 960, 38, 38)" fillcolor=orange]
	11135765760 -> 6140268752 [dir=none]
	6140268752 [label="self
 (1, 960, 1, 1)" fillcolor=orange]
	11135765760 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135765664 -> 11135765760
	11135765664 -> 11135575968 [dir=none]
	11135575968 [label="result
 (1, 960, 1, 1)" fillcolor=orange]
	11135765664 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135765520 -> 11135765664
	11135765520 -> 6140268592 [dir=none]
	6140268592 [label="input
 (1, 40, 1, 1)" fillcolor=orange]
	11135765520 -> 6138134448 [dir=none]
	6138134448 [label="weight
 (960, 40, 1, 1)" fillcolor=orange]
	11135765520 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (960,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141513056 -> 11135765520
	6141513056 [label=SwishImplementationBackward]
	11135765088 -> 6141513056
	11135765088 -> 6140269312 [dir=none]
	6140269312 [label="input
 (1, 960, 1, 1)" fillcolor=orange]
	11135765088 -> 6138134208 [dir=none]
	6138134208 [label="weight
 (40, 960, 1, 1)" fillcolor=orange]
	11135765088 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (40,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135764944 -> 11135765088
	11135764944 -> 6140268992 [dir=none]
	6140268992 [label="self
 (1, 960, 38, 38)" fillcolor=orange]
	11135764944 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 960, 38, 38)"]
	6141512832 -> 11135764944
	6141512832 [label=SwishImplementationBackward]
	11135764512 -> 6141512832
	11135764512 -> 6140269872 [dir=none]
	6140269872 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135764512 -> 11135576448 [dir=none]
	11135576448 [label="result1
 (960)" fillcolor=orange]
	11135764512 -> 11135576048 [dir=none]
	11135576048 [label="result2
 (960)" fillcolor=orange]
	11135764512 -> 6138131888 [dir=none]
	6138131888 [label="running_mean
 (960)" fillcolor=orange]
	11135764512 -> 6138133728 [dir=none]
	6138133728 [label="running_var
 (960)" fillcolor=orange]
	11135764512 -> 6138133488 [dir=none]
	6138133488 [label="weight
 (960)" fillcolor=orange]
	11135764512 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135764368 -> 11135764512
	11135764368 -> 6140270032 [dir=none]
	6140270032 [label="input
 (1, 960, 40, 40)" fillcolor=orange]
	11135764368 -> 6138133568 [dir=none]
	6138133568 [label="weight
 (960, 1, 3, 3)" fillcolor=orange]
	11135764368 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            960
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135764080 -> 11135764368
	11135764080 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6141512608 -> 11135764080
	6141512608 [label=SwishImplementationBackward]
	11135763600 -> 6141512608
	11135763600 -> 6140271232 [dir=none]
	6140271232 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135763600 -> 11135577008 [dir=none]
	11135577008 [label="result1
 (960)" fillcolor=orange]
	11135763600 -> 11135576768 [dir=none]
	11135576768 [label="result2
 (960)" fillcolor=orange]
	11135763600 -> 6138132768 [dir=none]
	6138132768 [label="running_mean
 (960)" fillcolor=orange]
	11135763600 -> 6138133088 [dir=none]
	6138133088 [label="running_var
 (960)" fillcolor=orange]
	11135763600 -> 6138132928 [dir=none]
	6138132928 [label="weight
 (960)" fillcolor=orange]
	11135763600 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135763456 -> 11135763600
	11135763456 -> 6140270352 [dir=none]
	6140270352 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	11135763456 -> 6138132848 [dir=none]
	6138132848 [label="weight
 (960, 160, 1, 1)" fillcolor=orange]
	11135763456 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135766624 -> 11135763456
	11135766624 [label="AddBackward0
------------
alpha: 1"]
	11135763024 -> 11135766624
	11135763024 -> 6140270192 [dir=none]
	6140270192 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11135763024 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135762928 -> 11135763024
	11135762928 -> 11135577408 [dir=none]
	11135577408 [label="other
 ()" fillcolor=orange]
	11135762928 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135762784 -> 11135762928
	11135762784 -> 6140270512 [dir=none]
	6140270512 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	11135762784 -> 11135577728 [dir=none]
	11135577728 [label="result1
 (160)" fillcolor=orange]
	11135762784 -> 11135577648 [dir=none]
	11135577648 [label="result2
 (160)" fillcolor=orange]
	11135762784 -> 6138132128 [dir=none]
	6138132128 [label="running_mean
 (160)" fillcolor=orange]
	11135762784 -> 6138132448 [dir=none]
	6138132448 [label="running_var
 (160)" fillcolor=orange]
	11135762784 -> 6138132288 [dir=none]
	6138132288 [label="weight
 (160)" fillcolor=orange]
	11135762784 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135762640 -> 11135762784
	11135762640 -> 6140270592 [dir=none]
	6140270592 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135762640 -> 6138132208 [dir=none]
	6138132208 [label="weight
 (160, 960, 1, 1)" fillcolor=orange]
	11135762640 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135696752 -> 11135762640
	11135696752 -> 6140271392 [dir=none]
	6140271392 [label="other
 (1, 960, 38, 38)" fillcolor=orange]
	11135696752 -> 6140271072 [dir=none]
	6140271072 [label="self
 (1, 960, 1, 1)" fillcolor=orange]
	11135696752 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135696416 -> 11135696752
	11135696416 -> 11135578048 [dir=none]
	11135578048 [label="result
 (1, 960, 1, 1)" fillcolor=orange]
	11135696416 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135696272 -> 11135696416
	11135696272 -> 6140270912 [dir=none]
	6140270912 [label="input
 (1, 40, 1, 1)" fillcolor=orange]
	11135696272 -> 6138131968 [dir=none]
	6138131968 [label="weight
 (960, 40, 1, 1)" fillcolor=orange]
	11135696272 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (960,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141512384 -> 11135696272
	6141512384 [label=SwishImplementationBackward]
	11135695840 -> 6141512384
	11135695840 -> 6140271632 [dir=none]
	6140271632 [label="input
 (1, 960, 1, 1)" fillcolor=orange]
	11135695840 -> 6138131728 [dir=none]
	6138131728 [label="weight
 (40, 960, 1, 1)" fillcolor=orange]
	11135695840 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (40,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135695696 -> 11135695840
	11135695696 -> 6140271392 [dir=none]
	6140271392 [label="self
 (1, 960, 38, 38)" fillcolor=orange]
	11135695696 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 960, 38, 38)"]
	6141512160 -> 11135695696
	6141512160 [label=SwishImplementationBackward]
	11135695264 -> 6141512160
	11135695264 -> 6140272192 [dir=none]
	6140272192 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135695264 -> 11135578528 [dir=none]
	11135578528 [label="result1
 (960)" fillcolor=orange]
	11135695264 -> 11135578128 [dir=none]
	11135578128 [label="result2
 (960)" fillcolor=orange]
	11135695264 -> 6138129408 [dir=none]
	6138129408 [label="running_mean
 (960)" fillcolor=orange]
	11135695264 -> 6138131248 [dir=none]
	6138131248 [label="running_var
 (960)" fillcolor=orange]
	11135695264 -> 6138131008 [dir=none]
	6138131008 [label="weight
 (960)" fillcolor=orange]
	11135695264 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135695120 -> 11135695264
	11135695120 -> 6140272512 [dir=none]
	6140272512 [label="input
 (1, 960, 40, 40)" fillcolor=orange]
	11135695120 -> 6138131088 [dir=none]
	6138131088 [label="weight
 (960, 1, 3, 3)" fillcolor=orange]
	11135695120 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            960
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135694832 -> 11135695120
	11135694832 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6141511936 -> 11135694832
	6141511936 [label=SwishImplementationBackward]
	11135694592 -> 6141511936
	11135694592 -> 6140273712 [dir=none]
	6140273712 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135694592 -> 11135579088 [dir=none]
	11135579088 [label="result1
 (960)" fillcolor=orange]
	11135694592 -> 11135578848 [dir=none]
	11135578848 [label="result2
 (960)" fillcolor=orange]
	11135694592 -> 6138130288 [dir=none]
	6138130288 [label="running_mean
 (960)" fillcolor=orange]
	11135694592 -> 6138130608 [dir=none]
	6138130608 [label="running_var
 (960)" fillcolor=orange]
	11135694592 -> 6138130448 [dir=none]
	6138130448 [label="weight
 (960)" fillcolor=orange]
	11135694592 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135694448 -> 11135694592
	11135694448 -> 6140272992 [dir=none]
	6140272992 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	11135694448 -> 6138130368 [dir=none]
	6138130368 [label="weight
 (960, 160, 1, 1)" fillcolor=orange]
	11135694448 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135763216 -> 11135694448
	11135763216 [label="AddBackward0
------------
alpha: 1"]
	11135694016 -> 11135763216
	11135694016 -> 6140272672 [dir=none]
	6140272672 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11135694016 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135693680 -> 11135694016
	11135693680 -> 11135579488 [dir=none]
	11135579488 [label="other
 ()" fillcolor=orange]
	11135693680 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135693536 -> 11135693680
	11135693536 -> 6140273152 [dir=none]
	6140273152 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	11135693536 -> 11135579808 [dir=none]
	11135579808 [label="result1
 (160)" fillcolor=orange]
	11135693536 -> 11135579728 [dir=none]
	11135579728 [label="result2
 (160)" fillcolor=orange]
	11135693536 -> 6138129648 [dir=none]
	6138129648 [label="running_mean
 (160)" fillcolor=orange]
	11135693536 -> 6138129968 [dir=none]
	6138129968 [label="running_var
 (160)" fillcolor=orange]
	11135693536 -> 6138129808 [dir=none]
	6138129808 [label="weight
 (160)" fillcolor=orange]
	11135693536 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135693392 -> 11135693536
	11135693392 -> 6140273312 [dir=none]
	6140273312 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135693392 -> 6138129728 [dir=none]
	6138129728 [label="weight
 (160, 960, 1, 1)" fillcolor=orange]
	11135693392 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135693104 -> 11135693392
	11135693104 -> 6140274032 [dir=none]
	6140274032 [label="other
 (1, 960, 38, 38)" fillcolor=orange]
	11135693104 -> 6140273632 [dir=none]
	6140273632 [label="self
 (1, 960, 1, 1)" fillcolor=orange]
	11135693104 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135693008 -> 11135693104
	11135693008 -> 11135580128 [dir=none]
	11135580128 [label="result
 (1, 960, 1, 1)" fillcolor=orange]
	11135693008 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135692864 -> 11135693008
	11135692864 -> 6140273472 [dir=none]
	6140273472 [label="input
 (1, 40, 1, 1)" fillcolor=orange]
	11135692864 -> 6138129488 [dir=none]
	6138129488 [label="weight
 (960, 40, 1, 1)" fillcolor=orange]
	11135692864 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (960,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141511712 -> 11135692864
	6141511712 [label=SwishImplementationBackward]
	11135692432 -> 6141511712
	11135692432 -> 6140274352 [dir=none]
	6140274352 [label="input
 (1, 960, 1, 1)" fillcolor=orange]
	11135692432 -> 6138129248 [dir=none]
	6138129248 [label="weight
 (40, 960, 1, 1)" fillcolor=orange]
	11135692432 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (40,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135692288 -> 11135692432
	11135692288 -> 6140274032 [dir=none]
	6140274032 [label="self
 (1, 960, 38, 38)" fillcolor=orange]
	11135692288 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 960, 38, 38)"]
	6141511488 -> 11135692288
	6141511488 [label=SwishImplementationBackward]
	11135691856 -> 6141511488
	11135691856 -> 6140274992 [dir=none]
	6140274992 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135691856 -> 11135580608 [dir=none]
	11135580608 [label="result1
 (960)" fillcolor=orange]
	11135691856 -> 11135580208 [dir=none]
	11135580208 [label="result2
 (960)" fillcolor=orange]
	11135691856 -> 6138126928 [dir=none]
	6138126928 [label="running_mean
 (960)" fillcolor=orange]
	11135691856 -> 6138128768 [dir=none]
	6138128768 [label="running_var
 (960)" fillcolor=orange]
	11135691856 -> 6138128528 [dir=none]
	6138128528 [label="weight
 (960)" fillcolor=orange]
	11135691856 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135691712 -> 11135691856
	11135691712 -> 6140275152 [dir=none]
	6140275152 [label="input
 (1, 960, 40, 40)" fillcolor=orange]
	11135691712 -> 6138128608 [dir=none]
	6138128608 [label="weight
 (960, 1, 3, 3)" fillcolor=orange]
	11135691712 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            960
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135691424 -> 11135691712
	11135691424 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6141511264 -> 11135691424
	6141511264 [label=SwishImplementationBackward]
	11135690944 -> 6141511264
	11135690944 -> 6140276272 [dir=none]
	6140276272 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135690944 -> 11135581168 [dir=none]
	11135581168 [label="result1
 (960)" fillcolor=orange]
	11135690944 -> 11135580928 [dir=none]
	11135580928 [label="result2
 (960)" fillcolor=orange]
	11135690944 -> 6138127808 [dir=none]
	6138127808 [label="running_mean
 (960)" fillcolor=orange]
	11135690944 -> 6138128128 [dir=none]
	6138128128 [label="running_var
 (960)" fillcolor=orange]
	11135690944 -> 6138127968 [dir=none]
	6138127968 [label="weight
 (960)" fillcolor=orange]
	11135690944 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135690800 -> 11135690944
	11135690800 -> 6140275472 [dir=none]
	6140275472 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	11135690800 -> 6138127888 [dir=none]
	6138127888 [label="weight
 (960, 160, 1, 1)" fillcolor=orange]
	11135690800 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135693968 -> 11135690800
	11135693968 [label="AddBackward0
------------
alpha: 1"]
	11135690368 -> 11135693968
	11135690368 -> 6140275312 [dir=none]
	6140275312 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11135690368 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135690272 -> 11135690368
	11135690272 -> 11135581568 [dir=none]
	11135581568 [label="other
 ()" fillcolor=orange]
	11135690272 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135690128 -> 11135690272
	11135690128 -> 6140275552 [dir=none]
	6140275552 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	11135690128 -> 11135581888 [dir=none]
	11135581888 [label="result1
 (160)" fillcolor=orange]
	11135690128 -> 11135581808 [dir=none]
	11135581808 [label="result2
 (160)" fillcolor=orange]
	11135690128 -> 6138127168 [dir=none]
	6138127168 [label="running_mean
 (160)" fillcolor=orange]
	11135690128 -> 6138127488 [dir=none]
	6138127488 [label="running_var
 (160)" fillcolor=orange]
	11135690128 -> 6138127328 [dir=none]
	6138127328 [label="weight
 (160)" fillcolor=orange]
	11135690128 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135689984 -> 11135690128
	11135689984 -> 6140275712 [dir=none]
	6140275712 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135689984 -> 6138127248 [dir=none]
	6138127248 [label="weight
 (160, 960, 1, 1)" fillcolor=orange]
	11135689984 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135689696 -> 11135689984
	11135689696 -> 6140276592 [dir=none]
	6140276592 [label="other
 (1, 960, 38, 38)" fillcolor=orange]
	11135689696 -> 6140276112 [dir=none]
	6140276112 [label="self
 (1, 960, 1, 1)" fillcolor=orange]
	11135689696 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135689360 -> 11135689696
	11135689360 -> 11135581408 [dir=none]
	11135581408 [label="result
 (1, 960, 1, 1)" fillcolor=orange]
	11135689360 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135689216 -> 11135689360
	11135689216 -> 6140275792 [dir=none]
	6140275792 [label="input
 (1, 40, 1, 1)" fillcolor=orange]
	11135689216 -> 6138127008 [dir=none]
	6138127008 [label="weight
 (960, 40, 1, 1)" fillcolor=orange]
	11135689216 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (960,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141511040 -> 11135689216
	6141511040 [label=SwishImplementationBackward]
	11135688784 -> 6141511040
	11135688784 -> 6140276992 [dir=none]
	6140276992 [label="input
 (1, 960, 1, 1)" fillcolor=orange]
	11135688784 -> 6138126768 [dir=none]
	6138126768 [label="weight
 (40, 960, 1, 1)" fillcolor=orange]
	11135688784 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (40,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135688640 -> 11135688784
	11135688640 -> 6140276592 [dir=none]
	6140276592 [label="self
 (1, 960, 38, 38)" fillcolor=orange]
	11135688640 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 960, 38, 38)"]
	6141510816 -> 11135688640
	6141510816 [label=SwishImplementationBackward]
	11135688208 -> 6141510816
	11135688208 -> 6140277392 [dir=none]
	6140277392 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135688208 -> 11135140384 [dir=none]
	11135140384 [label="result1
 (960)" fillcolor=orange]
	11135688208 -> 11135139984 [dir=none]
	11135139984 [label="result2
 (960)" fillcolor=orange]
	11135688208 -> 6138124448 [dir=none]
	6138124448 [label="running_mean
 (960)" fillcolor=orange]
	11135688208 -> 6138126288 [dir=none]
	6138126288 [label="running_var
 (960)" fillcolor=orange]
	11135688208 -> 6138126048 [dir=none]
	6138126048 [label="weight
 (960)" fillcolor=orange]
	11135688208 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135688064 -> 11135688208
	11135688064 -> 6140277552 [dir=none]
	6140277552 [label="input
 (1, 960, 40, 40)" fillcolor=orange]
	11135688064 -> 6138126128 [dir=none]
	6138126128 [label="weight
 (960, 1, 3, 3)" fillcolor=orange]
	11135688064 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            960
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135687776 -> 11135688064
	11135687776 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6141510592 -> 11135687776
	6141510592 [label=SwishImplementationBackward]
	11135687536 -> 6141510592
	11135687536 -> 6140278672 [dir=none]
	6140278672 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135687536 -> 11135140944 [dir=none]
	11135140944 [label="result1
 (960)" fillcolor=orange]
	11135687536 -> 11135140704 [dir=none]
	11135140704 [label="result2
 (960)" fillcolor=orange]
	11135687536 -> 6138125328 [dir=none]
	6138125328 [label="running_mean
 (960)" fillcolor=orange]
	11135687536 -> 6138125648 [dir=none]
	6138125648 [label="running_var
 (960)" fillcolor=orange]
	11135687536 -> 6138125488 [dir=none]
	6138125488 [label="weight
 (960)" fillcolor=orange]
	11135687536 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135687392 -> 11135687536
	11135687392 -> 6140277792 [dir=none]
	6140277792 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	11135687392 -> 6138125408 [dir=none]
	6138125408 [label="weight
 (960, 160, 1, 1)" fillcolor=orange]
	11135687392 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135690560 -> 11135687392
	11135690560 [label="AddBackward0
------------
alpha: 1"]
	11135686960 -> 11135690560
	11135686960 -> 6140277632 [dir=none]
	6140277632 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11135686960 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135686624 -> 11135686960
	11135686624 -> 11135141344 [dir=none]
	11135141344 [label="other
 ()" fillcolor=orange]
	11135686624 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135686480 -> 11135686624
	11135686480 -> 6140277952 [dir=none]
	6140277952 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	11135686480 -> 11135141664 [dir=none]
	11135141664 [label="result1
 (160)" fillcolor=orange]
	11135686480 -> 11135141584 [dir=none]
	11135141584 [label="result2
 (160)" fillcolor=orange]
	11135686480 -> 6138124688 [dir=none]
	6138124688 [label="running_mean
 (160)" fillcolor=orange]
	11135686480 -> 6138125008 [dir=none]
	6138125008 [label="running_var
 (160)" fillcolor=orange]
	11135686480 -> 6138124848 [dir=none]
	6138124848 [label="weight
 (160)" fillcolor=orange]
	11135686480 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135686336 -> 11135686480
	11135686336 -> 6140278032 [dir=none]
	6140278032 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135686336 -> 6138124768 [dir=none]
	6138124768 [label="weight
 (160, 960, 1, 1)" fillcolor=orange]
	11135686336 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135686048 -> 11135686336
	11135686048 -> 6140278832 [dir=none]
	6140278832 [label="other
 (1, 960, 38, 38)" fillcolor=orange]
	11135686048 -> 6140278512 [dir=none]
	6140278512 [label="self
 (1, 960, 1, 1)" fillcolor=orange]
	11135686048 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135685952 -> 11135686048
	11135685952 -> 11135141984 [dir=none]
	11135141984 [label="result
 (1, 960, 1, 1)" fillcolor=orange]
	11135685952 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135685808 -> 11135685952
	11135685808 -> 6140278352 [dir=none]
	6140278352 [label="input
 (1, 40, 1, 1)" fillcolor=orange]
	11135685808 -> 6138124528 [dir=none]
	6138124528 [label="weight
 (960, 40, 1, 1)" fillcolor=orange]
	11135685808 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (960,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141510368 -> 11135685808
	6141510368 [label=SwishImplementationBackward]
	11135685376 -> 6141510368
	11135685376 -> 6140279312 [dir=none]
	6140279312 [label="input
 (1, 960, 1, 1)" fillcolor=orange]
	11135685376 -> 6138124288 [dir=none]
	6138124288 [label="weight
 (40, 960, 1, 1)" fillcolor=orange]
	11135685376 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (40,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135685232 -> 11135685376
	11135685232 -> 6140278832 [dir=none]
	6140278832 [label="self
 (1, 960, 38, 38)" fillcolor=orange]
	11135685232 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 960, 38, 38)"]
	6141510144 -> 11135685232
	6141510144 [label=SwishImplementationBackward]
	11135684800 -> 6141510144
	11135684800 -> 6140279712 [dir=none]
	6140279712 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135684800 -> 11135142464 [dir=none]
	11135142464 [label="result1
 (960)" fillcolor=orange]
	11135684800 -> 11135142064 [dir=none]
	11135142064 [label="result2
 (960)" fillcolor=orange]
	11135684800 -> 6138121968 [dir=none]
	6138121968 [label="running_mean
 (960)" fillcolor=orange]
	11135684800 -> 6138123808 [dir=none]
	6138123808 [label="running_var
 (960)" fillcolor=orange]
	11135684800 -> 6138123568 [dir=none]
	6138123568 [label="weight
 (960)" fillcolor=orange]
	11135684800 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135684656 -> 11135684800
	11135684656 -> 6140279872 [dir=none]
	6140279872 [label="input
 (1, 960, 40, 40)" fillcolor=orange]
	11135684656 -> 6138123648 [dir=none]
	6138123648 [label="weight
 (960, 1, 3, 3)" fillcolor=orange]
	11135684656 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            960
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135684368 -> 11135684656
	11135684368 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6141509920 -> 11135684368
	6141509920 [label=SwishImplementationBackward]
	11135683888 -> 6141509920
	11135683888 -> 6140265952 [dir=none]
	6140265952 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135683888 -> 11135143024 [dir=none]
	11135143024 [label="result1
 (960)" fillcolor=orange]
	11135683888 -> 11135142784 [dir=none]
	11135142784 [label="result2
 (960)" fillcolor=orange]
	11135683888 -> 6138122848 [dir=none]
	6138122848 [label="running_mean
 (960)" fillcolor=orange]
	11135683888 -> 6138123168 [dir=none]
	6138123168 [label="running_var
 (960)" fillcolor=orange]
	11135683888 -> 6138123008 [dir=none]
	6138123008 [label="weight
 (960)" fillcolor=orange]
	11135683888 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135683744 -> 11135683888
	11135683744 -> 6140280112 [dir=none]
	6140280112 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	11135683744 -> 6138122928 [dir=none]
	6138122928 [label="weight
 (960, 160, 1, 1)" fillcolor=orange]
	11135683744 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135686912 -> 11135683744
	11135686912 [label="AddBackward0
------------
alpha: 1"]
	11135683312 -> 11135686912
	11135683312 -> 6140280032 [dir=none]
	6140280032 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11135683312 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135683216 -> 11135683312
	11135683216 -> 11135143424 [dir=none]
	11135143424 [label="other
 ()" fillcolor=orange]
	11135683216 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135683072 -> 11135683216
	11135683072 -> 6140280432 [dir=none]
	6140280432 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	11135683072 -> 11135143744 [dir=none]
	11135143744 [label="result1
 (160)" fillcolor=orange]
	11135683072 -> 11135143664 [dir=none]
	11135143664 [label="result2
 (160)" fillcolor=orange]
	11135683072 -> 6138122208 [dir=none]
	6138122208 [label="running_mean
 (160)" fillcolor=orange]
	11135683072 -> 6138122528 [dir=none]
	6138122528 [label="running_var
 (160)" fillcolor=orange]
	11135683072 -> 6138122368 [dir=none]
	6138122368 [label="weight
 (160)" fillcolor=orange]
	11135683072 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135682928 -> 11135683072
	11135682928 -> 6140280592 [dir=none]
	6140280592 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135682928 -> 6138122288 [dir=none]
	6138122288 [label="weight
 (160, 960, 1, 1)" fillcolor=orange]
	11135682928 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135682640 -> 11135682928
	11135682640 -> 6140266352 [dir=none]
	6140266352 [label="other
 (1, 960, 38, 38)" fillcolor=orange]
	11135682640 -> 6140265632 [dir=none]
	6140265632 [label="self
 (1, 960, 1, 1)" fillcolor=orange]
	11135682640 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135682304 -> 11135682640
	11135682304 -> 11135144064 [dir=none]
	11135144064 [label="result
 (1, 960, 1, 1)" fillcolor=orange]
	11135682304 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135682160 -> 11135682304
	11135682160 -> 6140264912 [dir=none]
	6140264912 [label="input
 (1, 40, 1, 1)" fillcolor=orange]
	11135682160 -> 6138122048 [dir=none]
	6138122048 [label="weight
 (960, 40, 1, 1)" fillcolor=orange]
	11135682160 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (960,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141509696 -> 11135682160
	6141509696 [label=SwishImplementationBackward]
	11135681728 -> 6141509696
	11135681728 -> 6140269232 [dir=none]
	6140269232 [label="input
 (1, 960, 1, 1)" fillcolor=orange]
	11135681728 -> 6138121808 [dir=none]
	6138121808 [label="weight
 (40, 960, 1, 1)" fillcolor=orange]
	11135681728 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (40,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135681584 -> 11135681728
	11135681584 -> 6140266352 [dir=none]
	6140266352 [label="self
 (1, 960, 38, 38)" fillcolor=orange]
	11135681584 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 960, 38, 38)"]
	6141951584 -> 11135681584
	6141951584 [label=SwishImplementationBackward]
	11135681152 -> 6141951584
	11135681152 -> 6140270112 [dir=none]
	6140270112 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135681152 -> 11135144544 [dir=none]
	11135144544 [label="result1
 (960)" fillcolor=orange]
	11135681152 -> 11135144144 [dir=none]
	11135144144 [label="result2
 (960)" fillcolor=orange]
	11135681152 -> 6138119488 [dir=none]
	6138119488 [label="running_mean
 (960)" fillcolor=orange]
	11135681152 -> 6138121328 [dir=none]
	6138121328 [label="running_var
 (960)" fillcolor=orange]
	11135681152 -> 6138121088 [dir=none]
	6138121088 [label="weight
 (960)" fillcolor=orange]
	11135681152 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135681008 -> 11135681152
	11135681008 -> 6140273232 [dir=none]
	6140273232 [label="input
 (1, 960, 40, 40)" fillcolor=orange]
	11135681008 -> 6138121168 [dir=none]
	6138121168 [label="weight
 (960, 1, 3, 3)" fillcolor=orange]
	11135681008 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            960
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135680720 -> 11135681008
	11135680720 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6141951360 -> 11135680720
	6141951360 [label=SwishImplementationBackward]
	11135680768 -> 6141951360
	11135680768 -> 6140277472 [dir=none]
	6140277472 [label="input
 (1, 960, 38, 38)" fillcolor=orange]
	11135680768 -> 11135145104 [dir=none]
	11135145104 [label="result1
 (960)" fillcolor=orange]
	11135680768 -> 11135144864 [dir=none]
	11135144864 [label="result2
 (960)" fillcolor=orange]
	11135680768 -> 6138120368 [dir=none]
	6138120368 [label="running_mean
 (960)" fillcolor=orange]
	11135680768 -> 6138120688 [dir=none]
	6138120688 [label="running_var
 (960)" fillcolor=orange]
	11135680768 -> 6138120528 [dir=none]
	6138120528 [label="weight
 (960)" fillcolor=orange]
	11135680768 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135614736 -> 11135680768
	11135614736 -> 6140274832 [dir=none]
	6140274832 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	11135614736 -> 6138120448 [dir=none]
	6138120448 [label="weight
 (960, 160, 1, 1)" fillcolor=orange]
	11135614736 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135683504 -> 11135614736
	11135683504 -> 6140275232 [dir=none]
	6140275232 [label="input
 (1, 160, 38, 38)" fillcolor=orange]
	11135683504 -> 11135145264 [dir=none]
	11135145264 [label="result1
 (160)" fillcolor=orange]
	11135683504 -> 11135144784 [dir=none]
	11135144784 [label="result2
 (160)" fillcolor=orange]
	11135683504 -> 6138119728 [dir=none]
	6138119728 [label="running_mean
 (160)" fillcolor=orange]
	11135683504 -> 6138120048 [dir=none]
	6138120048 [label="running_var
 (160)" fillcolor=orange]
	11135683504 -> 6138119888 [dir=none]
	6138119888 [label="weight
 (160)" fillcolor=orange]
	11135683504 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135614304 -> 11135683504
	11135614304 -> 6140275632 [dir=none]
	6140275632 [label="input
 (1, 480, 38, 38)" fillcolor=orange]
	11135614304 -> 6138119808 [dir=none]
	6138119808 [label="weight
 (160, 480, 1, 1)" fillcolor=orange]
	11135614304 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135614016 -> 11135614304
	11135614016 -> 6140278592 [dir=none]
	6140278592 [label="other
 (1, 480, 38, 38)" fillcolor=orange]
	11135614016 -> 6140277232 [dir=none]
	6140277232 [label="self
 (1, 480, 1, 1)" fillcolor=orange]
	11135614016 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135613680 -> 11135614016
	11135613680 -> 11135145904 [dir=none]
	11135145904 [label="result
 (1, 480, 1, 1)" fillcolor=orange]
	11135613680 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135613536 -> 11135613680
	11135613536 -> 6140275952 [dir=none]
	6140275952 [label="input
 (1, 20, 1, 1)" fillcolor=orange]
	11135613536 -> 6138119568 [dir=none]
	6138119568 [label="weight
 (480, 20, 1, 1)" fillcolor=orange]
	11135613536 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (480,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141951136 -> 11135613536
	6141951136 [label=SwishImplementationBackward]
	11135613104 -> 6141951136
	11135613104 -> 6140278912 [dir=none]
	6140278912 [label="input
 (1, 480, 1, 1)" fillcolor=orange]
	11135613104 -> 6138119328 [dir=none]
	6138119328 [label="weight
 (20, 480, 1, 1)" fillcolor=orange]
	11135613104 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (20,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135612960 -> 11135613104
	11135612960 -> 6140278592 [dir=none]
	6140278592 [label="self
 (1, 480, 38, 38)" fillcolor=orange]
	11135612960 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                             (1, 480, 38, 38)"]
	6141950912 -> 11135612960
	6141950912 [label=SwishImplementationBackward]
	11135612528 -> 6141950912
	11135612528 -> 6140280512 [dir=none]
	6140280512 [label="input
 (1, 480, 38, 38)" fillcolor=orange]
	11135612528 -> 11135146304 [dir=none]
	11135146304 [label="result1
 (480)" fillcolor=orange]
	11135612528 -> 11135145344 [dir=none]
	11135145344 [label="result2
 (480)" fillcolor=orange]
	11135612528 -> 6137838416 [dir=none]
	6137838416 [label="running_mean
 (480)" fillcolor=orange]
	11135612528 -> 6138118848 [dir=none]
	6138118848 [label="running_var
 (480)" fillcolor=orange]
	11135612528 -> 6138118608 [dir=none]
	6138118608 [label="weight
 (480)" fillcolor=orange]
	11135612528 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135612384 -> 11135612528
	11135612384 -> 6140280752 [dir=none]
	6140280752 [label="input
 (1, 480, 77, 77)" fillcolor=orange]
	11135612384 -> 6138118688 [dir=none]
	6138118688 [label="weight
 (480, 1, 3, 3)" fillcolor=orange]
	11135612384 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :            480
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	11135612096 -> 11135612384
	11135612096 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6141950688 -> 11135612096
	6141950688 [label=SwishImplementationBackward]
	11135611856 -> 6141950688
	11135611856 -> 6140269952 [dir=none]
	6140269952 [label="input
 (1, 480, 75, 75)" fillcolor=orange]
	11135611856 -> 11135146864 [dir=none]
	11135146864 [label="result1
 (480)" fillcolor=orange]
	11135611856 -> 11135146624 [dir=none]
	11135146624 [label="result2
 (480)" fillcolor=orange]
	11135611856 -> 6137839296 [dir=none]
	6137839296 [label="running_mean
 (480)" fillcolor=orange]
	11135611856 -> 6138118208 [dir=none]
	6138118208 [label="running_var
 (480)" fillcolor=orange]
	11135611856 -> 6137839456 [dir=none]
	6137839456 [label="weight
 (480)" fillcolor=orange]
	11135611856 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135611712 -> 11135611856
	11135611712 -> 6140265792 [dir=none]
	6140265792 [label="input
 (1, 80, 75, 75)" fillcolor=orange]
	11135611712 -> 6137839376 [dir=none]
	6137839376 [label="weight
 (480, 80, 1, 1)" fillcolor=orange]
	11135611712 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6140460816 -> 11135611712
	11135611424 -> 11135611712
	6137839376 [label="
 (480, 80, 1, 1)" fillcolor=lightblue]
	6137839376 -> 11135611424
	11135611424 [label=AccumulateGrad]
	11135611664 -> 11135611856
	6137839456 [label="
 (480)" fillcolor=lightblue]
	6137839456 -> 11135611664
	11135611664 [label=AccumulateGrad]
	11135612144 -> 11135611856
	6137839536 [label="
 (480)" fillcolor=lightblue]
	6137839536 -> 11135612144
	11135612144 [label=AccumulateGrad]
	6140279952 -> 6141950688
	6140279952 [label="
 (1, 480, 75, 75)" fillcolor=orange]
	11135612288 -> 11135612384
	6138118688 [label="
 (480, 1, 3, 3)" fillcolor=lightblue]
	6138118688 -> 11135612288
	11135612288 [label=AccumulateGrad]
	11135612576 -> 11135612528
	6138118608 [label="
 (480)" fillcolor=lightblue]
	6138118608 -> 11135612576
	11135612576 [label=AccumulateGrad]
	11135612816 -> 11135612528
	6138118768 [label="
 (480)" fillcolor=lightblue]
	6138118768 -> 11135612816
	11135612816 [label=AccumulateGrad]
	6140279792 -> 6141950912
	6140279792 [label="
 (1, 480, 38, 38)" fillcolor=orange]
	11135613152 -> 11135613104
	6138119328 [label="
 (20, 480, 1, 1)" fillcolor=lightblue]
	6138119328 -> 11135613152
	11135613152 [label=AccumulateGrad]
	11135613248 -> 11135613104
	6138119408 [label="
 (20)" fillcolor=lightblue]
	6138119408 -> 11135613248
	11135613248 [label=AccumulateGrad]
	6140278752 -> 6141951136
	6140278752 [label="
 (1, 20, 1, 1)" fillcolor=orange]
	11135613392 -> 11135613536
	6138119568 [label="
 (480, 20, 1, 1)" fillcolor=lightblue]
	6138119568 -> 11135613392
	11135613392 [label=AccumulateGrad]
	11135613584 -> 11135613536
	6138119648 [label="
 (480)" fillcolor=lightblue]
	6138119648 -> 11135613584
	11135613584 [label=AccumulateGrad]
	6141950912 -> 11135614016
	11135613968 -> 11135614304
	6138119808 [label="
 (160, 480, 1, 1)" fillcolor=lightblue]
	6138119808 -> 11135613968
	11135613968 [label=AccumulateGrad]
	11135614256 -> 11135683504
	6138119888 [label="
 (160)" fillcolor=lightblue]
	6138119888 -> 11135614256
	11135614256 [label=AccumulateGrad]
	11135614592 -> 11135683504
	6138119968 [label="
 (160)" fillcolor=lightblue]
	6138119968 -> 11135614592
	11135614592 [label=AccumulateGrad]
	11135614448 -> 11135614736
	6138120448 [label="
 (960, 160, 1, 1)" fillcolor=lightblue]
	6138120448 -> 11135614448
	11135614448 [label=AccumulateGrad]
	11135614688 -> 11135680768
	6138120528 [label="
 (960)" fillcolor=lightblue]
	6138120528 -> 11135614688
	11135614688 [label=AccumulateGrad]
	11135614832 -> 11135680768
	6138120608 [label="
 (960)" fillcolor=lightblue]
	6138120608 -> 11135614832
	11135614832 [label=AccumulateGrad]
	6140274272 -> 6141951360
	6140274272 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	11135680912 -> 11135681008
	6138121168 [label="
 (960, 1, 3, 3)" fillcolor=lightblue]
	6138121168 -> 11135680912
	11135680912 [label=AccumulateGrad]
	11135681200 -> 11135681152
	6138121088 [label="
 (960)" fillcolor=lightblue]
	6138121088 -> 11135681200
	11135681200 [label=AccumulateGrad]
	11135681440 -> 11135681152
	6138121248 [label="
 (960)" fillcolor=lightblue]
	6138121248 -> 11135681440
	11135681440 [label=AccumulateGrad]
	6140269392 -> 6141951584
	6140269392 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	11135681776 -> 11135681728
	6138121808 [label="
 (40, 960, 1, 1)" fillcolor=lightblue]
	6138121808 -> 11135681776
	11135681776 [label=AccumulateGrad]
	11135681872 -> 11135681728
	6138121888 [label="
 (40)" fillcolor=lightblue]
	6138121888 -> 11135681872
	11135681872 [label=AccumulateGrad]
	6140268512 -> 6141509696
	6140268512 [label="
 (1, 40, 1, 1)" fillcolor=orange]
	11135682016 -> 11135682160
	6138122048 [label="
 (960, 40, 1, 1)" fillcolor=lightblue]
	6138122048 -> 11135682016
	11135682016 [label=AccumulateGrad]
	11135682208 -> 11135682160
	6138122128 [label="
 (960)" fillcolor=lightblue]
	6138122128 -> 11135682208
	11135682208 [label=AccumulateGrad]
	6141951584 -> 11135682640
	11135682592 -> 11135682928
	6138122288 [label="
 (160, 960, 1, 1)" fillcolor=lightblue]
	6138122288 -> 11135682592
	11135682592 [label=AccumulateGrad]
	11135682880 -> 11135683072
	6138122368 [label="
 (160)" fillcolor=lightblue]
	6138122368 -> 11135682880
	11135682880 [label=AccumulateGrad]
	11135683360 -> 11135683072
	6138122448 [label="
 (160)" fillcolor=lightblue]
	6138122448 -> 11135683360
	11135683360 [label=AccumulateGrad]
	11135683504 -> 11135686912
	11135683456 -> 11135683744
	6138122928 [label="
 (960, 160, 1, 1)" fillcolor=lightblue]
	6138122928 -> 11135683456
	11135683456 [label=AccumulateGrad]
	11135683936 -> 11135683888
	6138123008 [label="
 (960)" fillcolor=lightblue]
	6138123008 -> 11135683936
	11135683936 [label=AccumulateGrad]
	11135684176 -> 11135683888
	6138123088 [label="
 (960)" fillcolor=lightblue]
	6138123088 -> 11135684176
	11135684176 [label=AccumulateGrad]
	6140279632 -> 6141509920
	6140279632 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	11135684320 -> 11135684656
	6138123648 [label="
 (960, 1, 3, 3)" fillcolor=lightblue]
	6138123648 -> 11135684320
	11135684320 [label=AccumulateGrad]
	11135684608 -> 11135684800
	6138123568 [label="
 (960)" fillcolor=lightblue]
	6138123568 -> 11135684608
	11135684608 [label=AccumulateGrad]
	11135685088 -> 11135684800
	6138123728 [label="
 (960)" fillcolor=lightblue]
	6138123728 -> 11135685088
	11135685088 [label=AccumulateGrad]
	6140279472 -> 6141510144
	6140279472 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	11135685184 -> 11135685376
	6138124288 [label="
 (40, 960, 1, 1)" fillcolor=lightblue]
	6138124288 -> 11135685184
	11135685184 [label=AccumulateGrad]
	11135685520 -> 11135685376
	6138124368 [label="
 (40)" fillcolor=lightblue]
	6138124368 -> 11135685520
	11135685520 [label=AccumulateGrad]
	6140278992 -> 6141510368
	6140278992 [label="
 (1, 40, 1, 1)" fillcolor=orange]
	11135685664 -> 11135685808
	6138124528 [label="
 (960, 40, 1, 1)" fillcolor=lightblue]
	6138124528 -> 11135685664
	11135685664 [label=AccumulateGrad]
	11135685616 -> 11135685808
	6138124608 [label="
 (960)" fillcolor=lightblue]
	6138124608 -> 11135685616
	11135685616 [label=AccumulateGrad]
	6141510144 -> 11135686048
	11135686240 -> 11135686336
	6138124768 [label="
 (160, 960, 1, 1)" fillcolor=lightblue]
	6138124768 -> 11135686240
	11135686240 [label=AccumulateGrad]
	11135686528 -> 11135686480
	6138124848 [label="
 (160)" fillcolor=lightblue]
	6138124848 -> 11135686528
	11135686528 [label=AccumulateGrad]
	11135686768 -> 11135686480
	6138124928 [label="
 (160)" fillcolor=lightblue]
	6138124928 -> 11135686768
	11135686768 [label=AccumulateGrad]
	11135686912 -> 11135690560
	11135687104 -> 11135687392
	6138125408 [label="
 (960, 160, 1, 1)" fillcolor=lightblue]
	6138125408 -> 11135687104
	11135687104 [label=AccumulateGrad]
	11135687344 -> 11135687536
	6138125488 [label="
 (960)" fillcolor=lightblue]
	6138125488 -> 11135687344
	11135687344 [label=AccumulateGrad]
	11135687824 -> 11135687536
	6138125568 [label="
 (960)" fillcolor=lightblue]
	6138125568 -> 11135687824
	11135687824 [label=AccumulateGrad]
	6140277312 -> 6141510592
	6140277312 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	11135687968 -> 11135688064
	6138126128 [label="
 (960, 1, 3, 3)" fillcolor=lightblue]
	6138126128 -> 11135687968
	11135687968 [label=AccumulateGrad]
	11135688256 -> 11135688208
	6138126048 [label="
 (960)" fillcolor=lightblue]
	6138126048 -> 11135688256
	11135688256 [label=AccumulateGrad]
	11135688496 -> 11135688208
	6138126208 [label="
 (960)" fillcolor=lightblue]
	6138126208 -> 11135688496
	11135688496 [label=AccumulateGrad]
	6140277152 -> 6141510816
	6140277152 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	11135688832 -> 11135688784
	6138126768 [label="
 (40, 960, 1, 1)" fillcolor=lightblue]
	6138126768 -> 11135688832
	11135688832 [label=AccumulateGrad]
	11135688928 -> 11135688784
	6138126848 [label="
 (40)" fillcolor=lightblue]
	6138126848 -> 11135688928
	11135688928 [label=AccumulateGrad]
	6140276752 -> 6141511040
	6140276752 [label="
 (1, 40, 1, 1)" fillcolor=orange]
	11135689072 -> 11135689216
	6138127008 [label="
 (960, 40, 1, 1)" fillcolor=lightblue]
	6138127008 -> 11135689072
	11135689072 [label=AccumulateGrad]
	11135689264 -> 11135689216
	6138127088 [label="
 (960)" fillcolor=lightblue]
	6138127088 -> 11135689264
	11135689264 [label=AccumulateGrad]
	6141510816 -> 11135689696
	11135689648 -> 11135689984
	6138127248 [label="
 (160, 960, 1, 1)" fillcolor=lightblue]
	6138127248 -> 11135689648
	11135689648 [label=AccumulateGrad]
	11135689936 -> 11135690128
	6138127328 [label="
 (160)" fillcolor=lightblue]
	6138127328 -> 11135689936
	11135689936 [label=AccumulateGrad]
	11135690416 -> 11135690128
	6138127408 [label="
 (160)" fillcolor=lightblue]
	6138127408 -> 11135690416
	11135690416 [label=AccumulateGrad]
	11135690560 -> 11135693968
	11135690512 -> 11135690800
	6138127888 [label="
 (960, 160, 1, 1)" fillcolor=lightblue]
	6138127888 -> 11135690512
	11135690512 [label=AccumulateGrad]
	11135690992 -> 11135690944
	6138127968 [label="
 (960)" fillcolor=lightblue]
	6138127968 -> 11135690992
	11135690992 [label=AccumulateGrad]
	11135691232 -> 11135690944
	6138128048 [label="
 (960)" fillcolor=lightblue]
	6138128048 -> 11135691232
	11135691232 [label=AccumulateGrad]
	6140274672 -> 6141511264
	6140274672 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	11135691376 -> 11135691712
	6138128608 [label="
 (960, 1, 3, 3)" fillcolor=lightblue]
	6138128608 -> 11135691376
	11135691376 [label=AccumulateGrad]
	11135691664 -> 11135691856
	6138128528 [label="
 (960)" fillcolor=lightblue]
	6138128528 -> 11135691664
	11135691664 [label=AccumulateGrad]
	11135692144 -> 11135691856
	6138128688 [label="
 (960)" fillcolor=lightblue]
	6138128688 -> 11135692144
	11135692144 [label=AccumulateGrad]
	6140274512 -> 6141511488
	6140274512 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	11135692240 -> 11135692432
	6138129248 [label="
 (40, 960, 1, 1)" fillcolor=lightblue]
	6138129248 -> 11135692240
	11135692240 [label=AccumulateGrad]
	11135692576 -> 11135692432
	6138129328 [label="
 (40)" fillcolor=lightblue]
	6138129328 -> 11135692576
	11135692576 [label=AccumulateGrad]
	6140274192 -> 6141511712
	6140274192 [label="
 (1, 40, 1, 1)" fillcolor=orange]
	11135692720 -> 11135692864
	6138129488 [label="
 (960, 40, 1, 1)" fillcolor=lightblue]
	6138129488 -> 11135692720
	11135692720 [label=AccumulateGrad]
	11135692672 -> 11135692864
	6138129568 [label="
 (960)" fillcolor=lightblue]
	6138129568 -> 11135692672
	11135692672 [label=AccumulateGrad]
	6141511488 -> 11135693104
	11135693296 -> 11135693392
	6138129728 [label="
 (160, 960, 1, 1)" fillcolor=lightblue]
	6138129728 -> 11135693296
	11135693296 [label=AccumulateGrad]
	11135693584 -> 11135693536
	6138129808 [label="
 (160)" fillcolor=lightblue]
	6138129808 -> 11135693584
	11135693584 [label=AccumulateGrad]
	11135693824 -> 11135693536
	6138129888 [label="
 (160)" fillcolor=lightblue]
	6138129888 -> 11135693824
	11135693824 [label=AccumulateGrad]
	11135693968 -> 11135763216
	11135694160 -> 11135694448
	6138130368 [label="
 (960, 160, 1, 1)" fillcolor=lightblue]
	6138130368 -> 11135694160
	11135694160 [label=AccumulateGrad]
	11135694400 -> 11135694592
	6138130448 [label="
 (960)" fillcolor=lightblue]
	6138130448 -> 11135694400
	11135694400 [label=AccumulateGrad]
	11135694880 -> 11135694592
	6138130528 [label="
 (960)" fillcolor=lightblue]
	6138130528 -> 11135694880
	11135694880 [label=AccumulateGrad]
	6140272032 -> 6141511936
	6140272032 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	11135695024 -> 11135695120
	6138131088 [label="
 (960, 1, 3, 3)" fillcolor=lightblue]
	6138131088 -> 11135695024
	11135695024 [label=AccumulateGrad]
	11135695312 -> 11135695264
	6138131008 [label="
 (960)" fillcolor=lightblue]
	6138131008 -> 11135695312
	11135695312 [label=AccumulateGrad]
	11135695552 -> 11135695264
	6138131168 [label="
 (960)" fillcolor=lightblue]
	6138131168 -> 11135695552
	11135695552 [label=AccumulateGrad]
	6140271712 -> 6141512160
	6140271712 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	11135695888 -> 11135695840
	6138131728 [label="
 (40, 960, 1, 1)" fillcolor=lightblue]
	6138131728 -> 11135695888
	11135695888 [label=AccumulateGrad]
	11135695984 -> 11135695840
	6138131808 [label="
 (40)" fillcolor=lightblue]
	6138131808 -> 11135695984
	11135695984 [label=AccumulateGrad]
	6140271472 -> 6141512384
	6140271472 [label="
 (1, 40, 1, 1)" fillcolor=orange]
	11135696128 -> 11135696272
	6138131968 [label="
 (960, 40, 1, 1)" fillcolor=lightblue]
	6138131968 -> 11135696128
	11135696128 [label=AccumulateGrad]
	11135696320 -> 11135696272
	6138132048 [label="
 (960)" fillcolor=lightblue]
	6138132048 -> 11135696320
	11135696320 [label=AccumulateGrad]
	6141512160 -> 11135696752
	11135696704 -> 11135762640
	6138132208 [label="
 (160, 960, 1, 1)" fillcolor=lightblue]
	6138132208 -> 11135696704
	11135696704 [label=AccumulateGrad]
	11135762592 -> 11135762784
	6138132288 [label="
 (160)" fillcolor=lightblue]
	6138132288 -> 11135762592
	11135762592 [label=AccumulateGrad]
	11135763072 -> 11135762784
	6138132368 [label="
 (160)" fillcolor=lightblue]
	6138132368 -> 11135763072
	11135763072 [label=AccumulateGrad]
	11135763216 -> 11135766624
	11135763168 -> 11135763456
	6138132848 [label="
 (960, 160, 1, 1)" fillcolor=lightblue]
	6138132848 -> 11135763168
	11135763168 [label=AccumulateGrad]
	11135763648 -> 11135763600
	6138132928 [label="
 (960)" fillcolor=lightblue]
	6138132928 -> 11135763648
	11135763648 [label=AccumulateGrad]
	11135763888 -> 11135763600
	6138133008 [label="
 (960)" fillcolor=lightblue]
	6138133008 -> 11135763888
	11135763888 [label=AccumulateGrad]
	6140269552 -> 6141512608
	6140269552 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	11135764032 -> 11135764368
	6138133568 [label="
 (960, 1, 3, 3)" fillcolor=lightblue]
	6138133568 -> 11135764032
	11135764032 [label=AccumulateGrad]
	11135764320 -> 11135764512
	6138133488 [label="
 (960)" fillcolor=lightblue]
	6138133488 -> 11135764320
	11135764320 [label=AccumulateGrad]
	11135764800 -> 11135764512
	6138133648 [label="
 (960)" fillcolor=lightblue]
	6138133648 -> 11135764800
	11135764800 [label=AccumulateGrad]
	6140269472 -> 6141512832
	6140269472 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	11135764896 -> 11135765088
	6138134208 [label="
 (40, 960, 1, 1)" fillcolor=lightblue]
	6138134208 -> 11135764896
	11135764896 [label=AccumulateGrad]
	11135765232 -> 11135765088
	6138134288 [label="
 (40)" fillcolor=lightblue]
	6138134288 -> 11135765232
	11135765232 [label=AccumulateGrad]
	6140269152 -> 6141513056
	6140269152 [label="
 (1, 40, 1, 1)" fillcolor=orange]
	11135765376 -> 11135765520
	6138134448 [label="
 (960, 40, 1, 1)" fillcolor=lightblue]
	6138134448 -> 11135765376
	11135765376 [label=AccumulateGrad]
	11135765328 -> 11135765520
	6138396736 [label="
 (960)" fillcolor=lightblue]
	6138396736 -> 11135765328
	11135765328 [label=AccumulateGrad]
	6141512832 -> 11135765760
	11135765952 -> 11135766048
	6138396896 [label="
 (160, 960, 1, 1)" fillcolor=lightblue]
	6138396896 -> 11135765952
	11135765952 [label=AccumulateGrad]
	11135766240 -> 11135766192
	6138396816 [label="
 (160)" fillcolor=lightblue]
	6138396816 -> 11135766240
	11135766240 [label=AccumulateGrad]
	11135766480 -> 11135766192
	6138396976 [label="
 (160)" fillcolor=lightblue]
	6138396976 -> 11135766480
	11135766480 [label=AccumulateGrad]
	11135766624 -> 11135770272
	11135766816 -> 11135767104
	6138397376 [label="
 (960, 160, 1, 1)" fillcolor=lightblue]
	6138397376 -> 11135766816
	11135766816 [label=AccumulateGrad]
	11135767056 -> 11135767248
	6138397456 [label="
 (960)" fillcolor=lightblue]
	6138397456 -> 11135767056
	11135767056 [label=AccumulateGrad]
	11135767536 -> 11135767248
	6138397536 [label="
 (960)" fillcolor=lightblue]
	6138397536 -> 11135767536
	11135767536 [label=AccumulateGrad]
	6140267152 -> 6141513280
	6140267152 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	11135767680 -> 11135767776
	6138398096 [label="
 (960, 1, 3, 3)" fillcolor=lightblue]
	6138398096 -> 11135767680
	11135767680 [label=AccumulateGrad]
	11135767968 -> 11135767920
	6138398016 [label="
 (960)" fillcolor=lightblue]
	6138398016 -> 11135767968
	11135767968 [label=AccumulateGrad]
	11135768208 -> 11135767920
	6138398176 [label="
 (960)" fillcolor=lightblue]
	6138398176 -> 11135768208
	11135768208 [label=AccumulateGrad]
	6140266992 -> 6141513504
	6140266992 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	11135768544 -> 11135768496
	6138398736 [label="
 (40, 960, 1, 1)" fillcolor=lightblue]
	6138398736 -> 11135768544
	11135768544 [label=AccumulateGrad]
	11135768640 -> 11135768496
	6138398816 [label="
 (40)" fillcolor=lightblue]
	6138398816 -> 11135768640
	11135768640 [label=AccumulateGrad]
	6140266752 -> 6141513728
	6140266752 [label="
 (1, 40, 1, 1)" fillcolor=orange]
	11135768784 -> 11135768928
	6138398976 [label="
 (960, 40, 1, 1)" fillcolor=lightblue]
	6138398976 -> 11135768784
	11135768784 [label=AccumulateGrad]
	11135768976 -> 11135768928
	6138399056 [label="
 (960)" fillcolor=lightblue]
	6138399056 -> 11135768976
	11135768976 [label=AccumulateGrad]
	6141513504 -> 11135769408
	11135769360 -> 11135769696
	6138399216 [label="
 (160, 960, 1, 1)" fillcolor=lightblue]
	6138399216 -> 11135769360
	11135769360 [label=AccumulateGrad]
	11135769648 -> 11135769840
	6138399296 [label="
 (160)" fillcolor=lightblue]
	6138399296 -> 11135769648
	11135769648 [label=AccumulateGrad]
	11135770128 -> 11135769840
	6138399376 [label="
 (160)" fillcolor=lightblue]
	6138399376 -> 11135770128
	11135770128 [label=AccumulateGrad]
	11135770272 -> 11135773680
	11135770224 -> 11135770512
	6138399856 [label="
 (960, 160, 1, 1)" fillcolor=lightblue]
	6138399856 -> 11135770224
	11135770224 [label=AccumulateGrad]
	11135770704 -> 11135770656
	6138399936 [label="
 (960)" fillcolor=lightblue]
	6138399936 -> 11135770704
	11135770704 [label=AccumulateGrad]
	11135770944 -> 11135770656
	6138400016 [label="
 (960)" fillcolor=lightblue]
	6138400016 -> 11135770944
	11135770944 [label=AccumulateGrad]
	6140264832 -> 6141513952
	6140264832 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	11135771088 -> 11135771424
	6138400576 [label="
 (960, 1, 3, 3)" fillcolor=lightblue]
	6138400576 -> 11135771088
	11135771088 [label=AccumulateGrad]
	11135771376 -> 11135771568
	6138400496 [label="
 (960)" fillcolor=lightblue]
	6138400496 -> 11135771376
	11135771376 [label=AccumulateGrad]
	11135771856 -> 11135771568
	6138400656 [label="
 (960)" fillcolor=lightblue]
	6138400656 -> 11135771856
	11135771856 [label=AccumulateGrad]
	6140264672 -> 6141514176
	6140264672 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	11135771952 -> 11135772144
	6138401216 [label="
 (40, 960, 1, 1)" fillcolor=lightblue]
	6138401216 -> 11135771952
	11135771952 [label=AccumulateGrad]
	11135772288 -> 11135772144
	6138401296 [label="
 (40)" fillcolor=lightblue]
	6138401296 -> 11135772288
	11135772288 [label=AccumulateGrad]
	6140182128 -> 6141514400
	6140182128 [label="
 (1, 40, 1, 1)" fillcolor=orange]
	11135772432 -> 11135772576
	6138401456 [label="
 (960, 40, 1, 1)" fillcolor=lightblue]
	6138401456 -> 11135772432
	11135772432 [label=AccumulateGrad]
	11135772384 -> 11135772576
	6138401536 [label="
 (960)" fillcolor=lightblue]
	6138401536 -> 11135772384
	11135772384 [label=AccumulateGrad]
	6141514176 -> 11135772816
	11135773008 -> 11135773104
	6138401696 [label="
 (160, 960, 1, 1)" fillcolor=lightblue]
	6138401696 -> 11135773008
	11135773008 [label=AccumulateGrad]
	11135773296 -> 11135773248
	6138401776 [label="
 (160)" fillcolor=lightblue]
	6138401776 -> 11135773296
	11135773296 [label=AccumulateGrad]
	11135773536 -> 11135773248
	6138401856 [label="
 (160)" fillcolor=lightblue]
	6138401856 -> 11135773536
	11135773536 [label=AccumulateGrad]
	11135773680 -> 11135777328
	11135773872 -> 11135774160
	6138402336 [label="
 (960, 160, 1, 1)" fillcolor=lightblue]
	6138402336 -> 11135773872
	11135773872 [label=AccumulateGrad]
	11135774112 -> 11135774304
	6138402416 [label="
 (960)" fillcolor=lightblue]
	6138402416 -> 11135774112
	11135774112 [label=AccumulateGrad]
	11135774592 -> 11135774304
	6138402496 [label="
 (960)" fillcolor=lightblue]
	6138402496 -> 11135774592
	11135774592 [label=AccumulateGrad]
	6140173888 -> 6141514624
	6140173888 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	11135774736 -> 11135774832
	6138403056 [label="
 (960, 1, 3, 3)" fillcolor=lightblue]
	6138403056 -> 11135774736
	11135774736 [label=AccumulateGrad]
	11135775024 -> 11135774976
	6138402976 [label="
 (960)" fillcolor=lightblue]
	6138402976 -> 11135775024
	11135775024 [label=AccumulateGrad]
	11135775264 -> 11135774976
	6138403136 [label="
 (960)" fillcolor=lightblue]
	6138403136 -> 11135775264
	11135775264 [label=AccumulateGrad]
	6140173088 -> 6141514848
	6140173088 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	11135775600 -> 11135775552
	6138403696 [label="
 (40, 960, 1, 1)" fillcolor=lightblue]
	6138403696 -> 11135775600
	11135775600 [label=AccumulateGrad]
	11135775696 -> 11135775552
	6138403776 [label="
 (40)" fillcolor=lightblue]
	6138403776 -> 11135775696
	11135775696 [label=AccumulateGrad]
	6140170608 -> 6141515072
	6140170608 [label="
 (1, 40, 1, 1)" fillcolor=orange]
	11135775840 -> 11135775984
	6138403936 [label="
 (960, 40, 1, 1)" fillcolor=lightblue]
	6138403936 -> 11135775840
	11135775840 [label=AccumulateGrad]
	11135776032 -> 11135775984
	6138404016 [label="
 (960)" fillcolor=lightblue]
	6138404016 -> 11135776032
	11135776032 [label=AccumulateGrad]
	6141514848 -> 11135776464
	11135776416 -> 11135776752
	6138404176 [label="
 (160, 960, 1, 1)" fillcolor=lightblue]
	6138404176 -> 11135776416
	11135776416 [label=AccumulateGrad]
	11135776704 -> 11135776896
	6138404256 [label="
 (160)" fillcolor=lightblue]
	6138404256 -> 11135776704
	11135776704 [label=AccumulateGrad]
	11135777184 -> 11135776896
	6138404336 [label="
 (160)" fillcolor=lightblue]
	6138404336 -> 11135777184
	11135777184 [label=AccumulateGrad]
	11135777328 -> 11135777472
	11135777424 -> 11135777760
	6138404736 [label="
 (960, 160, 1, 1)" fillcolor=lightblue]
	6138404736 -> 11135777424
	11135777424 [label=AccumulateGrad]
	11135777712 -> 11135777904
	6138404816 [label="
 (960)" fillcolor=lightblue]
	6138404816 -> 11135777712
	11135777712 [label=AccumulateGrad]
	11135778192 -> 11135777904
	6138404896 [label="
 (960)" fillcolor=lightblue]
	6138404896 -> 11135778192
	11135778192 [label=AccumulateGrad]
	6140175328 -> 6141515296
	6140175328 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	11135778336 -> 11135778432
	6138405456 [label="
 (960, 1, 5, 5)" fillcolor=lightblue]
	6138405456 -> 11135778336
	11135778336 [label=AccumulateGrad]
	11135778624 -> 11135778576
	6138405376 [label="
 (960)" fillcolor=lightblue]
	6138405376 -> 11135778624
	11135778624 [label=AccumulateGrad]
	11135778720 -> 11135778576
	6138405536 [label="
 (960)" fillcolor=lightblue]
	6138405536 -> 11135778720
	11135778720 [label=AccumulateGrad]
	6140174688 -> 6141515520
	6140174688 [label="
 (1, 960, 38, 38)" fillcolor=orange]
	11135861184 -> 11135861136
	6138406096 [label="
 (40, 960, 1, 1)" fillcolor=lightblue]
	6138406096 -> 11135861184
	11135861184 [label=AccumulateGrad]
	11135861280 -> 11135861136
	6138406176 [label="
 (40)" fillcolor=lightblue]
	6138406176 -> 11135861280
	11135861280 [label=AccumulateGrad]
	6140173328 -> 6141515744
	6140173328 [label="
 (1, 40, 1, 1)" fillcolor=orange]
	11135861424 -> 11135861568
	6138406336 [label="
 (960, 40, 1, 1)" fillcolor=lightblue]
	6138406336 -> 11135861424
	11135861424 [label=AccumulateGrad]
	11135861616 -> 11135861568
	6138406416 [label="
 (960)" fillcolor=lightblue]
	6138406416 -> 11135861616
	11135861616 [label=AccumulateGrad]
	6141515520 -> 11135862048
	11135862000 -> 11135862336
	6138406576 [label="
 (224, 960, 1, 1)" fillcolor=lightblue]
	6138406576 -> 11135862000
	11135862000 [label=AccumulateGrad]
	11135862288 -> 11135865936
	6138406656 [label="
 (224)" fillcolor=lightblue]
	6138406656 -> 11135862288
	11135862288 [label=AccumulateGrad]
	11135862624 -> 11135865936
	6138406736 [label="
 (224)" fillcolor=lightblue]
	6138406736 -> 11135862624
	11135862624 [label=AccumulateGrad]
	11135862480 -> 11135862768
	6138407216 [label="
 (1344, 224, 1, 1)" fillcolor=lightblue]
	6138407216 -> 11135862480
	11135862480 [label=AccumulateGrad]
	11135862720 -> 11135862912
	6138407296 [label="
 (1344)" fillcolor=lightblue]
	6138407296 -> 11135862720
	11135862720 [label=AccumulateGrad]
	11135863200 -> 11135862912
	6138407376 [label="
 (1344)" fillcolor=lightblue]
	6138407376 -> 11135863200
	11135863200 [label=AccumulateGrad]
	6140181648 -> 6141515968
	6140181648 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	11135863344 -> 11135863440
	6138407936 [label="
 (1344, 1, 5, 5)" fillcolor=lightblue]
	6138407936 -> 11135863344
	11135863344 [label=AccumulateGrad]
	11135863632 -> 11135863584
	6138407856 [label="
 (1344)" fillcolor=lightblue]
	6138407856 -> 11135863632
	11135863632 [label=AccumulateGrad]
	11135863872 -> 11135863584
	6138408016 [label="
 (1344)" fillcolor=lightblue]
	6138408016 -> 11135863872
	11135863872 [label=AccumulateGrad]
	6140180608 -> 6141516192
	6140180608 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	11135864208 -> 11135864160
	6138408496 [label="
 (56, 1344, 1, 1)" fillcolor=lightblue]
	6138408496 -> 11135864208
	11135864208 [label=AccumulateGrad]
	11135864304 -> 11135864160
	6138408576 [label="
 (56)" fillcolor=lightblue]
	6138408576 -> 11135864304
	11135864304 [label=AccumulateGrad]
	6140180128 -> 6141516416
	6140180128 [label="
 (1, 56, 1, 1)" fillcolor=orange]
	11135864448 -> 11135864592
	6138408736 [label="
 (1344, 56, 1, 1)" fillcolor=lightblue]
	6138408736 -> 11135864448
	11135864448 [label=AccumulateGrad]
	11135864640 -> 11135864592
	6138408816 [label="
 (1344)" fillcolor=lightblue]
	6138408816 -> 11135864640
	11135864640 [label=AccumulateGrad]
	6141516192 -> 11135865072
	11135865024 -> 11135865360
	6138408976 [label="
 (224, 1344, 1, 1)" fillcolor=lightblue]
	6138408976 -> 11135865024
	11135865024 [label=AccumulateGrad]
	11135865312 -> 11135865504
	6138409056 [label="
 (224)" fillcolor=lightblue]
	6138409056 -> 11135865312
	11135865312 [label=AccumulateGrad]
	11135865792 -> 11135865504
	6138409136 [label="
 (224)" fillcolor=lightblue]
	6138409136 -> 11135865792
	11135865792 [label=AccumulateGrad]
	11135865936 -> 11135869344
	11135865888 -> 11135866176
	6138409616 [label="
 (1344, 224, 1, 1)" fillcolor=lightblue]
	6138409616 -> 11135865888
	11135865888 [label=AccumulateGrad]
	11135866368 -> 11135866320
	6138409696 [label="
 (1344)" fillcolor=lightblue]
	6138409696 -> 11135866368
	11135866368 [label=AccumulateGrad]
	11135866608 -> 11135866320
	6138409776 [label="
 (1344)" fillcolor=lightblue]
	6138409776 -> 11135866608
	11135866608 [label=AccumulateGrad]
	6140171648 -> 6141516640
	6140171648 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	11135866752 -> 11135867088
	6138410336 [label="
 (1344, 1, 5, 5)" fillcolor=lightblue]
	6138410336 -> 11135866752
	11135866752 [label=AccumulateGrad]
	11135867040 -> 11135867232
	6138410256 [label="
 (1344)" fillcolor=lightblue]
	6138410256 -> 11135867040
	11135867040 [label=AccumulateGrad]
	11135867520 -> 11135867232
	6138410416 [label="
 (1344)" fillcolor=lightblue]
	6138410416 -> 11135867520
	11135867520 [label=AccumulateGrad]
	6140171088 -> 6141516864
	6140171088 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	11135867616 -> 11135867808
	6138410976 [label="
 (56, 1344, 1, 1)" fillcolor=lightblue]
	6138410976 -> 11135867616
	11135867616 [label=AccumulateGrad]
	11135867952 -> 11135867808
	6138411056 [label="
 (56)" fillcolor=lightblue]
	6138411056 -> 11135867952
	11135867952 [label=AccumulateGrad]
	6140169968 -> 6141517088
	6140169968 [label="
 (1, 56, 1, 1)" fillcolor=orange]
	11135868096 -> 11135868240
	6138411216 [label="
 (1344, 56, 1, 1)" fillcolor=lightblue]
	6138411216 -> 11135868096
	11135868096 [label=AccumulateGrad]
	11135868048 -> 11135868240
	6138411296 [label="
 (1344)" fillcolor=lightblue]
	6138411296 -> 11135868048
	11135868048 [label=AccumulateGrad]
	6141516864 -> 11135868480
	11135868672 -> 11135868768
	6138411456 [label="
 (224, 1344, 1, 1)" fillcolor=lightblue]
	6138411456 -> 11135868672
	11135868672 [label=AccumulateGrad]
	11135868960 -> 11135868912
	6138411536 [label="
 (224)" fillcolor=lightblue]
	6138411536 -> 11135868960
	11135868960 [label=AccumulateGrad]
	11135869200 -> 11135868912
	6138411616 [label="
 (224)" fillcolor=lightblue]
	6138411616 -> 11135869200
	11135869200 [label=AccumulateGrad]
	11135869344 -> 11135873232
	11135869536 -> 11135869824
	6138412096 [label="
 (1344, 224, 1, 1)" fillcolor=lightblue]
	6138412096 -> 11135869536
	11135869536 [label=AccumulateGrad]
	11135869776 -> 11135869968
	6138412176 [label="
 (1344)" fillcolor=lightblue]
	6138412176 -> 11135869776
	11135869776 [label=AccumulateGrad]
	11135870256 -> 11135869968
	6138412256 [label="
 (1344)" fillcolor=lightblue]
	6138412256 -> 11135870256
	11135870256 [label=AccumulateGrad]
	6140181168 -> 6141517312
	6140181168 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	11135870400 -> 11135870496
	6138412816 [label="
 (1344, 1, 5, 5)" fillcolor=lightblue]
	6138412816 -> 11135870400
	11135870400 [label=AccumulateGrad]
	11135870688 -> 11135870640
	6138412736 [label="
 (1344)" fillcolor=lightblue]
	6138412736 -> 11135870688
	11135870688 [label=AccumulateGrad]
	11135870928 -> 11135870640
	6138412896 [label="
 (1344)" fillcolor=lightblue]
	6138412896 -> 11135870928
	11135870928 [label=AccumulateGrad]
	6140181008 -> 6141517536
	6140181008 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	11135871264 -> 11135871216
	6138724816 [label="
 (56, 1344, 1, 1)" fillcolor=lightblue]
	6138724816 -> 11135871264
	11135871264 [label=AccumulateGrad]
	11135871360 -> 11135871216
	6138724896 [label="
 (56)" fillcolor=lightblue]
	6138724896 -> 11135871360
	11135871360 [label=AccumulateGrad]
	6140180768 -> 6141517760
	6140180768 [label="
 (1, 56, 1, 1)" fillcolor=orange]
	11135871504 -> 11135871648
	6138725056 [label="
 (1344, 56, 1, 1)" fillcolor=lightblue]
	6138725056 -> 11135871504
	11135871504 [label=AccumulateGrad]
	11135871696 -> 11135871648
	6138725136 [label="
 (1344)" fillcolor=lightblue]
	6138725136 -> 11135871696
	11135871696 [label=AccumulateGrad]
	6141517536 -> 11135872128
	11135872080 -> 11135872416
	6138725296 [label="
 (224, 1344, 1, 1)" fillcolor=lightblue]
	6138725296 -> 11135872080
	11135872080 [label=AccumulateGrad]
	11135872368 -> 11135872560
	6138725376 [label="
 (224)" fillcolor=lightblue]
	6138725376 -> 11135872368
	11135872368 [label=AccumulateGrad]
	11135872704 -> 11135872560
	6138725456 [label="
 (224)" fillcolor=lightblue]
	6138725456 -> 11135872704
	11135872704 [label=AccumulateGrad]
	11135873232 -> 11135948336
	11135872944 -> 11135874096
	6138725936 [label="
 (1344, 224, 1, 1)" fillcolor=lightblue]
	6138725936 -> 11135872944
	11135872944 [label=AccumulateGrad]
	11135874432 -> 11135874720
	6138726016 [label="
 (1344)" fillcolor=lightblue]
	6138726016 -> 11135874432
	11135874432 [label=AccumulateGrad]
	11135875680 -> 11135874720
	6138726096 [label="
 (1344)" fillcolor=lightblue]
	6138726096 -> 11135875680
	11135875680 [label=AccumulateGrad]
	6140179168 -> 6141517984
	6140179168 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	11135875584 -> 11135876400
	6138726656 [label="
 (1344, 1, 5, 5)" fillcolor=lightblue]
	6138726656 -> 11135875584
	11135875584 [label=AccumulateGrad]
	11135876592 -> 11135943344
	6138726576 [label="
 (1344)" fillcolor=lightblue]
	6138726576 -> 11135876592
	11135876592 [label=AccumulateGrad]
	11135877024 -> 11135943344
	6138726736 [label="
 (1344)" fillcolor=lightblue]
	6138726736 -> 11135877024
	11135877024 [label=AccumulateGrad]
	6140178848 -> 6141518208
	6140178848 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	11135943920 -> 11135944160
	6138727296 [label="
 (56, 1344, 1, 1)" fillcolor=lightblue]
	6138727296 -> 11135943920
	11135943920 [label=AccumulateGrad]
	11135944064 -> 11135944160
	6138727376 [label="
 (56)" fillcolor=lightblue]
	6138727376 -> 11135944064
	11135944064 [label=AccumulateGrad]
	6140178768 -> 6141518432
	6140178768 [label="
 (1, 56, 1, 1)" fillcolor=orange]
	11135944592 -> 11135945072
	6138727536 [label="
 (1344, 56, 1, 1)" fillcolor=lightblue]
	6138727536 -> 11135944592
	11135944592 [label=AccumulateGrad]
	11135944880 -> 11135945072
	6138727616 [label="
 (1344)" fillcolor=lightblue]
	6138727616 -> 11135944880
	11135944880 [label=AccumulateGrad]
	6141518208 -> 11135946224
	11135946320 -> 11135947040
	6138727776 [label="
 (224, 1344, 1, 1)" fillcolor=lightblue]
	6138727776 -> 11135946320
	11135946320 [label=AccumulateGrad]
	11135947232 -> 11135946944
	6138727856 [label="
 (224)" fillcolor=lightblue]
	6138727856 -> 11135947232
	11135947232 [label=AccumulateGrad]
	11135947952 -> 11135946944
	6138727936 [label="
 (224)" fillcolor=lightblue]
	6138727936 -> 11135947952
	11135947952 [label=AccumulateGrad]
	11135948336 -> 11135954096
	11135948912 -> 11135949392
	6138728416 [label="
 (1344, 224, 1, 1)" fillcolor=lightblue]
	6138728416 -> 11135948912
	11135948912 [label=AccumulateGrad]
	11135950112 -> 11135949824
	6138728496 [label="
 (1344)" fillcolor=lightblue]
	6138728496 -> 11135950112
	11135950112 [label=AccumulateGrad]
	11135950688 -> 11135949824
	6138728576 [label="
 (1344)" fillcolor=lightblue]
	6138728576 -> 11135950688
	11135950688 [label=AccumulateGrad]
	6140177248 -> 6141518656
	6140177248 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	11135951120 -> 11135951552
	6138729136 [label="
 (1344, 1, 5, 5)" fillcolor=lightblue]
	6138729136 -> 11135951120
	11135951120 [label=AccumulateGrad]
	11135951648 -> 11135951936
	6138729056 [label="
 (1344)" fillcolor=lightblue]
	6138729056 -> 11135951648
	11135951648 [label=AccumulateGrad]
	11135952800 -> 11135951936
	6138729216 [label="
 (1344)" fillcolor=lightblue]
	6138729216 -> 11135952800
	11135952800 [label=AccumulateGrad]
	6140177088 -> 6141518880
	6140177088 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	11135958320 -> 11135958608
	6138729776 [label="
 (56, 1344, 1, 1)" fillcolor=lightblue]
	6138729776 -> 11135958320
	11135958320 [label=AccumulateGrad]
	11135958176 -> 11135958608
	6138729856 [label="
 (56)" fillcolor=lightblue]
	6138729856 -> 11135958176
	11135958176 [label=AccumulateGrad]
	6140176688 -> 6141519104
	6140176688 [label="
 (1, 56, 1, 1)" fillcolor=orange]
	11135957696 -> 11135957408
	6138730016 [label="
 (1344, 56, 1, 1)" fillcolor=lightblue]
	6138730016 -> 11135957696
	11135957696 [label=AccumulateGrad]
	11135957744 -> 11135957408
	6138730096 [label="
 (1344)" fillcolor=lightblue]
	6138730096 -> 11135957744
	11135957744 [label=AccumulateGrad]
	6141518880 -> 11135956544
	11135956592 -> 11135956304
	6138730256 [label="
 (224, 1344, 1, 1)" fillcolor=lightblue]
	6138730256 -> 11135956592
	11135956592 [label=AccumulateGrad]
	11135955296 -> 11135954720
	6138730336 [label="
 (224)" fillcolor=lightblue]
	6138730336 -> 11135955296
	11135955296 [label=AccumulateGrad]
	11135955008 -> 11135954720
	6138730416 [label="
 (224)" fillcolor=lightblue]
	6138730416 -> 11135955008
	11135955008 [label=AccumulateGrad]
	11135954096 -> 6141750784
	11135953856 -> 6141861344
	6138730896 [label="
 (1344, 224, 1, 1)" fillcolor=lightblue]
	6138730896 -> 11135953856
	11135953856 [label=AccumulateGrad]
	6141860384 -> 6141859952
	6138730976 [label="
 (1344)" fillcolor=lightblue]
	6138730976 -> 6141860384
	6141860384 [label=AccumulateGrad]
	6141859040 -> 6141859952
	6138731056 [label="
 (1344)" fillcolor=lightblue]
	6138731056 -> 6141859040
	6141859040 [label=AccumulateGrad]
	6140175008 -> 6141519328
	6140175008 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	6141858560 -> 6141857600
	6138731536 [label="
 (1344, 1, 5, 5)" fillcolor=lightblue]
	6138731536 -> 6141858560
	6141858560 [label=AccumulateGrad]
	6141857072 -> 6141857312
	6138731456 [label="
 (1344)" fillcolor=lightblue]
	6138731456 -> 6141857072
	6141857072 [label=AccumulateGrad]
	6141855872 -> 6141857312
	6138731616 [label="
 (1344)" fillcolor=lightblue]
	6138731616 -> 6141855872
	6141855872 [label=AccumulateGrad]
	6140174848 -> 6141519552
	6140174848 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	6141855296 -> 6141854096
	6138732096 [label="
 (56, 1344, 1, 1)" fillcolor=lightblue]
	6138732096 -> 6141855296
	6141855296 [label=AccumulateGrad]
	6141854816 -> 6141854096
	6138732176 [label="
 (56)" fillcolor=lightblue]
	6138732176 -> 6141854816
	6141854816 [label=AccumulateGrad]
	6140174448 -> 6141519776
	6140174448 [label="
 (1, 56, 1, 1)" fillcolor=orange]
	6141860816 -> 6141754384
	6138732336 [label="
 (1344, 56, 1, 1)" fillcolor=lightblue]
	6138732336 -> 6141860816
	6141860816 [label=AccumulateGrad]
	6141861104 -> 6141754384
	6138732416 [label="
 (1344)" fillcolor=lightblue]
	6138732416 -> 6141861104
	6141861104 [label=AccumulateGrad]
	6141519552 -> 6141754144
	6141753616 -> 6141752752
	6138732576 [label="
 (224, 1344, 1, 1)" fillcolor=lightblue]
	6138732576 -> 6141753616
	6141753616 [label=AccumulateGrad]
	6141752560 -> 6141752416
	6138732656 [label="
 (224)" fillcolor=lightblue]
	6138732656 -> 6141752560
	6141752560 [label=AccumulateGrad]
	6141751120 -> 6141752416
	6138732736 [label="
 (224)" fillcolor=lightblue]
	6138732736 -> 6141751120
	6141751120 [label=AccumulateGrad]
	6141750784 -> 6141687360
	6141750928 -> 6141749536
	6138733216 [label="
 (1344, 224, 1, 1)" fillcolor=lightblue]
	6138733216 -> 6141750928
	6141750928 [label=AccumulateGrad]
	6141749104 -> 6141748432
	6138733296 [label="
 (1344)" fillcolor=lightblue]
	6138733296 -> 6141749104
	6141749104 [label=AccumulateGrad]
	6141747520 -> 6141748432
	6138733376 [label="
 (1344)" fillcolor=lightblue]
	6138733376 -> 6141747520
	6141747520 [label=AccumulateGrad]
	6140172848 -> 6141520000
	6140172848 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	6141746080 -> 6141746224
	6138733936 [label="
 (1344, 1, 5, 5)" fillcolor=lightblue]
	6138733936 -> 6141746080
	6141746080 [label=AccumulateGrad]
	6141745888 -> 6141745360
	6138733856 [label="
 (1344)" fillcolor=lightblue]
	6138733856 -> 6141745888
	6141745888 [label=AccumulateGrad]
	6141744400 -> 6141745360
	6138734016 [label="
 (1344)" fillcolor=lightblue]
	6138734016 -> 6141744400
	6141744400 [label=AccumulateGrad]
	6140172608 -> 6141520224
	6140172608 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	6141743536 -> 6141742864
	6138734576 [label="
 (56, 1344, 1, 1)" fillcolor=lightblue]
	6138734576 -> 6141743536
	6141743536 [label=AccumulateGrad]
	6141742384 -> 6141742864
	6138734656 [label="
 (56)" fillcolor=lightblue]
	6138734656 -> 6141742384
	6141742384 [label=AccumulateGrad]
	6140172128 -> 6141520448
	6140172128 [label="
 (1, 56, 1, 1)" fillcolor=orange]
	6141742144 -> 6141741328
	6138734816 [label="
 (1344, 56, 1, 1)" fillcolor=lightblue]
	6138734816 -> 6141742144
	6141742144 [label=AccumulateGrad]
	6141741088 -> 6141741328
	6138734896 [label="
 (1344)" fillcolor=lightblue]
	6138734896 -> 6141741088
	6141741088 [label=AccumulateGrad]
	6141520224 -> 6141740896
	6141739408 -> 6141689760
	6138735056 [label="
 (224, 1344, 1, 1)" fillcolor=lightblue]
	6138735056 -> 6141739408
	6141739408 [label=AccumulateGrad]
	6141689808 -> 6141689232
	6138735136 [label="
 (224)" fillcolor=lightblue]
	6138735136 -> 6141689808
	6141689808 [label=AccumulateGrad]
	6141687840 -> 6141689232
	6138735216 [label="
 (224)" fillcolor=lightblue]
	6138735216 -> 6141687840
	6141687840 [label=AccumulateGrad]
	6141687360 -> 6141675648
	6141686784 -> 6141686160
	6138735696 [label="
 (1344, 224, 1, 1)" fillcolor=lightblue]
	6138735696 -> 6141686784
	6141686784 [label=AccumulateGrad]
	6141685920 -> 6141685536
	6138735776 [label="
 (1344)" fillcolor=lightblue]
	6138735776 -> 6141685920
	6141685920 [label=AccumulateGrad]
	6141684384 -> 6141685536
	6138735856 [label="
 (1344)" fillcolor=lightblue]
	6138735856 -> 6141684384
	6141684384 [label=AccumulateGrad]
	6140170528 -> 6141520672
	6140170528 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	6141683472 -> 6141682896
	6138736416 [label="
 (1344, 1, 5, 5)" fillcolor=lightblue]
	6138736416 -> 6141683472
	6141683472 [label=AccumulateGrad]
	6141682848 -> 6141682272
	6138736336 [label="
 (1344)" fillcolor=lightblue]
	6138736336 -> 6141682848
	6141682848 [label=AccumulateGrad]
	6141681168 -> 6141682272
	6138736496 [label="
 (1344)" fillcolor=lightblue]
	6138736496 -> 6141681168
	6141681168 [label=AccumulateGrad]
	6140170368 -> 6141520896
	6140170368 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	6141680352 -> 6141680208
	6138736976 [label="
 (56, 1344, 1, 1)" fillcolor=lightblue]
	6138736976 -> 6141680352
	6141680352 [label=AccumulateGrad]
	6141678960 -> 6141680208
	6138737056 [label="
 (56)" fillcolor=lightblue]
	6138737056 -> 6141678960
	6141678960 [label=AccumulateGrad]
	6140170048 -> 6141521120
	6140170048 [label="
 (1, 56, 1, 1)" fillcolor=orange]
	6141681840 -> 6141678336
	6138737216 [label="
 (1344, 56, 1, 1)" fillcolor=lightblue]
	6138737216 -> 6141681840
	6141681840 [label=AccumulateGrad]
	6141678576 -> 6141678336
	6138737296 [label="
 (1344)" fillcolor=lightblue]
	6138737296 -> 6141678576
	6141678576 [label=AccumulateGrad]
	6141520896 -> 6141676176
	6141676608 -> 6141675792
	6138737456 [label="
 (224, 1344, 1, 1)" fillcolor=lightblue]
	6138737456 -> 6141676608
	6141676608 [label=AccumulateGrad]
	6141675696 -> 6141675552
	6138737536 [label="
 (224)" fillcolor=lightblue]
	6138737536 -> 6141675696
	6141675696 [label=AccumulateGrad]
	6141674064 -> 6141675552
	6138737616 [label="
 (224)" fillcolor=lightblue]
	6138737616 -> 6141674064
	6141674064 [label=AccumulateGrad]
	6141675648 -> 6141577632
	6141590352 -> 6141590592
	6138738096 [label="
 (1344, 224, 1, 1)" fillcolor=lightblue]
	6138738096 -> 6141590352
	6141590352 [label=AccumulateGrad]
	6141589584 -> 6141589968
	6138738176 [label="
 (1344)" fillcolor=lightblue]
	6138738176 -> 6141589584
	6141589584 [label=AccumulateGrad]
	6141588768 -> 6141589968
	6138738256 [label="
 (1344)" fillcolor=lightblue]
	6138738256 -> 6141588768
	6141588768 [label=AccumulateGrad]
	6140167968 -> 6141521344
	6140167968 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	6141588096 -> 6141587040
	6138738736 [label="
 (1344, 1, 5, 5)" fillcolor=lightblue]
	6138738736 -> 6141588096
	6141588096 [label=AccumulateGrad]
	6141586848 -> 6141586272
	6138738656 [label="
 (1344)" fillcolor=lightblue]
	6138738656 -> 6141586848
	6141586848 [label=AccumulateGrad]
	6141585840 -> 6141586272
	6138738816 [label="
 (1344)" fillcolor=lightblue]
	6138738816 -> 6141585840
	6141585840 [label=AccumulateGrad]
	6140167728 -> 6141521568
	6140167728 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	6141584688 -> 6141585216
	6138739376 [label="
 (56, 1344, 1, 1)" fillcolor=lightblue]
	6138739376 -> 6141584688
	6141584688 [label=AccumulateGrad]
	6141583776 -> 6141585216
	6138739456 [label="
 (56)" fillcolor=lightblue]
	6138739456 -> 6141583776
	6141583776 [label=AccumulateGrad]
	6140167488 -> 6141521792
	6140167488 [label="
 (1, 56, 1, 1)" fillcolor=orange]
	6141583248 -> 6141582528
	6138739616 [label="
 (1344, 56, 1, 1)" fillcolor=lightblue]
	6138739616 -> 6141583248
	6141583248 [label=AccumulateGrad]
	6141583008 -> 6141582528
	6138739696 [label="
 (1344)" fillcolor=lightblue]
	6138739696 -> 6141583008
	6141583008 [label=AccumulateGrad]
	6141521568 -> 6141581040
	6141580176 -> 6141580272
	6138739856 [label="
 (224, 1344, 1, 1)" fillcolor=lightblue]
	6138739856 -> 6141580176
	6141580176 [label=AccumulateGrad]
	6141579264 -> 6141579504
	6138739936 [label="
 (224)" fillcolor=lightblue]
	6138739936 -> 6141579264
	6141579264 [label=AccumulateGrad]
	6141581280 -> 6141579504
	6138740016 [label="
 (224)" fillcolor=lightblue]
	6138740016 -> 6141581280
	6141581280 [label=AccumulateGrad]
	6141577632 -> 6141576576
	6141576144 -> 6141576000
	6141603376 [label="
 (256, 224, 1, 1)" fillcolor=lightblue]
	6141603376 -> 6141576144
	6141576144 [label=AccumulateGrad]
	6141575760 -> 6141576000
	6141603056 [label="
 (256)" fillcolor=lightblue]
	6141603056 -> 6141575760
	6141575760 [label=AccumulateGrad]
	6141575808 -> 6141575520
	6141575808 [label="UpsampleNearest2DBackward0
--------------------------------
output_size   :         (38, 38)
scales_h      :             None
scales_w      :             None
self_sym_sizes: (1, 256, 19, 19)"]
	6141579072 -> 6141575808
	6141579072 -> 6139870992 [dir=none]
	6139870992 [label="input
 (1, 640, 19, 19)" fillcolor=orange]
	6141579072 -> 6141603856 [dir=none]
	6141603856 [label="weight
 (256, 640, 1, 1)" fillcolor=orange]
	6141579072 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (256,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141580896 -> 6141579072
	6141580896 [label="AddBackward0
------------
alpha: 1"]
	6141582048 -> 6141580896
	6141582048 -> 6139870912 [dir=none]
	6139870912 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6141582048 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141584784 -> 6141582048
	6141584784 -> 11134968000 [dir=none]
	11134968000 [label="other
 ()" fillcolor=orange]
	6141584784 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141586704 -> 6141584784
	6141586704 -> 6139856272 [dir=none]
	6139856272 [label="input
 (1, 640, 19, 19)" fillcolor=orange]
	6141586704 -> 11134968320 [dir=none]
	11134968320 [label="result1
 (640)" fillcolor=orange]
	6141586704 -> 11134968240 [dir=none]
	11134968240 [label="result2
 (640)" fillcolor=orange]
	6141586704 -> 6139567920 [dir=none]
	6139567920 [label="running_mean
 (640)" fillcolor=orange]
	6141586704 -> 6139568240 [dir=none]
	6139568240 [label="running_var
 (640)" fillcolor=orange]
	6141586704 -> 6139568080 [dir=none]
	6139568080 [label="weight
 (640)" fillcolor=orange]
	6141586704 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141591024 -> 6141586704
	6141591024 -> 6139856832 [dir=none]
	6139856832 [label="input
 (1, 3840, 19, 19)" fillcolor=orange]
	6141591024 -> 6139568000 [dir=none]
	6139568000 [label="weight
 (640, 3840, 1, 1)" fillcolor=orange]
	6141591024 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141591072 -> 6141591024
	6141591072 -> 6139859552 [dir=none]
	6139859552 [label="other
 (1, 3840, 19, 19)" fillcolor=orange]
	6141591072 -> 6139857952 [dir=none]
	6139857952 [label="self
 (1, 3840, 1, 1)" fillcolor=orange]
	6141591072 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6141676224 -> 6141591072
	6141676224 -> 11134968400 [dir=none]
	11134968400 [label="result
 (1, 3840, 1, 1)" fillcolor=orange]
	6141676224 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6141680400 -> 6141676224
	6141680400 -> 6139857072 [dir=none]
	6139857072 [label="input
 (1, 160, 1, 1)" fillcolor=orange]
	6141680400 -> 6139567760 [dir=none]
	6139567760 [label="weight
 (3840, 160, 1, 1)" fillcolor=orange]
	6141680400 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (3840,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142074144 -> 6141680400
	6142074144 [label=SwishImplementationBackward]
	6141681648 -> 6142074144
	6141681648 -> 6139861632 [dir=none]
	6139861632 [label="input
 (1, 3840, 1, 1)" fillcolor=orange]
	6141681648 -> 6139567520 [dir=none]
	6139567520 [label="weight
 (160, 3840, 1, 1)" fillcolor=orange]
	6141681648 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (160,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141684864 -> 6141681648
	6141684864 -> 6139859552 [dir=none]
	6139859552 [label="self
 (1, 3840, 19, 19)" fillcolor=orange]
	6141684864 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 3840, 19, 19)"]
	6142073920 -> 6141684864
	6142073920 [label=SwishImplementationBackward]
	6141688032 -> 6142073920
	6141688032 -> 6139863792 [dir=none]
	6139863792 [label="input
 (1, 3840, 19, 19)" fillcolor=orange]
	6141688032 -> 11134969200 [dir=none]
	11134969200 [label="result1
 (3840)" fillcolor=orange]
	6141688032 -> 11134969280 [dir=none]
	11134969280 [label="result2
 (3840)" fillcolor=orange]
	6141688032 -> 6139565280 [dir=none]
	6139565280 [label="running_mean
 (3840)" fillcolor=orange]
	6141688032 -> 6139567120 [dir=none]
	6139567120 [label="running_var
 (3840)" fillcolor=orange]
	6141688032 -> 6139566880 [dir=none]
	6139566880 [label="weight
 (3840)" fillcolor=orange]
	6141688032 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141687408 -> 6141688032
	6141687408 -> 6139864752 [dir=none]
	6139864752 [label="input
 (1, 3840, 21, 21)" fillcolor=orange]
	6141687408 -> 6139566960 [dir=none]
	6139566960 [label="weight
 (3840, 1, 3, 3)" fillcolor=orange]
	6141687408 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           3840
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141740368 -> 6141687408
	6141740368 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6142073696 -> 6141740368
	6142073696 [label=SwishImplementationBackward]
	6141746896 -> 6142073696
	6141746896 -> 6139855312 [dir=none]
	6139855312 [label="input
 (1, 3840, 19, 19)" fillcolor=orange]
	6141746896 -> 11134969760 [dir=none]
	11134969760 [label="result1
 (3840)" fillcolor=orange]
	6141746896 -> 11134969840 [dir=none]
	11134969840 [label="result2
 (3840)" fillcolor=orange]
	6141746896 -> 6139566160 [dir=none]
	6139566160 [label="running_mean
 (3840)" fillcolor=orange]
	6141746896 -> 6139566480 [dir=none]
	6139566480 [label="running_var
 (3840)" fillcolor=orange]
	6141746896 -> 6139566320 [dir=none]
	6139566320 [label="weight
 (3840)" fillcolor=orange]
	6141746896 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141749344 -> 6141746896
	6141749344 -> 6139866912 [dir=none]
	6139866912 [label="input
 (1, 640, 19, 19)" fillcolor=orange]
	6141749344 -> 6139566240 [dir=none]
	6139566240 [label="weight
 (3840, 640, 1, 1)" fillcolor=orange]
	6141749344 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141581808 -> 6141749344
	6141581808 [label="AddBackward0
------------
alpha: 1"]
	6141750160 -> 6141581808
	6141750160 -> 6139865392 [dir=none]
	6139865392 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6141750160 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141754864 -> 6141750160
	6141754864 -> 11134970160 [dir=none]
	11134970160 [label="other
 ()" fillcolor=orange]
	6141754864 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141753424 -> 6141754864
	6141753424 -> 6139869152 [dir=none]
	6139869152 [label="input
 (1, 640, 19, 19)" fillcolor=orange]
	6141753424 -> 11134970480 [dir=none]
	11134970480 [label="result1
 (640)" fillcolor=orange]
	6141753424 -> 11134970400 [dir=none]
	11134970400 [label="result2
 (640)" fillcolor=orange]
	6141753424 -> 6139565520 [dir=none]
	6139565520 [label="running_mean
 (640)" fillcolor=orange]
	6141753424 -> 6139565840 [dir=none]
	6139565840 [label="running_var
 (640)" fillcolor=orange]
	6141753424 -> 6139565680 [dir=none]
	6139565680 [label="weight
 (640)" fillcolor=orange]
	6141753424 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141855440 -> 6141753424
	6141855440 -> 6139870432 [dir=none]
	6139870432 [label="input
 (1, 3840, 19, 19)" fillcolor=orange]
	6141855440 -> 6139565600 [dir=none]
	6139565600 [label="weight
 (640, 3840, 1, 1)" fillcolor=orange]
	6141855440 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141859088 -> 6141855440
	6141859088 -> 6139855552 [dir=none]
	6139855552 [label="other
 (1, 3840, 19, 19)" fillcolor=orange]
	6141859088 -> 6139871152 [dir=none]
	6139871152 [label="self
 (1, 3840, 1, 1)" fillcolor=orange]
	6141859088 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6141859568 -> 6141859088
	6141859568 -> 11134970560 [dir=none]
	11134970560 [label="result
 (1, 3840, 1, 1)" fillcolor=orange]
	6141859568 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135954864 -> 6141859568
	11135954864 -> 6139870672 [dir=none]
	6139870672 [label="input
 (1, 160, 1, 1)" fillcolor=orange]
	11135954864 -> 6139565360 [dir=none]
	6139565360 [label="weight
 (3840, 160, 1, 1)" fillcolor=orange]
	11135954864 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (3840,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142073472 -> 11135954864
	6142073472 [label=SwishImplementationBackward]
	11135958896 -> 6142073472
	11135958896 -> 6139855952 [dir=none]
	6139855952 [label="input
 (1, 3840, 1, 1)" fillcolor=orange]
	11135958896 -> 6139565120 [dir=none]
	6139565120 [label="weight
 (160, 3840, 1, 1)" fillcolor=orange]
	11135958896 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (160,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135955728 -> 11135958896
	11135955728 -> 6139855552 [dir=none]
	6139855552 [label="self
 (1, 3840, 19, 19)" fillcolor=orange]
	11135955728 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 3840, 19, 19)"]
	6142073248 -> 11135955728
	6142073248 [label=SwishImplementationBackward]
	11135949200 -> 6142073248
	11135949200 -> 6139858272 [dir=none]
	6139858272 [label="input
 (1, 3840, 19, 19)" fillcolor=orange]
	11135949200 -> 11134971280 [dir=none]
	11134971280 [label="result1
 (3840)" fillcolor=orange]
	11135949200 -> 11134971360 [dir=none]
	11134971360 [label="result2
 (3840)" fillcolor=orange]
	11135949200 -> 6139562800 [dir=none]
	6139562800 [label="running_mean
 (3840)" fillcolor=orange]
	11135949200 -> 6139564640 [dir=none]
	6139564640 [label="running_var
 (3840)" fillcolor=orange]
	11135949200 -> 6139564400 [dir=none]
	6139564400 [label="weight
 (3840)" fillcolor=orange]
	11135949200 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135950208 -> 11135949200
	11135950208 -> 6139861792 [dir=none]
	6139861792 [label="input
 (1, 3840, 21, 21)" fillcolor=orange]
	11135950208 -> 6139564480 [dir=none]
	6139564480 [label="weight
 (3840, 1, 3, 3)" fillcolor=orange]
	11135950208 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           3840
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135949104 -> 11135950208
	11135949104 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6142073024 -> 11135949104
	6142073024 [label=SwishImplementationBackward]
	11135946032 -> 6142073024
	11135946032 -> 6139870032 [dir=none]
	6139870032 [label="input
 (1, 3840, 19, 19)" fillcolor=orange]
	11135946032 -> 11134971840 [dir=none]
	11134971840 [label="result1
 (3840)" fillcolor=orange]
	11135946032 -> 11134971920 [dir=none]
	11134971920 [label="result2
 (3840)" fillcolor=orange]
	11135946032 -> 6139563680 [dir=none]
	6139563680 [label="running_mean
 (3840)" fillcolor=orange]
	11135946032 -> 6139564000 [dir=none]
	6139564000 [label="running_var
 (3840)" fillcolor=orange]
	11135946032 -> 6139563840 [dir=none]
	6139563840 [label="weight
 (3840)" fillcolor=orange]
	11135946032 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135943440 -> 11135946032
	11135943440 -> 6139862672 [dir=none]
	6139862672 [label="input
 (1, 640, 19, 19)" fillcolor=orange]
	11135943440 -> 6139563760 [dir=none]
	6139563760 [label="weight
 (3840, 640, 1, 1)" fillcolor=orange]
	11135943440 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141751888 -> 11135943440
	6141751888 [label="AddBackward0
------------
alpha: 1"]
	11135875296 -> 6141751888
	11135875296 -> 6139862272 [dir=none]
	6139862272 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11135875296 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135872512 -> 11135875296
	11135872512 -> 11134972240 [dir=none]
	11134972240 [label="other
 ()" fillcolor=orange]
	11135872512 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135873856 -> 11135872512
	11135873856 -> 6139862992 [dir=none]
	6139862992 [label="input
 (1, 640, 19, 19)" fillcolor=orange]
	11135873856 -> 11134972560 [dir=none]
	11134972560 [label="result1
 (640)" fillcolor=orange]
	11135873856 -> 11134972480 [dir=none]
	11134972480 [label="result2
 (640)" fillcolor=orange]
	11135873856 -> 6139563040 [dir=none]
	6139563040 [label="running_mean
 (640)" fillcolor=orange]
	11135873856 -> 6139563360 [dir=none]
	6139563360 [label="running_var
 (640)" fillcolor=orange]
	11135873856 -> 6139563200 [dir=none]
	6139563200 [label="weight
 (640)" fillcolor=orange]
	11135873856 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135872272 -> 11135873856
	11135872272 -> 6139865552 [dir=none]
	6139865552 [label="input
 (1, 3840, 19, 19)" fillcolor=orange]
	11135872272 -> 6139563120 [dir=none]
	6139563120 [label="weight
 (640, 3840, 1, 1)" fillcolor=orange]
	11135872272 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135871408 -> 11135872272
	11135871408 -> 6139858592 [dir=none]
	6139858592 [label="other
 (1, 3840, 19, 19)" fillcolor=orange]
	11135871408 -> 6139868912 [dir=none]
	6139868912 [label="self
 (1, 3840, 1, 1)" fillcolor=orange]
	11135871408 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135870832 -> 11135871408
	11135870832 -> 11134972640 [dir=none]
	11134972640 [label="result
 (1, 3840, 1, 1)" fillcolor=orange]
	11135870832 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135870352 -> 11135870832
	11135870352 -> 6139865792 [dir=none]
	6139865792 [label="input
 (1, 160, 1, 1)" fillcolor=orange]
	11135870352 -> 6139562880 [dir=none]
	6139562880 [label="weight
 (3840, 160, 1, 1)" fillcolor=orange]
	11135870352 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (3840,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142072800 -> 11135870352
	6142072800 [label=SwishImplementationBackward]
	11135869248 -> 6142072800
	11135869248 -> 6139859152 [dir=none]
	6139859152 [label="input
 (1, 3840, 1, 1)" fillcolor=orange]
	11135869248 -> 6139562640 [dir=none]
	6139562640 [label="weight
 (160, 3840, 1, 1)" fillcolor=orange]
	11135869248 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (160,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135868816 -> 11135869248
	11135868816 -> 6139858592 [dir=none]
	6139858592 [label="self
 (1, 3840, 19, 19)" fillcolor=orange]
	11135868816 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 3840, 19, 19)"]
	6142072576 -> 11135868816
	6142072576 [label=SwishImplementationBackward]
	11135867472 -> 6142072576
	11135867472 -> 6139865152 [dir=none]
	6139865152 [label="input
 (1, 3840, 19, 19)" fillcolor=orange]
	11135867472 -> 11134973360 [dir=none]
	11134973360 [label="result1
 (3840)" fillcolor=orange]
	11135867472 -> 11134973440 [dir=none]
	11134973440 [label="result2
 (3840)" fillcolor=orange]
	11135867472 -> 6139560400 [dir=none]
	6139560400 [label="running_mean
 (3840)" fillcolor=orange]
	11135867472 -> 6139562240 [dir=none]
	6139562240 [label="running_var
 (3840)" fillcolor=orange]
	11135867472 -> 6139562000 [dir=none]
	6139562000 [label="weight
 (3840)" fillcolor=orange]
	11135867472 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135867184 -> 11135867472
	11135867184 -> 6139867152 [dir=none]
	6139867152 [label="input
 (1, 3840, 21, 21)" fillcolor=orange]
	11135867184 -> 6139562080 [dir=none]
	6139562080 [label="weight
 (3840, 1, 3, 3)" fillcolor=orange]
	11135867184 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           3840
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135866512 -> 11135867184
	11135866512 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6142072352 -> 11135866512
	6142072352 [label=SwishImplementationBackward]
	11135866032 -> 6142072352
	11135866032 -> 6139859712 [dir=none]
	6139859712 [label="input
 (1, 3840, 19, 19)" fillcolor=orange]
	11135866032 -> 6141703520 [dir=none]
	6141703520 [label="result1
 (3840)" fillcolor=orange]
	11135866032 -> 11134973680 [dir=none]
	11134973680 [label="result2
 (3840)" fillcolor=orange]
	11135866032 -> 6139561280 [dir=none]
	6139561280 [label="running_mean
 (3840)" fillcolor=orange]
	11135866032 -> 6139561600 [dir=none]
	6139561600 [label="running_var
 (3840)" fillcolor=orange]
	11135866032 -> 6139561440 [dir=none]
	6139561440 [label="weight
 (3840)" fillcolor=orange]
	11135866032 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135865216 -> 11135866032
	11135865216 -> 6139867952 [dir=none]
	6139867952 [label="input
 (1, 640, 19, 19)" fillcolor=orange]
	11135865216 -> 6139561360 [dir=none]
	6139561360 [label="weight
 (3840, 640, 1, 1)" fillcolor=orange]
	11135865216 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135874144 -> 11135865216
	11135874144 -> 6139868192 [dir=none]
	6139868192 [label="input
 (1, 640, 19, 19)" fillcolor=orange]
	11135874144 -> 11134973920 [dir=none]
	11134973920 [label="result1
 (640)" fillcolor=orange]
	11135874144 -> 11134974240 [dir=none]
	11134974240 [label="result2
 (640)" fillcolor=orange]
	11135874144 -> 6139560640 [dir=none]
	6139560640 [label="running_mean
 (640)" fillcolor=orange]
	11135874144 -> 6139560960 [dir=none]
	6139560960 [label="running_var
 (640)" fillcolor=orange]
	11135874144 -> 6139560800 [dir=none]
	6139560800 [label="weight
 (640)" fillcolor=orange]
	11135874144 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135863728 -> 11135874144
	11135863728 -> 6139868672 [dir=none]
	6139868672 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	11135863728 -> 6139560720 [dir=none]
	6139560720 [label="weight
 (640, 2304, 1, 1)" fillcolor=orange]
	11135863728 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135862576 -> 11135863728
	11135862576 -> 6139860112 [dir=none]
	6139860112 [label="other
 (1, 2304, 19, 19)" fillcolor=orange]
	11135862576 -> 6139855072 [dir=none]
	6139855072 [label="self
 (1, 2304, 1, 1)" fillcolor=orange]
	11135862576 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135862432 -> 11135862576
	11135862432 -> 11134974320 [dir=none]
	11134974320 [label="result
 (1, 2304, 1, 1)" fillcolor=orange]
	11135862432 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135862192 -> 11135862432
	11135862192 -> 6139870272 [dir=none]
	6139870272 [label="input
 (1, 96, 1, 1)" fillcolor=orange]
	11135862192 -> 6139560480 [dir=none]
	6139560480 [label="weight
 (2304, 96, 1, 1)" fillcolor=orange]
	11135862192 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (2304,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142072128 -> 11135862192
	6142072128 [label=SwishImplementationBackward]
	11135860896 -> 6142072128
	11135860896 -> 6139861152 [dir=none]
	6139861152 [label="input
 (1, 2304, 1, 1)" fillcolor=orange]
	11135860896 -> 6139560240 [dir=none]
	6139560240 [label="weight
 (96, 2304, 1, 1)" fillcolor=orange]
	11135860896 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (96,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135861328 -> 11135860896
	11135861328 -> 6139860112 [dir=none]
	6139860112 [label="self
 (1, 2304, 19, 19)" fillcolor=orange]
	11135861328 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 2304, 19, 19)"]
	6142071904 -> 11135861328
	6142071904 [label=SwishImplementationBackward]
	11135776848 -> 6142071904
	11135776848 -> 6139868432 [dir=none]
	6139868432 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	11135776848 -> 11134975040 [dir=none]
	11134975040 [label="result1
 (2304)" fillcolor=orange]
	11135776848 -> 11134975120 [dir=none]
	11134975120 [label="result2
 (2304)" fillcolor=orange]
	11135776848 -> 6139279328 [dir=none]
	6139279328 [label="running_mean
 (2304)" fillcolor=orange]
	11135776848 -> 6139281168 [dir=none]
	6139281168 [label="running_var
 (2304)" fillcolor=orange]
	11135776848 -> 6139280928 [dir=none]
	6139280928 [label="weight
 (2304)" fillcolor=orange]
	11135776848 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135777280 -> 11135776848
	11135777280 -> 6139870832 [dir=none]
	6139870832 [label="input
 (1, 2304, 21, 21)" fillcolor=orange]
	11135777280 -> 6139281008 [dir=none]
	6139281008 [label="weight
 (2304, 1, 3, 3)" fillcolor=orange]
	11135777280 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           2304
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135776176 -> 11135777280
	11135776176 [label="ConstantPadNdBackward0
----------------------
pad: (1, 1, 1, 1)"]
	6142071680 -> 11135776176
	6142071680 [label=SwishImplementationBackward]
	11135775168 -> 6142071680
	11135775168 -> 6139970000 [dir=none]
	6139970000 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	11135775168 -> 11134975600 [dir=none]
	11134975600 [label="result1
 (2304)" fillcolor=orange]
	11135775168 -> 11134975680 [dir=none]
	11134975680 [label="result2
 (2304)" fillcolor=orange]
	11135775168 -> 6139280208 [dir=none]
	6139280208 [label="running_mean
 (2304)" fillcolor=orange]
	11135775168 -> 6139280528 [dir=none]
	6139280528 [label="running_var
 (2304)" fillcolor=orange]
	11135775168 -> 6139280368 [dir=none]
	6139280368 [label="weight
 (2304)" fillcolor=orange]
	11135775168 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135774688 -> 11135775168
	11135774688 -> 6139857632 [dir=none]
	6139857632 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	11135774688 -> 6139280288 [dir=none]
	6139280288 [label="weight
 (2304, 384, 1, 1)" fillcolor=orange]
	11135774688 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135773824 -> 11135774688
	11135773824 [label="AddBackward0
------------
alpha: 1"]
	11135774016 -> 11135773824
	11135774016 -> 6139866032 [dir=none]
	6139866032 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11135774016 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135772864 -> 11135774016
	11135772864 -> 11134975840 [dir=none]
	11134975840 [label="other
 ()" fillcolor=orange]
	11135772864 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135772672 -> 11135772864
	11135772672 -> 6139860912 [dir=none]
	6139860912 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	11135772672 -> 11134845232 [dir=none]
	11134845232 [label="result1
 (384)" fillcolor=orange]
	11135772672 -> 11134845152 [dir=none]
	11134845152 [label="result2
 (384)" fillcolor=orange]
	11135772672 -> 6139279568 [dir=none]
	6139279568 [label="running_mean
 (384)" fillcolor=orange]
	11135772672 -> 6139279888 [dir=none]
	6139279888 [label="running_var
 (384)" fillcolor=orange]
	11135772672 -> 6139279728 [dir=none]
	6139279728 [label="weight
 (384)" fillcolor=orange]
	11135772672 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135771808 -> 11135772672
	11135771808 -> 6139969600 [dir=none]
	6139969600 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	11135771808 -> 6139279648 [dir=none]
	6139279648 [label="weight
 (384, 2304, 1, 1)" fillcolor=orange]
	11135771808 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135771280 -> 11135771808
	11135771280 -> 6139970160 [dir=none]
	6139970160 [label="other
 (1, 2304, 19, 19)" fillcolor=orange]
	11135771280 -> 6139969920 [dir=none]
	6139969920 [label="self
 (1, 2304, 1, 1)" fillcolor=orange]
	11135771280 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135770800 -> 11135771280
	11135770800 -> 11134845312 [dir=none]
	11134845312 [label="result
 (1, 2304, 1, 1)" fillcolor=orange]
	11135770800 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135769792 -> 11135770800
	11135769792 -> 6139969760 [dir=none]
	6139969760 [label="input
 (1, 96, 1, 1)" fillcolor=orange]
	11135769792 -> 6139279408 [dir=none]
	6139279408 [label="weight
 (2304, 96, 1, 1)" fillcolor=orange]
	11135769792 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (2304,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142071456 -> 11135769792
	6142071456 [label=SwishImplementationBackward]
	11135769120 -> 6142071456
	11135769120 -> 6139970400 [dir=none]
	6139970400 [label="input
 (1, 2304, 1, 1)" fillcolor=orange]
	11135769120 -> 6139279168 [dir=none]
	6139279168 [label="weight
 (96, 2304, 1, 1)" fillcolor=orange]
	11135769120 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (96,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135768688 -> 11135769120
	11135768688 -> 6139970160 [dir=none]
	6139970160 [label="self
 (1, 2304, 19, 19)" fillcolor=orange]
	11135768688 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 2304, 19, 19)"]
	6142071232 -> 11135768688
	6142071232 [label=SwishImplementationBackward]
	11135766912 -> 6142071232
	11135766912 -> 6139970720 [dir=none]
	6139970720 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	11135766912 -> 11134846112 [dir=none]
	11134846112 [label="result1
 (2304)" fillcolor=orange]
	11135766912 -> 11134846192 [dir=none]
	11134846192 [label="result2
 (2304)" fillcolor=orange]
	11135766912 -> 6139276848 [dir=none]
	6139276848 [label="running_mean
 (2304)" fillcolor=orange]
	11135766912 -> 6139278688 [dir=none]
	6139278688 [label="running_var
 (2304)" fillcolor=orange]
	11135766912 -> 6139278448 [dir=none]
	6139278448 [label="weight
 (2304)" fillcolor=orange]
	11135766912 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135767392 -> 11135766912
	11135767392 -> 6139970800 [dir=none]
	6139970800 [label="input
 (1, 2304, 23, 23)" fillcolor=orange]
	11135767392 -> 6139278528 [dir=none]
	6139278528 [label="weight
 (2304, 1, 5, 5)" fillcolor=orange]
	11135767392 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           2304
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135766960 -> 11135767392
	11135766960 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6142071008 -> 11135766960
	6142071008 [label=SwishImplementationBackward]
	11135765616 -> 6142071008
	11135765616 -> 6139972160 [dir=none]
	6139972160 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	11135765616 -> 11134846672 [dir=none]
	11134846672 [label="result1
 (2304)" fillcolor=orange]
	11135765616 -> 11134846752 [dir=none]
	11134846752 [label="result2
 (2304)" fillcolor=orange]
	11135765616 -> 6139277728 [dir=none]
	6139277728 [label="running_mean
 (2304)" fillcolor=orange]
	11135765616 -> 6139278048 [dir=none]
	6139278048 [label="running_var
 (2304)" fillcolor=orange]
	11135765616 -> 6139277888 [dir=none]
	6139277888 [label="weight
 (2304)" fillcolor=orange]
	11135765616 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135764752 -> 11135765616
	11135764752 -> 6139971280 [dir=none]
	6139971280 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	11135764752 -> 6139277808 [dir=none]
	6139277808 [label="weight
 (2304, 384, 1, 1)" fillcolor=orange]
	11135764752 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135773584 -> 11135764752
	11135773584 [label="AddBackward0
------------
alpha: 1"]
	11135763792 -> 11135773584
	11135763792 -> 6139971120 [dir=none]
	6139971120 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11135763792 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135762736 -> 11135763792
	11135762736 -> 11134847072 [dir=none]
	11134847072 [label="other
 ()" fillcolor=orange]
	11135762736 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135763312 -> 11135762736
	11135763312 -> 6139971520 [dir=none]
	6139971520 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	11135763312 -> 11134847392 [dir=none]
	11134847392 [label="result1
 (384)" fillcolor=orange]
	11135763312 -> 11134847312 [dir=none]
	11134847312 [label="result2
 (384)" fillcolor=orange]
	11135763312 -> 6139277088 [dir=none]
	6139277088 [label="running_mean
 (384)" fillcolor=orange]
	11135763312 -> 6139277408 [dir=none]
	6139277408 [label="running_var
 (384)" fillcolor=orange]
	11135763312 -> 6139277248 [dir=none]
	6139277248 [label="weight
 (384)" fillcolor=orange]
	11135763312 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135762496 -> 11135763312
	11135762496 -> 6139971680 [dir=none]
	6139971680 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	11135762496 -> 6139277168 [dir=none]
	6139277168 [label="weight
 (384, 2304, 1, 1)" fillcolor=orange]
	11135762496 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135696032 -> 11135762496
	11135696032 -> 6139972320 [dir=none]
	6139972320 [label="other
 (1, 2304, 19, 19)" fillcolor=orange]
	11135696032 -> 6139971920 [dir=none]
	6139971920 [label="self
 (1, 2304, 1, 1)" fillcolor=orange]
	11135696032 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135695456 -> 11135696032
	11135695456 -> 11134847472 [dir=none]
	11134847472 [label="result
 (1, 2304, 1, 1)" fillcolor=orange]
	11135695456 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135694976 -> 11135695456
	11135694976 -> 6139971840 [dir=none]
	6139971840 [label="input
 (1, 96, 1, 1)" fillcolor=orange]
	11135694976 -> 6139276928 [dir=none]
	6139276928 [label="weight
 (2304, 96, 1, 1)" fillcolor=orange]
	11135694976 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (2304,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142070784 -> 11135694976
	6142070784 [label=SwishImplementationBackward]
	11135693872 -> 6142070784
	11135693872 -> 6139972560 [dir=none]
	6139972560 [label="input
 (1, 2304, 1, 1)" fillcolor=orange]
	11135693872 -> 6139276688 [dir=none]
	6139276688 [label="weight
 (96, 2304, 1, 1)" fillcolor=orange]
	11135693872 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (96,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135693440 -> 11135693872
	11135693440 -> 6139972320 [dir=none]
	6139972320 [label="self
 (1, 2304, 19, 19)" fillcolor=orange]
	11135693440 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 2304, 19, 19)"]
	6142070560 -> 11135693440
	6142070560 [label=SwishImplementationBackward]
	11135692096 -> 6142070560
	11135692096 -> 6139972960 [dir=none]
	6139972960 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	11135692096 -> 11134848192 [dir=none]
	11134848192 [label="result1
 (2304)" fillcolor=orange]
	11135692096 -> 11134848272 [dir=none]
	11134848272 [label="result2
 (2304)" fillcolor=orange]
	11135692096 -> 6139274448 [dir=none]
	6139274448 [label="running_mean
 (2304)" fillcolor=orange]
	11135692096 -> 6139276208 [dir=none]
	6139276208 [label="running_var
 (2304)" fillcolor=orange]
	11135692096 -> 6139275968 [dir=none]
	6139275968 [label="weight
 (2304)" fillcolor=orange]
	11135692096 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135691808 -> 11135692096
	11135691808 -> 6139973040 [dir=none]
	6139973040 [label="input
 (1, 2304, 23, 23)" fillcolor=orange]
	11135691808 -> 6139276048 [dir=none]
	6139276048 [label="weight
 (2304, 1, 5, 5)" fillcolor=orange]
	11135691808 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           2304
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135691136 -> 11135691808
	11135691136 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6142070336 -> 11135691136
	6142070336 [label=SwishImplementationBackward]
	11135690656 -> 6142070336
	11135690656 -> 6139974000 [dir=none]
	6139974000 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	11135690656 -> 11134848752 [dir=none]
	11134848752 [label="result1
 (2304)" fillcolor=orange]
	11135690656 -> 11134848832 [dir=none]
	11134848832 [label="result2
 (2304)" fillcolor=orange]
	11135690656 -> 6139275248 [dir=none]
	6139275248 [label="running_mean
 (2304)" fillcolor=orange]
	11135690656 -> 6139275568 [dir=none]
	6139275568 [label="running_var
 (2304)" fillcolor=orange]
	11135690656 -> 6139275408 [dir=none]
	6139275408 [label="weight
 (2304)" fillcolor=orange]
	11135690656 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135689840 -> 11135690656
	11135689840 -> 6139973280 [dir=none]
	6139973280 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	11135689840 -> 6139275328 [dir=none]
	6139275328 [label="weight
 (2304, 384, 1, 1)" fillcolor=orange]
	11135689840 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135763504 -> 11135689840
	11135763504 [label="AddBackward0
------------
alpha: 1"]
	11135688352 -> 11135763504
	11135688352 -> 6139973200 [dir=none]
	6139973200 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11135688352 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135687920 -> 11135688352
	11135687920 -> 11134849152 [dir=none]
	11134849152 [label="other
 ()" fillcolor=orange]
	11135687920 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135687488 -> 11135687920
	11135687488 -> 6139973360 [dir=none]
	6139973360 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	11135687488 -> 11134849472 [dir=none]
	11134849472 [label="result1
 (384)" fillcolor=orange]
	11135687488 -> 11134849392 [dir=none]
	11134849392 [label="result2
 (384)" fillcolor=orange]
	11135687488 -> 6139274688 [dir=none]
	6139274688 [label="running_mean
 (384)" fillcolor=orange]
	11135687488 -> 6139275008 [dir=none]
	6139275008 [label="running_var
 (384)" fillcolor=orange]
	11135687488 -> 6139274848 [dir=none]
	6139274848 [label="weight
 (384)" fillcolor=orange]
	11135687488 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135687056 -> 11135687488
	11135687056 -> 6139973600 [dir=none]
	6139973600 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	11135687056 -> 6139274768 [dir=none]
	6139274768 [label="weight
 (384, 2304, 1, 1)" fillcolor=orange]
	11135687056 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135686384 -> 11135687056
	11135686384 -> 6139974160 [dir=none]
	6139974160 [label="other
 (1, 2304, 19, 19)" fillcolor=orange]
	11135686384 -> 6139973920 [dir=none]
	6139973920 [label="self
 (1, 2304, 1, 1)" fillcolor=orange]
	11135686384 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135685760 -> 11135686384
	11135685760 -> 11134849552 [dir=none]
	11134849552 [label="result
 (1, 2304, 1, 1)" fillcolor=orange]
	11135685760 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135685328 -> 11135685760
	11135685328 -> 6139973760 [dir=none]
	6139973760 [label="input
 (1, 96, 1, 1)" fillcolor=orange]
	11135685328 -> 6139274528 [dir=none]
	6139274528 [label="weight
 (2304, 96, 1, 1)" fillcolor=orange]
	11135685328 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (2304,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142070112 -> 11135685328
	6142070112 [label=SwishImplementationBackward]
	11135683792 -> 6142070112
	11135683792 -> 6139974400 [dir=none]
	6139974400 [label="input
 (1, 2304, 1, 1)" fillcolor=orange]
	11135683792 -> 6139274288 [dir=none]
	6139274288 [label="weight
 (96, 2304, 1, 1)" fillcolor=orange]
	11135683792 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (96,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135684032 -> 11135683792
	11135684032 -> 6139974160 [dir=none]
	6139974160 [label="self
 (1, 2304, 19, 19)" fillcolor=orange]
	11135684032 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 2304, 19, 19)"]
	6142069888 -> 11135684032
	6142069888 [label=SwishImplementationBackward]
	11135682784 -> 6142069888
	11135682784 -> 6139974720 [dir=none]
	6139974720 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	11135682784 -> 11134850272 [dir=none]
	11134850272 [label="result1
 (2304)" fillcolor=orange]
	11135682784 -> 11134850352 [dir=none]
	11134850352 [label="result2
 (2304)" fillcolor=orange]
	11135682784 -> 6139272048 [dir=none]
	6139272048 [label="running_mean
 (2304)" fillcolor=orange]
	11135682784 -> 6139273888 [dir=none]
	6139273888 [label="running_var
 (2304)" fillcolor=orange]
	11135682784 -> 6139273648 [dir=none]
	6139273648 [label="weight
 (2304)" fillcolor=orange]
	11135682784 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135682352 -> 11135682784
	11135682352 -> 6139974960 [dir=none]
	6139974960 [label="input
 (1, 2304, 23, 23)" fillcolor=orange]
	11135682352 -> 6139273728 [dir=none]
	6139273728 [label="weight
 (2304, 1, 5, 5)" fillcolor=orange]
	11135682352 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           2304
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135681296 -> 11135682352
	11135681296 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6142069664 -> 11135681296
	6142069664 [label=SwishImplementationBackward]
	11135680624 -> 6142069664
	11135680624 -> 6139975840 [dir=none]
	6139975840 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	11135680624 -> 11134850832 [dir=none]
	11134850832 [label="result1
 (2304)" fillcolor=orange]
	11135680624 -> 11134850912 [dir=none]
	11134850912 [label="result2
 (2304)" fillcolor=orange]
	11135680624 -> 6139272928 [dir=none]
	6139272928 [label="running_mean
 (2304)" fillcolor=orange]
	11135680624 -> 6139273248 [dir=none]
	6139273248 [label="running_var
 (2304)" fillcolor=orange]
	11135680624 -> 6139273088 [dir=none]
	6139273088 [label="weight
 (2304)" fillcolor=orange]
	11135680624 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135614400 -> 11135680624
	11135614400 -> 6139975280 [dir=none]
	6139975280 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	11135614400 -> 6139273008 [dir=none]
	6139273008 [label="weight
 (2304, 384, 1, 1)" fillcolor=orange]
	11135614400 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135688688 -> 11135614400
	11135688688 [label="AddBackward0
------------
alpha: 1"]
	11135613296 -> 11135688688
	11135613296 -> 6139975120 [dir=none]
	6139975120 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11135613296 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135612720 -> 11135613296
	11135612720 -> 11134851232 [dir=none]
	11134851232 [label="other
 ()" fillcolor=orange]
	11135612720 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135612240 -> 11135612720
	11135612240 -> 6139975360 [dir=none]
	6139975360 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	11135612240 -> 11134851552 [dir=none]
	11134851552 [label="result1
 (384)" fillcolor=orange]
	11135612240 -> 11134851472 [dir=none]
	11134851472 [label="result2
 (384)" fillcolor=orange]
	11135612240 -> 6139272288 [dir=none]
	6139272288 [label="running_mean
 (384)" fillcolor=orange]
	11135612240 -> 6139272608 [dir=none]
	6139272608 [label="running_var
 (384)" fillcolor=orange]
	11135612240 -> 6139272448 [dir=none]
	6139272448 [label="weight
 (384)" fillcolor=orange]
	11135612240 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135611808 -> 11135612240
	11135611808 -> 6139975520 [dir=none]
	6139975520 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	11135611808 -> 6139272368 [dir=none]
	6139272368 [label="weight
 (384, 2304, 1, 1)" fillcolor=orange]
	11135611808 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135611232 -> 11135611808
	11135611232 -> 6139976000 [dir=none]
	6139976000 [label="other
 (1, 2304, 19, 19)" fillcolor=orange]
	11135611232 -> 6139975760 [dir=none]
	6139975760 [label="self
 (1, 2304, 1, 1)" fillcolor=orange]
	11135611232 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135611136 -> 11135611232
	11135611136 -> 11134851632 [dir=none]
	11134851632 [label="result
 (1, 2304, 1, 1)" fillcolor=orange]
	11135611136 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135610992 -> 11135611136
	11135610992 -> 6139975600 [dir=none]
	6139975600 [label="input
 (1, 96, 1, 1)" fillcolor=orange]
	11135610992 -> 6139272128 [dir=none]
	6139272128 [label="weight
 (2304, 96, 1, 1)" fillcolor=orange]
	11135610992 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (2304,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142069440 -> 11135610992
	6142069440 [label=SwishImplementationBackward]
	11135610560 -> 6142069440
	11135610560 -> 6139976160 [dir=none]
	6139976160 [label="input
 (1, 2304, 1, 1)" fillcolor=orange]
	11135610560 -> 6139271888 [dir=none]
	6139271888 [label="weight
 (96, 2304, 1, 1)" fillcolor=orange]
	11135610560 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (96,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135610416 -> 11135610560
	11135610416 -> 6139976000 [dir=none]
	6139976000 [label="self
 (1, 2304, 19, 19)" fillcolor=orange]
	11135610416 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 2304, 19, 19)"]
	6142069216 -> 11135610416
	6142069216 [label=SwishImplementationBackward]
	11135609984 -> 6142069216
	11135609984 -> 6139976720 [dir=none]
	6139976720 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	11135609984 -> 11134852352 [dir=none]
	11134852352 [label="result1
 (2304)" fillcolor=orange]
	11135609984 -> 11134852432 [dir=none]
	11134852432 [label="result2
 (2304)" fillcolor=orange]
	11135609984 -> 6139269568 [dir=none]
	6139269568 [label="running_mean
 (2304)" fillcolor=orange]
	11135609984 -> 6139271408 [dir=none]
	6139271408 [label="running_var
 (2304)" fillcolor=orange]
	11135609984 -> 6139271168 [dir=none]
	6139271168 [label="weight
 (2304)" fillcolor=orange]
	11135609984 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135609840 -> 11135609984
	11135609840 -> 6139976800 [dir=none]
	6139976800 [label="input
 (1, 2304, 23, 23)" fillcolor=orange]
	11135609840 -> 6139271248 [dir=none]
	6139271248 [label="weight
 (2304, 1, 5, 5)" fillcolor=orange]
	11135609840 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           2304
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135609552 -> 11135609840
	11135609552 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6142068992 -> 11135609552
	6142068992 [label=SwishImplementationBackward]
	11135609072 -> 6142068992
	11135609072 -> 6139978000 [dir=none]
	6139978000 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	11135609072 -> 11134852912 [dir=none]
	11134852912 [label="result1
 (2304)" fillcolor=orange]
	11135609072 -> 11134852992 [dir=none]
	11134852992 [label="result2
 (2304)" fillcolor=orange]
	11135609072 -> 6139270448 [dir=none]
	6139270448 [label="running_mean
 (2304)" fillcolor=orange]
	11135609072 -> 6139270768 [dir=none]
	6139270768 [label="running_var
 (2304)" fillcolor=orange]
	11135609072 -> 6139270608 [dir=none]
	6139270608 [label="weight
 (2304)" fillcolor=orange]
	11135609072 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135608928 -> 11135609072
	11135608928 -> 6139977200 [dir=none]
	6139977200 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	11135608928 -> 6139270528 [dir=none]
	6139270528 [label="weight
 (2304, 384, 1, 1)" fillcolor=orange]
	11135608928 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135613872 -> 11135608928
	11135613872 [label="AddBackward0
------------
alpha: 1"]
	11135608496 -> 11135613872
	11135608496 -> 6139977040 [dir=none]
	6139977040 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11135608496 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135608400 -> 11135608496
	11135608400 -> 11134853312 [dir=none]
	11134853312 [label="other
 ()" fillcolor=orange]
	11135608400 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135608256 -> 11135608400
	11135608256 -> 6139977360 [dir=none]
	6139977360 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	11135608256 -> 11134853632 [dir=none]
	11134853632 [label="result1
 (384)" fillcolor=orange]
	11135608256 -> 11134853552 [dir=none]
	11134853552 [label="result2
 (384)" fillcolor=orange]
	11135608256 -> 6139269808 [dir=none]
	6139269808 [label="running_mean
 (384)" fillcolor=orange]
	11135608256 -> 6139270128 [dir=none]
	6139270128 [label="running_var
 (384)" fillcolor=orange]
	11135608256 -> 6139269968 [dir=none]
	6139269968 [label="weight
 (384)" fillcolor=orange]
	11135608256 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135608112 -> 11135608256
	11135608112 -> 6139977440 [dir=none]
	6139977440 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	11135608112 -> 6139269888 [dir=none]
	6139269888 [label="weight
 (384, 2304, 1, 1)" fillcolor=orange]
	11135608112 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135607824 -> 11135608112
	11135607824 -> 6139978080 [dir=none]
	6139978080 [label="other
 (1, 2304, 19, 19)" fillcolor=orange]
	11135607824 -> 6139977840 [dir=none]
	6139977840 [label="self
 (1, 2304, 1, 1)" fillcolor=orange]
	11135607824 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135607488 -> 11135607824
	11135607488 -> 11134853712 [dir=none]
	11134853712 [label="result
 (1, 2304, 1, 1)" fillcolor=orange]
	11135607488 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135607344 -> 11135607488
	11135607344 -> 6139977680 [dir=none]
	6139977680 [label="input
 (1, 96, 1, 1)" fillcolor=orange]
	11135607344 -> 6139269648 [dir=none]
	6139269648 [label="weight
 (2304, 96, 1, 1)" fillcolor=orange]
	11135607344 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (2304,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142068768 -> 11135607344
	6142068768 [label=SwishImplementationBackward]
	11135606912 -> 6142068768
	11135606912 -> 6139978320 [dir=none]
	6139978320 [label="input
 (1, 2304, 1, 1)" fillcolor=orange]
	11135606912 -> 6139269408 [dir=none]
	6139269408 [label="weight
 (96, 2304, 1, 1)" fillcolor=orange]
	11135606912 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (96,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135606768 -> 11135606912
	11135606768 -> 6139978080 [dir=none]
	6139978080 [label="self
 (1, 2304, 19, 19)" fillcolor=orange]
	11135606768 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 2304, 19, 19)"]
	6142068544 -> 11135606768
	6142068544 [label=SwishImplementationBackward]
	11135606336 -> 6142068544
	11135606336 -> 6139978720 [dir=none]
	6139978720 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	11135606336 -> 11134854432 [dir=none]
	11134854432 [label="result1
 (2304)" fillcolor=orange]
	11135606336 -> 11134854512 [dir=none]
	11134854512 [label="result2
 (2304)" fillcolor=orange]
	11135606336 -> 6139267088 [dir=none]
	6139267088 [label="running_mean
 (2304)" fillcolor=orange]
	11135606336 -> 6139268928 [dir=none]
	6139268928 [label="running_var
 (2304)" fillcolor=orange]
	11135606336 -> 6139268688 [dir=none]
	6139268688 [label="weight
 (2304)" fillcolor=orange]
	11135606336 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135606192 -> 11135606336
	11135606192 -> 6139978800 [dir=none]
	6139978800 [label="input
 (1, 2304, 23, 23)" fillcolor=orange]
	11135606192 -> 6139268768 [dir=none]
	6139268768 [label="weight
 (2304, 1, 5, 5)" fillcolor=orange]
	11135606192 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           2304
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135605904 -> 11135606192
	11135605904 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6142068320 -> 11135605904
	6142068320 [label=SwishImplementationBackward]
	11135605664 -> 6142068320
	11135605664 -> 6139979760 [dir=none]
	6139979760 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	11135605664 -> 11134854992 [dir=none]
	11134854992 [label="result1
 (2304)" fillcolor=orange]
	11135605664 -> 11134855072 [dir=none]
	11134855072 [label="result2
 (2304)" fillcolor=orange]
	11135605664 -> 6139267968 [dir=none]
	6139267968 [label="running_mean
 (2304)" fillcolor=orange]
	11135605664 -> 6139268288 [dir=none]
	6139268288 [label="running_var
 (2304)" fillcolor=orange]
	11135605664 -> 6139268128 [dir=none]
	6139268128 [label="weight
 (2304)" fillcolor=orange]
	11135605664 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135605520 -> 11135605664
	11135605520 -> 6139979120 [dir=none]
	6139979120 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	11135605520 -> 6139268048 [dir=none]
	6139268048 [label="weight
 (2304, 384, 1, 1)" fillcolor=orange]
	11135605520 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135608688 -> 11135605520
	11135608688 [label="AddBackward0
------------
alpha: 1"]
	11135605088 -> 11135608688
	11135605088 -> 6139978880 [dir=none]
	6139978880 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11135605088 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135604752 -> 11135605088
	11135604752 -> 11134855392 [dir=none]
	11134855392 [label="other
 ()" fillcolor=orange]
	11135604752 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135604608 -> 11135604752
	11135604608 -> 6139979280 [dir=none]
	6139979280 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	11135604608 -> 11134855712 [dir=none]
	11134855712 [label="result1
 (384)" fillcolor=orange]
	11135604608 -> 11134855632 [dir=none]
	11134855632 [label="result2
 (384)" fillcolor=orange]
	11135604608 -> 6139267328 [dir=none]
	6139267328 [label="running_mean
 (384)" fillcolor=orange]
	11135604608 -> 6139267648 [dir=none]
	6139267648 [label="running_var
 (384)" fillcolor=orange]
	11135604608 -> 6139267488 [dir=none]
	6139267488 [label="weight
 (384)" fillcolor=orange]
	11135604608 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135604464 -> 11135604608
	11135604464 -> 6139979440 [dir=none]
	6139979440 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	11135604464 -> 6139267408 [dir=none]
	6139267408 [label="weight
 (384, 2304, 1, 1)" fillcolor=orange]
	11135604464 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135604176 -> 11135604464
	11135604176 -> 6139979920 [dir=none]
	6139979920 [label="other
 (1, 2304, 19, 19)" fillcolor=orange]
	11135604176 -> 6139979680 [dir=none]
	6139979680 [label="self
 (1, 2304, 1, 1)" fillcolor=orange]
	11135604176 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135604080 -> 11135604176
	11135604080 -> 11134855792 [dir=none]
	11134855792 [label="result
 (1, 2304, 1, 1)" fillcolor=orange]
	11135604080 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135603936 -> 11135604080
	11135603936 -> 6139979520 [dir=none]
	6139979520 [label="input
 (1, 96, 1, 1)" fillcolor=orange]
	11135603936 -> 6139267168 [dir=none]
	6139267168 [label="weight
 (2304, 96, 1, 1)" fillcolor=orange]
	11135603936 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (2304,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142068096 -> 11135603936
	6142068096 [label=SwishImplementationBackward]
	11135603504 -> 6142068096
	11135603504 -> 6139980160 [dir=none]
	6139980160 [label="input
 (1, 2304, 1, 1)" fillcolor=orange]
	11135603504 -> 6139266928 [dir=none]
	6139266928 [label="weight
 (96, 2304, 1, 1)" fillcolor=orange]
	11135603504 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (96,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135603360 -> 11135603504
	11135603360 -> 6139979920 [dir=none]
	6139979920 [label="self
 (1, 2304, 19, 19)" fillcolor=orange]
	11135603360 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 2304, 19, 19)"]
	6142067872 -> 11135603360
	6142067872 [label=SwishImplementationBackward]
	11135602928 -> 6142067872
	11135602928 -> 6139980640 [dir=none]
	6139980640 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	11135602928 -> 11134856512 [dir=none]
	11134856512 [label="result1
 (2304)" fillcolor=orange]
	11135602928 -> 11134856592 [dir=none]
	11134856592 [label="result2
 (2304)" fillcolor=orange]
	11135602928 -> 6139018944 [dir=none]
	6139018944 [label="running_mean
 (2304)" fillcolor=orange]
	11135602928 -> 6139266528 [dir=none]
	6139266528 [label="running_var
 (2304)" fillcolor=orange]
	11135602928 -> 6139266288 [dir=none]
	6139266288 [label="weight
 (2304)" fillcolor=orange]
	11135602928 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135602784 -> 11135602928
	11135602784 -> 6139980800 [dir=none]
	6139980800 [label="input
 (1, 2304, 23, 23)" fillcolor=orange]
	11135602784 -> 6139266368 [dir=none]
	6139266368 [label="weight
 (2304, 1, 5, 5)" fillcolor=orange]
	11135602784 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           2304
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135602496 -> 11135602784
	11135602496 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6142067648 -> 11135602496
	6142067648 [label=SwishImplementationBackward]
	11135602016 -> 6142067648
	11135602016 -> 6139981600 [dir=none]
	6139981600 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	11135602016 -> 11134857072 [dir=none]
	11134857072 [label="result1
 (2304)" fillcolor=orange]
	11135602016 -> 11134857152 [dir=none]
	11134857152 [label="result2
 (2304)" fillcolor=orange]
	11135602016 -> 6139265648 [dir=none]
	6139265648 [label="running_mean
 (2304)" fillcolor=orange]
	11135602016 -> 6139265968 [dir=none]
	6139265968 [label="running_var
 (2304)" fillcolor=orange]
	11135602016 -> 6139265808 [dir=none]
	6139265808 [label="weight
 (2304)" fillcolor=orange]
	11135602016 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135601872 -> 11135602016
	11135601872 -> 6139981040 [dir=none]
	6139981040 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	11135601872 -> 6139265728 [dir=none]
	6139265728 [label="weight
 (2304, 384, 1, 1)" fillcolor=orange]
	11135601872 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135605040 -> 11135601872
	11135605040 [label="AddBackward0
------------
alpha: 1"]
	11135601440 -> 11135605040
	11135601440 -> 6139980880 [dir=none]
	6139980880 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	11135601440 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135601344 -> 11135601440
	11135601344 -> 11134857472 [dir=none]
	11134857472 [label="other
 ()" fillcolor=orange]
	11135601344 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	11135601200 -> 11135601344
	11135601200 -> 6139981120 [dir=none]
	6139981120 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	11135601200 -> 11134857792 [dir=none]
	11134857792 [label="result1
 (384)" fillcolor=orange]
	11135601200 -> 11134857712 [dir=none]
	11134857712 [label="result2
 (384)" fillcolor=orange]
	11135601200 -> 6139019184 [dir=none]
	6139019184 [label="running_mean
 (384)" fillcolor=orange]
	11135601200 -> 6139265328 [dir=none]
	6139265328 [label="running_var
 (384)" fillcolor=orange]
	11135601200 -> 6139265168 [dir=none]
	6139265168 [label="weight
 (384)" fillcolor=orange]
	11135601200 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135601056 -> 11135601200
	11135601056 -> 6139981280 [dir=none]
	6139981280 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	11135601056 -> 6139265088 [dir=none]
	6139265088 [label="weight
 (384, 2304, 1, 1)" fillcolor=orange]
	11135601056 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135600768 -> 11135601056
	11135600768 -> 6139981680 [dir=none]
	6139981680 [label="other
 (1, 2304, 19, 19)" fillcolor=orange]
	11135600768 -> 6139981520 [dir=none]
	6139981520 [label="self
 (1, 2304, 1, 1)" fillcolor=orange]
	11135600768 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	11135600432 -> 11135600768
	11135600432 -> 11134857872 [dir=none]
	11134857872 [label="result
 (1, 2304, 1, 1)" fillcolor=orange]
	11135600432 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	11135600288 -> 11135600432
	11135600288 -> 6139981360 [dir=none]
	6139981360 [label="input
 (1, 96, 1, 1)" fillcolor=orange]
	11135600288 -> 6139019024 [dir=none]
	6139019024 [label="weight
 (2304, 96, 1, 1)" fillcolor=orange]
	11135600288 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (2304,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142067424 -> 11135600288
	6142067424 [label=SwishImplementationBackward]
	11135599856 -> 6142067424
	11135599856 -> 6139982080 [dir=none]
	6139982080 [label="input
 (1, 2304, 1, 1)" fillcolor=orange]
	11135599856 -> 6139018784 [dir=none]
	6139018784 [label="weight
 (96, 2304, 1, 1)" fillcolor=orange]
	11135599856 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (96,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135599712 -> 11135599856
	11135599712 -> 6139981680 [dir=none]
	6139981680 [label="self
 (1, 2304, 19, 19)" fillcolor=orange]
	11135599712 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 2304, 19, 19)"]
	6142067200 -> 11135599712
	6142067200 [label=SwishImplementationBackward]
	11135599280 -> 6142067200
	11135599280 -> 6139982560 [dir=none]
	6139982560 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	11135599280 -> 11134858592 [dir=none]
	11134858592 [label="result1
 (2304)" fillcolor=orange]
	11135599280 -> 11134858672 [dir=none]
	11134858672 [label="result2
 (2304)" fillcolor=orange]
	11135599280 -> 6139016464 [dir=none]
	6139016464 [label="running_mean
 (2304)" fillcolor=orange]
	11135599280 -> 6139018304 [dir=none]
	6139018304 [label="running_var
 (2304)" fillcolor=orange]
	11135599280 -> 6139018064 [dir=none]
	6139018064 [label="weight
 (2304)" fillcolor=orange]
	11135599280 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	11135599136 -> 11135599280
	11135599136 -> 6139982720 [dir=none]
	6139982720 [label="input
 (1, 2304, 23, 23)" fillcolor=orange]
	11135599136 -> 6139018144 [dir=none]
	6139018144 [label="weight
 (2304, 1, 5, 5)" fillcolor=orange]
	11135599136 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           2304
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135598848 -> 11135599136
	11135598848 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6142066976 -> 11135598848
	6142066976 [label=SwishImplementationBackward]
	11135598896 -> 6142066976
	11135598896 -> 6139983760 [dir=none]
	6139983760 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	11135598896 -> 11134859152 [dir=none]
	11134859152 [label="result1
 (2304)" fillcolor=orange]
	11135598896 -> 11134859232 [dir=none]
	11134859232 [label="result2
 (2304)" fillcolor=orange]
	11135598896 -> 6139017344 [dir=none]
	6139017344 [label="running_mean
 (2304)" fillcolor=orange]
	11135598896 -> 6139017664 [dir=none]
	6139017664 [label="running_var
 (2304)" fillcolor=orange]
	11135598896 -> 6139017504 [dir=none]
	6139017504 [label="weight
 (2304)" fillcolor=orange]
	11135598896 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6142050112 -> 11135598896
	6142050112 -> 6139982960 [dir=none]
	6139982960 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6142050112 -> 6139017424 [dir=none]
	6139017424 [label="weight
 (2304, 384, 1, 1)" fillcolor=orange]
	6142050112 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135601632 -> 6142050112
	11135601632 [label="AddBackward0
------------
alpha: 1"]
	6142049680 -> 11135601632
	6142049680 -> 6139982880 [dir=none]
	6139982880 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6142049680 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6142049344 -> 6142049680
	6142049344 -> 11134859552 [dir=none]
	11134859552 [label="other
 ()" fillcolor=orange]
	6142049344 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6142049200 -> 6142049344
	6142049200 -> 6139983200 [dir=none]
	6139983200 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6142049200 -> 11134859872 [dir=none]
	11134859872 [label="result1
 (384)" fillcolor=orange]
	6142049200 -> 11134859792 [dir=none]
	11134859792 [label="result2
 (384)" fillcolor=orange]
	6142049200 -> 6139016704 [dir=none]
	6139016704 [label="running_mean
 (384)" fillcolor=orange]
	6142049200 -> 6139017024 [dir=none]
	6139017024 [label="running_var
 (384)" fillcolor=orange]
	6142049200 -> 6139016864 [dir=none]
	6139016864 [label="weight
 (384)" fillcolor=orange]
	6142049200 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6142049056 -> 6142049200
	6142049056 -> 6139983360 [dir=none]
	6139983360 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6142049056 -> 6139016784 [dir=none]
	6139016784 [label="weight
 (384, 2304, 1, 1)" fillcolor=orange]
	6142049056 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142048768 -> 6142049056
	6142048768 -> 6139983840 [dir=none]
	6139983840 [label="other
 (1, 2304, 19, 19)" fillcolor=orange]
	6142048768 -> 6139983600 [dir=none]
	6139983600 [label="self
 (1, 2304, 1, 1)" fillcolor=orange]
	6142048768 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6142048672 -> 6142048768
	6142048672 -> 11134859952 [dir=none]
	11134859952 [label="result
 (1, 2304, 1, 1)" fillcolor=orange]
	6142048672 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6142048528 -> 6142048672
	6142048528 -> 6139983520 [dir=none]
	6139983520 [label="input
 (1, 96, 1, 1)" fillcolor=orange]
	6142048528 -> 6139016544 [dir=none]
	6139016544 [label="weight
 (2304, 96, 1, 1)" fillcolor=orange]
	6142048528 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (2304,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142066752 -> 6142048528
	6142066752 [label=SwishImplementationBackward]
	6142048096 -> 6142066752
	6142048096 -> 6139984080 [dir=none]
	6139984080 [label="input
 (1, 2304, 1, 1)" fillcolor=orange]
	6142048096 -> 6139016304 [dir=none]
	6139016304 [label="weight
 (96, 2304, 1, 1)" fillcolor=orange]
	6142048096 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (96,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142047952 -> 6142048096
	6142047952 -> 6139983840 [dir=none]
	6139983840 [label="self
 (1, 2304, 19, 19)" fillcolor=orange]
	6142047952 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 2304, 19, 19)"]
	6141525600 -> 6142047952
	6141525600 [label=SwishImplementationBackward]
	6142047520 -> 6141525600
	6142047520 -> 6139984400 [dir=none]
	6139984400 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6142047520 -> 11134860672 [dir=none]
	11134860672 [label="result1
 (2304)" fillcolor=orange]
	6142047520 -> 11134860752 [dir=none]
	11134860752 [label="result2
 (2304)" fillcolor=orange]
	6142047520 -> 6139013984 [dir=none]
	6139013984 [label="running_mean
 (2304)" fillcolor=orange]
	6142047520 -> 6139015824 [dir=none]
	6139015824 [label="running_var
 (2304)" fillcolor=orange]
	6142047520 -> 6139015584 [dir=none]
	6139015584 [label="weight
 (2304)" fillcolor=orange]
	6142047520 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6142047376 -> 6142047520
	6142047376 -> 6139984640 [dir=none]
	6139984640 [label="input
 (1, 2304, 23, 23)" fillcolor=orange]
	6142047376 -> 6139015664 [dir=none]
	6139015664 [label="weight
 (2304, 1, 5, 5)" fillcolor=orange]
	6142047376 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           2304
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142047088 -> 6142047376
	6142047088 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6141525376 -> 6142047088
	6141525376 [label=SwishImplementationBackward]
	6142046608 -> 6141525376
	6142046608 -> 6139985520 [dir=none]
	6139985520 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6142046608 -> 11134861232 [dir=none]
	11134861232 [label="result1
 (2304)" fillcolor=orange]
	6142046608 -> 11134860912 [dir=none]
	11134860912 [label="result2
 (2304)" fillcolor=orange]
	6142046608 -> 6139014864 [dir=none]
	6139014864 [label="running_mean
 (2304)" fillcolor=orange]
	6142046608 -> 6139015184 [dir=none]
	6139015184 [label="running_var
 (2304)" fillcolor=orange]
	6142046608 -> 6139015024 [dir=none]
	6139015024 [label="weight
 (2304)" fillcolor=orange]
	6142046608 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6142046464 -> 6142046608
	6142046464 -> 6139984960 [dir=none]
	6139984960 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6142046464 -> 6139014944 [dir=none]
	6139014944 [label="weight
 (2304, 384, 1, 1)" fillcolor=orange]
	6142046464 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142049632 -> 6142046464
	6142049632 [label="AddBackward0
------------
alpha: 1"]
	6142046032 -> 6142049632
	6142046032 -> 6139984800 [dir=none]
	6139984800 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6142046032 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6142045936 -> 6142046032
	6142045936 -> 11134878000 [dir=none]
	11134878000 [label="other
 ()" fillcolor=orange]
	6142045936 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6142045792 -> 6142045936
	6142045792 -> 6139985040 [dir=none]
	6139985040 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6142045792 -> 11134878320 [dir=none]
	11134878320 [label="result1
 (384)" fillcolor=orange]
	6142045792 -> 11134878240 [dir=none]
	11134878240 [label="result2
 (384)" fillcolor=orange]
	6142045792 -> 6139014224 [dir=none]
	6139014224 [label="running_mean
 (384)" fillcolor=orange]
	6142045792 -> 6139014544 [dir=none]
	6139014544 [label="running_var
 (384)" fillcolor=orange]
	6142045792 -> 6139014384 [dir=none]
	6139014384 [label="weight
 (384)" fillcolor=orange]
	6142045792 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6142045648 -> 6142045792
	6142045648 -> 6139985200 [dir=none]
	6139985200 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6142045648 -> 6139014304 [dir=none]
	6139014304 [label="weight
 (384, 2304, 1, 1)" fillcolor=orange]
	6142045648 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142045360 -> 6142045648
	6142045360 -> 6139985680 [dir=none]
	6139985680 [label="other
 (1, 2304, 19, 19)" fillcolor=orange]
	6142045360 -> 6139985440 [dir=none]
	6139985440 [label="self
 (1, 2304, 1, 1)" fillcolor=orange]
	6142045360 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6142045024 -> 6142045360
	6142045024 -> 11134878400 [dir=none]
	11134878400 [label="result
 (1, 2304, 1, 1)" fillcolor=orange]
	6142045024 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6142044880 -> 6142045024
	6142044880 -> 6139985280 [dir=none]
	6139985280 [label="input
 (1, 96, 1, 1)" fillcolor=orange]
	6142044880 -> 6139014064 [dir=none]
	6139014064 [label="weight
 (2304, 96, 1, 1)" fillcolor=orange]
	6142044880 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (2304,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141525152 -> 6142044880
	6141525152 [label=SwishImplementationBackward]
	6142044448 -> 6141525152
	6142044448 -> 6139972080 [dir=none]
	6139972080 [label="input
 (1, 2304, 1, 1)" fillcolor=orange]
	6142044448 -> 6139013824 [dir=none]
	6139013824 [label="weight
 (96, 2304, 1, 1)" fillcolor=orange]
	6142044448 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (96,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142044304 -> 6142044448
	6142044304 -> 6139985680 [dir=none]
	6139985680 [label="self
 (1, 2304, 19, 19)" fillcolor=orange]
	6142044304 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 2304, 19, 19)"]
	6141524928 -> 6142044304
	6141524928 [label=SwishImplementationBackward]
	6142043872 -> 6141524928
	6142043872 -> 6139975920 [dir=none]
	6139975920 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6142043872 -> 11134879200 [dir=none]
	11134879200 [label="result1
 (2304)" fillcolor=orange]
	6142043872 -> 11134879280 [dir=none]
	11134879280 [label="result2
 (2304)" fillcolor=orange]
	6142043872 -> 6139011504 [dir=none]
	6139011504 [label="running_mean
 (2304)" fillcolor=orange]
	6142043872 -> 6139013344 [dir=none]
	6139013344 [label="running_var
 (2304)" fillcolor=orange]
	6142043872 -> 6139013104 [dir=none]
	6139013104 [label="weight
 (2304)" fillcolor=orange]
	6142043872 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6142043728 -> 6142043872
	6142043728 -> 6139976320 [dir=none]
	6139976320 [label="input
 (1, 2304, 23, 23)" fillcolor=orange]
	6142043728 -> 6139013184 [dir=none]
	6139013184 [label="weight
 (2304, 1, 5, 5)" fillcolor=orange]
	6142043728 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           2304
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142043440 -> 6142043728
	6142043440 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6141524704 -> 6142043440
	6141524704 [label=SwishImplementationBackward]
	6142043200 -> 6141524704
	6142043200 -> 6139984560 [dir=none]
	6139984560 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6142043200 -> 11134879760 [dir=none]
	11134879760 [label="result1
 (2304)" fillcolor=orange]
	6142043200 -> 11134879840 [dir=none]
	11134879840 [label="result2
 (2304)" fillcolor=orange]
	6142043200 -> 6139012384 [dir=none]
	6139012384 [label="running_mean
 (2304)" fillcolor=orange]
	6142043200 -> 6139012704 [dir=none]
	6139012704 [label="running_var
 (2304)" fillcolor=orange]
	6142043200 -> 6139012544 [dir=none]
	6139012544 [label="weight
 (2304)" fillcolor=orange]
	6142043200 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6142043056 -> 6142043200
	6142043056 -> 6139978160 [dir=none]
	6139978160 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6142043056 -> 6139012464 [dir=none]
	6139012464 [label="weight
 (2304, 384, 1, 1)" fillcolor=orange]
	6142043056 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142046224 -> 6142043056
	6142046224 [label="AddBackward0
------------
alpha: 1"]
	6142042624 -> 6142046224
	6142042624 -> 6139977600 [dir=none]
	6139977600 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6142042624 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6142042288 -> 6142042624
	6142042288 -> 11134880160 [dir=none]
	11134880160 [label="other
 ()" fillcolor=orange]
	6142042288 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6142042144 -> 6142042288
	6142042144 -> 6139978400 [dir=none]
	6139978400 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6142042144 -> 11134880480 [dir=none]
	11134880480 [label="result1
 (384)" fillcolor=orange]
	6142042144 -> 11134880400 [dir=none]
	11134880400 [label="result2
 (384)" fillcolor=orange]
	6142042144 -> 6139011744 [dir=none]
	6139011744 [label="running_mean
 (384)" fillcolor=orange]
	6142042144 -> 6139012064 [dir=none]
	6139012064 [label="running_var
 (384)" fillcolor=orange]
	6142042144 -> 6139011904 [dir=none]
	6139011904 [label="weight
 (384)" fillcolor=orange]
	6142042144 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6142042000 -> 6142042144
	6142042000 -> 6139978640 [dir=none]
	6139978640 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6142042000 -> 6139011824 [dir=none]
	6139011824 [label="weight
 (384, 2304, 1, 1)" fillcolor=orange]
	6142042000 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142041712 -> 6142042000
	6142041712 -> 6139985360 [dir=none]
	6139985360 [label="other
 (1, 2304, 19, 19)" fillcolor=orange]
	6142041712 -> 6139982480 [dir=none]
	6139982480 [label="self
 (1, 2304, 1, 1)" fillcolor=orange]
	6142041712 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6142041616 -> 6142041712
	6142041616 -> 11134880560 [dir=none]
	11134880560 [label="result
 (1, 2304, 1, 1)" fillcolor=orange]
	6142041616 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6142041472 -> 6142041616
	6142041472 -> 6139981840 [dir=none]
	6139981840 [label="input
 (1, 96, 1, 1)" fillcolor=orange]
	6142041472 -> 6139011584 [dir=none]
	6139011584 [label="weight
 (2304, 96, 1, 1)" fillcolor=orange]
	6142041472 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (2304,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141524480 -> 6142041472
	6141524480 [label=SwishImplementationBackward]
	6142041040 -> 6141524480
	6142041040 -> 6139970560 [dir=none]
	6139970560 [label="input
 (1, 2304, 1, 1)" fillcolor=orange]
	6142041040 -> 6139011344 [dir=none]
	6139011344 [label="weight
 (96, 2304, 1, 1)" fillcolor=orange]
	6142041040 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (96,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142040896 -> 6142041040
	6142040896 -> 6139985360 [dir=none]
	6139985360 [label="self
 (1, 2304, 19, 19)" fillcolor=orange]
	6142040896 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 2304, 19, 19)"]
	6141524256 -> 6142040896
	6141524256 [label=SwishImplementationBackward]
	6142040464 -> 6141524256
	6142040464 -> 6139973840 [dir=none]
	6139973840 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6142040464 -> 11134881280 [dir=none]
	11134881280 [label="result1
 (2304)" fillcolor=orange]
	6142040464 -> 11134881360 [dir=none]
	11134881360 [label="result2
 (2304)" fillcolor=orange]
	6142040464 -> 6139009024 [dir=none]
	6139009024 [label="running_mean
 (2304)" fillcolor=orange]
	6142040464 -> 6139010864 [dir=none]
	6139010864 [label="running_var
 (2304)" fillcolor=orange]
	6142040464 -> 6139010624 [dir=none]
	6139010624 [label="weight
 (2304)" fillcolor=orange]
	6142040464 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6142040320 -> 6142040464
	6142040320 -> 6139974880 [dir=none]
	6139974880 [label="input
 (1, 2304, 23, 23)" fillcolor=orange]
	6142040320 -> 6139010704 [dir=none]
	6139010704 [label="weight
 (2304, 1, 5, 5)" fillcolor=orange]
	6142040320 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           2304
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142040032 -> 6142040320
	6142040032 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6141524032 -> 6142040032
	6141524032 [label=SwishImplementationBackward]
	6142039552 -> 6141524032
	6142039552 -> 6139972640 [dir=none]
	6139972640 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6142039552 -> 11134881840 [dir=none]
	11134881840 [label="result1
 (2304)" fillcolor=orange]
	6142039552 -> 11134881920 [dir=none]
	11134881920 [label="result2
 (2304)" fillcolor=orange]
	6142039552 -> 6139009904 [dir=none]
	6139009904 [label="running_mean
 (2304)" fillcolor=orange]
	6142039552 -> 6139010224 [dir=none]
	6139010224 [label="running_var
 (2304)" fillcolor=orange]
	6142039552 -> 6139010064 [dir=none]
	6139010064 [label="weight
 (2304)" fillcolor=orange]
	6142039552 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6142039408 -> 6142039552
	6142039408 -> 6139979840 [dir=none]
	6139979840 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6142039408 -> 6139009984 [dir=none]
	6139009984 [label="weight
 (2304, 384, 1, 1)" fillcolor=orange]
	6142039408 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142042576 -> 6142039408
	6142042576 [label="AddBackward0
------------
alpha: 1"]
	6142038976 -> 6142042576
	6142038976 -> 6139977280 [dir=none]
	6139977280 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6142038976 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6142038880 -> 6142038976
	6142038880 -> 11134882240 [dir=none]
	11134882240 [label="other
 ()" fillcolor=orange]
	6142038880 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6142038736 -> 6142038880
	6142038736 -> 6139982800 [dir=none]
	6139982800 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6142038736 -> 11134882560 [dir=none]
	11134882560 [label="result1
 (384)" fillcolor=orange]
	6142038736 -> 11134882480 [dir=none]
	11134882480 [label="result2
 (384)" fillcolor=orange]
	6142038736 -> 6139009264 [dir=none]
	6139009264 [label="running_mean
 (384)" fillcolor=orange]
	6142038736 -> 6139009584 [dir=none]
	6139009584 [label="running_var
 (384)" fillcolor=orange]
	6142038736 -> 6139009424 [dir=none]
	6139009424 [label="weight
 (384)" fillcolor=orange]
	6142038736 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6142038592 -> 6142038736
	6142038592 -> 6139969840 [dir=none]
	6139969840 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6142038592 -> 6139009344 [dir=none]
	6139009344 [label="weight
 (384, 2304, 1, 1)" fillcolor=orange]
	6142038592 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142038304 -> 6142038592
	6142038304 -> 6139973120 [dir=none]
	6139973120 [label="other
 (1, 2304, 19, 19)" fillcolor=orange]
	6142038304 -> 6139971440 [dir=none]
	6139971440 [label="self
 (1, 2304, 1, 1)" fillcolor=orange]
	6142038304 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6142037968 -> 6142038304
	6142037968 -> 11134882640 [dir=none]
	11134882640 [label="result
 (1, 2304, 1, 1)" fillcolor=orange]
	6142037968 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6142037824 -> 6142037968
	6142037824 -> 6139971200 [dir=none]
	6139971200 [label="input
 (1, 96, 1, 1)" fillcolor=orange]
	6142037824 -> 6139009104 [dir=none]
	6139009104 [label="weight
 (2304, 96, 1, 1)" fillcolor=orange]
	6142037824 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (2304,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141523808 -> 6142037824
	6141523808 [label=SwishImplementationBackward]
	6142034464 -> 6141523808
	6142034464 -> 6137297904 [dir=none]
	6137297904 [label="input
 (1, 2304, 1, 1)" fillcolor=orange]
	6142034464 -> 6139008864 [dir=none]
	6139008864 [label="weight
 (96, 2304, 1, 1)" fillcolor=orange]
	6142034464 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (96,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142034896 -> 6142034464
	6142034896 -> 6139973120 [dir=none]
	6139973120 [label="self
 (1, 2304, 19, 19)" fillcolor=orange]
	6142034896 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 2304, 19, 19)"]
	6141523584 -> 6142034896
	6141523584 [label=SwishImplementationBackward]
	6142035712 -> 6141523584
	6142035712 -> 6139977920 [dir=none]
	6139977920 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6142035712 -> 11134883360 [dir=none]
	11134883360 [label="result1
 (2304)" fillcolor=orange]
	6142035712 -> 11134883440 [dir=none]
	11134883440 [label="result2
 (2304)" fillcolor=orange]
	6142035712 -> 6139006544 [dir=none]
	6139006544 [label="running_mean
 (2304)" fillcolor=orange]
	6142035712 -> 6139008384 [dir=none]
	6139008384 [label="running_var
 (2304)" fillcolor=orange]
	6142035712 -> 6139008144 [dir=none]
	6139008144 [label="weight
 (2304)" fillcolor=orange]
	6142035712 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6142036144 -> 6142035712
	6142036144 -> 6137297264 [dir=none]
	6137297264 [label="input
 (1, 2304, 23, 23)" fillcolor=orange]
	6142036144 -> 6139008224 [dir=none]
	6139008224 [label="weight
 (2304, 1, 5, 5)" fillcolor=orange]
	6142036144 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           2304
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142036768 -> 6142036144
	6142036768 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6141523360 -> 6142036768
	6141523360 [label=SwishImplementationBackward]
	6142037200 -> 6141523360
	6142037200 -> 6139975440 [dir=none]
	6139975440 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6142037200 -> 11134883920 [dir=none]
	11134883920 [label="result1
 (2304)" fillcolor=orange]
	6142037200 -> 11134884000 [dir=none]
	11134884000 [label="result2
 (2304)" fillcolor=orange]
	6142037200 -> 6139007424 [dir=none]
	6139007424 [label="running_mean
 (2304)" fillcolor=orange]
	6142037200 -> 6139007744 [dir=none]
	6139007744 [label="running_var
 (2304)" fillcolor=orange]
	6142037200 -> 6139007584 [dir=none]
	6139007584 [label="weight
 (2304)" fillcolor=orange]
	6142037200 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6142037536 -> 6142037200
	6142037536 -> 6139980720 [dir=none]
	6139980720 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6142037536 -> 6139007504 [dir=none]
	6139007504 [label="weight
 (2304, 384, 1, 1)" fillcolor=orange]
	6142037536 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6142039168 -> 6142037536
	6142039168 [label="AddBackward0
------------
alpha: 1"]
	6139644320 -> 6142039168
	6139644320 -> 6139979360 [dir=none]
	6139979360 [label="other
 (1, 1, 1, 1)" fillcolor=orange]
	6139644320 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	6139644752 -> 6139644320
	6139644752 -> 11134884320 [dir=none]
	11134884320 [label="other
 ()" fillcolor=orange]
	6139644752 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6139645376 -> 6139644752
	6139645376 -> 6139983680 [dir=none]
	6139983680 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6139645376 -> 11134884640 [dir=none]
	11134884640 [label="result1
 (384)" fillcolor=orange]
	6139645376 -> 11134884560 [dir=none]
	11134884560 [label="result2
 (384)" fillcolor=orange]
	6139645376 -> 6139006784 [dir=none]
	6139006784 [label="running_mean
 (384)" fillcolor=orange]
	6139645376 -> 6139007104 [dir=none]
	6139007104 [label="running_var
 (384)" fillcolor=orange]
	6139645376 -> 6139006944 [dir=none]
	6139006944 [label="weight
 (384)" fillcolor=orange]
	6139645376 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6139645472 -> 6139645376
	6139645472 -> 6139984880 [dir=none]
	6139984880 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6139645472 -> 6139006864 [dir=none]
	6139006864 [label="weight
 (384, 2304, 1, 1)" fillcolor=orange]
	6139645472 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6139646096 -> 6139645472
	6139646096 -> 6139979040 [dir=none]
	6139979040 [label="other
 (1, 2304, 19, 19)" fillcolor=orange]
	6139646096 -> 6139974080 [dir=none]
	6139974080 [label="self
 (1, 2304, 1, 1)" fillcolor=orange]
	6139646096 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6139646336 -> 6139646096
	6139646336 -> 11134884720 [dir=none]
	11134884720 [label="result
 (1, 2304, 1, 1)" fillcolor=orange]
	6139646336 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6139646768 -> 6139646336
	6139646768 -> 6139971760 [dir=none]
	6139971760 [label="input
 (1, 96, 1, 1)" fillcolor=orange]
	6139646768 -> 6139006624 [dir=none]
	6139006624 [label="weight
 (2304, 96, 1, 1)" fillcolor=orange]
	6139646768 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (2304,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141523136 -> 6139646768
	6141523136 [label=SwishImplementationBackward]
	6139647488 -> 6141523136
	6139647488 -> 6139012144 [dir=none]
	6139012144 [label="input
 (1, 2304, 1, 1)" fillcolor=orange]
	6139647488 -> 6139006384 [dir=none]
	6139006384 [label="weight
 (96, 2304, 1, 1)" fillcolor=orange]
	6139647488 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (96,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6139647920 -> 6139647488
	6139647920 -> 6139979040 [dir=none]
	6139979040 [label="self
 (1, 2304, 19, 19)" fillcolor=orange]
	6139647920 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 2304, 19, 19)"]
	6141522912 -> 6139647920
	6141522912 [label=SwishImplementationBackward]
	6139648736 -> 6141522912
	6139648736 -> 6139983120 [dir=none]
	6139983120 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6139648736 -> 11134885440 [dir=none]
	11134885440 [label="result1
 (2304)" fillcolor=orange]
	6139648736 -> 11134885520 [dir=none]
	11134885520 [label="result2
 (2304)" fillcolor=orange]
	6139648736 -> 6139004144 [dir=none]
	6139004144 [label="running_mean
 (2304)" fillcolor=orange]
	6139648736 -> 6139005984 [dir=none]
	6139005984 [label="running_var
 (2304)" fillcolor=orange]
	6139648736 -> 6139005744 [dir=none]
	6139005744 [label="weight
 (2304)" fillcolor=orange]
	6139648736 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6139649168 -> 6139648736
	6139649168 -> 6139983440 [dir=none]
	6139983440 [label="input
 (1, 2304, 23, 23)" fillcolor=orange]
	6139649168 -> 6139005824 [dir=none]
	6139005824 [label="weight
 (2304, 1, 5, 5)" fillcolor=orange]
	6139649168 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           2304
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6139649888 -> 6139649168
	6139649888 [label="ConstantPadNdBackward0
----------------------
pad: (2, 2, 2, 2)"]
	6141522688 -> 6139649888
	6141522688 [label=SwishImplementationBackward]
	6139650800 -> 6141522688
	6139650800 -> 6139970320 [dir=none]
	6139970320 [label="input
 (1, 2304, 19, 19)" fillcolor=orange]
	6139650800 -> 11134886000 [dir=none]
	11134886000 [label="result1
 (2304)" fillcolor=orange]
	6139650800 -> 11134886080 [dir=none]
	11134886080 [label="result2
 (2304)" fillcolor=orange]
	6139650800 -> 6139005024 [dir=none]
	6139005024 [label="running_mean
 (2304)" fillcolor=orange]
	6139650800 -> 6139005344 [dir=none]
	6139005344 [label="running_var
 (2304)" fillcolor=orange]
	6139650800 -> 6139005184 [dir=none]
	6139005184 [label="weight
 (2304)" fillcolor=orange]
	6139650800 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6139650896 -> 6139650800
	6139650896 -> 6139974560 [dir=none]
	6139974560 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6139650896 -> 6139005104 [dir=none]
	6139005104 [label="weight
 (2304, 384, 1, 1)" fillcolor=orange]
	6139650896 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6139644272 -> 6139650896
	6139644272 -> 6139985120 [dir=none]
	6139985120 [label="input
 (1, 384, 19, 19)" fillcolor=orange]
	6139644272 -> 11134885760 [dir=none]
	11134885760 [label="result1
 (384)" fillcolor=orange]
	6139644272 -> 11134885680 [dir=none]
	11134885680 [label="result2
 (384)" fillcolor=orange]
	6139644272 -> 6139004384 [dir=none]
	6139004384 [label="running_mean
 (384)" fillcolor=orange]
	6139644272 -> 6139004704 [dir=none]
	6139004704 [label="running_var
 (384)" fillcolor=orange]
	6139644272 -> 6139004544 [dir=none]
	6139004544 [label="weight
 (384)" fillcolor=orange]
	6139644272 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6139652048 -> 6139644272
	6139652048 -> 6139970080 [dir=none]
	6139970080 [label="input
 (1, 1344, 19, 19)" fillcolor=orange]
	6139652048 -> 6139004464 [dir=none]
	6139004464 [label="weight
 (384, 1344, 1, 1)" fillcolor=orange]
	6139652048 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6139652672 -> 6139652048
	6139652672 -> 6139973520 [dir=none]
	6139973520 [label="other
 (1, 1344, 19, 19)" fillcolor=orange]
	6139652672 -> 6139981440 [dir=none]
	6139981440 [label="self
 (1, 1344, 1, 1)" fillcolor=orange]
	6139652672 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	6139652912 -> 6139652672
	6139652912 -> 11134886480 [dir=none]
	11134886480 [label="result
 (1, 1344, 1, 1)" fillcolor=orange]
	6139652912 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	6139653104 -> 6139652912
	6139653104 -> 6139972400 [dir=none]
	6139972400 [label="input
 (1, 56, 1, 1)" fillcolor=orange]
	6139653104 -> 6139004224 [dir=none]
	6139004224 [label="weight
 (1344, 56, 1, 1)" fillcolor=orange]
	6139653104 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:        (1344,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141522464 -> 6139653104
	6141522464 [label=SwishImplementationBackward]
	6139654064 -> 6141522464
	6139654064 -> 6139982160 [dir=none]
	6139982160 [label="input
 (1, 1344, 1, 1)" fillcolor=orange]
	6139654064 -> 6139003984 [dir=none]
	6139003984 [label="weight
 (56, 1344, 1, 1)" fillcolor=orange]
	6139654064 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:          (56,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6139654160 -> 6139654064
	6139654160 -> 6139973520 [dir=none]
	6139973520 [label="self
 (1, 1344, 19, 19)" fillcolor=orange]
	6139654160 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self          :                               [saved tensor]
self_sym_sizes:                            (1, 1344, 19, 19)"]
	6141522240 -> 6139654160
	6141522240 [label=SwishImplementationBackward]
	6139655312 -> 6141522240
	6139655312 -> 6137284064 [dir=none]
	6137284064 [label="input
 (1, 1344, 19, 19)" fillcolor=orange]
	6139655312 -> 11134887200 [dir=none]
	11134887200 [label="result1
 (1344)" fillcolor=orange]
	6139655312 -> 11134887280 [dir=none]
	11134887280 [label="result2
 (1344)" fillcolor=orange]
	6139655312 -> 6138739536 [dir=none]
	6138739536 [label="running_mean
 (1344)" fillcolor=orange]
	6139655312 -> 6139003504 [dir=none]
	6139003504 [label="running_var
 (1344)" fillcolor=orange]
	6139655312 -> 6139003264 [dir=none]
	6139003264 [label="weight
 (1344)" fillcolor=orange]
	6139655312 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6139655408 -> 6139655312
	6139655408 -> 6137282864 [dir=none]
	6137282864 [label="input
 (1, 1344, 41, 41)" fillcolor=orange]
	6139655408 -> 6139003344 [dir=none]
	6139003344 [label="weight
 (1344, 1, 5, 5)" fillcolor=orange]
	6139655408 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :           1344
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	6139656128 -> 6139655408
	6139656128 [label="ConstantPadNdBackward0
----------------------
pad: (1, 2, 1, 2)"]
	6141522016 -> 6139656128
	6141522016 [label=SwishImplementationBackward]
	6139657040 -> 6141522016
	6139657040 -> 6140167248 [dir=none]
	6140167248 [label="input
 (1, 1344, 38, 38)" fillcolor=orange]
	6139657040 -> 11136017376 [dir=none]
	11136017376 [label="result1
 (1344)" fillcolor=orange]
	6139657040 -> 11134887520 [dir=none]
	11134887520 [label="result2
 (1344)" fillcolor=orange]
	6139657040 -> 6138740416 [dir=none]
	6138740416 [label="running_mean
 (1344)" fillcolor=orange]
	6139657040 -> 6139002944 [dir=none]
	6139002944 [label="running_var
 (1344)" fillcolor=orange]
	6139657040 -> 6138740576 [dir=none]
	6138740576 [label="weight
 (1344)" fillcolor=orange]
	6139657040 [label="NativeBatchNormBackward0
----------------------------
eps         :          0.001
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6139657472 -> 6139657040
	6139657472 -> 6140166368 [dir=none]
	6140166368 [label="input
 (1, 224, 38, 38)" fillcolor=orange]
	6139657472 -> 6138740496 [dir=none]
	6138740496 [label="weight
 (1344, 224, 1, 1)" fillcolor=orange]
	6139657472 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141576576 -> 6139657472
	6139658192 -> 6139657472
	6138740496 [label="
 (1344, 224, 1, 1)" fillcolor=lightblue]
	6138740496 -> 6139658192
	6139658192 [label=AccumulateGrad]
	6139657088 -> 6139657040
	6138740576 [label="
 (1344)" fillcolor=lightblue]
	6138740576 -> 6139657088
	6139657088 [label=AccumulateGrad]
	6139656512 -> 6139657040
	6138740656 [label="
 (1344)" fillcolor=lightblue]
	6138740656 -> 6139656512
	6139656512 [label=AccumulateGrad]
	6137283984 -> 6141522016
	6137283984 [label="
 (1, 1344, 38, 38)" fillcolor=orange]
	6139656416 -> 6139655408
	6139003344 [label="
 (1344, 1, 5, 5)" fillcolor=lightblue]
	6139003344 -> 6139656416
	6139656416 [label=AccumulateGrad]
	6139655696 -> 6139655312
	6139003264 [label="
 (1344)" fillcolor=lightblue]
	6139003264 -> 6139655696
	6139655696 [label=AccumulateGrad]
	6139654688 -> 6139655312
	6139003424 [label="
 (1344)" fillcolor=lightblue]
	6139003424 -> 6139654688
	6139654688 [label=AccumulateGrad]
	6139983920 -> 6141522240
	6139983920 [label="
 (1, 1344, 19, 19)" fillcolor=orange]
	6139654448 -> 6139654064
	6139003984 [label="
 (56, 1344, 1, 1)" fillcolor=lightblue]
	6139003984 -> 6139654448
	6139654448 [label=AccumulateGrad]
	6139653632 -> 6139654064
	6139004064 [label="
 (56)" fillcolor=lightblue]
	6139004064 -> 6139653632
	6139653632 [label=AccumulateGrad]
	6139980400 -> 6141522464
	6139980400 [label="
 (1, 56, 1, 1)" fillcolor=orange]
	6139653440 -> 6139653104
	6139004224 [label="
 (1344, 56, 1, 1)" fillcolor=lightblue]
	6139004224 -> 6139653440
	6139653440 [label=AccumulateGrad]
	6139653392 -> 6139653104
	6139004304 [label="
 (1344)" fillcolor=lightblue]
	6139004304 -> 6139653392
	6139653392 [label=AccumulateGrad]
	6141522240 -> 6139652672
	6139652192 -> 6139652048
	6139004464 [label="
 (384, 1344, 1, 1)" fillcolor=lightblue]
	6139004464 -> 6139652192
	6139652192 [label=AccumulateGrad]
	6139651664 -> 6139644272
	6139004544 [label="
 (384)" fillcolor=lightblue]
	6139004544 -> 6139651664
	6139651664 [label=AccumulateGrad]
	6139651424 -> 6139644272
	6139004624 [label="
 (384)" fillcolor=lightblue]
	6139004624 -> 6139651424
	6139651424 [label=AccumulateGrad]
	6139651616 -> 6139650896
	6139005104 [label="
 (2304, 384, 1, 1)" fillcolor=lightblue]
	6139005104 -> 6139651616
	6139651616 [label=AccumulateGrad]
	6139650512 -> 6139650800
	6139005184 [label="
 (2304)" fillcolor=lightblue]
	6139005184 -> 6139650512
	6139650512 [label=AccumulateGrad]
	6139650176 -> 6139650800
	6139005264 [label="
 (2304)" fillcolor=lightblue]
	6139005264 -> 6139650176
	6139650176 [label=AccumulateGrad]
	6139984160 -> 6141522688
	6139984160 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6139649840 -> 6139649168
	6139005824 [label="
 (2304, 1, 5, 5)" fillcolor=lightblue]
	6139005824 -> 6139649840
	6139649840 [label=AccumulateGrad]
	6139649120 -> 6139648736
	6139005744 [label="
 (2304)" fillcolor=lightblue]
	6139005744 -> 6139649120
	6139649120 [label=AccumulateGrad]
	6139648112 -> 6139648736
	6139005904 [label="
 (2304)" fillcolor=lightblue]
	6139005904 -> 6139648112
	6139648112 [label=AccumulateGrad]
	6139980080 -> 6141522912
	6139980080 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6139647872 -> 6139647488
	6139006384 [label="
 (96, 2304, 1, 1)" fillcolor=lightblue]
	6139006384 -> 6139647872
	6139647872 [label=AccumulateGrad]
	6139647296 -> 6139647488
	6139006464 [label="
 (96)" fillcolor=lightblue]
	6139006464 -> 6139647296
	6139647296 [label=AccumulateGrad]
	6139979600 -> 6141523136
	6139979600 [label="
 (1, 96, 1, 1)" fillcolor=orange]
	6139646864 -> 6139646768
	6139006624 [label="
 (2304, 96, 1, 1)" fillcolor=lightblue]
	6139006624 -> 6139646864
	6139646864 [label=AccumulateGrad]
	6139647152 -> 6139646768
	6139006704 [label="
 (2304)" fillcolor=lightblue]
	6139006704 -> 6139647152
	6139647152 [label=AccumulateGrad]
	6141522912 -> 6139646096
	6139645616 -> 6139645472
	6139006864 [label="
 (384, 2304, 1, 1)" fillcolor=lightblue]
	6139006864 -> 6139645616
	6139645616 [label=AccumulateGrad]
	6139644992 -> 6139645376
	6139006944 [label="
 (384)" fillcolor=lightblue]
	6139006944 -> 6139644992
	6139644992 [label=AccumulateGrad]
	6139644608 -> 6139645376
	6139007024 [label="
 (384)" fillcolor=lightblue]
	6139007024 -> 6139644608
	6139644608 [label=AccumulateGrad]
	6139644272 -> 6142039168
	6139643936 -> 6142037536
	6139007504 [label="
 (2304, 384, 1, 1)" fillcolor=lightblue]
	6139007504 -> 6139643936
	6139643936 [label=AccumulateGrad]
	6142037488 -> 6142037200
	6139007584 [label="
 (2304)" fillcolor=lightblue]
	6139007584 -> 6142037488
	6142037488 [label=AccumulateGrad]
	6142036480 -> 6142037200
	6139007664 [label="
 (2304)" fillcolor=lightblue]
	6139007664 -> 6142036480
	6142036480 [label=AccumulateGrad]
	6139976640 -> 6141523360
	6139976640 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6142036288 -> 6142036144
	6139008224 [label="
 (2304, 1, 5, 5)" fillcolor=lightblue]
	6139008224 -> 6142036288
	6142036288 [label=AccumulateGrad]
	6142035760 -> 6142035712
	6139008144 [label="
 (2304)" fillcolor=lightblue]
	6139008144 -> 6142035760
	6142035760 [label=AccumulateGrad]
	6142034992 -> 6142035712
	6139008304 [label="
 (2304)" fillcolor=lightblue]
	6139008304 -> 6142034992
	6142034992 [label=AccumulateGrad]
	6139976960 -> 6141523584
	6139976960 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6142034512 -> 6142034464
	6139008864 [label="
 (96, 2304, 1, 1)" fillcolor=lightblue]
	6139008864 -> 6142034512
	6142034512 [label=AccumulateGrad]
	6142034272 -> 6142034464
	6139008944 [label="
 (96)" fillcolor=lightblue]
	6139008944 -> 6142034272
	6142034272 [label=AccumulateGrad]
	6139974320 -> 6141523808
	6139974320 [label="
 (1, 96, 1, 1)" fillcolor=orange]
	6142033984 -> 6142037824
	6139009104 [label="
 (2304, 96, 1, 1)" fillcolor=lightblue]
	6139009104 -> 6142033984
	6142033984 [label=AccumulateGrad]
	6142037872 -> 6142037824
	6139009184 [label="
 (2304)" fillcolor=lightblue]
	6139009184 -> 6142037872
	6142037872 [label=AccumulateGrad]
	6141523584 -> 6142038304
	6142038256 -> 6142038592
	6139009344 [label="
 (384, 2304, 1, 1)" fillcolor=lightblue]
	6139009344 -> 6142038256
	6142038256 [label=AccumulateGrad]
	6142038544 -> 6142038736
	6139009424 [label="
 (384)" fillcolor=lightblue]
	6139009424 -> 6142038544
	6142038544 [label=AccumulateGrad]
	6142039024 -> 6142038736
	6139009504 [label="
 (384)" fillcolor=lightblue]
	6139009504 -> 6142039024
	6142039024 [label=AccumulateGrad]
	6142039168 -> 6142042576
	6142039120 -> 6142039408
	6139009984 [label="
 (2304, 384, 1, 1)" fillcolor=lightblue]
	6139009984 -> 6142039120
	6142039120 [label=AccumulateGrad]
	6142039600 -> 6142039552
	6139010064 [label="
 (2304)" fillcolor=lightblue]
	6139010064 -> 6142039600
	6142039600 [label=AccumulateGrad]
	6142039840 -> 6142039552
	6139010144 [label="
 (2304)" fillcolor=lightblue]
	6139010144 -> 6142039840
	6142039840 [label=AccumulateGrad]
	6139972880 -> 6141524032
	6139972880 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6142039984 -> 6142040320
	6139010704 [label="
 (2304, 1, 5, 5)" fillcolor=lightblue]
	6139010704 -> 6142039984
	6142039984 [label=AccumulateGrad]
	6142040272 -> 6142040464
	6139010624 [label="
 (2304)" fillcolor=lightblue]
	6139010624 -> 6142040272
	6142040272 [label=AccumulateGrad]
	6142040752 -> 6142040464
	6139010784 [label="
 (2304)" fillcolor=lightblue]
	6139010784 -> 6142040752
	6142040752 [label=AccumulateGrad]
	6139970960 -> 6141524256
	6139970960 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6142040848 -> 6142041040
	6139011344 [label="
 (96, 2304, 1, 1)" fillcolor=lightblue]
	6139011344 -> 6142040848
	6142040848 [label=AccumulateGrad]
	6142041184 -> 6142041040
	6139011424 [label="
 (96)" fillcolor=lightblue]
	6139011424 -> 6142041184
	6142041184 [label=AccumulateGrad]
	6139985600 -> 6141524480
	6139985600 [label="
 (1, 96, 1, 1)" fillcolor=orange]
	6142041328 -> 6142041472
	6139011584 [label="
 (2304, 96, 1, 1)" fillcolor=lightblue]
	6139011584 -> 6142041328
	6142041328 [label=AccumulateGrad]
	6142041280 -> 6142041472
	6139011664 [label="
 (2304)" fillcolor=lightblue]
	6139011664 -> 6142041280
	6142041280 [label=AccumulateGrad]
	6141524256 -> 6142041712
	6142041904 -> 6142042000
	6139011824 [label="
 (384, 2304, 1, 1)" fillcolor=lightblue]
	6139011824 -> 6142041904
	6142041904 [label=AccumulateGrad]
	6142042192 -> 6142042144
	6139011904 [label="
 (384)" fillcolor=lightblue]
	6139011904 -> 6142042192
	6142042192 [label=AccumulateGrad]
	6142042432 -> 6142042144
	6139011984 [label="
 (384)" fillcolor=lightblue]
	6139011984 -> 6142042432
	6142042432 [label=AccumulateGrad]
	6142042576 -> 6142046224
	6142042768 -> 6142043056
	6139012464 [label="
 (2304, 384, 1, 1)" fillcolor=lightblue]
	6139012464 -> 6142042768
	6142042768 [label=AccumulateGrad]
	6142043008 -> 6142043200
	6139012544 [label="
 (2304)" fillcolor=lightblue]
	6139012544 -> 6142043008
	6142043008 [label=AccumulateGrad]
	6142043488 -> 6142043200
	6139012624 [label="
 (2304)" fillcolor=lightblue]
	6139012624 -> 6142043488
	6142043488 [label=AccumulateGrad]
	6139975680 -> 6141524704
	6139975680 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6142043632 -> 6142043728
	6139013184 [label="
 (2304, 1, 5, 5)" fillcolor=lightblue]
	6139013184 -> 6142043632
	6142043632 [label=AccumulateGrad]
	6142043920 -> 6142043872
	6139013104 [label="
 (2304)" fillcolor=lightblue]
	6139013104 -> 6142043920
	6142043920 [label=AccumulateGrad]
	6142044160 -> 6142043872
	6139013264 [label="
 (2304)" fillcolor=lightblue]
	6139013264 -> 6142044160
	6142044160 [label=AccumulateGrad]
	6139975200 -> 6141524928
	6139975200 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6142044496 -> 6142044448
	6139013824 [label="
 (96, 2304, 1, 1)" fillcolor=lightblue]
	6139013824 -> 6142044496
	6142044496 [label=AccumulateGrad]
	6142044592 -> 6142044448
	6139013904 [label="
 (96)" fillcolor=lightblue]
	6139013904 -> 6142044592
	6142044592 [label=AccumulateGrad]
	6139985760 -> 6141525152
	6139985760 [label="
 (1, 96, 1, 1)" fillcolor=orange]
	6142044736 -> 6142044880
	6139014064 [label="
 (2304, 96, 1, 1)" fillcolor=lightblue]
	6139014064 -> 6142044736
	6142044736 [label=AccumulateGrad]
	6142044928 -> 6142044880
	6139014144 [label="
 (2304)" fillcolor=lightblue]
	6139014144 -> 6142044928
	6142044928 [label=AccumulateGrad]
	6141524928 -> 6142045360
	6142045312 -> 6142045648
	6139014304 [label="
 (384, 2304, 1, 1)" fillcolor=lightblue]
	6139014304 -> 6142045312
	6142045312 [label=AccumulateGrad]
	6142045600 -> 6142045792
	6139014384 [label="
 (384)" fillcolor=lightblue]
	6139014384 -> 6142045600
	6142045600 [label=AccumulateGrad]
	6142046080 -> 6142045792
	6139014464 [label="
 (384)" fillcolor=lightblue]
	6139014464 -> 6142046080
	6142046080 [label=AccumulateGrad]
	6142046224 -> 6142049632
	6142046176 -> 6142046464
	6139014944 [label="
 (2304, 384, 1, 1)" fillcolor=lightblue]
	6139014944 -> 6142046176
	6142046176 [label=AccumulateGrad]
	6142046656 -> 6142046608
	6139015024 [label="
 (2304)" fillcolor=lightblue]
	6139015024 -> 6142046656
	6142046656 [label=AccumulateGrad]
	6142046896 -> 6142046608
	6139015104 [label="
 (2304)" fillcolor=lightblue]
	6139015104 -> 6142046896
	6142046896 [label=AccumulateGrad]
	6139984320 -> 6141525376
	6139984320 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6142047040 -> 6142047376
	6139015664 [label="
 (2304, 1, 5, 5)" fillcolor=lightblue]
	6139015664 -> 6142047040
	6142047040 [label=AccumulateGrad]
	6142047328 -> 6142047520
	6139015584 [label="
 (2304)" fillcolor=lightblue]
	6139015584 -> 6142047328
	6142047328 [label=AccumulateGrad]
	6142047808 -> 6142047520
	6139015744 [label="
 (2304)" fillcolor=lightblue]
	6139015744 -> 6142047808
	6142047808 [label=AccumulateGrad]
	6139984240 -> 6141525600
	6139984240 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	6142047904 -> 6142048096
	6139016304 [label="
 (96, 2304, 1, 1)" fillcolor=lightblue]
	6139016304 -> 6142047904
	6142047904 [label=AccumulateGrad]
	6142048240 -> 6142048096
	6139016384 [label="
 (96)" fillcolor=lightblue]
	6139016384 -> 6142048240
	6142048240 [label=AccumulateGrad]
	6139984000 -> 6142066752
	6139984000 [label="
 (1, 96, 1, 1)" fillcolor=orange]
	6142048384 -> 6142048528
	6139016544 [label="
 (2304, 96, 1, 1)" fillcolor=lightblue]
	6139016544 -> 6142048384
	6142048384 [label=AccumulateGrad]
	6142048336 -> 6142048528
	6139016624 [label="
 (2304)" fillcolor=lightblue]
	6139016624 -> 6142048336
	6142048336 [label=AccumulateGrad]
	6141525600 -> 6142048768
	6142048960 -> 6142049056
	6139016784 [label="
 (384, 2304, 1, 1)" fillcolor=lightblue]
	6139016784 -> 6142048960
	6142048960 [label=AccumulateGrad]
	6142049248 -> 6142049200
	6139016864 [label="
 (384)" fillcolor=lightblue]
	6139016864 -> 6142049248
	6142049248 [label=AccumulateGrad]
	6142049488 -> 6142049200
	6139016944 [label="
 (384)" fillcolor=lightblue]
	6139016944 -> 6142049488
	6142049488 [label=AccumulateGrad]
	6142049632 -> 11135601632
	6142049824 -> 6142050112
	6139017424 [label="
 (2304, 384, 1, 1)" fillcolor=lightblue]
	6139017424 -> 6142049824
	6142049824 [label=AccumulateGrad]
	6142050064 -> 11135598896
	6139017504 [label="
 (2304)" fillcolor=lightblue]
	6139017504 -> 6142050064
	6142050064 [label=AccumulateGrad]
	6142050208 -> 11135598896
	6139017584 [label="
 (2304)" fillcolor=lightblue]
	6139017584 -> 6142050208
	6142050208 [label=AccumulateGrad]
	6139982320 -> 6142066976
	6139982320 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	11135599040 -> 11135599136
	6139018144 [label="
 (2304, 1, 5, 5)" fillcolor=lightblue]
	6139018144 -> 11135599040
	11135599040 [label=AccumulateGrad]
	11135599328 -> 11135599280
	6139018064 [label="
 (2304)" fillcolor=lightblue]
	6139018064 -> 11135599328
	11135599328 [label=AccumulateGrad]
	11135599568 -> 11135599280
	6139018224 [label="
 (2304)" fillcolor=lightblue]
	6139018224 -> 11135599568
	11135599568 [label=AccumulateGrad]
	6139982240 -> 6142067200
	6139982240 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	11135599904 -> 11135599856
	6139018784 [label="
 (96, 2304, 1, 1)" fillcolor=lightblue]
	6139018784 -> 11135599904
	11135599904 [label=AccumulateGrad]
	11135600000 -> 11135599856
	6139018864 [label="
 (96)" fillcolor=lightblue]
	6139018864 -> 11135600000
	11135600000 [label=AccumulateGrad]
	6139981920 -> 6142067424
	6139981920 [label="
 (1, 96, 1, 1)" fillcolor=orange]
	11135600144 -> 11135600288
	6139019024 [label="
 (2304, 96, 1, 1)" fillcolor=lightblue]
	6139019024 -> 11135600144
	11135600144 [label=AccumulateGrad]
	11135600336 -> 11135600288
	6139019104 [label="
 (2304)" fillcolor=lightblue]
	6139019104 -> 11135600336
	11135600336 [label=AccumulateGrad]
	6142067200 -> 11135600768
	11135600720 -> 11135601056
	6139265088 [label="
 (384, 2304, 1, 1)" fillcolor=lightblue]
	6139265088 -> 11135600720
	11135600720 [label=AccumulateGrad]
	11135601008 -> 11135601200
	6139265168 [label="
 (384)" fillcolor=lightblue]
	6139265168 -> 11135601008
	11135601008 [label=AccumulateGrad]
	11135601488 -> 11135601200
	6139265248 [label="
 (384)" fillcolor=lightblue]
	6139265248 -> 11135601488
	11135601488 [label=AccumulateGrad]
	11135601632 -> 11135605040
	11135601584 -> 11135601872
	6139265728 [label="
 (2304, 384, 1, 1)" fillcolor=lightblue]
	6139265728 -> 11135601584
	11135601584 [label=AccumulateGrad]
	11135602064 -> 11135602016
	6139265808 [label="
 (2304)" fillcolor=lightblue]
	6139265808 -> 11135602064
	11135602064 [label=AccumulateGrad]
	11135602304 -> 11135602016
	6139265888 [label="
 (2304)" fillcolor=lightblue]
	6139265888 -> 11135602304
	11135602304 [label=AccumulateGrad]
	6139980480 -> 6142067648
	6139980480 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	11135602448 -> 11135602784
	6139266368 [label="
 (2304, 1, 5, 5)" fillcolor=lightblue]
	6139266368 -> 11135602448
	11135602448 [label=AccumulateGrad]
	11135602736 -> 11135602928
	6139266288 [label="
 (2304)" fillcolor=lightblue]
	6139266288 -> 11135602736
	11135602736 [label=AccumulateGrad]
	11135603216 -> 11135602928
	6139266448 [label="
 (2304)" fillcolor=lightblue]
	6139266448 -> 11135603216
	11135603216 [label=AccumulateGrad]
	6139980240 -> 6142067872
	6139980240 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	11135603312 -> 11135603504
	6139266928 [label="
 (96, 2304, 1, 1)" fillcolor=lightblue]
	6139266928 -> 11135603312
	11135603312 [label=AccumulateGrad]
	11135603648 -> 11135603504
	6139267008 [label="
 (96)" fillcolor=lightblue]
	6139267008 -> 11135603648
	11135603648 [label=AccumulateGrad]
	6139980000 -> 6142068096
	6139980000 [label="
 (1, 96, 1, 1)" fillcolor=orange]
	11135603792 -> 11135603936
	6139267168 [label="
 (2304, 96, 1, 1)" fillcolor=lightblue]
	6139267168 -> 11135603792
	11135603792 [label=AccumulateGrad]
	11135603744 -> 11135603936
	6139267248 [label="
 (2304)" fillcolor=lightblue]
	6139267248 -> 11135603744
	11135603744 [label=AccumulateGrad]
	6142067872 -> 11135604176
	11135604368 -> 11135604464
	6139267408 [label="
 (384, 2304, 1, 1)" fillcolor=lightblue]
	6139267408 -> 11135604368
	11135604368 [label=AccumulateGrad]
	11135604656 -> 11135604608
	6139267488 [label="
 (384)" fillcolor=lightblue]
	6139267488 -> 11135604656
	11135604656 [label=AccumulateGrad]
	11135604896 -> 11135604608
	6139267568 [label="
 (384)" fillcolor=lightblue]
	6139267568 -> 11135604896
	11135604896 [label=AccumulateGrad]
	11135605040 -> 11135608688
	11135605232 -> 11135605520
	6139268048 [label="
 (2304, 384, 1, 1)" fillcolor=lightblue]
	6139268048 -> 11135605232
	11135605232 [label=AccumulateGrad]
	11135605472 -> 11135605664
	6139268128 [label="
 (2304)" fillcolor=lightblue]
	6139268128 -> 11135605472
	11135605472 [label=AccumulateGrad]
	11135605952 -> 11135605664
	6139268208 [label="
 (2304)" fillcolor=lightblue]
	6139268208 -> 11135605952
	11135605952 [label=AccumulateGrad]
	6139978560 -> 6142068320
	6139978560 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	11135606096 -> 11135606192
	6139268768 [label="
 (2304, 1, 5, 5)" fillcolor=lightblue]
	6139268768 -> 11135606096
	11135606096 [label=AccumulateGrad]
	11135606384 -> 11135606336
	6139268688 [label="
 (2304)" fillcolor=lightblue]
	6139268688 -> 11135606384
	11135606384 [label=AccumulateGrad]
	11135606624 -> 11135606336
	6139268848 [label="
 (2304)" fillcolor=lightblue]
	6139268848 -> 11135606624
	11135606624 [label=AccumulateGrad]
	6139978480 -> 6142068544
	6139978480 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	11135606960 -> 11135606912
	6139269408 [label="
 (96, 2304, 1, 1)" fillcolor=lightblue]
	6139269408 -> 11135606960
	11135606960 [label=AccumulateGrad]
	11135607056 -> 11135606912
	6139269488 [label="
 (96)" fillcolor=lightblue]
	6139269488 -> 11135607056
	11135607056 [label=AccumulateGrad]
	6139978240 -> 6142068768
	6139978240 [label="
 (1, 96, 1, 1)" fillcolor=orange]
	11135607200 -> 11135607344
	6139269648 [label="
 (2304, 96, 1, 1)" fillcolor=lightblue]
	6139269648 -> 11135607200
	11135607200 [label=AccumulateGrad]
	11135607392 -> 11135607344
	6139269728 [label="
 (2304)" fillcolor=lightblue]
	6139269728 -> 11135607392
	11135607392 [label=AccumulateGrad]
	6142068544 -> 11135607824
	11135607776 -> 11135608112
	6139269888 [label="
 (384, 2304, 1, 1)" fillcolor=lightblue]
	6139269888 -> 11135607776
	11135607776 [label=AccumulateGrad]
	11135608064 -> 11135608256
	6139269968 [label="
 (384)" fillcolor=lightblue]
	6139269968 -> 11135608064
	11135608064 [label=AccumulateGrad]
	11135608544 -> 11135608256
	6139270048 [label="
 (384)" fillcolor=lightblue]
	6139270048 -> 11135608544
	11135608544 [label=AccumulateGrad]
	11135608688 -> 11135613872
	11135608640 -> 11135608928
	6139270528 [label="
 (2304, 384, 1, 1)" fillcolor=lightblue]
	6139270528 -> 11135608640
	11135608640 [label=AccumulateGrad]
	11135609120 -> 11135609072
	6139270608 [label="
 (2304)" fillcolor=lightblue]
	6139270608 -> 11135609120
	11135609120 [label=AccumulateGrad]
	11135609360 -> 11135609072
	6139270688 [label="
 (2304)" fillcolor=lightblue]
	6139270688 -> 11135609360
	11135609360 [label=AccumulateGrad]
	6139976560 -> 6142068992
	6139976560 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	11135609504 -> 11135609840
	6139271248 [label="
 (2304, 1, 5, 5)" fillcolor=lightblue]
	6139271248 -> 11135609504
	11135609504 [label=AccumulateGrad]
	11135609792 -> 11135609984
	6139271168 [label="
 (2304)" fillcolor=lightblue]
	6139271168 -> 11135609792
	11135609792 [label=AccumulateGrad]
	11135610272 -> 11135609984
	6139271328 [label="
 (2304)" fillcolor=lightblue]
	6139271328 -> 11135610272
	11135610272 [label=AccumulateGrad]
	6139976400 -> 6142069216
	6139976400 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	11135610368 -> 11135610560
	6139271888 [label="
 (96, 2304, 1, 1)" fillcolor=lightblue]
	6139271888 -> 11135610368
	11135610368 [label=AccumulateGrad]
	11135610704 -> 11135610560
	6139271968 [label="
 (96)" fillcolor=lightblue]
	6139271968 -> 11135610704
	11135610704 [label=AccumulateGrad]
	6139976080 -> 6142069440
	6139976080 [label="
 (1, 96, 1, 1)" fillcolor=orange]
	11135610848 -> 11135610992
	6139272128 [label="
 (2304, 96, 1, 1)" fillcolor=lightblue]
	6139272128 -> 11135610848
	11135610848 [label=AccumulateGrad]
	11135610800 -> 11135610992
	6139272208 [label="
 (2304)" fillcolor=lightblue]
	6139272208 -> 11135610800
	11135610800 [label=AccumulateGrad]
	6142069216 -> 11135611232
	11135611280 -> 11135611808
	6139272368 [label="
 (384, 2304, 1, 1)" fillcolor=lightblue]
	6139272368 -> 11135611280
	11135611280 [label=AccumulateGrad]
	11135611520 -> 11135612240
	6139272448 [label="
 (384)" fillcolor=lightblue]
	6139272448 -> 11135611520
	11135611520 [label=AccumulateGrad]
	11135613008 -> 11135612240
	6139272528 [label="
 (384)" fillcolor=lightblue]
	6139272528 -> 11135613008
	11135613008 [label=AccumulateGrad]
	11135613872 -> 11135688688
	11135613728 -> 11135614400
	6139273008 [label="
 (2304, 384, 1, 1)" fillcolor=lightblue]
	6139273008 -> 11135613728
	11135613728 [label=AccumulateGrad]
	11135614880 -> 11135680624
	6139273088 [label="
 (2304)" fillcolor=lightblue]
	6139273088 -> 11135614880
	11135614880 [label=AccumulateGrad]
	11135614544 -> 11135680624
	6139273168 [label="
 (2304)" fillcolor=lightblue]
	6139273168 -> 11135614544
	11135614544 [label=AccumulateGrad]
	6139974640 -> 6142069664
	6139974640 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	11135681632 -> 11135682352
	6139273728 [label="
 (2304, 1, 5, 5)" fillcolor=lightblue]
	6139273728 -> 11135681632
	11135681632 [label=AccumulateGrad]
	11135682448 -> 11135682784
	6139273648 [label="
 (2304)" fillcolor=lightblue]
	6139273648 -> 11135682448
	11135682448 [label=AccumulateGrad]
	11135683024 -> 11135682784
	6139273808 [label="
 (2304)" fillcolor=lightblue]
	6139273808 -> 11135683024
	11135683024 [label=AccumulateGrad]
	6139974480 -> 6142069888
	6139974480 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	11135684080 -> 11135683792
	6139274288 [label="
 (96, 2304, 1, 1)" fillcolor=lightblue]
	6139274288 -> 11135684080
	11135684080 [label=AccumulateGrad]
	11135684464 -> 11135683792
	6139274368 [label="
 (96)" fillcolor=lightblue]
	6139274368 -> 11135684464
	11135684464 [label=AccumulateGrad]
	6139974240 -> 6142070112
	6139974240 [label="
 (1, 96, 1, 1)" fillcolor=orange]
	11135684944 -> 11135685328
	6139274528 [label="
 (2304, 96, 1, 1)" fillcolor=lightblue]
	6139274528 -> 11135684944
	11135684944 [label=AccumulateGrad]
	11135685040 -> 11135685328
	6139274608 [label="
 (2304)" fillcolor=lightblue]
	6139274608 -> 11135685040
	11135685040 [label=AccumulateGrad]
	6142069888 -> 11135686384
	11135687248 -> 11135687056
	6139274768 [label="
 (384, 2304, 1, 1)" fillcolor=lightblue]
	6139274768 -> 11135687248
	11135687248 [label=AccumulateGrad]
	11135687680 -> 11135687488
	6139274848 [label="
 (384)" fillcolor=lightblue]
	6139274848 -> 11135687680
	11135687680 [label=AccumulateGrad]
	11135688400 -> 11135687488
	6139274928 [label="
 (384)" fillcolor=lightblue]
	6139274928 -> 11135688400
	11135688400 [label=AccumulateGrad]
	11135688688 -> 11135763504
	11135688976 -> 11135689840
	6139275328 [label="
 (2304, 384, 1, 1)" fillcolor=lightblue]
	6139275328 -> 11135688976
	11135688976 [label=AccumulateGrad]
	11135689792 -> 11135690656
	6139275408 [label="
 (2304)" fillcolor=lightblue]
	6139275408 -> 11135689792
	11135689792 [label=AccumulateGrad]
	11135691088 -> 11135690656
	6139275488 [label="
 (2304)" fillcolor=lightblue]
	6139275488 -> 11135691088
	11135691088 [label=AccumulateGrad]
	6139972800 -> 6142070336
	6139972800 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	11135690848 -> 11135691808
	6139276048 [label="
 (2304, 1, 5, 5)" fillcolor=lightblue]
	6139276048 -> 11135690848
	11135690848 [label=AccumulateGrad]
	11135692000 -> 11135692096
	6139275968 [label="
 (2304)" fillcolor=lightblue]
	6139275968 -> 11135692000
	11135692000 [label=AccumulateGrad]
	11135693152 -> 11135692096
	6139276128 [label="
 (2304)" fillcolor=lightblue]
	6139276128 -> 11135693152
	11135693152 [label=AccumulateGrad]
	6139972720 -> 6142070560
	6139972720 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	11135694304 -> 11135693872
	6139276688 [label="
 (96, 2304, 1, 1)" fillcolor=lightblue]
	6139276688 -> 11135694304
	11135694304 [label=AccumulateGrad]
	11135694112 -> 11135693872
	6139276768 [label="
 (96)" fillcolor=lightblue]
	6139276768 -> 11135694112
	11135694112 [label=AccumulateGrad]
	6139972480 -> 6142070784
	6139972480 [label="
 (1, 96, 1, 1)" fillcolor=orange]
	11135694544 -> 11135694976
	6139276928 [label="
 (2304, 96, 1, 1)" fillcolor=lightblue]
	6139276928 -> 11135694544
	11135694544 [label=AccumulateGrad]
	11135694256 -> 11135694976
	6139277008 [label="
 (2304)" fillcolor=lightblue]
	6139277008 -> 11135694256
	11135694256 [label=AccumulateGrad]
	6142070560 -> 11135696032
	11135696608 -> 11135762496
	6139277168 [label="
 (384, 2304, 1, 1)" fillcolor=lightblue]
	6139277168 -> 11135696608
	11135696608 [label=AccumulateGrad]
	11135763744 -> 11135763312
	6139277248 [label="
 (384)" fillcolor=lightblue]
	6139277248 -> 11135763744
	11135763744 [label=AccumulateGrad]
	11135696848 -> 11135763312
	6139277328 [label="
 (384)" fillcolor=lightblue]
	6139277328 -> 11135696848
	11135696848 [label=AccumulateGrad]
	11135763504 -> 11135773584
	11135764224 -> 11135764752
	6139277808 [label="
 (2304, 384, 1, 1)" fillcolor=lightblue]
	6139277808 -> 11135764224
	11135764224 [label=AccumulateGrad]
	11135765040 -> 11135765616
	6139277888 [label="
 (2304)" fillcolor=lightblue]
	6139277888 -> 11135765040
	11135765040 [label=AccumulateGrad]
	11135766096 -> 11135765616
	6139277968 [label="
 (2304)" fillcolor=lightblue]
	6139277968 -> 11135766096
	11135766096 [label=AccumulateGrad]
	6139970640 -> 6142071008
	6139970640 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	11135766528 -> 11135767392
	6139278528 [label="
 (2304, 1, 5, 5)" fillcolor=lightblue]
	6139278528 -> 11135766528
	11135766528 [label=AccumulateGrad]
	11135767200 -> 11135766912
	6139278448 [label="
 (2304)" fillcolor=lightblue]
	6139278448 -> 11135767200
	11135767200 [label=AccumulateGrad]
	11135768064 -> 11135766912
	6139278608 [label="
 (2304)" fillcolor=lightblue]
	6139278608 -> 11135768064
	11135768064 [label=AccumulateGrad]
	6139970480 -> 6142071232
	6139970480 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	11135769264 -> 11135769120
	6139279168 [label="
 (96, 2304, 1, 1)" fillcolor=lightblue]
	6139279168 -> 11135769264
	11135769264 [label=AccumulateGrad]
	11135769552 -> 11135769120
	6139279248 [label="
 (96)" fillcolor=lightblue]
	6139279248 -> 11135769552
	11135769552 [label=AccumulateGrad]
	6139970240 -> 6142071456
	6139970240 [label="
 (1, 96, 1, 1)" fillcolor=orange]
	11135770368 -> 11135769792
	6139279408 [label="
 (2304, 96, 1, 1)" fillcolor=lightblue]
	6139279408 -> 11135770368
	11135770368 [label=AccumulateGrad]
	11135769936 -> 11135769792
	6139279488 [label="
 (2304)" fillcolor=lightblue]
	6139279488 -> 11135769936
	11135769936 [label=AccumulateGrad]
	6142071232 -> 11135771280
	11135771232 -> 11135771808
	6139279648 [label="
 (384, 2304, 1, 1)" fillcolor=lightblue]
	6139279648 -> 11135771232
	11135771232 [label=AccumulateGrad]
	11135772096 -> 11135772672
	6139279728 [label="
 (384)" fillcolor=lightblue]
	6139279728 -> 11135772096
	11135772096 [label=AccumulateGrad]
	11135773152 -> 11135772672
	6139279808 [label="
 (384)" fillcolor=lightblue]
	6139279808 -> 11135773152
	11135773152 [label=AccumulateGrad]
	11135773584 -> 11135773824
	11135774448 -> 11135774688
	6139280288 [label="
 (2304, 384, 1, 1)" fillcolor=lightblue]
	6139280288 -> 11135774448
	11135774448 [label=AccumulateGrad]
	11135774880 -> 11135775168
	6139280368 [label="
 (2304)" fillcolor=lightblue]
	6139280368 -> 11135774880
	11135774880 [label=AccumulateGrad]
	11135776320 -> 11135775168
	6139280448 [label="
 (2304)" fillcolor=lightblue]
	6139280448 -> 11135776320
	11135776320 [label=AccumulateGrad]
	6139864352 -> 6142071680
	6139864352 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	11135776272 -> 11135777280
	6139281008 [label="
 (2304, 1, 3, 3)" fillcolor=lightblue]
	6139281008 -> 11135776272
	11135776272 [label=AccumulateGrad]
	11135776992 -> 11135776848
	6139280928 [label="
 (2304)" fillcolor=lightblue]
	6139280928 -> 11135776992
	11135776992 [label=AccumulateGrad]
	11135777568 -> 11135776848
	6139281088 [label="
 (2304)" fillcolor=lightblue]
	6139281088 -> 11135777568
	11135777568 [label=AccumulateGrad]
	6139864112 -> 6142071904
	6139864112 [label="
 (1, 2304, 19, 19)" fillcolor=orange]
	11135778480 -> 11135860896
	6139560240 [label="
 (96, 2304, 1, 1)" fillcolor=lightblue]
	6139560240 -> 11135778480
	11135778480 [label=AccumulateGrad]
	11135778768 -> 11135860896
	6139560320 [label="
 (96)" fillcolor=lightblue]
	6139560320 -> 11135778768
	11135778768 [label=AccumulateGrad]
	6139860672 -> 6142072128
	6139860672 [label="
 (1, 96, 1, 1)" fillcolor=orange]
	11135861760 -> 11135862192
	6139560480 [label="
 (2304, 96, 1, 1)" fillcolor=lightblue]
	6139560480 -> 11135861760
	11135861760 [label=AccumulateGrad]
	11135862144 -> 11135862192
	6139560560 [label="
 (2304)" fillcolor=lightblue]
	6139560560 -> 11135862144
	11135862144 [label=AccumulateGrad]
	6142071904 -> 11135862576
	11135863296 -> 11135863728
	6139560720 [label="
 (640, 2304, 1, 1)" fillcolor=lightblue]
	6139560720 -> 11135863296
	11135863296 [label=AccumulateGrad]
	11135864064 -> 11135874144
	6139560800 [label="
 (640)" fillcolor=lightblue]
	6139560800 -> 11135864064
	11135864064 [label=AccumulateGrad]
	11135864784 -> 11135874144
	6139560880 [label="
 (640)" fillcolor=lightblue]
	6139560880 -> 11135864784
	11135864784 [label=AccumulateGrad]
	11135864352 -> 11135865216
	6139561360 [label="
 (3840, 640, 1, 1)" fillcolor=lightblue]
	6139561360 -> 11135864352
	11135864352 [label=AccumulateGrad]
	11135865168 -> 11135866032
	6139561440 [label="
 (3840)" fillcolor=lightblue]
	6139561440 -> 11135865168
	11135865168 [label=AccumulateGrad]
	11135866464 -> 11135866032
	6139561520 [label="
 (3840)" fillcolor=lightblue]
	6139561520 -> 11135866464
	11135866464 [label=AccumulateGrad]
	6139867712 -> 6142072352
	6139867712 [label="
 (1, 3840, 19, 19)" fillcolor=orange]
	11135866224 -> 11135867184
	6139562080 [label="
 (3840, 1, 3, 3)" fillcolor=lightblue]
	6139562080 -> 11135866224
	11135866224 [label=AccumulateGrad]
	11135867376 -> 11135867472
	6139562000 [label="
 (3840)" fillcolor=lightblue]
	6139562000 -> 11135867376
	11135867376 [label=AccumulateGrad]
	11135868528 -> 11135867472
	6139562160 [label="
 (3840)" fillcolor=lightblue]
	6139562160 -> 11135868528
	11135868528 [label=AccumulateGrad]
	6139864592 -> 6142072576
	6139864592 [label="
 (1, 3840, 19, 19)" fillcolor=orange]
	11135869680 -> 11135869248
	6139562640 [label="
 (160, 3840, 1, 1)" fillcolor=lightblue]
	6139562640 -> 11135869680
	11135869680 [label=AccumulateGrad]
	11135869488 -> 11135869248
	6139562720 [label="
 (160)" fillcolor=lightblue]
	6139562720 -> 11135869488
	11135869488 [label=AccumulateGrad]
	6139858912 -> 6142072800
	6139858912 [label="
 (1, 160, 1, 1)" fillcolor=orange]
	11135869920 -> 11135870352
	6139562880 [label="
 (3840, 160, 1, 1)" fillcolor=lightblue]
	6139562880 -> 11135869920
	11135869920 [label=AccumulateGrad]
	11135869632 -> 11135870352
	6139562960 [label="
 (3840)" fillcolor=lightblue]
	6139562960 -> 11135869632
	11135869632 [label=AccumulateGrad]
	6142072576 -> 11135871408
	11135871984 -> 11135872272
	6139563120 [label="
 (640, 3840, 1, 1)" fillcolor=lightblue]
	6139563120 -> 11135871984
	11135871984 [label=AccumulateGrad]
	11135872224 -> 11135873856
	6139563200 [label="
 (640)" fillcolor=lightblue]
	6139563200 -> 11135872224
	11135872224 [label=AccumulateGrad]
	11135875152 -> 11135873856
	6139563280 [label="
 (640)" fillcolor=lightblue]
	6139563280 -> 11135875152
	11135875152 [label=AccumulateGrad]
	11135874144 -> 6141751888
	11135876160 -> 11135943440
	6139563760 [label="
 (3840, 640, 1, 1)" fillcolor=lightblue]
	6139563760 -> 11135876160
	11135876160 [label=AccumulateGrad]
	11135944352 -> 11135946032
	6139563840 [label="
 (3840)" fillcolor=lightblue]
	6139563840 -> 11135944352
	11135944352 [label=AccumulateGrad]
	11135946800 -> 11135946032
	6139563920 [label="
 (3840)" fillcolor=lightblue]
	6139563920 -> 11135946800
	11135946800 [label=AccumulateGrad]
	6139857232 -> 6142073024
	6139857232 [label="
 (1, 3840, 19, 19)" fillcolor=orange]
	11135947760 -> 11135950208
	6139564480 [label="
 (3840, 1, 3, 3)" fillcolor=lightblue]
	6139564480 -> 11135947760
	11135947760 [label=AccumulateGrad]
	11135949680 -> 11135949200
	6139564400 [label="
 (3840)" fillcolor=lightblue]
	6139564400 -> 11135949680
	11135949680 [label=AccumulateGrad]
	11135952368 -> 11135949200
	6139564560 [label="
 (3840)" fillcolor=lightblue]
	6139564560 -> 11135952368
	11135952368 [label=AccumulateGrad]
	6139856592 -> 6142073248
	6139856592 [label="
 (1, 3840, 19, 19)" fillcolor=orange]
	11135956976 -> 11135958896
	6139565120 [label="
 (160, 3840, 1, 1)" fillcolor=lightblue]
	6139565120 -> 11135956976
	11135956976 [label=AccumulateGrad]
	11135955104 -> 11135958896
	6139565200 [label="
 (160)" fillcolor=lightblue]
	6139565200 -> 11135955104
	11135955104 [label=AccumulateGrad]
	6139855792 -> 6142073472
	6139855792 [label="
 (1, 160, 1, 1)" fillcolor=orange]
	11135953520 -> 11135954864
	6139565360 [label="
 (3840, 160, 1, 1)" fillcolor=lightblue]
	6139565360 -> 11135953520
	11135953520 [label=AccumulateGrad]
	11135954240 -> 11135954864
	6139565440 [label="
 (3840)" fillcolor=lightblue]
	6139565440 -> 11135954240
	11135954240 [label=AccumulateGrad]
	6142073248 -> 6141859088
	6141857792 -> 6141855440
	6139565600 [label="
 (640, 3840, 1, 1)" fillcolor=lightblue]
	6139565600 -> 6141857792
	6141857792 [label=AccumulateGrad]
	6141854528 -> 6141753424
	6139565680 [label="
 (640)" fillcolor=lightblue]
	6139565680 -> 6141854528
	6141854528 [label=AccumulateGrad]
	6141861632 -> 6141753424
	6139565760 [label="
 (640)" fillcolor=lightblue]
	6139565760 -> 6141861632
	6141861632 [label=AccumulateGrad]
	6141751888 -> 6141581808
	6141754192 -> 6141749344
	6139566240 [label="
 (3840, 640, 1, 1)" fillcolor=lightblue]
	6139566240 -> 6141754192
	6141754192 [label=AccumulateGrad]
	6141746608 -> 6141746896
	6139566320 [label="
 (3840)" fillcolor=lightblue]
	6139566320 -> 6141746608
	6141746608 [label=AccumulateGrad]
	6141742816 -> 6141746896
	6139566400 [label="
 (3840)" fillcolor=lightblue]
	6139566400 -> 6141742816
	6141742816 [label=AccumulateGrad]
	6139863472 -> 6142073696
	6139863472 [label="
 (1, 3840, 19, 19)" fillcolor=orange]
	6141741712 -> 6141687408
	6139566960 [label="
 (3840, 1, 3, 3)" fillcolor=lightblue]
	6139566960 -> 6141741712
	6141741712 [label=AccumulateGrad]
	6141685488 -> 6141688032
	6139566880 [label="
 (3840)" fillcolor=lightblue]
	6139566880 -> 6141685488
	6141685488 [label=AccumulateGrad]
	6141741904 -> 6141688032
	6139567040 [label="
 (3840)" fillcolor=lightblue]
	6139567040 -> 6141741904
	6141741904 [label=AccumulateGrad]
	6139863232 -> 6142073920
	6139863232 [label="
 (1, 3840, 19, 19)" fillcolor=orange]
	6141682416 -> 6141681648
	6139567520 [label="
 (160, 3840, 1, 1)" fillcolor=lightblue]
	6139567520 -> 6141682416
	6141682416 [label=AccumulateGrad]
	6141680784 -> 6141681648
	6139567600 [label="
 (160)" fillcolor=lightblue]
	6139567600 -> 6141680784
	6141680784 [label=AccumulateGrad]
	6139861392 -> 6142074144
	6139861392 [label="
 (1, 160, 1, 1)" fillcolor=orange]
	6141678096 -> 6141680400
	6139567760 [label="
 (3840, 160, 1, 1)" fillcolor=lightblue]
	6139567760 -> 6141678096
	6141678096 [label=AccumulateGrad]
	6141677088 -> 6141680400
	6139567840 [label="
 (3840)" fillcolor=lightblue]
	6139567840 -> 6141677088
	6141677088 [label=AccumulateGrad]
	6142073920 -> 6141591072
	6141589152 -> 6141591024
	6139568000 [label="
 (640, 3840, 1, 1)" fillcolor=lightblue]
	6139568000 -> 6141589152
	6141589152 [label=AccumulateGrad]
	6141587952 -> 6141586704
	6139568080 [label="
 (640)" fillcolor=lightblue]
	6139568080 -> 6141587952
	6141587952 [label=AccumulateGrad]
	6141584016 -> 6141586704
	6139568160 [label="
 (640)" fillcolor=lightblue]
	6139568160 -> 6141584016
	6141584016 [label=AccumulateGrad]
	6141581808 -> 6141580896
	6141579984 -> 6141579072
	6141603856 [label="
 (256, 640, 1, 1)" fillcolor=lightblue]
	6141603856 -> 6141579984
	6141579984 [label=AccumulateGrad]
	6141576384 -> 6141579072
	6141603696 [label="
 (256)" fillcolor=lightblue]
	6141603696 -> 6141576384
	6141576384 [label=AccumulateGrad]
	6140460192 -> 6140459856
	6117679536 [label="
 (256, 256, 3, 3)" fillcolor=lightblue]
	6117679536 -> 6140460192
	6140460192 [label=AccumulateGrad]
	6140459808 -> 6140459856
	6141596256 [label="
 (256)" fillcolor=lightblue]
	6141596256 -> 6140459808
	6140459808 [label=AccumulateGrad]
	6140459568 -> 6140459328
	6141592976 [label="
 (256)" fillcolor=lightblue]
	6141592976 -> 6140459568
	6140459568 [label=AccumulateGrad]
	6140459376 -> 6140459328
	6141606736 [label="
 (256)" fillcolor=lightblue]
	6141606736 -> 6140459376
	6140459376 [label=AccumulateGrad]
	6140458944 -> 6140458608
	6141603936 [label="
 (256, 256, 3, 3)" fillcolor=lightblue]
	6141603936 -> 6140458944
	6140458944 [label=AccumulateGrad]
	6140458848 -> 6140458608
	6141603456 [label="
 (256)" fillcolor=lightblue]
	6141603456 -> 6140458848
	6140458848 [label=AccumulateGrad]
	6140458800 -> 6140458320
	6141602656 [label="
 (256)" fillcolor=lightblue]
	6141602656 -> 6140458800
	6140458800 [label=AccumulateGrad]
	6140458368 -> 6140458320
	6141601936 [label="
 (256)" fillcolor=lightblue]
	6141601936 -> 6140458368
	6140458368 [label=AccumulateGrad]
	6140457888 -> 6140457456
	6141596016 [label="
 (256, 256, 3, 3)" fillcolor=lightblue]
	6141596016 -> 6140457888
	6140457888 [label=AccumulateGrad]
	6140457744 -> 6140457456
	6141595776 [label="
 (256)" fillcolor=lightblue]
	6141595776 -> 6140457744
	6140457744 [label=AccumulateGrad]
	6140457312 -> 6140457120
	6141595136 [label="
 (256)" fillcolor=lightblue]
	6141595136 -> 6140457312
	6140457312 [label=AccumulateGrad]
	6140456976 -> 6140457120
	6141594656 [label="
 (256)" fillcolor=lightblue]
	6141594656 -> 6140456976
	6140456976 [label=AccumulateGrad]
	6140456928 -> 6140456832
	6141606976 [label="
 (1024, 256, 3, 3)" fillcolor=lightblue]
	6141606976 -> 6140456928
	6140456928 [label=AccumulateGrad]
	6140456352 -> 6140456832
	6141606816 [label="
 (1024)" fillcolor=lightblue]
	6141606816 -> 6140456352
	6140456352 [label=AccumulateGrad]
	6140456064 -> 6140455824
	6140456064 -> 11136030320 [dir=none]
	11136030320 [label="result
 (1, 256, 150, 150)" fillcolor=orange]
	6140456064 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	6140457360 -> 6140456064
	6140457360 -> 6139868032 [dir=none]
	6139868032 [label="input
 (1, 256, 150, 150)" fillcolor=orange]
	6140457360 -> 11136030560 [dir=none]
	11136030560 [label="result1
 (256)" fillcolor=orange]
	6140457360 -> 11136030640 [dir=none]
	11136030640 [label="result2
 (256)" fillcolor=orange]
	6140457360 -> 6141594096 [dir=none]
	6141594096 [label="running_mean
 (256)" fillcolor=orange]
	6140457360 -> 6141607776 [dir=none]
	6141607776 [label="running_var
 (256)" fillcolor=orange]
	6140457360 -> 6141592496 [dir=none]
	6141592496 [label="weight
 (256)" fillcolor=orange]
	6140457360 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6140458080 -> 6140457360
	6140458080 -> 6139868352 [dir=none]
	6139868352 [label="input
 (1, 256, 150, 150)" fillcolor=orange]
	6140458080 -> 6141593936 [dir=none]
	6141593936 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	6140458080 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (256,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6140459616 -> 6140458080
	6140459616 -> 11136030960 [dir=none]
	11136030960 [label="result
 (1, 256, 150, 150)" fillcolor=orange]
	6140459616 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	6140460240 -> 6140459616
	6140460240 -> 6139868512 [dir=none]
	6139868512 [label="input
 (1, 256, 150, 150)" fillcolor=orange]
	6140460240 -> 11136031120 [dir=none]
	11136031120 [label="result1
 (256)" fillcolor=orange]
	6140460240 -> 11136031200 [dir=none]
	11136031200 [label="result2
 (256)" fillcolor=orange]
	6140460240 -> 6141601136 [dir=none]
	6141601136 [label="running_mean
 (256)" fillcolor=orange]
	6140460240 -> 6141597056 [dir=none]
	6141597056 [label="running_var
 (256)" fillcolor=orange]
	6140460240 -> 6141598016 [dir=none]
	6141598016 [label="weight
 (256)" fillcolor=orange]
	6140460240 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141577488 -> 6140460240
	6141577488 -> 6139868832 [dir=none]
	6139868832 [label="input
 (1, 256, 150, 150)" fillcolor=orange]
	6141577488 -> 6141598656 [dir=none]
	6141598656 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	6141577488 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (256,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141586512 -> 6141577488
	6141586512 -> 11136031520 [dir=none]
	11136031520 [label="result
 (1, 256, 150, 150)" fillcolor=orange]
	6141586512 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	6141677040 -> 6141586512
	6141677040 -> 6139868992 [dir=none]
	6139868992 [label="input
 (1, 256, 150, 150)" fillcolor=orange]
	6141677040 -> 11136031600 [dir=none]
	11136031600 [label="result1
 (256)" fillcolor=orange]
	6141677040 -> 11136031680 [dir=none]
	11136031680 [label="result2
 (256)" fillcolor=orange]
	6141677040 -> 6141594976 [dir=none]
	6141594976 [label="running_mean
 (256)" fillcolor=orange]
	6141677040 -> 6141603616 [dir=none]
	6141603616 [label="running_var
 (256)" fillcolor=orange]
	6141677040 -> 6141606176 [dir=none]
	6141606176 [label="weight
 (256)" fillcolor=orange]
	6141677040 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	6141681888 -> 6141677040
	6141681888 -> 6139869872 [dir=none]
	6139869872 [label="input
 (1, 256, 150, 150)" fillcolor=orange]
	6141681888 -> 6141607296 [dir=none]
	6141607296 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	6141681888 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (256,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141688416 -> 6141681888
	6141688416 [label="AddBackward0
------------
alpha: 1"]
	6141744880 -> 6141688416
	6141744880 -> 6140371856 [dir=none]
	6140371856 [label="input
 (1, 48, 150, 150)" fillcolor=orange]
	6141744880 -> 6141602096 [dir=none]
	6141602096 [label="weight
 (256, 48, 1, 1)" fillcolor=orange]
	6141744880 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (256,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	6141740608 -> 6141744880
	6141751168 -> 6141744880
	6141602096 [label="
 (256, 48, 1, 1)" fillcolor=lightblue]
	6141602096 -> 6141751168
	6141751168 [label=AccumulateGrad]
	6141753184 -> 6141744880
	6141602016 [label="
 (256)" fillcolor=lightblue]
	6141602016 -> 6141753184
	6141753184 [label=AccumulateGrad]
	6141746272 -> 6141688416
	6141746272 [label="UpsampleNearest2DBackward0
--------------------------------
output_size   :       (150, 150)
scales_h      :             None
scales_w      :             None
self_sym_sizes: (1, 256, 75, 75)"]
	6140460096 -> 6141746272
	6141686880 -> 6141681888
	6141607296 [label="
 (256, 256, 3, 3)" fillcolor=lightblue]
	6141607296 -> 6141686880
	6141686880 [label=AccumulateGrad]
	6141739648 -> 6141681888
	6141607136 [label="
 (256)" fillcolor=lightblue]
	6141607136 -> 6141739648
	6141739648 [label=AccumulateGrad]
	6141674304 -> 6141677040
	6141606176 [label="
 (256)" fillcolor=lightblue]
	6141606176 -> 6141674304
	6141674304 [label=AccumulateGrad]
	6141675024 -> 6141677040
	6141605056 [label="
 (256)" fillcolor=lightblue]
	6141605056 -> 6141675024
	6141675024 [label=AccumulateGrad]
	6141585168 -> 6141577488
	6141598656 [label="
 (256, 256, 3, 3)" fillcolor=lightblue]
	6141598656 -> 6141585168
	6141585168 [label=AccumulateGrad]
	6141584496 -> 6141577488
	6141598256 [label="
 (256)" fillcolor=lightblue]
	6141598256 -> 6141584496
	6141584496 [label=AccumulateGrad]
	6141575232 -> 6140460240
	6141598016 [label="
 (256)" fillcolor=lightblue]
	6141598016 -> 6141575232
	6141575232 [label=AccumulateGrad]
	6141589200 -> 6140460240
	6141597296 [label="
 (256)" fillcolor=lightblue]
	6141597296 -> 6141589200
	6141589200 [label=AccumulateGrad]
	6140459136 -> 6140458080
	6141593936 [label="
 (256, 256, 3, 3)" fillcolor=lightblue]
	6141593936 -> 6140459136
	6140459136 [label=AccumulateGrad]
	6140458992 -> 6140458080
	6141593696 [label="
 (256)" fillcolor=lightblue]
	6141593696 -> 6140458992
	6140458992 [label=AccumulateGrad]
	6140457504 -> 6140457360
	6141592496 [label="
 (256)" fillcolor=lightblue]
	6141592496 -> 6140457504
	6140457504 [label=AccumulateGrad]
	6140456544 -> 6140457360
	6141591696 [label="
 (256)" fillcolor=lightblue]
	6141591696 -> 6140456544
	6140456544 [label=AccumulateGrad]
	6140455680 -> 6140455296
	6140455680 -> 6140376656 [dir=none]
	6140376656 [label="input
 (1, 32, 300, 300)" fillcolor=orange]
	6140455680 -> 6141606336 [dir=none]
	6141606336 [label="weight
 (256, 32, 1, 1)" fillcolor=orange]
	6140455680 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:         (256,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	11135950064 -> 6140455680
	6140457072 -> 6140455680
	6141606336 [label="
 (256, 32, 1, 1)" fillcolor=lightblue]
	6141606336 -> 6140457072
	6140457072 [label=AccumulateGrad]
	6140455872 -> 6140455680
	6141606256 [label="
 (256)" fillcolor=lightblue]
	6141606256 -> 6140455872
	6140455872 [label=AccumulateGrad]
	6140455056 -> 6140455104
	6140455056 [label="UnsqueezeBackward0
------------------
dim: 2"]
	6140456112 -> 6140455056
	6140456112 [label="SliceBackward0
-----------------------------------
dim           :                   1
end           : 9223372036854775807
self_sym_sizes:            (1, 256)
start         :                   0
step          :                   1"]
	6140460384 -> 6140456112
	6140460384 [label="UnsqueezeBackward0
------------------
dim: 0"]
	6141590112 -> 6140460384
	6141590112 [label="SelectBackward0
------------------------
dim           :        0
index         :        0
self_sym_sizes: (5, 256)"]
	6141686400 -> 6141590112
	6141598736 [label="
 (5, 256)" fillcolor=lightblue]
	6141598736 -> 6141686400
	6141686400 [label=AccumulateGrad]
	6140454096 -> 6140454336
	6140454096 [label=TBackward0]
	6140453232 -> 6140454096
	6140452272 -> 6140453808
	6140450784 -> 6140450592
	6140450784 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	6141580560 -> 6140450784
	6141580560 [label="ViewBackward0
-------------------------------
self_sym_sizes: (90000, 1, 256)"]
	6140452080 -> 6141580560
	6140452080 [label="AddBackward0
------------
alpha: 1"]
	6140452848 -> 6140452080
	6140452848 [label="UnsafeViewBackward0
----------------------------
self_sym_sizes: (90000, 256)"]
	6140452944 -> 6140452848
	6140452944 -> 11136036080 [dir=none]
	11136036080 [label="mat2
 (256, 256)" fillcolor=orange]
	6140452944 -> 11136035680 [dir=none]
	11136035680 [label="self
 (90000, 256)" fillcolor=orange]
	6140452944 [label="MmBackward0
--------------------------------
mat2            : [saved tensor]
mat2_sym_sizes  :     (256, 256)
mat2_sym_strides:       (1, 256)
self            : [saved tensor]
self_sym_sizes  :   (90000, 256)
self_sym_strides:     (1, 90000)"]
	6140451600 -> 6140452944
	6140451600 [label="ReshapeAliasBackward0
-------------------------------
self_sym_sizes: (90000, 1, 256)"]
	6140454576 -> 6140451600
	6140453856 -> 6140452944
	6140453856 [label=TBackward0]
	6140453232 -> 6140453856
	6140452272 -> 6140452080
	6140449104 -> 6140449824
	6140449104 [label=TBackward0]
	6141673776 -> 6140449104
	6141600656 [label="
 (256, 256)" fillcolor=lightblue]
	6141600656 -> 6141673776
	6141673776 [label=AccumulateGrad]
	6140448480 -> 6140448288
	6141600336 [label="
 (256)" fillcolor=lightblue]
	6141600336 -> 6140448480
	6140448480 [label=AccumulateGrad]
	6140448336 -> 6140448288
	6141600176 [label="
 (256)" fillcolor=lightblue]
	6141600176 -> 6140448336
	6140448336 [label=AccumulateGrad]
	6140448048 -> 6140447808
	6140448048 [label="ViewBackward0
--------------------------
self_sym_sizes: (100, 256)"]
	6140449056 -> 6140448048
	6140449056 -> 6139862112 [dir=none]
	6139862112 [label="mat1
 (100, 256)" fillcolor=orange]
	6140449056 -> 11136037280 [dir=none]
	11136037280 [label="mat2
 (256, 256)" fillcolor=orange]
	6140449056 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (100, 256)
mat1_sym_strides:       (256, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (256, 256)
mat2_sym_strides:       (1, 256)"]
	6140450112 -> 6140449056
	6138738416 [label="
 (256)" fillcolor=lightblue]
	6138738416 -> 6140450112
	6140450112 [label=AccumulateGrad]
	6140449968 -> 6140449056
	6140449968 [label="ViewBackward0
----------------------------
self_sym_sizes: (100, 8, 32)"]
	6140450304 -> 6140449968
	6140450304 [label=CloneBackward0]
	6140453328 -> 6140450304
	6140453328 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	6140454480 -> 6140453328
	6140454480 -> 6139860352 [dir=none]
	6139860352 [label="mat2
 (8, 100, 32)" fillcolor=orange]
	6140454480 -> 6139862192 [dir=none]
	6139862192 [label="self
 (8, 100, 100)" fillcolor=orange]
	6140454480 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	6140458128 -> 6140454480
	6140458128 -> 11136038160 [dir=none]
	11136038160 [label="result
 (8, 100, 100)" fillcolor=orange]
	6140458128 [label="SoftmaxBackward0
----------------------------
dim   : 18446744073709551615
result:       [saved tensor]"]
	6140460048 -> 6140458128
	6140460048 -> 6139860192 [dir=none]
	6139860192 [label="mat2
 (8, 32, 100)" fillcolor=orange]
	6140460048 -> 6139859952 [dir=none]
	6139859952 [label="self
 (8, 100, 32)" fillcolor=orange]
	6140460048 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	6140455728 -> 6140460048
	6140455728 -> 11136038240 [dir=none]
	11136038240 [label="other
 ()" fillcolor=orange]
	6140455728 [label="DivBackward0
---------------------
other: [saved tensor]
self :           None"]
	6141749920 -> 6140455728
	6141749920 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	6141859424 -> 6141749920
	6141859424 [label="ViewBackward0
-----------------------------
self_sym_sizes: (100, 1, 256)"]
	6141858848 -> 6141859424
	6141858848 [label="ViewBackward0
--------------------------
self_sym_sizes: (100, 256)"]
	11135956880 -> 6141858848
	11135956880 -> 11136038640 [dir=none]
	11136038640 [label="mat1
 (100, 256)" fillcolor=orange]
	11135956880 -> 11136038320 [dir=none]
	11136038320 [label="mat2
 (256, 256)" fillcolor=orange]
	11135956880 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (100, 256)
mat1_sym_strides:       (256, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (256, 256)
mat2_sym_strides:       (1, 256)"]
	11135951360 -> 11135956880
	11135951360 [label="SplitBackward0
----------------------
dim           :      0
self_sym_sizes: (768,)
split_size    :    256"]
	11135943152 -> 11135951360
	6141607456 [label="
 (768)" fillcolor=lightblue]
	6141607456 -> 11135943152
	11135943152 [label=AccumulateGrad]
	11135952704 -> 11135956880
	11135952704 [label="ViewBackward0
-----------------------------
self_sym_sizes: (100, 1, 256)"]
	11135945168 -> 11135952704
	11135945168 [label="AddBackward0
------------
alpha: 1"]
	6140448288 -> 11135945168
	6140453184 -> 11135945168
	11135955824 -> 11135956880
	11135955824 [label=TBackward0]
	11135947520 -> 11135955824
	11135947520 [label="SplitBackward0
--------------------------
dim           :          0
self_sym_sizes: (768, 256)
split_size    :        256"]
	11135945888 -> 11135947520
	6075227952 [label="
 (768, 256)" fillcolor=lightblue]
	6075227952 -> 11135945888
	11135945888 [label=AccumulateGrad]
	6140454432 -> 6140460048
	6140454432 [label="TransposeBackward0
--------------------------
dim0: 18446744073709551614
dim1: 18446744073709551615"]
	6141853856 -> 6140454432
	6141853856 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	11135948768 -> 6141853856
	11135948768 [label="ViewBackward0
-----------------------------
self_sym_sizes: (100, 1, 256)"]
	11135954000 -> 11135948768
	11135954000 [label="ViewBackward0
--------------------------
self_sym_sizes: (100, 256)"]
	11135876112 -> 11135954000
	11135876112 -> 11136040000 [dir=none]
	11136040000 [label="mat1
 (100, 256)" fillcolor=orange]
	11135876112 -> 11136039840 [dir=none]
	11136039840 [label="mat2
 (256, 256)" fillcolor=orange]
	11135876112 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (100, 256)
mat1_sym_strides:       (256, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (256, 256)
mat2_sym_strides:       (1, 256)"]
	11135951360 -> 11135876112
	11135871840 -> 11135876112
	11135871840 [label="ViewBackward0
-----------------------------
self_sym_sizes: (100, 1, 256)"]
	11135945168 -> 11135871840
	11135871936 -> 11135876112
	11135871936 [label=TBackward0]
	11135947520 -> 11135871936
	6140454864 -> 6140454480
	6140454864 [label="TransposeBackward0
------------------
dim0: 0
dim1: 1"]
	6141856352 -> 6140454864
	6141856352 [label="ViewBackward0
-----------------------------
self_sym_sizes: (100, 1, 256)"]
	11135951072 -> 6141856352
	11135951072 [label="ViewBackward0
--------------------------
self_sym_sizes: (100, 256)"]
	6141747856 -> 11135951072
	6141747856 -> 11135926112 [dir=none]
	11135926112 [label="mat1
 (100, 256)" fillcolor=orange]
	6141747856 -> 11135926192 [dir=none]
	11135926192 [label="mat2
 (256, 256)" fillcolor=orange]
	6141747856 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (100, 256)
mat1_sym_strides:       (256, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (256, 256)
mat2_sym_strides:       (1, 256)"]
	11135951360 -> 6141747856
	11135871120 -> 6141747856
	11135871120 [label="ViewBackward0
-----------------------------
self_sym_sizes: (100, 1, 256)"]
	6140448288 -> 11135871120
	11135872656 -> 6141747856
	11135872656 [label=TBackward0]
	11135947520 -> 11135872656
	6140448432 -> 6140449056
	6140448432 [label=TBackward0]
	6140451216 -> 6140448432
	6138724416 [label="
 (256, 256)" fillcolor=lightblue]
	6138724416 -> 6140451216
	6140451216 [label=AccumulateGrad]
	6140447904 -> 6140447760
	4620175216 [label="
 (256)" fillcolor=lightblue]
	4620175216 -> 6140447904
	6140447904 [label=AccumulateGrad]
	6140447520 -> 6140447760
	5491947088 [label="
 (256)" fillcolor=lightblue]
	5491947088 -> 6140447520
	6140447520 [label=AccumulateGrad]
	6140447568 -> 6140447088
	6140447568 [label="ViewBackward0
--------------------------
self_sym_sizes: (100, 256)"]
	6140451792 -> 6140447568
	6140451792 -> 11135924912 [dir=none]
	11135924912 [label="mat1
 (100, 2048)" fillcolor=orange]
	6140451792 -> 11135924752 [dir=none]
	11135924752 [label="mat2
 (2048, 256)" fillcolor=orange]
	6140451792 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :    (100, 2048)
mat1_sym_strides:      (2048, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (2048, 256)
mat2_sym_strides:      (1, 2048)"]
	6140452464 -> 6140451792
	6141599456 [label="
 (256)" fillcolor=lightblue]
	6141599456 -> 6140452464
	6140452464 [label=AccumulateGrad]
	6140450064 -> 6140451792
	6140450064 [label="ViewBackward0
------------------------------
self_sym_sizes: (100, 1, 2048)"]
	6140451024 -> 6140450064
	6140451024 -> 11135924272 [dir=none]
	11135924272 [label="result
 (100, 1, 2048)" fillcolor=orange]
	6140451024 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	6141740080 -> 6140451024
	6141740080 [label="ViewBackward0
---------------------------
self_sym_sizes: (100, 2048)"]
	11135870784 -> 6141740080
	11135870784 -> 11135924032 [dir=none]
	11135924032 [label="mat1
 (100, 256)" fillcolor=orange]
	11135870784 -> 11135924592 [dir=none]
	11135924592 [label="mat2
 (256, 2048)" fillcolor=orange]
	11135870784 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (100, 256)
mat1_sym_strides:       (256, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :    (256, 2048)
mat2_sym_strides:       (1, 256)"]
	11135868624 -> 11135870784
	6141599856 [label="
 (2048)" fillcolor=lightblue]
	6141599856 -> 11135868624
	11135868624 [label=AccumulateGrad]
	11135869104 -> 11135870784
	11135869104 [label="ViewBackward0
-----------------------------
self_sym_sizes: (100, 1, 256)"]
	6140447760 -> 11135869104
	11135873664 -> 11135870784
	11135873664 [label=TBackward0]
	11135866944 -> 11135873664
	6141599776 [label="
 (2048, 256)" fillcolor=lightblue]
	6141599776 -> 11135866944
	11135866944 [label=AccumulateGrad]
	6140448096 -> 6140451792
	6140448096 [label=TBackward0]
	6140449920 -> 6140448096
	6141599616 [label="
 (256, 2048)" fillcolor=lightblue]
	6141599616 -> 6140449920
	6140449920 [label=AccumulateGrad]
	6140447040 -> 6140446800
	6141599296 [label="
 (256)" fillcolor=lightblue]
	6141599296 -> 6140447040
	6140447040 [label=AccumulateGrad]
	6140446848 -> 6140446800
	6141599136 [label="
 (256)" fillcolor=lightblue]
	6141599136 -> 6140446848
	6140446848 [label=AccumulateGrad]
	6140446080 -> 6140445792
	6140446080 [label=TBackward0]
	6140450352 -> 6140446080
	6138728736 [label="
 (101, 256)" fillcolor=lightblue]
	6138728736 -> 6140450352
	6140450352 [label=AccumulateGrad]
	6140445408 -> 6140273872
}
