{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing for all the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Goals\n",
    "\n",
    "\n",
    "- **COCO** dataset:\n",
    "    1. Transform the folder structure from [images, annotations] to [train, validation]\n",
    "    2. Transform the instances_train2017.json and instances_val2017.json to text files.\n",
    "        - Bounding Boxes \n",
    "        - Class code\n",
    "        - Segmentation data (mask data with format [(x_i, y_i), (x_(i+1), y_(i+1), ... )])\n",
    "    3. Resize images and annotations\n",
    "    4. Compute mean and standard deviation for the data using 2500 images as samples\n",
    "\n",
    "\n",
    "- **Vis-Drone** dataset:\n",
    "    1. Extract the bounding boxes from format [x_min, y_min, width, height] to [x_min, y_min, x_max, y_max]\n",
    "    2. Resize images and annotations\n",
    "    3. Produce the segmentation data from the bounding box data: [(x_min, y_min), (x_min, y_max), (x_max, y_min), (x_max, y_max)]\n",
    "    4. Compute mean and standard deviation for the data\n",
    "\n",
    "\n",
    "- **UAV-SOD Drone** dataset:\n",
    "    1. Extract the bounding box data and the class codes from XML files and create the text file equivalent\n",
    "    2. Resize images and annotations\n",
    "    3. Produce the segmentation data from the bounding box data: [(x_min, y_min), (x_min, y_max), (x_max, y_min), (x_max, y_max)]\n",
    "    4. Compute mean and standard deviation for the data\n",
    "\n",
    "\n",
    "- City Scapes dataset:\n",
    "    1. Transform the folder structure from [images, annotations] to [train, validation]\n",
    "    2. Resize images and annotations\n",
    "    3. Produce the segmentation data from the bounding box data: [(x_min, y_min), (x_min, y_max), (x_max, y_min), (x_max, y_max)]\n",
    "    4. Compute mean and standard deviation for the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('..')) \n",
    "import warnings\n",
    "import os, random\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import src.data_preprocessing as preprocessing\n",
    "\n",
    " \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Import base data paths\n",
    "COCO_DATA_PATH = \"data/coco2017/\"\n",
    "VIS_DATA_PATH = \"data/vis_drone_data/\"\n",
    "SOD_DATA_PATH = \"data/uav_sod_data/\"\n",
    "CITY_DATA_PATH = \"data/city-scapes-data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COCO2017 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train, test and validation paths\n",
    "train_path      = os.path.join(COCO_DATA_PATH, \"train\")\n",
    "validation_path = os.path.join(COCO_DATA_PATH, \"validation\")\n",
    "\n",
    "coco_paths = [train_path, validation_path]\n",
    "\n",
    "# Fix the annotations format, resize the images\n",
    "for path in coco_paths:\n",
    "    images_path      = os.path.join(path, \"images\")\n",
    "    annotations_path = os.path.join(path, \"annotations\")\n",
    "    \n",
    "    # Annotations and image transformations\n",
    "    preprocessing.convert_coco_annotations(path)\n",
    "    preprocessing.verify_annotations(path)\n",
    "    preprocessing.resize_data(path)\n",
    "    \n",
    "# Get the mean and standard deviation for the COCO training set \n",
    "preprocessing.compute_mean_std(os.path.join(train_path, \"images\") , \"coco_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vis-Drone Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train, test and validation paths\n",
    "train_path      = os.path.join(VIS_DATA_PATH, \"train\")\n",
    "validation_path = os.path.join(VIS_DATA_PATH, \"validation\")\n",
    "\n",
    "vis_paths = [train_path, validation_path]\n",
    "\n",
    "\n",
    "# Fix the annotations format, resize the images\n",
    "for path in coco_paths:\n",
    "    images_path      = os.path.join(path, \"images\")\n",
    "    annotations_path = os.path.join(path, \"annotations\")\n",
    "    \n",
    "    # Annotations and image transformations\n",
    "    preprocessing.extract_annotation_values(annotations_path)\n",
    "    preprocessing.resize_data(path)\n",
    "    \n",
    "    \n",
    "# Get the mean and standard deviation for the Vis-Drone training set \n",
    "preprocessing.compute_mean_std(os.path.join(train_path, \"images\") , \"vis_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UAV-SOD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train, test and validation paths\n",
    "train_path      = os.path.join(SOD_DATA_PATH, \"train\")\n",
    "test_path       = os.path.join(SOD_DATA_PATH, \"test\"  )\n",
    "validation_path = os.path.join(SOD_DATA_PATH, \"validation\")\n",
    "\n",
    "uav_paths = [train_path, test_path, validation_path]\n",
    "\n",
    "\n",
    "# Fix the annotations format, resize the images\n",
    "for path in uav_paths:\n",
    "    images_path      = os.path.join(path, \"images\")\n",
    "    annotations_path = os.path.join(path, \"annotations\")\n",
    "    \n",
    "    # Annotation and image transformations\n",
    "    preprocessing.xml_to_txt(annotations_path)\n",
    "    preprocessing.resize_data(path)\n",
    "    \n",
    "\n",
    "# Get the mean and standard deviation for the UAV training set \n",
    "preprocessing.compute_mean_std(os.path.join(train_path, \"images\") , \"uav_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CityScapes Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the process by re-organizing the folder structure for the annotations\n",
    "images_path      = \"city_scapes_images/leftImg8bit\"\n",
    "annotations_path = \"city_scapes_annotations\"\n",
    "preprocessing.reorganize_cityscapes(images_path, annotations_path)\n",
    "\n",
    "\n",
    "# Define the train, test and validation paths\n",
    "train_path      = os.path.join(CITY_DATA_PATH, \"train\")\n",
    "test_path       = os.path.join(CITY_DATA_PATH, \"test\"  )\n",
    "validation_path = os.path.join(CITY_DATA_PATH, \"validation\")\n",
    "\n",
    "city_paths = [train_path, test_path, validation_path]\n",
    "\n",
    "# Fix the annotations format, resize the images\n",
    "for path in city_paths:\n",
    "    images_path      = os.path.join(path, \"images\")\n",
    "    annotations_path = os.path.join(path, \"annotations\")\n",
    "    \n",
    "    # Annotation and image transformations\n",
    "    preprocessing.json_to_text(annotations_path, annotations_path)\n",
    "    preprocessing.resize_data(path)\n",
    "\n",
    "\n",
    "# Rename the image and annotation files in order to make it easier for the training\n",
    "preprocessing.compute_mean_std(images_path, \"city_scapes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Validation\n",
    "\n",
    "\n",
    "In this case we want to plot images and the corresponding annotations after the pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO2017 dataset pre-processing plotting\n",
    "preprocessing.plot_images_and_annotations(COCO_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vis-drone dataset pre-processing plotting\n",
    "preprocessing.plot_images_and_annotations(VIS_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOD-UAV dataset pre-processing plotting\n",
    "preprocessing.plot_images_and_annotations(SOD_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# City-scapes dataset pre-processing plotting\n",
    "preprocessing.plot_images_and_annotations(CITY_DATA_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
