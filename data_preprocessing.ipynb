{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing for all the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Goals\n",
    "\n",
    "\n",
    "- **COCO** dataset:\n",
    "    1. Transform the folder structure from [images, annotations] to [train, validation]\n",
    "    2. Transform the instances_train2017.json and instances_val2017.json to text files.\n",
    "        - Bounding Boxes \n",
    "        - Class code\n",
    "        - Segmentation data (mask data with format [(x_i, y_i), (x_(i+1), y_(i+1), ... )])\n",
    "    3. Resize images and annotations\n",
    "    4. Compute mean and standard deviation for the data using 2500 images as samples\n",
    "\n",
    "\n",
    "- **Vis-Drone** dataset:\n",
    "    1. Extract the bounding boxes from format [x_min, y_min, width, height] to [x_min, y_min, x_max, y_max]\n",
    "    2. Resize images and annotations\n",
    "    3. Produce the segmentation data from the bounding box data: [(x_min, y_min), (x_min, y_max), (x_max, y_min), (x_max, y_max)]\n",
    "    4. Compute mean and standard deviation for the data\n",
    "\n",
    "\n",
    "- **UAV-SOD Drone** dataset:\n",
    "    1. Extract the bounding box data and the class codes from XML files and create the text file equivalent\n",
    "    2. Resize images and annotations\n",
    "    3. Produce the segmentation data from the bounding box data: [(x_min, y_min), (x_min, y_max), (x_max, y_min), (x_max, y_max)]\n",
    "    4. Compute mean and standard deviation for the data\n",
    "\n",
    "\n",
    "- City Scapes dataset:\n",
    "    1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "import torch    \n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, shutil, cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import src.data_preprocessing as preprocessing\n",
    "import src.utils as utils\n",
    " \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Import base data paths\n",
    "COCO_DATA_PATH = \"data/coco2017/\"\n",
    "VIS_DATA_PATH = \"data/vis_drone_data/\"\n",
    "SOD_DATA_PATH = \"data/uav_sod_data/\"\n",
    "CITY_DATA_PATH = \"data/city_scapes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COCO2017 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train, test and validation paths\n",
    "train_path      = os.path.join(COCO_DATA_PATH, \"train\")\n",
    "validation_path = os.path.join(COCO_DATA_PATH, \"validation\")\n",
    "\n",
    "coco_paths = [train_path, validation_path]\n",
    "\n",
    "\n",
    "# Fix the annotations format, resize the images\n",
    "for path in coco_paths:\n",
    "    images_path      = os.path.join(path, \"images\")\n",
    "    annotations_path = os.path.join(path, \"annotations\")\n",
    "    \n",
    "    # Annotations and image transformations\n",
    "    preprocessing.convert_coco_annotations(os.path.join(annotations_path, \"annotations.json\"))\n",
    "    preprocessing.resize_data(path)\n",
    "    preprocessing.compute_mean_std(images_path , \"coco_data\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "input_json_path = 'instances_val2017.json'\n",
    "output_directory = 'annotations'\n",
    "preprocessing.convert_coco_annotations(input_json_path, output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vis-Drone Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train, test and validation paths\n",
    "train_path      = os.path.join(VIS_DATA_PATH, \"train\")\n",
    "validation_path = os.path.join(VIS_DATA_PATH, \"validation\")\n",
    "\n",
    "coco_paths = [train_path, validation_path]\n",
    "\n",
    "\n",
    "# Fix the annotations format, resize the images\n",
    "for path in coco_paths:\n",
    "    images_path      = os.path.join(path, \"images\")\n",
    "    annotations_path = os.path.join(path, \"annotations\")\n",
    "    \n",
    "    # Annotations and image transformations\n",
    "    preprocessing.extract_annotation_values(annotations_path)\n",
    "    preprocessing.resize_data(path)\n",
    "    preprocessing.compute_mean_std(images_path , \"vis_drone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UAV-SOD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train, test and validation paths\n",
    "train_path      = os.path.join(SOD_DATA_PATH, \"train\")\n",
    "test_path       = os.path.join(SOD_DATA_PATH, \"test\"  )\n",
    "validation_path = os.path.join(SOD_DATA_PATH, \"validation\")\n",
    "\n",
    "uav_paths = [train_path, test_path, validation_path]\n",
    "\n",
    "\n",
    "# Fix the annotations format, resize the images\n",
    "for path in uav_paths:\n",
    "    images_path      = os.path.join(path, \"images\")\n",
    "    annotations_path = os.path.join(path, \"annotations\")\n",
    "    \n",
    "    # Annotation and image transformations\n",
    "    preprocessing.xml_to_txt(annotations_path)\n",
    "    preprocessing.resize_data(path)\n",
    "    preprocessing.compute_mean_std(images_path, \"uav_sod\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CityScapes Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
