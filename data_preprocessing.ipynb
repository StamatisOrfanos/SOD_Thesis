{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing for all the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Goals\n",
    "\n",
    "\n",
    "- **COCO** dataset:\n",
    "    1. Transform the folder structure from [images, annotations] to [train, validation]\n",
    "    2. Transform the instances_train2017.json and instances_val2017.json to text files.\n",
    "        - Bounding Boxes \n",
    "        - Class code\n",
    "        - Segmentation data (mask data with format [(x_i, y_i), (x_(i+1), y_(i+1), ... )])\n",
    "    3. Resize images and annotations\n",
    "    4. Compute mean and standard deviation for the data using 2500 images as samples\n",
    "\n",
    "\n",
    "- **Vis-Drone** dataset:\n",
    "    1. Extract the bounding boxes from format [x_min, y_min, width, height] to [x_min, y_min, x_max, y_max]\n",
    "    2. Resize images and annotations\n",
    "    3. Produce the segmentation data from the bounding box data: [(x_min, y_min), (x_min, y_max), (x_max, y_min), (x_max, y_max)]\n",
    "    4. Compute mean and standard deviation for the data\n",
    "\n",
    "\n",
    "- **UAV-SOD Drone** dataset:\n",
    "    1. Extract the bounding box data and the class codes from XML files and create the text file equivalent\n",
    "    2. Resize images and annotations\n",
    "    3. Produce the segmentation data from the bounding box data: [(x_min, y_min), (x_min, y_max), (x_max, y_min), (x_max, y_max)]\n",
    "    4. Compute mean and standard deviation for the data\n",
    "\n",
    "\n",
    "- City Scapes dataset:\n",
    "    1. Transform the folder structure from [images, annotations] to [train, validation]\n",
    "    2. Resize images and annotations\n",
    "    3. Produce the segmentation data from the bounding box data: [(x_min, y_min), (x_min, y_max), (x_max, y_min), (x_max, y_max)]\n",
    "    4. Compute mean and standard deviation for the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('..')) \n",
    "import warnings\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import src.data_preprocessing as preprocessing\n",
    "\n",
    " \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Import base data paths\n",
    "COCO_DATA_PATH = \"data/coco2017/\"\n",
    "VIS_DATA_PATH = \"data/vis_drone_data/\"\n",
    "SOD_DATA_PATH = \"data/uav_sod_data/\"\n",
    "CITY_DATA_PATH = \"data/city_scapes/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COCO2017 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the process by re-organizing the folder structure to the typical train -> [images, annotations] and validation -> [images, annotations]\n",
    "preprocessing.reorganize_coco_structure(COCO_DATA_PATH)\n",
    "\n",
    "# Define the train, test and validation paths\n",
    "train_path      = os.path.join(COCO_DATA_PATH, \"train\")\n",
    "validation_path = os.path.join(COCO_DATA_PATH, \"validation\")\n",
    "\n",
    "coco_paths = [train_path, validation_path]\n",
    "\n",
    "# Fix the annotations format, resize the images\n",
    "for path in coco_paths:\n",
    "    images_path      = os.path.join(path, \"images\")\n",
    "    annotations_path = os.path.join(path, \"annotations\")\n",
    "    \n",
    "    # Annotations and image transformations\n",
    "    preprocessing.convert_coco_annotations(os.path.join(annotations_path, \"annotations.json\"), \"annotations\")\n",
    "    preprocessing.resize_data(path)\n",
    "    \n",
    "# Get the mean and standard deviation for the COCO training set \n",
    "preprocessing.compute_mean_std(os.path.join(train_path, \"images\") , \"coco_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vis-Drone Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train, test and validation paths\n",
    "train_path      = os.path.join(VIS_DATA_PATH, \"train\")\n",
    "validation_path = os.path.join(VIS_DATA_PATH, \"validation\")\n",
    "\n",
    "vis_paths = [train_path, validation_path]\n",
    "\n",
    "\n",
    "# Fix the annotations format, resize the images\n",
    "for path in coco_paths:\n",
    "    images_path      = os.path.join(path, \"images\")\n",
    "    annotations_path = os.path.join(path, \"annotations\")\n",
    "    \n",
    "    # Annotations and image transformations\n",
    "    preprocessing.extract_annotation_values(annotations_path)\n",
    "    preprocessing.resize_data(path)\n",
    "    \n",
    "    \n",
    "# Get the mean and standard deviation for the Vis-Drone training set \n",
    "preprocessing.compute_mean_std(os.path.join(train_path, \"images\") , \"vis_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UAV-SOD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train, test and validation paths\n",
    "train_path      = os.path.join(SOD_DATA_PATH, \"train\")\n",
    "test_path       = os.path.join(SOD_DATA_PATH, \"test\"  )\n",
    "validation_path = os.path.join(SOD_DATA_PATH, \"validation\")\n",
    "\n",
    "uav_paths = [train_path, test_path, validation_path]\n",
    "\n",
    "\n",
    "# Fix the annotations format, resize the images\n",
    "for path in uav_paths:\n",
    "    images_path      = os.path.join(path, \"images\")\n",
    "    annotations_path = os.path.join(path, \"annotations\")\n",
    "    \n",
    "    # Annotation and image transformations\n",
    "    preprocessing.xml_to_txt(annotations_path)\n",
    "    preprocessing.resize_data(path)\n",
    "    \n",
    "\n",
    "# Get the mean and standard deviation for the UAV training set \n",
    "preprocessing.compute_mean_std(os.path.join(train_path, \"images\") , \"uav_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CityScapes Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting JSON to Text files: 100%|██████████| 1/1 [00:00<00:00, 1041.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# Start the process by re-organizing the folder structure for the annotations\n",
    "preprocessing.reorganize_cityscapes_annotations(CITY_DATA_PATH)\n",
    "\n",
    "# Start the process by re-organizing the folder structure for the images\n",
    "# SOS: CityScapes has a weird dataset where the images and annotations are at two completely different folders\n",
    "image_folder = \"city_scapes\"\n",
    "preprocessing.reorganize_cityscapes_annotations(image_folder)\n",
    "\n",
    "\n",
    "# Manual Action: Move the images with the annotation files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Note\n",
    "\n",
    "The last cell is important to be executed after a manual action, where we take the images from the images city scapes folder and add to them the annotations folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train, test and validation paths\n",
    "train_path      = os.path.join(CITY_DATA_PATH, \"train\")\n",
    "test_path       = os.path.join(CITY_DATA_PATH, \"test\"  )\n",
    "validation_path = os.path.join(CITY_DATA_PATH, \"validation\")\n",
    "\n",
    "city_paths = [train_path, test_path, validation_path]\n",
    "\n",
    "# Fix the annotations format, resize the images\n",
    "for path in city_paths:\n",
    "    images_path      = os.path.join(path, \"images\")\n",
    "    annotations_path = os.path.join(path, \"annotations\")\n",
    "    \n",
    "    # Annotation and image transformations\n",
    "    preprocessing.json_to_text(annotations_path, annotations_path)\n",
    "    preprocessing.resize_data(path)\n",
    "\n",
    "\n",
    "# Rename the image and annotation files in order to make it easier for the training\n",
    "preprocessing.rename_files(CITY_DATA_PATH)\n",
    "preprocessing.compute_mean_std(images_path, \"uav_sod\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
