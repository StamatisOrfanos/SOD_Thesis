Given that thus far the model makes sense and everything should work fine, I think it is the time to define the loss function. 
In this case I think a good approach would be to use smooth_l1_loss for the bounding box, cross_entropy_loss for the predicted 
classes vs the actual classes and binary_cross_entropy_with_logits for the masks right?




That is great progress, at this point I think it is time to talk about the data at hand. I have four datasets:
1. COCO2017
2. City-scapes (5000 images and annotations)
3. Vis-drone dataset
4. SOD-drone dataset

In order to have a common data structure to make the training easier I created a pre-processing script that transforms all the data to one specific format. 
For all the datasets we have the base directory that contains three folders: train, test and validation.

For each one of the train, test, validation we have two folders named images and annotations. The images folder contains images type .jpg or .png and have 
a static size of 600x600. The annotations folder contains .txt file with the annotations of an image. In order to make the training efficient the name of 
the image is the same with the name of the annotations, like for example if the image is image_1.jpg the annotation is image_1.txt.

The annotations of the images contains multiple lines each line for an object in the image. The format is the following:
x_min, y_min, x_max, y_max, class_code, [(x_1, y_1), ...., (x_n, y_n)]

The bounding box data are: x_min, y_min, x_max, y_max, 
The code for the object: class_code
The mask data: [(x_1, y_1), ...., (x_n, y_n)]. 

In the case of the mask data we have a interesting situation. Some of the datasets did not include mask data so we use the bounding box coordinates to 
create the mask as follows:
[(x_min, y_min), (x_min, y_max), (x_max, y_min), (x_max, y_max)], which means that the mask data are not static and it depends in the shape of the object 
for the number of tuples we have in the mask data (tuples = points of the shape). 

I would like to ask the following:
1. Do the data match the inputs of the EFPN model and are those data suitable for the training of the model?
2. If not what changes should I make?
3. At this moment I would like to also ask how do we train a small object detection like this? I have not trained a model on small object detection 
before and I would like a step by step process.