\chapter{Discussion}


\section{Differences between models}

The Extended Masked-Attention Mask Transformer (EMAMT) is an adaptation of the original Masked-Attention Mask Transformer (MAMT) but incorporates 
an Efficient Feature Pyramid Network (EFPN) as its backbone, enhancing its efficiency particularly for small object detection in challenging environments 
like aerial or urban imagery. 

In terms of size and complexity, EMAMT is designed to be significantly lighter—56\% fewer parameters compared to MAMT—without compromising significantly 
on detection accuracy. This reduction in size facilitates a lower computational demand, measured at 492 gigaflops, which is substantially less than the 
original MAMT's 868 gigaflops, potentially enhancing deployment capabilities on resource constrained platforms.

However, this efficiency comes with trade-offs. The performance of EMAMT, while impressive, generally trails behind that of MAMT when measured by 
mean Average Precision (mAP) across various Intersection over Union (IoU) thresholds. For instance, on the MS COCO dataset, EMAMT shows a performance drop 
of about 6.5\% in mAP when compared to MAMT. Despite this, it still maintains a competitive edge in scenarios involving small objects, as evidenced by its 
performance on datasets specifically challenging for object scale, like UAV-SOD.

The use of different backbones also influences the loss functions and accuracy. While MAMT uses a Sliding Window Transformer, which supports a dynamic 
range of features but at a high computational cost, EMAMT's EFPN provides a static yet optimized set of pyramid features that are especially effective for 
varied object sizes and types encountered in practical applications.

Additionally, it is important to highlight that the performance of our EMAMT is commendable and compares favorably with many models in the field of object 
detection and instance segmentation. However, it should be noted that when compared to the Mask2Former model, which represents the state-of-the-art for these tasks.
This comparison underscores the exceptionally high benchmark set by Mask2Former due to its sophisticated design tailored specifically for advanced 
segmentation and detection capabilities.

Overall, EMAMT represents a strategic balance between efficiency and performance, making it a viable option for applications where speed and model size are 
just as critical as accuracy. This balance is crucial for real world applications where computational resources and response times are often limited.


\section{Performance difference between datasets}

The Extended Masked-Attention Mask Transformer (EMAMT) has been benchmarked across three distinct datasets—MS COCO, UAV-SOD, and VisDrone, each providing unique 
insights into its performance nuances compared to the original Masked-Attention Mask Transformer (MAMT).

In the MS COCO dataset, characterized by its diverse and complex scenes, EMAMT showed a decrease in performance, with a drop of approximately 6.5\% in 
mean Average Precision (mAP). This illustrates the trade-offs of a reduced computational footprint, where EMAMT sacrifices some accuracy for efficiency, 
particularly in scenarios with objects that are rare in the dataset.

On the other hand the EMAMT model excelled in the UAV-SOD dataset, which focuses on small object detection from aerial views. Here, the model slightly outperformed the MAMT model, 
underscoring its effectiveness in environments where its optimized architecture for aerial imagery and small scale object detection could be fully leveraged. 
This suggests that EMAMT’s design, which includes an Enhanced Feature Pyramid Network (EFPN) backbone, is particularly well suited for parsing the details required 
in drone based monitoring.

However, the performance in the VisDrone dataset, with its varied object numbers and missing annotations. The model saw a significant reduction 
in performance, about 13.7\% lower in mAP compared to MAMT, indicating challenges in handling varied object numbers. These varied results across datasets 
highlight EMAMT's suitability for specific applications, particularly where efficiency and specialized small object detection are prioritized.