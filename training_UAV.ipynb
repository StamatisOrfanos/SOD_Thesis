{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Extended Mask2Former UAV-SOD Drone Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os, json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from src.data_set_up import SOD_Data\n",
    "from models.extended_mask2former_model import ExtendedMask2Former\n",
    "\n",
    "\n",
    "# Import data paths\n",
    "map_path = \"src/code_map.json\"\n",
    "data_info_path = \"src/data_info/uav_data_preprocessing.json\"\n",
    "base_dir = \"data/uav_sod_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up GPU growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device we are going to load the model and the data\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up basic static data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47168887769178647, 0.5133378785061212, 0.5267694282792925]\n",
      "[0.12757125130655708, 0.09660376509464505, 0.07690925977558358]\n"
     ]
    }
   ],
   "source": [
    "# Load the classes of the UAV-SOD Drone dataset\n",
    "map = open(map_path)\n",
    "data = json.load(map)\n",
    "classes = data[\"UAV_SOD_DRONE\"][\"CATEGORY_ID_TO_NAME\"]\n",
    "map.close() \n",
    "\n",
    "number_classes = len(classes)\n",
    "\n",
    "\n",
    "# Load the mean and standard deviation for the train data\n",
    "map = open(data_info_path)\n",
    "data = json.load(map)\n",
    "mean = data[\"uav_data\"][\"mean\"]\n",
    "standard_deviation = data[\"uav_data\"][\"std\"]\n",
    "map.close() \n",
    "\n",
    "\n",
    "# Define train, test and validation path\n",
    "train_path = os.path.join(base_dir, \"train\")\n",
    "test_path = os.path.join(base_dir, \"test\")\n",
    "validation_path = os.path.join(base_dir, \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function that creates batches of [(image_1, annotations_1), ..., (image_n, annotations_n)]\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# Transformations for each one of the type of data\n",
    "data_transform = {\n",
    "    \"train\": transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=standard_deviation)]),\n",
    "\n",
    "    \"test\": transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=standard_deviation)]), \n",
    "    \n",
    "    \"validation\": transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=standard_deviation)]) \n",
    "}\n",
    "\n",
    "\n",
    "# Dataset and DataLoader\n",
    "train_dataset      = SOD_Data(os.path.join(train_path, \"/images\"), os.path.join(train_path, \"/annotations\"), transform=data_transform[\"train\"])\n",
    "test_dataset       = SOD_Data(os.path.join(test_path, \"/images\"),  os.path.join(test_path, \"/annotations\"),  transform=data_transform[\"test\"])\n",
    "validation_dataset = SOD_Data(os.path.join(validation_path, \"/images\"),  os.path.join(validation_path, \"/annotations\"), transform=data_transform[\"validation\"])\n",
    "\n",
    "train_loader      = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader       = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model\n",
    "model = ExtendedMask2Former(number_classes)\n",
    "\n",
    "# Optimizer and Scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 10\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, targets in train_loader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = model.compute_loss(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "    scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
