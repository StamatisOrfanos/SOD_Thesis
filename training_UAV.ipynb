{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Extended Mask2Former UAV-SOD Drone Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import os, json, statistics\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from src.data_set_up import SOD_Data\n",
    "from models.extended_mask2former_model import ExtendedMask2Former\n",
    "from models.efpn_backbone.anchors import Anchors\n",
    "from src.helpers import train, validate, test\n",
    "\n",
    "\n",
    "# Import data paths\n",
    "map_path = \"src/code_map.json\"\n",
    "data_info_path = \"src/data_info/uav_data_preprocessing.json\"\n",
    "base_dir = \"data/uav_sod_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up GPU growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device we are going to load the model and the data\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up basic static data\n",
    "\n",
    "- Get the number of classes\n",
    "- Get the mean and standard deviation \n",
    "- Create the data paths for the [train, test, validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classes of the UAV-SOD Drone dataset\n",
    "map = open(map_path)\n",
    "data = json.load(map)\n",
    "classes = data[\"UAV_SOD_DRONE\"][\"CATEGORY_ID_TO_NAME\"]\n",
    "map.close() \n",
    "\n",
    "\n",
    "# The number of classes plus the background\n",
    "number_classes = len(classes) + 1\n",
    "\n",
    "\n",
    "# Load the mean and standard deviation for the train data\n",
    "map = open(data_info_path)\n",
    "data = json.load(map)\n",
    "mean = data[\"uav_data\"][\"mean\"]\n",
    "standard_deviation = data[\"uav_data\"][\"std\"]\n",
    "map.close() \n",
    "\n",
    "\n",
    "# Define train, test and validation path\n",
    "train_path = os.path.join(base_dir, \"train\")\n",
    "test_path = os.path.join(base_dir, \"test\")\n",
    "validation_path = os.path.join(base_dir, \"validation\")\n",
    "\n",
    "\n",
    "# Define train, test and validation path\n",
    "train_path = os.path.join(base_dir, 'train')\n",
    "test_path = os.path.join(base_dir, 'test')\n",
    "validation_path = os.path.join(base_dir, 'validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset - Dataloader\n",
    "- Collate function\n",
    "- Data transformations\n",
    "- DataLoader and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transform function\n",
    "data_transform = {\n",
    "    \"train\": transforms.Compose([\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=standard_deviation)]),\n",
    "\n",
    "    \"test\": transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=standard_deviation)]), \n",
    "            \n",
    "    \"validation\": transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=standard_deviation)]) \n",
    "}\n",
    "\n",
    "\n",
    "# Dataset and DataLoader\n",
    "train_dataset      = SOD_Data(train_path +'/images', train_path + '/annotations', data_transform['train'])\n",
    "test_dataset       = SOD_Data(test_path + '/images', test_path  + '/annotations', data_transform['test'])\n",
    "validation_dataset = SOD_Data(validation_path + '/images', validation_path + '/annotations', data_transform['validation'])\n",
    "\n",
    "train_loader      = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "test_loader       = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=4, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bounding Box Heuristics\n",
    "\n",
    "In order to create accurate anchors we get the dataset's bounding box statistics, like mean and standard deviation in order to create representative anchors to help the model find the bounding boxes faster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a dictionary of the main statistics\n",
    "bbox_stats = train_dataset.analyze_bounding_boxes()\n",
    "\n",
    "# Get mean for width and height\n",
    "mean_width = bbox_stats['mean_width']\n",
    "mean_height = bbox_stats['mean_height']\n",
    "\n",
    "# Get standard deviation for width and height\n",
    "std_width = bbox_stats['std_width']\n",
    "std_height = bbox_stats['std_height']\n",
    "\n",
    "# Print statistics\n",
    "print(\"Aspect Ratios:\", sorted(set(bbox_stats['aspect_ratios'])))\n",
    "print(\"Mean Width:\", bbox_stats['mean_width'])\n",
    "print(\"Mean Height:\", bbox_stats['mean_height'])\n",
    "print(\"Width Std Dev:\", bbox_stats['std_width'])\n",
    "print(\"Height Std Dev:\", bbox_stats['std_height'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the statistics above decide on the values of the statistics \n",
    "feature_map_shapes = [(19, 19)]\n",
    "\n",
    "# Get all the scales\n",
    "scales = [32]\n",
    "\n",
    "# Define the aspect ratios\n",
    "aspect_ratios = [0.5, 1.0]\n",
    "anchors = torch.tensor(Anchors.generate_anchors(feature_map_shapes, scales, aspect_ratios), dtype=torch.float32)\n",
    "\n",
    "print(\"The number of anchors is: {}\".format(anchors.size(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the ExtendedMask2Former model with all the parameters needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the ExtendedMask2Former model and load it to device\n",
    "model = ExtendedMask2Former(num_classes=number_classes, num_anchors=anchors.size(0), device=device).to(device)\n",
    "anchors = anchors.to(device)\n",
    "\n",
    "# Hyperparameters selection\n",
    "num_epochs = 1\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Define the optimizer and the scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(columns=['epoch', 'loss', 'precision', 'recall', 'mAP', 'mAPCOCO'])\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "  model.train()\n",
    "  per_epoch_predictions = []\n",
    "  per_epoch_ground_truths = []\n",
    "  per_epoch_loss = []\n",
    "  \n",
    "  for images, targets in train_loader:\n",
    "      images = torch.stack(images).to(device)\n",
    "      targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "      \n",
    "      # Concatenate and stack data\n",
    "      batched_bboxes = torch.cat([t['boxes'] for t in targets]).to(device)\n",
    "      batched_labels = torch.cat([t['labels'] for t in targets]).to(device)\n",
    "      batched_masks  = torch.stack([t['masks'] for t in targets]).to(device)\n",
    "      batched_mask_labels = torch.stack([t['mask_labels'] for t in targets]).to(device)\n",
    "      \n",
    "      # Get the predictions of the model and the actual data to feed to the loss function\n",
    "      predictions = model(images, batched_masks)\n",
    "      actual = {'boxes': batched_bboxes, 'labels': batched_labels, 'masks': batched_masks, 'mask_labels': batched_mask_labels}\n",
    "      \n",
    "      # Get the loss value and background propagate the value \n",
    "      loss = model.compute_loss(predictions, actual, anchors)\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      # Get the predictions, actual data and loss for each batch to calculate the epoch metrics\n",
    "      per_epoch_loss.append(loss)\n",
    "      per_epoch_predictions.append(predictions)\n",
    "      per_epoch_ground_truths.append(actual)\n",
    "  \n",
    "  # Get Mean Average Precisions for IoU of [0.5] and [0.5-0.95] with Mean Average Precision\n",
    "  map = model.calculate_map(predictions, targets, [0.5])\n",
    "  mapCOCO = model.calculate_map(predictions, targets, torch.arange(0.5, 1.0, 0.05))\n",
    "  loss = statistics.mean(per_epoch_loss)\n",
    "  \n",
    "  # Add epoch metrics\n",
    "  new_row = {'epoch': epoch, 'loss': loss, 'precision': map['precision'], 'recall': map['recall'], 'mAP': map['mAP'], 'mAPCOCO': mapCOCO['mAP']}\n",
    "  metrics_df.loc[len(metrics_df)] = new_row  # type: ignore\n",
    "  \n",
    "  # Save model info every 25 epochs to check progress with evaluation\n",
    "  if epoch % 25 == 0 and epoch != 0: torch.save(model, 'results/model_uav_{}.pt'.format(epoch)) # type: ignore\n",
    "  print('For the epoch:{} the loss is: {}, the precision is: {}, the recall is: {}, the mAP[0.5] is: {} and the mAP[0.5-0.95] is: {}'.format(loss, map['precision'], map['recall'], map['mAP'], mapCOCO['mAP']))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the training metrics for the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv(\"training_metrics_uav.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
