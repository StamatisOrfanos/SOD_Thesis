{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Extended Mask2Former UAV-SOD Drone Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import os, json\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from src.data_set_up import SOD_Data\n",
    "from models.extended_mask2former_model import ExtendedMask2Former\n",
    "from models.efpn_backbone.anchors import Anchors\n",
    "from src.helpers import train, validate, test\n",
    "\n",
    "\n",
    "# Import data paths\n",
    "map_path = \"src/code_map.json\"\n",
    "data_info_path = \"src/data_info/uav_data_preprocessing.json\"\n",
    "base_dir = \"data/uav_sod_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up GPU growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device we are going to load the model and the data\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up basic static data\n",
    "\n",
    "- Get the number of classes\n",
    "- Get the mean and standard deviation \n",
    "- Create the data paths for the [train, test, validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classes of the UAV-SOD Drone dataset\n",
    "map = open(map_path)\n",
    "data = json.load(map)\n",
    "classes = data[\"UAV_SOD_DRONE\"][\"CATEGORY_ID_TO_NAME\"]\n",
    "map.close() \n",
    "\n",
    "# The number of classes plus the background\n",
    "number_classes = len(classes) + 1\n",
    "\n",
    "\n",
    "# Load the mean and standard deviation for the train data\n",
    "map = open(data_info_path)\n",
    "data = json.load(map)\n",
    "mean = data[\"uav_data\"][\"mean\"]\n",
    "standard_deviation = data[\"uav_data\"][\"std\"]\n",
    "map.close() \n",
    "\n",
    "\n",
    "# Define train, test and validation path\n",
    "train_path = os.path.join(base_dir, \"train\")\n",
    "test_path = os.path.join(base_dir, \"test\")\n",
    "validation_path = os.path.join(base_dir, \"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset - Dataloader\n",
    "- Collate function\n",
    "- Data transformations\n",
    "- DataLoader and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transform function\n",
    "data_transform = {\n",
    "    \"train\": transforms.Compose([\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=standard_deviation)]),\n",
    "\n",
    "    \"test\": transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=standard_deviation)]), \n",
    "            \n",
    "    \"validation\": transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=standard_deviation)]) \n",
    "}\n",
    "\n",
    "\n",
    "# Dataset and DataLoader\n",
    "train_dataset      = SOD_Data(train_path +\"/images\", train_path + \"/annotations\", data_transform[\"train\"])\n",
    "test_dataset       = SOD_Data(test_path + \"/images\", test_path  + \"/annotations\", data_transform[\"test\"])\n",
    "validation_dataset = SOD_Data(validation_path + \"/images\", validation_path + \"/annotations\", data_transform[\"validation\"])\n",
    "\n",
    "train_loader      = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)), pin_memory=True)\n",
    "test_loader       = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=4, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bounding Box Heuristics\n",
    "\n",
    "In order to create accurate anchors we get the dataset's bounding box statistics, like mean and standard deviation in order to create representative anchors to help the model find the bounding boxes faster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect Ratios: [0.0, 0.14285714285714285, 0.15384615384615385, 0.16666666666666666, 0.17647058823529413, 0.18421052631578946, 0.1875, 0.2, 0.2222222222222222, 0.22727272727272727, 0.23076923076923078, 0.23404255319148937, 0.23529411764705882, 0.23809523809523808, 0.24242424242424243, 0.25, 0.2608695652173913, 0.26548672566371684, 0.26666666666666666, 0.2727272727272727, 0.2777777777777778, 0.2786885245901639, 0.28, 0.2830188679245283, 0.2857142857142857, 0.288135593220339, 0.2894736842105263, 0.29411764705882354, 0.2962962962962963, 0.2972972972972973, 0.3, 0.30434782608695654, 0.30952380952380953, 0.3114754098360656, 0.3125, 0.3140495867768595, 0.3142857142857143, 0.3157894736842105, 0.3170731707317073, 0.3181818181818182, 0.3188405797101449, 0.3235294117647059, 0.3246753246753247, 0.328125, 0.3333333333333333, 0.34285714285714286, 0.34615384615384615, 0.34782608695652173, 0.35, 0.35135135135135137, 0.35294117647058826, 0.3548387096774194, 0.35555555555555557, 0.35714285714285715, 0.359375, 0.36, 0.3611111111111111, 0.36134453781512604, 0.3620689655172414, 0.3628808864265928, 0.36363636363636365, 0.36666666666666664, 0.3670886075949367, 0.367816091954023, 0.3684210526315789, 0.36904761904761907, 0.37142857142857144, 0.37254901960784315, 0.375, 0.37623762376237624, 0.37735849056603776, 0.37777777777777777, 0.38095238095238093, 0.38461538461538464, 0.3888888888888889, 0.391304347826087, 0.39285714285714285, 0.3939393939393939, 0.3968253968253968, 0.4, 0.40350877192982454, 0.40540540540540543, 0.40625, 0.4074074074074074, 0.4076923076923077, 0.40816326530612246, 0.4090909090909091, 0.4117647058823529, 0.4166666666666667, 0.42105263157894735, 0.423728813559322, 0.42592592592592593, 0.42857142857142855, 0.4318181818181818, 0.43333333333333335, 0.43478260869565216, 0.4358974358974359, 0.4375, 0.4411764705882353, 0.4418604651162791, 0.4423076923076923, 0.4444444444444444, 0.44680851063829785, 0.4473684210526316, 0.448, 0.45, 0.4528301886792453, 0.45454545454545453, 0.4580152671755725, 0.4583333333333333, 0.45977011494252873, 0.46, 0.46153846153846156, 0.4642857142857143, 0.4666666666666667, 0.46808510638297873, 0.47058823529411764, 0.4722222222222222, 0.4731182795698925, 0.47368421052631576, 0.4745762711864407, 0.47619047619047616, 0.4782608695652174, 0.48, 0.4827586206896552, 0.4838709677419355, 0.4847560975609756, 0.4857142857142857, 0.4864864864864865, 0.48717948717948717, 0.4883720930232558, 0.4888888888888889, 0.49056603773584906, 0.49295774647887325, 0.5, 0.5054945054945055, 0.5128205128205128, 0.5151515151515151, 0.5172413793103449, 0.5189873417721519, 0.5217391304347826, 0.5227272727272727, 0.5238095238095238, 0.5263157894736842, 0.5277777777777778, 0.5294117647058824, 0.53125, 0.5333333333333333, 0.5348837209302325, 0.5357142857142857, 0.5365853658536586, 0.5384615384615384, 0.5405405405405406, 0.5409836065573771, 0.5416666666666666, 0.5436893203883495, 0.5454545454545454, 0.5462184873949579, 0.5476190476190477, 0.5483870967741935, 0.55, 0.5517241379310345, 0.5531914893617021, 0.5555555555555556, 0.5573770491803278, 0.5581395348837209, 0.5588235294117647, 0.56, 0.5625, 0.5641025641025641, 0.5652173913043478, 0.5660377358490566, 0.5666666666666667, 0.5681818181818182, 0.5684210526315789, 0.5714285714285714, 0.575, 0.5757575757575758, 0.576271186440678, 0.5764705882352941, 0.5769230769230769, 0.5789473684210527, 0.5806451612903226, 0.5813953488372093, 0.582089552238806, 0.5833333333333334, 0.5846153846153846, 0.5853658536585366, 0.5862068965517241, 0.5882352941176471, 0.5897435897435898, 0.5909090909090909, 0.5925925925925926, 0.5934065934065934, 0.59375, 0.5945945945945946, 0.5952380952380952, 0.5961538461538461, 0.6, 0.6046511627906976, 0.6056338028169014, 0.6063829787234043, 0.6071428571428571, 0.6086956521739131, 0.6101694915254238, 0.6111111111111112, 0.6129032258064516, 0.6136363636363636, 0.6153846153846154, 0.6176470588235294, 0.6181818181818182, 0.6185567010309279, 0.6190476190476191, 0.6206896551724138, 0.6216216216216216, 0.6222222222222222, 0.6224489795918368, 0.6226415094339622, 0.625, 0.6271186440677966, 0.6274509803921569, 0.6275862068965518, 0.627906976744186, 0.6285714285714286, 0.6296296296296297, 0.6302521008403361, 0.6311475409836066, 0.631578947368421, 0.6333333333333333, 0.6341463414634146, 0.6363636363636364, 0.6388888888888888, 0.64, 0.6410256410256411, 0.6428571428571429, 0.6444444444444445, 0.6451612903225806, 0.6458333333333334, 0.6470588235294118, 0.6486486486486487, 0.6491228070175439, 0.65, 0.6511627906976745, 0.6521739130434783, 0.6530612244897959, 0.6538461538461539, 0.6551724137931034, 0.65625, 0.6571428571428571, 0.6578947368421053, 0.6620689655172414, 0.6625, 0.6666666666666666, 0.668918918918919, 0.6724137931034483, 0.673469387755102, 0.6739130434782609, 0.675, 0.6756756756756757, 0.6764705882352942, 0.6774193548387096, 0.6785714285714286, 0.68, 0.6818181818181818, 0.6829268292682927, 0.6833333333333333, 0.6842105263157895, 0.6857142857142857, 0.6875, 0.6888888888888889, 0.6896551724137931, 0.6904761904761905, 0.6909090909090909, 0.6910569105691057, 0.6923076923076923, 0.6933333333333334, 0.6944444444444444, 0.6956521739130435, 0.6967509025270758, 0.696969696969697, 0.6981132075471698, 0.7, 0.7017543859649122, 0.7027027027027027, 0.7037037037037037, 0.7049180327868853, 0.7058823529411765, 0.7073170731707317, 0.7083333333333334, 0.7096774193548387, 0.7142857142857143, 0.7166666666666667, 0.717391304347826, 0.717948717948718, 0.7181818181818181, 0.71875, 0.72, 0.7205882352941176, 0.7209302325581395, 0.7222222222222222, 0.7241379310344828, 0.725, 0.7254901960784313, 0.7272727272727273, 0.7291666666666666, 0.7297297297297297, 0.7307692307692307, 0.7317073170731707, 0.7333333333333333, 0.7345132743362832, 0.7352941176470589, 0.7368421052631579, 0.7377049180327869, 0.7380952380952381, 0.7391304347826086, 0.74, 0.7407407407407407, 0.7413793103448276, 0.7415730337078652, 0.7419354838709677, 0.7428571428571429, 0.7435897435897436, 0.7446808510638298, 0.746031746031746, 0.7464788732394366, 0.7469879518072289, 0.75, 0.7523809523809524, 0.7547169811320755, 0.7551020408163265, 0.7555555555555555, 0.7560975609756098, 0.7567567567567568, 0.7575757575757576, 0.7586206896551724, 0.7592592592592593, 0.76, 0.7619047619047619, 0.7625, 0.7627118644067796, 0.7631578947368421, 0.7647058823529411, 0.765625, 0.7659574468085106, 0.7666666666666667, 0.7678571428571429, 0.7692307692307693, 0.7702702702702703, 0.7708333333333334, 0.7714285714285715, 0.7719298245614035, 0.7727272727272727, 0.7735849056603774, 0.7741935483870968, 0.7761194029850746, 0.7777777777777778, 0.78, 0.7804878048780488, 0.78125, 0.782608695652174, 0.7837837837837838, 0.7857142857142857, 0.7863247863247863, 0.7872340425531915, 0.7878787878787878, 0.7894736842105263, 0.7916666666666666, 0.7917981072555205, 0.7920792079207921, 0.7931034482758621, 0.7941176470588235, 0.7948717948717948, 0.7951807228915663, 0.7959183673469388, 0.7966101694915254, 0.7978723404255319, 0.8, 0.803921568627451, 0.8043478260869565, 0.8048780487804879, 0.8053435114503816, 0.8055555555555556, 0.8064516129032258, 0.8076923076923077, 0.8085106382978723, 0.8095238095238095, 0.810126582278481, 0.8103448275862069, 0.8108108108108109, 0.8113207547169812, 0.8125, 0.813953488372093, 0.8148148148148148, 0.8157894736842105, 0.8163265306122449, 0.8181818181818182, 0.8191881918819188, 0.8205128205128205, 0.8214285714285714, 0.821917808219178, 0.8222222222222222, 0.8225806451612904, 0.8235294117647058, 0.825, 0.8260869565217391, 0.8275862068965517, 0.8285714285714286, 0.8297872340425532, 0.8307692307692308, 0.8333333333333334, 0.8351648351648352, 0.835820895522388, 0.8360655737704918, 0.8363636363636363, 0.8367346938775511, 0.8372093023255814, 0.837696335078534, 0.8378378378378378, 0.8387096774193549, 0.8392857142857143, 0.8396624472573839, 0.84, 0.8421052631578947, 0.8431372549019608, 0.84375, 0.8441558441558441, 0.8444444444444444, 0.8461538461538461, 0.8478260869565217, 0.8484848484848485, 0.85, 0.8507462686567164, 0.8518518518518519, 0.8529411764705882, 0.8536585365853658, 0.8541666666666666, 0.8571428571428571, 0.8591549295774648, 0.859375, 0.86, 0.8611111111111112, 0.8620689655172413, 0.8625, 0.8636363636363636, 0.8648648648648649, 0.8653846153846154, 0.8666666666666667, 0.8679245283018868, 0.868421052631579, 0.8695652173913043, 0.8705882352941177, 0.8709677419354839, 0.8717948717948718, 0.875, 0.8769230769230769, 0.8771929824561403, 0.8775510204081632, 0.8780487804878049, 0.8787878787878788, 0.8793103448275862, 0.88, 0.8809523809523809, 0.8823529411764706, 0.8837209302325582, 0.8840579710144928, 0.8842105263157894, 0.8846153846153846, 0.8857142857142857, 0.8863636363636364, 0.8867924528301887, 0.8875, 0.8888888888888888, 0.8913043478260869, 0.8918918918918919, 0.8923076923076924, 0.8928571428571429, 0.8947368421052632, 0.896551724137931, 0.8970588235294118, 0.8974358974358975, 0.8979591836734694, 0.8983050847457628, 0.9, 0.9019607843137255, 0.9024390243902439, 0.9032258064516129, 0.9038461538461539, 0.9047619047619048, 0.9054054054054054, 0.9056603773584906, 0.90625, 0.9069767441860465, 0.9074074074074074, 0.9090909090909091, 0.9111111111111111, 0.9117647058823529, 0.9130434782608695, 0.9137931034482759, 0.9142857142857143, 0.9148936170212766, 0.9166666666666666, 0.9176470588235294, 0.9183673469387755, 0.918918918918919, 0.92, 0.9210526315789473, 0.9215686274509803, 0.9230769230769231, 0.9238095238095239, 0.9245283018867925, 0.925, 0.9259259259259259, 0.926829268292683, 0.9271523178807947, 0.9272727272727272, 0.9285714285714286, 0.9302325581395349, 0.9310344827586207, 0.9318181818181818, 0.9333333333333333, 0.9347826086956522, 0.9354838709677419, 0.9361702127659575, 0.9365079365079365, 0.9375, 0.9382716049382716, 0.9387755102040817, 0.9393939393939394, 0.94, 0.9411764705882353, 0.9428571428571428, 0.9444444444444444, 0.9459459459459459, 0.9464285714285714, 0.9473684210526315, 0.9487179487179487, 0.95, 0.9523809523809523, 0.9545454545454546, 0.954954954954955, 0.9552238805970149, 0.9555555555555556, 0.9565217391304348, 0.9574468085106383, 0.9583333333333334, 0.9591836734693877, 0.96, 0.9607843137254902, 0.9615384615384616, 0.9629629629629629, 0.9642857142857143, 0.9649122807017544, 0.9655172413793104, 0.9666666666666667, 0.967741935483871, 0.968, 0.9682539682539683, 0.968421052631579, 0.96875, 0.9690721649484536, 0.9692307692307692, 0.9696969696969697, 0.9705882352941176, 0.9714285714285714, 0.9722222222222222, 0.9726027397260274, 0.972972972972973, 0.9736842105263158, 0.9743589743589743, 0.975, 0.975609756097561, 0.9761904761904762, 0.9767441860465116, 0.9772727272727273, 0.9777777777777777, 0.9787234042553191, 0.9791666666666666, 0.9795918367346939, 0.9803921568627451, 0.9805825242718447, 0.9807692307692307, 0.9811320754716981, 0.9821428571428571, 0.9824561403508771, 0.9827586206896551, 0.9838709677419355, 0.9848484848484849, 0.9850746268656716, 0.9861111111111112, 0.9882352941176471, 1.0, 1.0095238095238095, 1.015625, 1.0163934426229508, 1.0169491525423728, 1.0172413793103448, 1.0175438596491229, 1.018181818181818, 1.0188679245283019, 1.0192307692307692, 1.02, 1.0208333333333333, 1.0212765957446808, 1.0222222222222221, 1.0227272727272727, 1.0232558139534884, 1.0238095238095237, 1.024390243902439, 1.025, 1.0256410256410255, 1.0263157894736843, 1.0277777777777777, 1.0285714285714285, 1.0294117647058822, 1.0303030303030303, 1.03125, 1.032258064516129, 1.0333333333333334, 1.0344827586206897, 1.0357142857142858, 1.037037037037037, 1.0377358490566038, 1.0384615384615385, 1.0392156862745099, 1.04, 1.0405405405405406, 1.0408163265306123, 1.0416666666666667, 1.0425531914893618, 1.0434782608695652, 1.0444444444444445, 1.0454545454545454, 1.0465116279069768, 1.0476190476190477, 1.048780487804878, 1.05, 1.0512820512820513, 1.0526315789473684, 1.0533333333333332, 1.054054054054054, 1.0555555555555556, 1.0566037735849056, 1.0571428571428572, 1.0588235294117647, 1.06, 1.0606060606060606, 1.0612244897959184, 1.0625, 1.0634920634920635, 1.0638297872340425, 1.064516129032258, 1.0649350649350648, 1.0655737704918034, 1.0666666666666667, 1.0689655172413792, 1.069767441860465, 1.0714285714285714, 1.0731707317073171, 1.0740740740740742, 1.0746268656716418, 1.075, 1.0757575757575757, 1.0769230769230769, 1.0789473684210527, 1.08, 1.0810810810810811, 1.0833333333333333, 1.0851063829787233, 1.0857142857142856, 1.0862068965517242, 1.0869565217391304, 1.088235294117647, 1.0888888888888888, 1.0909090909090908, 1.0925925925925926, 1.0933333333333333, 1.09375, 1.0952380952380953, 1.096774193548387, 1.0975609756097562, 1.0980392156862746, 1.1, 1.1020408163265305, 1.1025641025641026, 1.103448275862069, 1.105263157894737, 1.1063829787234043, 1.1067961165048543, 1.1071428571428572, 1.1081081081081081, 1.109375, 1.1097560975609757, 1.1111111111111112, 1.1142857142857143, 1.1153846153846154, 1.1162790697674418, 1.1176470588235294, 1.118421052631579, 1.119047619047619, 1.12, 1.1206896551724137, 1.121212121212121, 1.1219512195121952, 1.1232876712328768, 1.125, 1.127659574468085, 1.1282051282051282, 1.1290322580645162, 1.1304347826086956, 1.131578947368421, 1.1323529411764706, 1.1333333333333333, 1.1346153846153846, 1.135135135135135, 1.1363636363636365, 1.1372549019607843, 1.1379310344827587, 1.1388888888888888, 1.1395348837209303, 1.14, 1.1408450704225352, 1.1428571428571428, 1.146341463414634, 1.1470588235294117, 1.1477272727272727, 1.1481481481481481, 1.1486486486486487, 1.148936170212766, 1.15, 1.1505376344086022, 1.1515151515151516, 1.1538461538461537, 1.15625, 1.1578947368421053, 1.1587301587301588, 1.1594202898550725, 1.16, 1.1607142857142858, 1.1612903225806452, 1.162162162162162, 1.1666666666666667, 1.1686746987951808, 1.169811320754717, 1.170731707317073, 1.1714285714285715, 1.1724137931034482, 1.1730769230769231, 1.173913043478261, 1.175, 1.1764705882352942, 1.1772151898734178, 1.1777777777777778, 1.1785714285714286, 1.1818181818181819, 1.183673469387755, 1.1842105263157894, 1.1851851851851851, 1.1875, 1.1886792452830188, 1.1891891891891893, 1.1904761904761905, 1.1914893617021276, 1.1923076923076923, 1.1935483870967742, 1.1944444444444444, 1.1956521739130435, 1.2, 1.2025316455696202, 1.2045454545454546, 1.205128205128205, 1.2058823529411764, 1.206896551724138, 1.2083333333333333, 1.2093023255813953, 1.2096774193548387, 1.2105263157894737, 1.2115384615384615, 1.2142857142857142, 1.2153846153846153, 1.2156862745098038, 1.2173913043478262, 1.21875, 1.2203389830508475, 1.2222222222222223, 1.225, 1.2258064516129032, 1.2264150943396226, 1.2272727272727273, 1.2285714285714286, 1.2291666666666667, 1.2307692307692308, 1.2325581395348837, 1.2333333333333334, 1.2340425531914894, 1.2352941176470589, 1.2363636363636363, 1.236842105263158, 1.2380952380952381, 1.24, 1.2413793103448276, 1.2424242424242424, 1.2432432432432432, 1.2444444444444445, 1.2448979591836735, 1.25, 1.255813953488372, 1.2564102564102564, 1.2571428571428571, 1.2580645161290323, 1.2592592592592593, 1.2608695652173914, 1.2619047619047619, 1.263157894736842, 1.2647058823529411, 1.2653061224489797, 1.2666666666666666, 1.2692307692307692, 1.2702702702702702, 1.2708333333333333, 1.2727272727272727, 1.2745098039215685, 1.275, 1.2758620689655173, 1.2777777777777777, 1.2790697674418605, 1.28, 1.28125, 1.2820512820512822, 1.2833333333333334, 1.2857142857142858, 1.288888888888889, 1.2894736842105263, 1.2903225806451613, 1.2916666666666667, 1.293103448275862, 1.2941176470588236, 1.2954545454545454, 1.2962962962962963, 1.2972972972972974, 1.2982456140350878, 1.2985074626865671, 1.3, 1.301418439716312, 1.302325581395349, 1.303030303030303, 1.3043478260869565, 1.3076923076923077, 1.3103448275862069, 1.3125, 1.3157894736842106, 1.3170731707317074, 1.3181818181818181, 1.3191489361702127, 1.32, 1.3214285714285714, 1.3225806451612903, 1.323076923076923, 1.3235294117647058, 1.323943661971831, 1.325, 1.3255813953488371, 1.3278688524590163, 1.3333333333333333, 1.3372093023255813, 1.3396226415094339, 1.3409090909090908, 1.3421052631578947, 1.3448275862068966, 1.3461538461538463, 1.346938775510204, 1.3478260869565217, 1.3488372093023255, 1.35, 1.3513513513513513, 1.3529411764705883, 1.3548387096774193, 1.3555555555555556, 1.3571428571428572, 1.358974358974359, 1.36, 1.3611111111111112, 1.3636363636363635, 1.3666666666666667, 1.368421052631579, 1.3695652173913044, 1.3703703703703705, 1.375, 1.3783783783783783, 1.3793103448275863, 1.380952380952381, 1.3823529411764706, 1.3846153846153846, 1.3863636363636365, 1.3870967741935485, 1.3888888888888888, 1.3902439024390243, 1.391304347826087, 1.3928571428571428, 1.3968253968253967, 1.4, 1.4047619047619047, 1.4054054054054055, 1.4074074074074074, 1.4090909090909092, 1.411764705882353, 1.4166666666666667, 1.4210526315789473, 1.4230769230769231, 1.4233983286908078, 1.4242424242424243, 1.425, 1.4285714285714286, 1.4328358208955223, 1.434782608695652, 1.435897435897436, 1.4375, 1.44, 1.4411764705882353, 1.4444444444444444, 1.4473684210526316, 1.4482758620689655, 1.45, 1.4516129032258065, 1.4545454545454546, 1.457142857142857, 1.4583333333333333, 1.4594594594594594, 1.4615384615384615, 1.4642857142857142, 1.4651162790697674, 1.4666666666666666, 1.46875, 1.4705882352941178, 1.4722222222222223, 1.4727272727272727, 1.4736842105263157, 1.4761904761904763, 1.4782608695652173, 1.48, 1.4814814814814814, 1.4821428571428572, 1.4827586206896552, 1.4838709677419355, 1.4848484848484849, 1.4878048780487805, 1.5, 1.512396694214876, 1.5135135135135136, 1.5151515151515151, 1.5161290322580645, 1.5172413793103448, 1.5185185185185186, 1.52, 1.5217391304347827, 1.5238095238095237, 1.5263157894736843, 1.5272727272727273, 1.5294117647058822, 1.5303030303030303, 1.53125, 1.532846715328467, 1.5333333333333334, 1.5365853658536586, 1.5384615384615385, 1.5405405405405406, 1.540983606557377, 1.5416666666666667, 1.5454545454545454, 1.546875, 1.5483870967741935, 1.55, 1.5517241379310345, 1.5555555555555556, 1.558139534883721, 1.56, 1.5625, 1.565217391304348, 1.5666666666666667, 1.5714285714285714, 1.5769230769230769, 1.5789473684210527, 1.5806451612903225, 1.5833333333333333, 1.588235294117647, 1.5909090909090908, 1.59375, 1.6, 1.606060606060606, 1.608695652173913, 1.6111111111111112, 1.6153846153846154, 1.619047619047619, 1.6206896551724137, 1.625, 1.6296296296296295, 1.631578947368421, 1.6333333333333333, 1.6363636363636365, 1.64, 1.6428571428571428, 1.6470588235294117, 1.6486486486486487, 1.65, 1.6521739130434783, 1.65625, 1.6578947368421053, 1.661764705882353, 1.6666666666666667, 1.6774193548387097, 1.68, 1.6818181818181819, 1.6842105263157894, 1.6857142857142857, 1.6875, 1.6896551724137931, 1.6923076923076923, 1.6938775510204083, 1.6956521739130435, 1.7, 1.7037037037037037, 1.7058823529411764, 1.7083333333333333, 1.7096774193548387, 1.7142857142857142, 1.72, 1.7222222222222223, 1.7265625, 1.7272727272727273, 1.728395061728395, 1.7317073170731707, 1.7333333333333334, 1.736842105263158, 1.7407407407407407, 1.7419354838709677, 1.75, 1.7575757575757576, 1.76, 1.7619047619047619, 1.7647058823529411, 1.7692307692307692, 1.775, 1.7777777777777777, 1.78125, 1.7826086956521738, 1.7857142857142858, 1.7894736842105263, 1.8, 1.8032786885245902, 1.8048780487804879, 1.8076923076923077, 1.8095238095238095, 1.8125, 1.8181818181818181, 1.8205128205128205, 1.8235294117647058, 1.826086956521739, 1.8275862068965518, 1.8333333333333333, 1.84, 1.8421052631578947, 1.8461538461538463, 1.8484848484848484, 1.85, 1.8571428571428572, 1.8666666666666667, 1.875, 1.878787878787879, 1.88, 1.8888888888888888, 1.894736842105263, 1.9, 1.9024390243902438, 1.9090909090909092, 1.911764705882353, 1.9130434782608696, 1.9166666666666667, 1.9230769230769231, 1.9285714285714286, 1.9333333333333333, 1.9375, 1.9411764705882353, 1.9444444444444444, 1.945945945945946, 1.9545454545454546, 1.959016393442623, 1.9615384615384615, 1.9666666666666666, 2.0, 2.019230769230769, 2.033333333333333, 2.0384615384615383, 2.04, 2.0434782608695654, 2.0454545454545454, 2.05, 2.0555555555555554, 2.0625, 2.066666666666667, 2.0714285714285716, 2.076923076923077, 2.0833333333333335, 2.090909090909091, 2.0952380952380953, 2.1, 2.103448275862069, 2.1052631578947367, 2.108108108108108, 2.111111111111111, 2.12, 2.125, 2.135135135135135, 2.1363636363636362, 2.142857142857143, 2.1538461538461537, 2.1578947368421053, 2.161290322580645, 2.1666666666666665, 2.1818181818181817, 2.185185185185185, 2.2, 2.2083333333333335, 2.2222222222222223, 2.230769230769231, 2.235294117647059, 2.238095238095238, 2.25, 2.263157894736842, 2.272727272727273, 2.2777777777777777, 2.2857142857142856, 2.2941176470588234, 2.3, 2.3076923076923075, 2.3333333333333335, 2.3529411764705883, 2.3636363636363638, 2.375, 2.4, 2.409090909090909, 2.411764705882353, 2.4166666666666665, 2.4285714285714284, 2.4705882352941178, 2.5, 2.5238095238095237, 2.5294117647058822, 2.533333333333333, 2.5454545454545454, 2.5555555555555554, 2.5714285714285716, 2.588235294117647, 2.6, 2.619047619047619, 2.625, 2.6363636363636362, 2.642857142857143, 2.6666666666666665, 2.6875, 2.7058823529411766, 2.7142857142857144, 2.7222222222222223, 2.7333333333333334, 2.7419354838709675, 2.75, 2.764705882352941, 2.7777777777777777, 2.7857142857142856, 2.791044776119403, 2.8, 2.8181818181818183, 2.8333333333333335, 2.8461538461538463, 2.857142857142857, 2.8636363636363638, 2.8666666666666667, 2.9, 2.909090909090909, 2.923076923076923, 2.925925925925926, 2.9473684210526314, 3.0, 3.054054054054054, 3.1, 3.125, 3.1666666666666665, 3.2, 3.25, 3.272727272727273, 3.3333333333333335, 3.375, 3.4, 3.4285714285714284, 3.4545454545454546, 3.4705882352941178, 3.5, 3.6, 3.6666666666666665, 3.7333333333333334, 3.75, 3.8, 3.8181818181818183, 3.88, 3.9166666666666665, 3.9285714285714284, 4.0, 4.111111111111111, 4.2, 4.25, 4.266666666666667, 4.333333333333333, 4.444444444444445, 4.5, 4.666666666666667, 4.75, 4.875, 5.0, 5.076923076923077, 5.214285714285714, 5.25, 5.428571428571429, 6.0]\n",
      "Mean Width: 19.68087705761317\n",
      "Mean Height: 19.810185185185187\n",
      "Width Std Dev: 16.490880836813414\n",
      "Height Std Dev: 17.31675011466088\n"
     ]
    }
   ],
   "source": [
    "# Return a dictionary of the main statistics\n",
    "bbox_stats = train_dataset.analyze_bounding_boxes()\n",
    "\n",
    "# Get mean for width and height\n",
    "mean_width = bbox_stats['mean_width']\n",
    "mean_height = bbox_stats['mean_height']\n",
    "\n",
    "# Get standard deviation for width and height\n",
    "std_width = bbox_stats['std_width']\n",
    "std_height = bbox_stats['std_height']\n",
    "\n",
    "# Print statistics\n",
    "print(\"Aspect Ratios:\", sorted(set(bbox_stats['aspect_ratios'])))\n",
    "print(\"Mean Width:\", bbox_stats['mean_width'])\n",
    "print(\"Mean Height:\", bbox_stats['mean_height'])\n",
    "print(\"Width Std Dev:\", bbox_stats['std_width'])\n",
    "print(\"Height Std Dev:\", bbox_stats['std_height'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of anchors is: 648\n"
     ]
    }
   ],
   "source": [
    "# Based on the statistics above decide on the values of the statistics, the scales and the aspect ratios  \n",
    "feature_map_shapes = [(18, 18)]\n",
    "scales = [32]\n",
    "aspect_ratios = [0.5, 1.0]\n",
    "\n",
    "anchors = torch.tensor(Anchors.generate_anchors(feature_map_shapes, scales, aspect_ratios), dtype=torch.float32)\n",
    "\n",
    "print(\"The number of anchors is: {}\".format(anchors.size(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the ExtendedMask2Former model with all the parameters needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n"
     ]
    }
   ],
   "source": [
    "# Initialise the ExtendedMask2Former model and load it to device\n",
    "model = ExtendedMask2Former(num_classes=number_classes, num_anchors=anchors.size(0), device=device).to(device)\n",
    "anchors = anchors.to(device)\n",
    "\n",
    "\n",
    "# Hyperparameters selection\n",
    "num_epochs = 1\n",
    "learning_rate = 0.001\n",
    "batch_size = 1\n",
    "\n",
    "# Define the optimizer and the scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(columns=['epoch', 'train_loss', 'val_loss', 'precision', 'recall', 'AP', 'mAP'])\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train(model, train_loader, device, anchors, optimizer, number_classes)    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
