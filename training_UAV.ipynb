{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Extended Mask2Former UAV-SOD Drone Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os, json\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from src.data_set_up import SOD_Data\n",
    "from models.extended_mask2former_model import ExtendedMask2Former\n",
    "from models.efpn_backbone.anchors import Anchors\n",
    "\n",
    "\n",
    "# Import data paths\n",
    "map_path = \"src/code_map.json\"\n",
    "data_info_path = \"src/data_info/uav_data_preprocessing.json\"\n",
    "base_dir = \"data/uav_sod_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up GPU growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device we are going to load the model and the data\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up basic static data\n",
    "\n",
    "- Get the number of classes\n",
    "- Get the mean and standard deviation \n",
    "- Create the data paths for the [train, test, validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classes of the UAV-SOD Drone dataset\n",
    "map = open(map_path)\n",
    "data = json.load(map)\n",
    "classes = data[\"UAV_SOD_DRONE\"][\"CATEGORY_ID_TO_NAME\"]\n",
    "map.close() \n",
    "\n",
    "# The number of classes plus the background\n",
    "number_classes = len(classes) + 1\n",
    "\n",
    "\n",
    "# Load the mean and standard deviation for the train data\n",
    "map = open(data_info_path)\n",
    "data = json.load(map)\n",
    "mean = data[\"uav_data\"][\"mean\"]\n",
    "standard_deviation = data[\"uav_data\"][\"std\"]\n",
    "map.close() \n",
    "\n",
    "\n",
    "# Define train, test and validation path\n",
    "train_path = os.path.join(base_dir, \"train\")\n",
    "test_path = os.path.join(base_dir, \"test\")\n",
    "validation_path = os.path.join(base_dir, \"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset - Dataloader\n",
    "- Collate function\n",
    "- Data transformations\n",
    "- DataLoader and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transform function\n",
    "data_transform = {\n",
    "    \"train\": transforms.Compose([\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=standard_deviation)]),\n",
    "\n",
    "    \"test\": transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=standard_deviation)]), \n",
    "            \n",
    "    \"validation\": transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=standard_deviation)]) \n",
    "}\n",
    "\n",
    "\n",
    "# Dataset and DataLoader\n",
    "train_dataset      = SOD_Data(train_path +\"/images\", train_path + \"/annotations\", data_transform[\"train\"])\n",
    "test_dataset       = SOD_Data(test_path + \"/images\", test_path  + \"/annotations\", data_transform[\"test\"])\n",
    "validation_dataset = SOD_Data(validation_path + \"/images\", validation_path + \"/annotations\", data_transform[\"validation\"])\n",
    "\n",
    "train_loader      = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "test_loader       = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=1, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images = torch.stack(images).to(device)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            outputs = model(images)\n",
    "            loss = model.compute_loss(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "    return val_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming feature_map_shapes, scales, and aspect_ratios are defined\n",
    "feature_map_shapes = [(8,8), (16,16), (38, 38)]\n",
    "scales = [32]\n",
    "aspect_ratios = [0.5, 1, 2]\n",
    "\n",
    "anchors = torch.tensor(Anchors.generate_anchors(feature_map_shapes, scales, aspect_ratios), dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExtendedMask2Former(num_classes=number_classes).to(device)\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 1\n",
    "learning_rate = 0.001\n",
    "batch_size = 2\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, device, anchors):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, targets in train_loader:\n",
    "        images = torch.stack(images).to(device)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = model.compute_loss(outputs, targets, anchors)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, device, anchors)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss:.4f}')\n",
    "    \n",
    "    # validation_loss = validate(model, validation_loader, device, anchors)\n",
    "    # print(f'Validation Loss: {validation_loss:.4f}')\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "# # Test the model\n",
    "# test_loss = test(model, test_loader, device, anchors)\n",
    "# print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def validate(model, val_loader, device, anchors):\n",
    "#     model.eval()\n",
    "#     val_loss = 0\n",
    "#     with torch.no_grad():\n",
    "#         for images, targets in val_loader:\n",
    "#             images = torch.stack(images).to(device)\n",
    "#             targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "#             outputs, _ = model(images)\n",
    "#             loss = model.compute_loss(outputs, targets, anchors)\n",
    "#             val_loss += loss.item()\n",
    "#     return val_loss / len(val_loader)\n",
    "\n",
    "# def test(model, test_loader, device, anchors):\n",
    "#     model.eval()\n",
    "#     test_loss = 0\n",
    "#     with torch.no_grad():\n",
    "#         for images, targets in test_loader:\n",
    "#             images = torch.stack(images).to(device)\n",
    "#             targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "#             outputs, _ = model(images)\n",
    "#             loss = model.compute_loss(outputs, targets, anchors)\n",
    "#             test_loss += loss.item()\n",
    "#     return test_loss / len(test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
